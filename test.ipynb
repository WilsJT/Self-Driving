{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c5cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, learning_curve, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16ea9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>90</th>\n",
       "      <th>120</th>\n",
       "      <th>135</th>\n",
       "      <th>150</th>\n",
       "      <th>speed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.442252</td>\n",
       "      <td>-0.169266</td>\n",
       "      <td>-0.728503</td>\n",
       "      <td>-1.127933</td>\n",
       "      <td>-0.801854</td>\n",
       "      <td>-0.169266</td>\n",
       "      <td>1.554570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.480616</td>\n",
       "      <td>-0.167738</td>\n",
       "      <td>-0.747360</td>\n",
       "      <td>-1.173858</td>\n",
       "      <td>-0.747360</td>\n",
       "      <td>-0.148480</td>\n",
       "      <td>1.504180</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>2050</td>\n",
       "      <td>1.395053</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>-0.808261</td>\n",
       "      <td>-1.203214</td>\n",
       "      <td>-0.808261</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>1.515073</td>\n",
       "      <td>358</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29051</th>\n",
       "      <td>2051</td>\n",
       "      <td>1.463368</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>-0.801349</td>\n",
       "      <td>-1.193423</td>\n",
       "      <td>-0.801349</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>1.463368</td>\n",
       "      <td>367</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29052</th>\n",
       "      <td>2052</td>\n",
       "      <td>1.286868</td>\n",
       "      <td>-0.089803</td>\n",
       "      <td>-0.800793</td>\n",
       "      <td>-1.205045</td>\n",
       "      <td>-0.800793</td>\n",
       "      <td>-0.003265</td>\n",
       "      <td>1.612830</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29053</th>\n",
       "      <td>2053</td>\n",
       "      <td>1.367514</td>\n",
       "      <td>-0.096175</td>\n",
       "      <td>-0.805693</td>\n",
       "      <td>-1.215923</td>\n",
       "      <td>-0.757765</td>\n",
       "      <td>-0.046524</td>\n",
       "      <td>1.554566</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29054</th>\n",
       "      <td>2054</td>\n",
       "      <td>2.206032</td>\n",
       "      <td>0.312789</td>\n",
       "      <td>-0.536776</td>\n",
       "      <td>-1.045008</td>\n",
       "      <td>-0.536776</td>\n",
       "      <td>0.178806</td>\n",
       "      <td>-0.579067</td>\n",
       "      <td>295</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29055 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        30        45        60        90       120       135  \\\n",
       "0               0  1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357   \n",
       "1               1  1.442252 -0.169266 -0.728503 -1.127933 -0.801854 -0.169266   \n",
       "2               2  1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357   \n",
       "3               3  1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357   \n",
       "4               4  1.480616 -0.167738 -0.747360 -1.173858 -0.747360 -0.148480   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "29050        2050  1.395053 -0.045195 -0.808261 -1.203214 -0.808261 -0.045195   \n",
       "29051        2051  1.463368 -0.065307 -0.801349 -1.193423 -0.801349 -0.065307   \n",
       "29052        2052  1.286868 -0.089803 -0.800793 -1.205045 -0.800793 -0.003265   \n",
       "29053        2053  1.367514 -0.096175 -0.805693 -1.215923 -0.757765 -0.046524   \n",
       "29054        2054  2.206032  0.312789 -0.536776 -1.045008 -0.536776  0.178806   \n",
       "\n",
       "            150  speed  label  \n",
       "0      1.491395      0      0  \n",
       "1      1.554570      0      0  \n",
       "2      1.491395      0      0  \n",
       "3      1.491395      0      0  \n",
       "4      1.504180     23      1  \n",
       "...         ...    ...    ...  \n",
       "29050  1.515073    358      4  \n",
       "29051  1.463368    367      4  \n",
       "29052  1.612830    323      4  \n",
       "29053  1.554566    323      4  \n",
       "29054 -0.579067    295      4  \n",
       "\n",
       "[29055 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899cc27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>90</th>\n",
       "      <th>120</th>\n",
       "      <th>135</th>\n",
       "      <th>150</th>\n",
       "      <th>speed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.442252</td>\n",
       "      <td>-0.169266</td>\n",
       "      <td>-0.728503</td>\n",
       "      <td>-1.127933</td>\n",
       "      <td>-0.801854</td>\n",
       "      <td>-0.169266</td>\n",
       "      <td>1.554570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.480616</td>\n",
       "      <td>-0.167738</td>\n",
       "      <td>-0.747360</td>\n",
       "      <td>-1.173858</td>\n",
       "      <td>-0.747360</td>\n",
       "      <td>-0.148480</td>\n",
       "      <td>1.504180</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>1.395053</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>-0.808261</td>\n",
       "      <td>-1.203214</td>\n",
       "      <td>-0.808261</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>1.515073</td>\n",
       "      <td>358</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29051</th>\n",
       "      <td>1.463368</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>-0.801349</td>\n",
       "      <td>-1.193423</td>\n",
       "      <td>-0.801349</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>1.463368</td>\n",
       "      <td>367</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29052</th>\n",
       "      <td>1.286868</td>\n",
       "      <td>-0.089803</td>\n",
       "      <td>-0.800793</td>\n",
       "      <td>-1.205045</td>\n",
       "      <td>-0.800793</td>\n",
       "      <td>-0.003265</td>\n",
       "      <td>1.612830</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29053</th>\n",
       "      <td>1.367514</td>\n",
       "      <td>-0.096175</td>\n",
       "      <td>-0.805693</td>\n",
       "      <td>-1.215923</td>\n",
       "      <td>-0.757765</td>\n",
       "      <td>-0.046524</td>\n",
       "      <td>1.554566</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29054</th>\n",
       "      <td>2.206032</td>\n",
       "      <td>0.312789</td>\n",
       "      <td>-0.536776</td>\n",
       "      <td>-1.045008</td>\n",
       "      <td>-0.536776</td>\n",
       "      <td>0.178806</td>\n",
       "      <td>-0.579067</td>\n",
       "      <td>295</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29055 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             30        45        60        90       120       135       150  \\\n",
       "0      1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357  1.491395   \n",
       "1      1.442252 -0.169266 -0.728503 -1.127933 -0.801854 -0.169266  1.554570   \n",
       "2      1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357  1.491395   \n",
       "3      1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357  1.491395   \n",
       "4      1.480616 -0.167738 -0.747360 -1.173858 -0.747360 -0.148480  1.504180   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29050  1.395053 -0.045195 -0.808261 -1.203214 -0.808261 -0.045195  1.515073   \n",
       "29051  1.463368 -0.065307 -0.801349 -1.193423 -0.801349 -0.065307  1.463368   \n",
       "29052  1.286868 -0.089803 -0.800793 -1.205045 -0.800793 -0.003265  1.612830   \n",
       "29053  1.367514 -0.096175 -0.805693 -1.215923 -0.757765 -0.046524  1.554566   \n",
       "29054  2.206032  0.312789 -0.536776 -1.045008 -0.536776  0.178806 -0.579067   \n",
       "\n",
       "       speed  label  \n",
       "0          0      0  \n",
       "1          0      0  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4         23      1  \n",
       "...      ...    ...  \n",
       "29050    358      4  \n",
       "29051    367      4  \n",
       "29052    323      4  \n",
       "29053    323      4  \n",
       "29054    295      4  \n",
       "\n",
       "[29055 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "# df = df[df.label.isin([3, 4, 5]) == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b0eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df[\"label\"])\n",
    "data = np.array(df[[\"30\", \"45\", \"60\", \"90\", \"120\", \"135\", \"150\", \"speed\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f38d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1c6dc",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ecfec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38711023047241633"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33)\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "KNN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "506f9b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(KNN, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b96e1",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43f929ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6115055963413166"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "822028b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 5, 6, 7], dtype=int64),\n",
       " array([2501, 1459,   62,   12,   35,  105, 1298], dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rf.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a65b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(rf, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8e06df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 405 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "405 fits failed out of a total of 1215.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "405 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 317, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.61361214 0.6154125  0.61829349 0.56400822 0.56211749 0.56265747\n",
      " 0.56796931 0.56706902 0.56778903 0.57580136 0.57796194 0.57859225\n",
      " 0.59488683 0.59182605 0.59551712 0.60947079 0.61190154 0.61559256\n",
      " 0.56346804 0.56283794 0.56346809 0.56256777 0.56490824 0.56607873\n",
      " 0.57544143 0.57616174 0.57634173 0.5937167  0.59497711 0.59380689\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.57886218 0.57976225 0.58012266\n",
      " 0.56238749 0.56184727 0.56103685 0.56706892 0.56814929 0.56823916\n",
      " 0.57427109 0.57562137 0.57517124 0.57832169 0.5808427  0.5796725\n",
      " 0.5803026  0.57922227 0.58111302 0.56445845 0.56193763 0.56184768\n",
      " 0.56436841 0.56769926 0.56535862 0.57544124 0.57562169 0.576522\n",
      " 0.57931265 0.58057302 0.57922237        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61226137 0.61397187 0.61676271 0.56355794 0.56166687 0.56472835\n",
      " 0.56481822 0.56769916 0.56742911 0.57679159 0.57733177 0.57976259\n",
      " 0.5924562  0.5920961  0.59488695 0.61514243 0.61712271 0.617663\n",
      " 0.56085747 0.56373785 0.56202764 0.56562867 0.56715918 0.56742911\n",
      " 0.57688171 0.5755313  0.57688185 0.59479671 0.59317663 0.59497721\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.61361182 0.61631255 0.61577262\n",
      " 0.56400873 0.56238735 0.56409816 0.5675192  0.56904937 0.56877929\n",
      " 0.57589166 0.57832247 0.57679181 0.59182588 0.59182603 0.59182617\n",
      " 0.60974067 0.61433208 0.61739298 0.56427822 0.56643904 0.56661903\n",
      " 0.57202064 0.57256079 0.57238066 0.57598188 0.57949281 0.57877267\n",
      " 0.59407668 0.58813513 0.59002549        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57940236 0.58102266 0.58102286 0.55887627 0.56355806 0.56463814\n",
      " 0.56976975 0.56715879 0.56832955 0.57571131 0.57661175 0.57715193\n",
      " 0.57895205 0.58237324 0.57949215 0.58399398 0.58426401 0.58246359\n",
      " 0.5657189  0.56553882 0.56562872 0.5697698  0.56796955 0.57202059\n",
      " 0.57706206 0.57805266 0.5779623  0.58363389 0.58183355 0.58111307\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.61496239 0.6184733  0.61721304\n",
      " 0.56211715 0.56130731 0.56499838 0.56895976 0.5675191  0.56895935\n",
      " 0.57670179 0.58012291 0.5796728  0.59056564 0.59200601 0.5904758\n",
      " 0.61541228 0.62027396 0.62009373 0.56346838 0.56670863 0.5657189\n",
      " 0.57040001 0.57076045 0.57130026 0.57697199 0.58030306 0.57814255\n",
      " 0.59092581 0.59218602 0.59029576        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61748299 0.61514218 0.61505212 0.56121688 0.56472823 0.56319748\n",
      " 0.56760902 0.56949948 0.56850917 0.57544163 0.57904241 0.5794026\n",
      " 0.59056552 0.59101602 0.59065556 0.61028112 0.61586278 0.61496225\n",
      " 0.56769923 0.56814968 0.5677893  0.56958991 0.56995012 0.57076028\n",
      " 0.57742215 0.57931263 0.57868278 0.59416679 0.5913757  0.59299669\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.57778178 0.58192303 0.58210311\n",
      " 0.56283763 0.56049723 0.56373773 0.56652869 0.56886924 0.56796882\n",
      " 0.57796208 0.57634141 0.57688178 0.57985271 0.57904202 0.58201275\n",
      " 0.58309364 0.5858848  0.58498429 0.56913987 0.566979   0.56769928\n",
      " 0.56832972 0.56986018 0.57121036 0.57706203 0.57706189 0.57967289\n",
      " 0.58246342 0.5830036  0.58444424        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61946354 0.61820311 0.62144416 0.56175733 0.56355832 0.56346787\n",
      " 0.56751891 0.5676089  0.56868944 0.57742176 0.57733204 0.57877216\n",
      " 0.59002559 0.59218619 0.59317648 0.61568231 0.61847328 0.61946366\n",
      " 0.56580878 0.56670907 0.5659891  0.5686894  0.56995002 0.57265064\n",
      " 0.57733191 0.57922283 0.580213   0.59245629 0.59020562 0.59227633\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.72794477, 1.44751048, 2.19249137, 0.28718146, 0.57310406,\n",
      "       0.84656199, 0.30198185, 0.5977265 , 0.89306974, 0.33562771,\n",
      "       0.66495848, 1.0157148 , 0.37785912, 0.7583789 , 1.15031258,\n",
      "       0.96818209, 2.06176678, 3.1631705 , 0.42598764, 0.84141421,\n",
      "       1.21516792, 0.42808986, 0.8537244 , 1.27877649, 0.49467397,\n",
      "       1.0037291 , 1.46023075, 0.55903109, 1.10826222, 1.69062392,\n",
      "       0.01826914, 0.03292394, 0.04754011, 0.01895078, 0.03324517,\n",
      "       0.04658294, 0.01926796, 0.03424199, 0.04942576, 0.01860404,\n",
      "       0.03242477, 0.05485733, 0.01828432, 0.0315938 , 0.04587777,\n",
      "       0.35339872, 0.6950895 , 1.05254261, 0.30447006, 0.63392925,\n",
      "       0.89273151, 0.3111736 , 0.61315608, 0.92641234, 0.33846807,\n",
      "       0.66922998, 1.02192426, 0.34200454, 0.68355966, 1.02912935,\n",
      "       0.46845007, 0.92132823, 1.41431626, 0.39879529, 0.79932984,\n",
      "       1.20056454, 0.41629918, 0.85407925, 1.25005293, 0.4518319 ,\n",
      "       0.94217912, 1.38925354, 0.46906447, 0.94037636, 1.39727847,\n",
      "       0.01760832, 0.03160961, 0.04489032, 0.01796492, 0.03229904,\n",
      "       0.04670294, 0.01795594, 0.03357689, 0.04648018, 0.0186162 ,\n",
      "       0.03491211, 0.04853702, 0.01894848, 0.03192854, 0.04686912,\n",
      "       0.56480368, 1.12510022, 1.79416776, 0.29950778, 0.60514649,\n",
      "       0.90746609, 0.31553102, 0.64555923, 0.98636015, 0.36622802,\n",
      "       0.8070058 , 1.07257978, 0.40688467, 0.82167665, 1.24375486,\n",
      "       0.77514068, 1.5625128 , 2.3678894 , 0.41021776, 0.83698734,\n",
      "       1.27002549, 0.43030643, 0.87514361, 1.31093534, 0.49234025,\n",
      "       1.05059663, 1.45405006, 0.57671046, 1.10882282, 1.72095998,\n",
      "       0.01696046, 0.03176999, 0.04543193, 0.01762843, 0.03263474,\n",
      "       0.04486728, 0.01761977, 0.03290153, 0.0455567 , 0.01860054,\n",
      "       0.03297742, 0.04588517, 0.01860579, 0.03257879, 0.04538663,\n",
      "       1.70106236, 3.3545049 , 5.09618274, 0.74207767, 1.44553534,\n",
      "       2.16858149, 0.79372613, 1.5427316 , 2.32107782, 0.88644687,\n",
      "       1.72995615, 2.59912411, 1.05216487, 2.06266618, 3.14107482,\n",
      "       2.35789251, 4.75853173, 7.28106777, 1.01483075, 2.0165019 ,\n",
      "       3.08127642, 1.10014121, 2.19086997, 3.2421658 , 1.27238075,\n",
      "       2.48852738, 3.72007767, 1.45547907, 2.9607563 , 4.40757179,\n",
      "       0.01727454, 0.03257147, 0.04756331, 0.01793742, 0.03358873,\n",
      "       0.04622165, 0.01794934, 0.03158514, 0.04520575, 0.01828869,\n",
      "       0.03430311, 0.04621784, 0.01793361, 0.03189882, 0.04606024,\n",
      "       0.83143886, 1.67759116, 2.54789877, 0.70524804, 1.43455593,\n",
      "       2.14401436, 0.74984392, 1.49143116, 2.24658879, 0.80292741,\n",
      "       1.6255482 , 2.46010637, 0.8476158 , 1.67249314, 2.51781329,\n",
      "       1.20069496, 2.4063189 , 3.6304419 , 0.99851791, 2.02950454,\n",
      "       3.00951687, 1.09433993, 2.11174011, 3.27005561, 1.15790033,\n",
      "       2.29515632, 3.44705335, 1.19028211, 2.44118913, 3.62069305,\n",
      "       0.01760666, 0.03223459, 0.04686276, 0.01962598, 0.03426552,\n",
      "       0.04690011, 0.01831102, 0.03289938, 0.04523706, 0.01829839,\n",
      "       0.03323301, 0.04621339, 0.01861644, 0.03224826, 0.04621037,\n",
      "       1.37477477, 2.8133556 , 4.18113979, 0.716314  , 1.4308424 ,\n",
      "       2.14354014, 0.78875597, 1.51695959, 2.31726615, 0.89846889,\n",
      "       1.74284569, 3.00432118, 1.13544424, 2.06207712, 3.14248951,\n",
      "       1.99944496, 4.09609254, 6.07132769, 1.00622153, 2.04132716,\n",
      "       3.08048614, 1.10716446, 2.17887592, 3.28909302, 1.25032926,\n",
      "       2.50967852, 3.72272229, 1.48105319, 2.93265128, 4.45248135,\n",
      "       0.01793917, 0.03292815, 0.04654185, 0.02026947, 0.03226995,\n",
      "       0.0468843 , 0.01893544, 0.03356457, 0.04751563, 0.01797597,\n",
      "       0.04785975, 0.0538528 , 0.01995858, 0.03475046, 0.0478158 ,\n",
      "       1.70638585, 3.4012026 , 5.12968294, 0.71445084, 1.43262506,\n",
      "       2.20878681, 0.838667  , 1.49267785, 2.30009214, 0.89663307,\n",
      "       1.74456231, 2.65039555, 1.01985089, 2.04374965, 3.09568008,\n",
      "       2.37929002, 4.78703181, 7.15136298, 1.01309411, 2.04483708,\n",
      "       3.08126648, 1.10175753, 2.22152026, 3.26954452, 1.26791453,\n",
      "       2.51016013, 3.7409819 , 1.48762194, 2.96705961, 4.37736845,\n",
      "       0.01795371, 0.04952176, 0.05187591, 0.01992114, 0.03524017,\n",
      "       0.0498662 , 0.0188059 , 0.03245099, 0.04619892, 0.01894935,\n",
      "       0.03260279, 0.04869668, 0.01929275, 0.03445641, 0.0492324 ,\n",
      "       0.83817172, 1.67585182, 2.5445799 , 0.70997421, 1.41541823,\n",
      "       2.14835111, 0.75694251, 1.50804965, 2.25954509, 0.93274196,\n",
      "       1.60487843, 2.42882538, 0.87272811, 1.6883173 , 2.53122473,\n",
      "       1.19980899, 2.38604379, 3.61557007, 1.00098697, 2.05273763,\n",
      "       3.01703095, 1.09585333, 2.15555469, 3.20034003, 1.15860168,\n",
      "       2.29484256, 3.49582982, 1.1909682 , 2.39394355, 3.61559073,\n",
      "       0.01767707, 0.03192814, 0.04585449, 0.01829394, 0.03322395,\n",
      "       0.04788431, 0.01797795, 0.0345784 , 0.04688183, 0.01828257,\n",
      "       0.03291233, 0.04920745, 0.01960564, 0.03354732, 0.04652301,\n",
      "       1.40350223, 2.84308616, 4.17999307, 0.70979253, 1.43261305,\n",
      "       2.14379025, 0.78895195, 1.54211617, 2.29762634, 0.90502238,\n",
      "       1.74576068, 2.64552251, 1.02035085, 2.07091427, 3.0751605 ,\n",
      "       1.99580741, 4.03030578, 6.02801069, 1.02996699, 2.04381235,\n",
      "       3.04329658, 1.10202352, 2.18977753, 3.31353903, 1.24821846,\n",
      "       2.50862908, 3.70433187, 1.48105955, 2.91913978, 4.41897178,\n",
      "       0.01893751, 0.03163354, 0.04589399, 0.01786733, 0.03158379,\n",
      "       0.04720561, 0.01830037, 0.03309433, 0.04722627, 0.01861628,\n",
      "       0.0322597 , 0.04688629, 0.01795141, 0.0319225 , 0.046863  ]), 'std_fit_time': array([6.08839522e-03, 1.18410813e-02, 4.36317688e-02, 4.13909184e-03,\n",
      "       4.08450068e-03, 3.28768468e-03, 3.73171246e-03, 4.54934640e-03,\n",
      "       1.00383297e-02, 4.31601920e-03, 1.63577458e-03, 2.45792674e-02,\n",
      "       2.26269774e-03, 9.44229711e-03, 1.08047822e-02, 2.53106889e-03,\n",
      "       6.60647726e-02, 3.56127700e-02, 1.61622879e-02, 2.67831137e-02,\n",
      "       3.38338018e-03, 1.06108275e-02, 1.29198002e-02, 4.90667237e-03,\n",
      "       2.05810560e-02, 3.61108677e-02, 2.15939974e-02, 5.43302798e-03,\n",
      "       3.02646493e-03, 2.97004863e-02, 4.53283500e-04, 1.69495321e-05,\n",
      "       4.69628294e-04, 5.61957980e-07, 4.43835523e-04, 5.05753528e-04,\n",
      "       9.33204985e-04, 4.70302644e-04, 1.05205515e-03, 4.63342735e-04,\n",
      "       3.90320188e-04, 1.00265990e-02, 9.40212023e-04, 4.78679713e-04,\n",
      "       1.47400196e-06, 4.64653421e-03, 4.12376309e-03, 3.64792477e-03,\n",
      "       1.24711353e-02, 4.54106393e-02, 4.07465609e-03, 4.35792778e-03,\n",
      "       2.76121054e-03, 3.31964205e-03, 1.04340327e-02, 9.74579840e-03,\n",
      "       3.51040819e-02, 1.46956545e-03, 2.06785453e-03, 4.83085110e-03,\n",
      "       8.49798678e-03, 9.81447715e-03, 3.17092140e-02, 1.33927428e-03,\n",
      "       6.03934615e-03, 5.62151145e-03, 1.67663863e-03, 3.53811279e-02,\n",
      "       1.49724081e-02, 4.79989198e-03, 5.57842887e-02, 1.11949584e-01,\n",
      "       2.65142565e-02, 2.15663506e-02, 4.99239976e-03, 4.62180112e-04,\n",
      "       8.96188881e-04, 8.16046959e-04, 3.64530148e-05, 8.39872844e-04,\n",
      "       6.77066574e-04, 3.13538310e-05, 4.70134086e-04, 1.01409892e-03,\n",
      "       4.69853561e-04, 1.77713193e-03, 1.24515350e-03, 8.16340395e-04,\n",
      "       7.96848989e-04, 7.84476167e-04, 2.84715155e-03, 9.07207350e-03,\n",
      "       9.58661927e-02, 1.65787272e-03, 3.39976861e-03, 3.90472782e-03,\n",
      "       2.43752799e-03, 1.17930169e-02, 3.01264702e-02, 1.26914717e-02,\n",
      "       4.85945178e-02, 1.45231034e-02, 4.55053124e-03, 6.46770300e-03,\n",
      "       3.01736610e-02, 1.89905061e-03, 1.24888299e-02, 4.45365825e-02,\n",
      "       9.79831898e-03, 6.25446518e-02, 5.34390046e-02, 2.67928233e-03,\n",
      "       2.54050596e-02, 1.64041254e-02, 3.08560159e-03, 7.29894480e-02,\n",
      "       2.87059844e-02, 2.79472639e-02, 1.05935417e-02, 4.51826597e-02,\n",
      "       3.01039584e-05, 2.56594740e-04, 3.62582239e-04, 4.83214763e-04,\n",
      "       1.01473324e-03, 1.60822124e-05, 9.16949142e-04, 8.30684363e-04,\n",
      "       4.78957561e-04, 4.58695715e-04, 7.50437172e-04, 1.95225205e-05,\n",
      "       9.24610373e-04, 9.39481371e-04, 6.88143271e-04, 2.59888442e-02,\n",
      "       3.50760915e-03, 2.02934020e-02, 2.83409801e-02, 7.76249841e-03,\n",
      "       4.38676897e-03, 3.85842679e-02, 1.67668166e-02, 1.81361635e-02,\n",
      "       3.54941117e-02, 1.11665427e-02, 1.10254907e-02, 3.62126365e-02,\n",
      "       1.37502966e-02, 1.17516486e-01, 7.30800092e-03, 3.48130039e-02,\n",
      "       1.46770372e-01, 2.77921515e-03, 8.50695871e-03, 2.99541795e-02,\n",
      "       1.14877794e-02, 3.56251054e-02, 7.59678305e-03, 4.60878907e-02,\n",
      "       2.12171474e-02, 3.82778059e-02, 8.83561777e-03, 4.78350417e-02,\n",
      "       3.52827397e-02, 4.60914743e-04, 1.23285179e-03, 1.24125142e-03,\n",
      "       1.52972353e-05, 1.86446419e-03, 9.23802729e-04, 8.41366318e-04,\n",
      "       9.43808433e-04, 4.75350858e-04, 4.69809939e-04, 1.96730251e-03,\n",
      "       1.26429246e-03, 1.89248893e-05, 7.43145607e-06, 1.97189270e-03,\n",
      "       1.05209604e-02, 1.81513772e-02, 5.33883733e-02, 7.82795249e-03,\n",
      "       5.99416269e-02, 4.78972934e-02, 6.65801176e-03, 1.13665380e-02,\n",
      "       1.57518942e-02, 7.17451927e-03, 2.01074250e-02, 3.91686103e-02,\n",
      "       1.46937961e-02, 1.08973917e-02, 2.16114791e-02, 6.33512457e-03,\n",
      "       1.37665608e-02, 3.42555882e-02, 6.74388993e-03, 3.53101314e-02,\n",
      "       3.24788040e-02, 1.57788222e-02, 5.68685435e-03, 7.62989322e-02,\n",
      "       3.95766871e-03, 4.38265612e-03, 2.67795104e-02, 1.23668353e-02,\n",
      "       4.02227781e-02, 3.26874161e-02, 4.60275793e-04, 4.52207597e-04,\n",
      "       1.71399948e-05, 1.69028830e-03, 4.78863503e-04, 1.85347339e-05,\n",
      "       4.52497987e-04, 1.79379945e-05, 4.82939338e-04, 4.62185387e-04,\n",
      "       1.88315296e-03, 4.68850040e-04, 4.69854771e-04, 9.38357516e-04,\n",
      "       9.40436806e-04, 5.78947778e-03, 3.39710865e-02, 2.52834674e-02,\n",
      "       1.41598885e-03, 6.85640202e-03, 1.10577528e-02, 3.23585244e-02,\n",
      "       1.13441787e-02, 3.62978363e-02, 4.46510985e-02, 1.40888145e-02,\n",
      "       2.91422513e-01, 3.19354024e-02, 9.18422253e-02, 6.69594498e-02,\n",
      "       4.26016342e-03, 1.92299282e-01, 7.49466247e-02, 5.56934812e-04,\n",
      "       2.88259571e-02, 4.26843981e-02, 2.45171454e-02, 7.80964766e-03,\n",
      "       3.97238375e-02, 3.81545531e-03, 3.06839056e-02, 4.12311740e-02,\n",
      "       1.24456882e-02, 8.81280861e-03, 1.01890721e-01, 1.63687083e-05,\n",
      "       8.15636111e-04, 4.95460208e-04, 1.25420701e-03, 4.80216805e-04,\n",
      "       1.93877946e-05, 8.12243007e-04, 9.47561962e-04, 4.79531346e-04,\n",
      "       3.55269462e-05, 2.11406344e-02, 1.43205575e-03, 1.73083058e-05,\n",
      "       6.42973343e-04, 1.02554543e-03, 8.14509160e-03, 2.88413114e-02,\n",
      "       4.13609958e-02, 2.97440514e-03, 9.44975520e-03, 2.80317617e-02,\n",
      "       8.63471836e-02, 5.81774019e-02, 2.24925712e-02, 2.93610524e-02,\n",
      "       1.91210434e-03, 2.32901297e-02, 1.45786394e-02, 5.23473776e-03,\n",
      "       3.77691215e-02, 1.09702933e-02, 5.56827771e-02, 4.82887151e-02,\n",
      "       8.32620483e-03, 5.18630672e-03, 5.63068429e-02, 3.05073931e-02,\n",
      "       1.57237525e-02, 1.92448632e-02, 2.92288495e-02, 9.89739495e-03,\n",
      "       3.45246474e-02, 4.48184756e-03, 3.96153537e-02, 1.17620843e-02,\n",
      "       1.70079347e-06, 1.55707348e-02, 1.64652993e-03, 1.80499644e-05,\n",
      "       4.69516710e-04, 8.14393406e-04, 2.43447228e-04, 3.91773906e-04,\n",
      "       4.52602004e-04, 2.97360213e-07, 9.23690583e-04, 1.91323947e-03,\n",
      "       4.61338301e-04, 7.08809957e-04, 8.65190163e-04, 5.74619294e-03,\n",
      "       2.33739605e-02, 1.97548358e-02, 2.98454718e-03, 2.27322341e-02,\n",
      "       3.20127595e-02, 3.23326662e-03, 8.31005665e-03, 2.24319824e-02,\n",
      "       7.84597770e-02, 7.11577644e-03, 1.64400130e-02, 2.87257089e-02,\n",
      "       1.16353282e-02, 4.20947040e-02, 1.66896505e-02, 1.50720023e-02,\n",
      "       5.99880078e-02, 2.00711159e-02, 4.46842860e-02, 2.16970689e-02,\n",
      "       4.36089849e-02, 2.57494399e-02, 2.41312068e-02, 1.25572971e-02,\n",
      "       2.20809349e-02, 1.95288289e-02, 5.33383674e-03, 3.81791454e-02,\n",
      "       4.62368090e-02, 8.82113323e-04, 1.84886738e-05, 1.65780462e-05,\n",
      "       4.59729728e-04, 4.57596597e-04, 8.27674309e-04, 1.65627999e-05,\n",
      "       1.69298865e-03, 8.07689856e-04, 4.43665580e-04, 1.12391596e-07,\n",
      "       1.25019093e-03, 9.20826404e-04, 5.13629741e-04, 3.64418740e-04,\n",
      "       5.81805094e-03, 3.78188715e-02, 5.93858427e-02, 3.56508035e-03,\n",
      "       9.52086307e-03, 2.50663642e-02, 3.97319425e-02, 1.33554146e-02,\n",
      "       3.36197240e-03, 1.87593091e-02, 1.53088172e-02, 3.81501351e-02,\n",
      "       8.38681362e-03, 9.44653696e-03, 1.85031375e-02, 1.40700617e-02,\n",
      "       2.91325687e-02, 4.43422507e-02, 6.82274958e-03, 2.87476522e-02,\n",
      "       2.76368847e-02, 4.00625578e-02, 1.17349438e-02, 2.75240864e-02,\n",
      "       1.30070911e-02, 4.01445551e-02, 1.58432558e-02, 3.78351115e-02,\n",
      "       1.99378704e-02, 5.15418244e-02, 1.39208280e-03, 3.96798637e-04,\n",
      "       8.27086945e-04, 1.48804648e-04, 4.71542568e-04, 2.02990073e-03,\n",
      "       4.35467356e-04, 6.05573471e-04, 4.96433718e-04, 9.64970256e-04,\n",
      "       4.62331720e-04, 1.39929233e-03, 4.89903609e-07, 2.25557361e-05,\n",
      "       8.13868546e-04]), 'mean_score_time': array([0.03791134, 0.07447108, 0.11176737, 0.01769837, 0.03355225,\n",
      "       0.04954648, 0.01760372, 0.0339187 , 0.0497152 , 0.01863988,\n",
      "       0.03556752, 0.05226032, 0.01992186, 0.03889354, 0.05784241,\n",
      "       0.03692134, 0.07949289, 0.11736997, 0.01861548, 0.03527625,\n",
      "       0.05368972, 0.02043621, 0.03623533, 0.05427686, 0.01961335,\n",
      "       0.03956827, 0.05750148, 0.02195326, 0.04220955, 0.0624845 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.02127695, 0.04056009, 0.06053344, 0.01862979, 0.03540238,\n",
      "       0.05531685, 0.0189627 , 0.03556967, 0.05424086, 0.01995945,\n",
      "       0.03990881, 0.05668696, 0.02194111, 0.04157845, 0.06035233,\n",
      "       0.02127369, 0.0409019 , 0.06149062, 0.01896238, 0.03557253,\n",
      "       0.05341633, 0.01861572, 0.03709976, 0.0530657 , 0.01998631,\n",
      "       0.04253292, 0.05386265, 0.02095668, 0.04070266, 0.06151676,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03092758, 0.06217845, 0.09128912, 0.01859323, 0.03590457,\n",
      "       0.052876  , 0.01960969, 0.03622532, 0.05519358, 0.01930102,\n",
      "       0.04811263, 0.05686116, 0.02196654, 0.0415442 , 0.06316257,\n",
      "       0.03092082, 0.05918829, 0.09125781, 0.01862804, 0.03723478,\n",
      "       0.05284834, 0.01861699, 0.0385627 , 0.05681594, 0.01992551,\n",
      "       0.0408895 , 0.05950451, 0.0216097 , 0.04155731, 0.06483912,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03925371, 0.0783445 , 0.11602426, 0.01961239, 0.03624916,\n",
      "       0.05368376, 0.01961517, 0.03655601, 0.0545458 , 0.02159731,\n",
      "       0.03855109, 0.05849608, 0.02228626, 0.04289707, 0.06446894,\n",
      "       0.03891985, 0.07837224, 0.11507201, 0.01827637, 0.03623692,\n",
      "       0.05353713, 0.01884842, 0.03693763, 0.0539089 , 0.02061288,\n",
      "       0.03857549, 0.05717039, 0.02160891, 0.04421401, 0.06374598,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.02260335, 0.04189801, 0.06281932, 0.01847569, 0.03557285,\n",
      "       0.05320287, 0.01925675, 0.03755601, 0.05474114, 0.0202752 ,\n",
      "       0.03856309, 0.058707  , 0.02094499, 0.04158298, 0.06239549,\n",
      "       0.02199324, 0.04206491, 0.06147989, 0.01828551, 0.03688979,\n",
      "       0.0555083 , 0.02027853, 0.03723963, 0.05537264, 0.0216074 ,\n",
      "       0.03924115, 0.05835366, 0.0216078 , 0.04189388, 0.06216749,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03226328, 0.06316392, 0.09552224, 0.01930483, 0.03690275,\n",
      "       0.05284595, 0.0198462 , 0.03689249, 0.05522458, 0.02127862,\n",
      "       0.03954156, 0.0678366 , 0.02558263, 0.04290334, 0.06482855,\n",
      "       0.03360184, 0.06316439, 0.09555403, 0.01861199, 0.03616683,\n",
      "       0.05851094, 0.01903844, 0.03871489, 0.05452164, 0.01994594,\n",
      "       0.03957367, 0.05815482, 0.02227505, 0.04685473, 0.07066083,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.0418756 , 0.08151841, 0.12003024, 0.02113636, 0.03893479,\n",
      "       0.05696535, 0.02193809, 0.03906592, 0.05871503, 0.02161082,\n",
      "       0.04321281, 0.06284388, 0.02356354, 0.04620043, 0.068319  ,\n",
      "       0.04006362, 0.08022881, 0.11652088, 0.01993092, 0.03923551,\n",
      "       0.05782175, 0.02160414, 0.05383317, 0.05885593, 0.02194047,\n",
      "       0.04222067, 0.06417076, 0.02426998, 0.04985754, 0.06714209,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.02260367, 0.04505221, 0.06616282, 0.02063314, 0.039229  ,\n",
      "       0.05787245, 0.02092123, 0.03989132, 0.05983424, 0.02526999,\n",
      "       0.04110297, 0.06182249, 0.02327077, 0.04489088, 0.06672208,\n",
      "       0.02292752, 0.04488031, 0.06690518, 0.0202802 , 0.0387342 ,\n",
      "       0.05716689, 0.02093101, 0.03955499, 0.07230735, 0.0216217 ,\n",
      "       0.04190127, 0.06268191, 0.02596641, 0.04352697, 0.06616012,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03292497, 0.06413674, 0.096071  , 0.01994578, 0.03871846,\n",
      "       0.05785831, 0.01994793, 0.03955205, 0.06017319, 0.0229276 ,\n",
      "       0.04190445, 0.06215946, 0.02328451, 0.04578257, 0.06714741,\n",
      "       0.03670653, 0.06574957, 0.09793353, 0.02094324, 0.03975471,\n",
      "       0.05783176, 0.02094316, 0.041888  , 0.05882724, 0.02160343,\n",
      "       0.04164322, 0.06133413, 0.02327005, 0.04623445, 0.0687867 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), 'std_score_time': array([1.77578722e-05, 9.41336220e-04, 1.54997641e-03, 1.80366207e-03,\n",
      "       5.05992919e-04, 9.57913573e-04, 4.83061590e-04, 3.30994681e-05,\n",
      "       8.42606302e-04, 9.21463294e-04, 4.65493333e-04, 4.31395842e-04,\n",
      "       1.80877156e-05, 2.83803802e-05, 1.25153985e-06, 2.35293356e-05,\n",
      "       1.69713419e-03, 9.03651546e-04, 4.72213381e-04, 1.24245607e-03,\n",
      "       1.02636096e-03, 3.17926344e-03, 4.70360280e-04, 8.16123996e-04,\n",
      "       9.41168212e-04, 1.22344875e-03, 4.86655650e-04, 3.39985971e-05,\n",
      "       1.22753454e-03, 1.23238395e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 4.70021695e-04, 4.71091074e-04, 4.66159655e-04,\n",
      "       4.52489236e-04, 4.09094803e-04, 3.57040302e-03, 1.61519667e-05,\n",
      "       9.39202193e-04, 9.76965957e-04, 8.28556830e-04, 1.39981375e-03,\n",
      "       6.45382031e-04, 8.15074920e-04, 1.70037390e-03, 1.06948687e-03,\n",
      "       4.72171582e-04, 1.84688497e-05, 4.61539219e-04, 1.58579723e-05,\n",
      "       4.69515983e-04, 4.09551090e-04, 4.69522198e-04, 2.05850951e-03,\n",
      "       1.05886377e-03, 7.98232556e-04, 6.64799151e-03, 8.12084907e-04,\n",
      "       1.42817360e-03, 2.87647468e-04, 1.86187918e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 8.29900664e-04, 9.24255493e-04,\n",
      "       2.50155709e-03, 4.78094562e-04, 4.05233662e-07, 8.03132392e-04,\n",
      "       1.70862724e-03, 9.31373627e-04, 1.23457607e-03, 4.43328661e-04,\n",
      "       1.03426168e-02, 8.29728535e-04, 8.13321930e-04, 4.87049069e-04,\n",
      "       2.62002993e-03, 2.84996368e-06, 1.68035699e-03, 1.90591235e-03,\n",
      "       4.79763009e-04, 3.29251181e-03, 1.61431895e-03, 4.73451849e-04,\n",
      "       9.39605358e-04, 1.39798913e-03, 1.81744544e-05, 3.03756872e-05,\n",
      "       2.04529812e-03, 9.39459892e-04, 4.67324297e-04, 4.32529475e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.55354562e-04,\n",
      "       1.46756463e-03, 9.65101760e-04, 1.24498469e-03, 9.19983453e-04,\n",
      "       8.33208114e-04, 4.68841634e-04, 4.88229132e-04, 2.03661321e-03,\n",
      "       9.47962511e-04, 4.63484287e-04, 4.66453925e-04, 4.85139974e-04,\n",
      "       1.66350953e-05, 2.34353422e-03, 1.97156773e-05, 8.18829117e-04,\n",
      "       5.62479539e-04, 4.79347667e-04, 1.24485617e-03, 1.69097815e-03,\n",
      "       6.67461687e-04, 1.57348234e-06, 8.01416320e-04, 4.68279595e-04,\n",
      "       1.24738973e-03, 4.51651177e-04, 4.69740686e-04, 1.69501459e-03,\n",
      "       8.28314801e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.69708955e-03, 1.40404440e-03, 2.16527851e-03, 4.37848968e-04,\n",
      "       9.39988570e-04, 9.48582068e-04, 4.88289567e-04, 2.33690231e-03,\n",
      "       1.50482696e-03, 4.61536099e-04, 9.40661589e-04, 2.46798730e-03,\n",
      "       5.61957980e-07, 4.51916629e-04, 3.51749930e-04, 7.51884716e-04,\n",
      "       6.21828198e-04, 4.78543936e-04, 4.70527507e-04, 3.23072570e-05,\n",
      "       1.70737429e-03, 1.25371943e-03, 4.74528699e-04, 4.03625935e-04,\n",
      "       1.69721214e-03, 9.47288238e-04, 1.07140451e-03, 4.68956207e-04,\n",
      "       8.10500031e-04, 4.96123202e-04, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 4.58831626e-04, 1.24434675e-03, 1.56453685e-03,\n",
      "       4.76941508e-04, 8.11960233e-04, 1.85456351e-05, 8.28444241e-04,\n",
      "       7.97488214e-04, 1.22728638e-03, 1.24126901e-03, 9.28942596e-04,\n",
      "       8.24833476e-03, 4.79063967e-04, 3.25039790e-03, 1.61283471e-03,\n",
      "       3.09028308e-03, 9.42625120e-04, 1.64373167e-03, 4.68909417e-04,\n",
      "       5.56062746e-04, 5.17021963e-03, 1.28094029e-04, 3.27409771e-03,\n",
      "       4.44517458e-04, 3.04718055e-05, 1.22656728e-03, 4.89073202e-04,\n",
      "       4.71064286e-04, 4.94665001e-03, 2.29905072e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 8.14578490e-04, 1.03013505e-03,\n",
      "       4.32559306e-04, 1.41185840e-03, 8.13133297e-04, 8.31078424e-04,\n",
      "       2.14953236e-03, 2.23966326e-03, 2.06776988e-04, 4.71258324e-04,\n",
      "       1.69555208e-03, 8.13882049e-04, 8.56070814e-04, 4.77821698e-04,\n",
      "       7.10148227e-04, 2.41080052e-04, 8.13710444e-04, 3.47868245e-03,\n",
      "       8.25245226e-04, 1.23671478e-03, 1.67380484e-05, 1.68212728e-03,\n",
      "       1.58683670e-02, 1.64789392e-03, 8.13031150e-04, 1.88070479e-03,\n",
      "       4.00358264e-03, 4.44570652e-04, 5.09000207e-03, 1.25703786e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.65782668e-04,\n",
      "       8.47471471e-04, 8.50540250e-04, 9.24760531e-04, 1.24379406e-03,\n",
      "       8.15166042e-04, 1.74127194e-05, 8.13030715e-04, 2.14489698e-03,\n",
      "       4.69971301e-03, 2.99524173e-04, 1.62877381e-03, 4.70753015e-04,\n",
      "       3.38873243e-05, 1.99814405e-03, 1.68587394e-05, 8.15564976e-04,\n",
      "       1.50931790e-03, 4.68788621e-04, 2.29784639e-04, 4.51589433e-04,\n",
      "       1.87195280e-05, 4.52703680e-04, 1.97660014e-02, 4.54179488e-04,\n",
      "       7.67535787e-04, 8.40530175e-04, 4.23120646e-03, 1.22881664e-03,\n",
      "       4.74679769e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.63014314e-05, 4.60824609e-04, 4.48339825e-04, 2.78268518e-06,\n",
      "       2.23439383e-04, 1.74836679e-05, 1.40826266e-06, 4.83059119e-04,\n",
      "       9.39591988e-04, 1.62946391e-03, 2.68832146e-05, 4.81863957e-04,\n",
      "       4.85308825e-04, 8.22215014e-04, 9.34308931e-04, 4.09220509e-03,\n",
      "       1.09661201e-04, 1.98861678e-03, 2.79627038e-06, 1.23882310e-03,\n",
      "       1.39034041e-03, 7.83539170e-04, 1.64101210e-03, 1.36304901e-03,\n",
      "       4.87668534e-04, 3.47515033e-04, 3.92886667e-04, 4.71261219e-04,\n",
      "       1.25838329e-03, 1.28351492e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00]), 'param_RF__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_RF__max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_RF__max_features': masked_array(data=['sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_RF__max_leaf_nodes': masked_array(data=[None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_RF__n_estimators': masked_array(data=[50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'gini', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'log_loss', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': None, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 5, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'log2', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': None, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 8, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 10, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 16, 'RF__n_estimators': 150}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 50}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 100}, {'RF__criterion': 'entropy', 'RF__max_depth': 10, 'RF__max_features': 'None', 'RF__max_leaf_nodes': 32, 'RF__n_estimators': 150}], 'split0_test_score': array([0.61382663, 0.61409668, 0.61760735, 0.55981637, 0.56008642,\n",
      "       0.56224683, 0.56764785, 0.56413719, 0.5679179 , 0.57493924,\n",
      "       0.57953011, 0.57709965, 0.59114232, 0.58952201, 0.59492304,\n",
      "       0.60815555, 0.61112611, 0.61706724, 0.56278693, 0.55792601,\n",
      "       0.55954631, 0.56143667, 0.56332703, 0.56440724, 0.57142857,\n",
      "       0.57601944, 0.57493924, 0.59060221, 0.59033216, 0.58979206,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57926006, 0.57844991, 0.57817985, 0.55819606, 0.56143667,\n",
      "       0.56089657, 0.5668377 , 0.56521739, 0.56899811, 0.57223873,\n",
      "       0.5762895 , 0.57331893, 0.5779098 , 0.57871996, 0.57953011,\n",
      "       0.5779098 , 0.57763975, 0.58115042, 0.55981637, 0.56035647,\n",
      "       0.55981637, 0.55846611, 0.56548744, 0.56251688, 0.5762895 ,\n",
      "       0.57439914, 0.57385903, 0.57655955, 0.57817985, 0.57709965,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.6178774 , 0.62003781, 0.61976776, 0.56116662, 0.56467729,\n",
      "       0.56521739, 0.56710775, 0.56521739, 0.56467729, 0.57655955,\n",
      "       0.57709965, 0.57844991, 0.59114232, 0.59033216, 0.59033216,\n",
      "       0.6184175 , 0.62219822, 0.62300837, 0.5557656 , 0.56062652,\n",
      "       0.56062652, 0.56197678, 0.56332703, 0.56467729, 0.57520929,\n",
      "       0.57385903, 0.5762895 , 0.59573319, 0.59087227, 0.59195247,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61922765, 0.62003781, 0.61868755, 0.56116662, 0.56440724,\n",
      "       0.56170672, 0.5662976 , 0.57034837, 0.56980826, 0.57250878,\n",
      "       0.57412908, 0.57520929, 0.58898191, 0.58817175, 0.5879017 ,\n",
      "       0.61490683, 0.61679719, 0.62003781, 0.56440724, 0.56197678,\n",
      "       0.56413719, 0.56926816, 0.57034837, 0.56818796, 0.57331893,\n",
      "       0.57926006, 0.57520929, 0.59141237, 0.5873616 , 0.5868215 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57899001, 0.58250068, 0.58007021, 0.56359708, 0.56224683,\n",
      "       0.56575749, 0.56710775, 0.56656765, 0.56440724, 0.57493924,\n",
      "       0.57763975, 0.57655955, 0.58034026, 0.58196057, 0.58142047,\n",
      "       0.58169052, 0.58088037, 0.57899001, 0.56170672, 0.56278693,\n",
      "       0.56089657, 0.56710775, 0.56467729, 0.57142857, 0.57574939,\n",
      "       0.57466919, 0.57547934, 0.57953011, 0.57899001, 0.57980016,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61868755, 0.62300837, 0.62030786, 0.56413719, 0.56062652,\n",
      "       0.56494734, 0.57007831, 0.5679179 , 0.56980826, 0.57196867,\n",
      "       0.57844991, 0.5762895 , 0.58709155, 0.58763165, 0.58763165,\n",
      "       0.61733729, 0.62462868, 0.62570888, 0.56062652, 0.56602755,\n",
      "       0.56386713, 0.57088847, 0.56899811, 0.56926816, 0.5768296 ,\n",
      "       0.57763975, 0.57547934, 0.58547124, 0.5868215 , 0.58763165,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.62057791, 0.61733729, 0.61733729, 0.56170672, 0.56332703,\n",
      "       0.56305698, 0.5673778 , 0.56818796, 0.56926816, 0.57601944,\n",
      "       0.57709965, 0.5773697 , 0.58952201, 0.58628139, 0.58817175,\n",
      "       0.61031596, 0.61463678, 0.61733729, 0.5668377 , 0.56359708,\n",
      "       0.56521739, 0.5662976 , 0.57061842, 0.56953821, 0.57385903,\n",
      "       0.57466919, 0.57466919, 0.58952201, 0.5879017 , 0.58520119,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57980016, 0.58223062, 0.58304078, 0.56413719, 0.55846611,\n",
      "       0.56332703, 0.56521739, 0.56953821, 0.56845801, 0.5768296 ,\n",
      "       0.57331893, 0.57601944, 0.58061032, 0.57817985, 0.58412098,\n",
      "       0.58196057, 0.58250068, 0.58034026, 0.56872806, 0.5668377 ,\n",
      "       0.56521739, 0.56764785, 0.56764785, 0.56872806, 0.57709965,\n",
      "       0.57520929, 0.57574939, 0.58520119, 0.58196057, 0.58223062,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.62327842, 0.62219822, 0.62624899, 0.56008642, 0.55873616,\n",
      "       0.56116662, 0.57115852, 0.56872806, 0.56845801, 0.5779098 ,\n",
      "       0.57709965, 0.57844991, 0.5868215 , 0.58925196, 0.58925196,\n",
      "       0.62111801, 0.62516878, 0.62624899, 0.56656765, 0.56413719,\n",
      "       0.56305698, 0.56845801, 0.56926816, 0.57331893, 0.57493924,\n",
      "       0.57520929, 0.5768296 , 0.59222252, 0.5873616 , 0.5879017 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split1_test_score': array([0.60977586, 0.61463678, 0.61490683, 0.56494734, 0.56305698,\n",
      "       0.56386713, 0.56521739, 0.5673778 , 0.56710775, 0.57520929,\n",
      "       0.57520929, 0.5773697 , 0.59573319, 0.59033216, 0.59195247,\n",
      "       0.60923575, 0.61031596, 0.61193627, 0.56116662, 0.56386713,\n",
      "       0.56386713, 0.56089657, 0.56575749, 0.56521739, 0.57601944,\n",
      "       0.57169862, 0.57385903, 0.59168242, 0.59384283, 0.59087227,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.5773697 , 0.58196057, 0.57953011, 0.5662976 , 0.56278693,\n",
      "       0.56386713, 0.56575749, 0.56872806, 0.5668377 , 0.57304888,\n",
      "       0.57277883, 0.57493924, 0.58142047, 0.58223062, 0.57763975,\n",
      "       0.58142047, 0.57980016, 0.57763975, 0.56467729, 0.56035647,\n",
      "       0.55981637, 0.56602755, 0.56656765, 0.56467729, 0.57331893,\n",
      "       0.57115852, 0.57277883, 0.57709965, 0.5779098 , 0.57926006,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.6073454 , 0.6084256 , 0.61355658, 0.56440724, 0.56305698,\n",
      "       0.56170672, 0.56170672, 0.5679179 , 0.56764785, 0.57601944,\n",
      "       0.5762895 , 0.57817985, 0.59033216, 0.59033216, 0.59519309,\n",
      "       0.60977586, 0.61301647, 0.61166622, 0.56116662, 0.5668377 ,\n",
      "       0.56035647, 0.56602755, 0.5668377 , 0.56764785, 0.57655955,\n",
      "       0.57547934, 0.57385903, 0.59195247, 0.58952201, 0.59114232,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.6078855 , 0.61274642, 0.61058601, 0.55792601, 0.56170672,\n",
      "       0.56413719, 0.56548744, 0.5673778 , 0.5673778 , 0.57466919,\n",
      "       0.57655955, 0.57493924, 0.59276262, 0.59195247, 0.59060221,\n",
      "       0.60518499, 0.61112611, 0.61355658, 0.56170672, 0.56602755,\n",
      "       0.56494734, 0.56953821, 0.56953821, 0.57223873, 0.57196867,\n",
      "       0.57358898, 0.57547934, 0.59303268, 0.58385093, 0.59006211,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57844991, 0.57980016, 0.58007021, 0.55657575, 0.56197678,\n",
      "       0.56305698, 0.57007831, 0.5679179 , 0.56764785, 0.57520929,\n",
      "       0.57223873, 0.57412908, 0.57817985, 0.58088037, 0.57871996,\n",
      "       0.58115042, 0.58304078, 0.58034026, 0.56413719, 0.56305698,\n",
      "       0.56656765, 0.56953821, 0.56548744, 0.5679179 , 0.57304888,\n",
      "       0.57250878, 0.57520929, 0.58250068, 0.57763975, 0.57844991,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.6089657 , 0.61247637, 0.61166622, 0.56278693, 0.56035647,\n",
      "       0.56305698, 0.56278693, 0.56494734, 0.56764785, 0.5779098 ,\n",
      "       0.57655955, 0.57763975, 0.59087227, 0.59357278, 0.58817175,\n",
      "       0.61382663, 0.61274642, 0.61328652, 0.55954631, 0.5679179 ,\n",
      "       0.56197678, 0.56656765, 0.56548744, 0.57007831, 0.57223873,\n",
      "       0.57655955, 0.57331893, 0.59249257, 0.59519309, 0.58763165,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61328652, 0.61355658, 0.61382663, 0.56359708, 0.56494734,\n",
      "       0.56575749, 0.5668377 , 0.57061842, 0.5679179 , 0.56926816,\n",
      "       0.5779098 , 0.5773697 , 0.58979206, 0.58979206, 0.59114232,\n",
      "       0.60761545, 0.61328652, 0.61193627, 0.56548744, 0.56602755,\n",
      "       0.5668377 , 0.56818796, 0.56332703, 0.5668377 , 0.57574939,\n",
      "       0.57926006, 0.57439914, 0.59411288, 0.59357278, 0.59357278,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57574939, 0.58061032, 0.57980016, 0.56116662, 0.55927626,\n",
      "       0.56548744, 0.56710775, 0.56872806, 0.56980826, 0.5762895 ,\n",
      "       0.57899001, 0.57493924, 0.57520929, 0.58115042, 0.58223062,\n",
      "       0.58007021, 0.58088037, 0.58412098, 0.56386713, 0.56440724,\n",
      "       0.56656765, 0.56251688, 0.56521739, 0.56899811, 0.57196867,\n",
      "       0.57547934, 0.57709965, 0.57601944, 0.58007021, 0.58007021,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61463678, 0.61409668, 0.61490683, 0.56305698, 0.56251688,\n",
      "       0.56467729, 0.56386713, 0.5668377 , 0.56656765, 0.57601944,\n",
      "       0.57331893, 0.5779098 , 0.58898191, 0.59087227, 0.59276262,\n",
      "       0.61112611, 0.61058601, 0.61031596, 0.56116662, 0.56494734,\n",
      "       0.56197678, 0.56710775, 0.56575749, 0.56872806, 0.5768296 ,\n",
      "       0.57601944, 0.57763975, 0.58817175, 0.58898191, 0.59114232,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split2_test_score': array([0.61723393, 0.61750405, 0.62236629, 0.56726094, 0.56320908,\n",
      "       0.56185845, 0.57104268, 0.56969206, 0.56834144, 0.57725554,\n",
      "       0.57914641, 0.5813074 , 0.59778498, 0.59562399, 0.59967585,\n",
      "       0.61102107, 0.61426256, 0.61777418, 0.56645057, 0.56672069,\n",
      "       0.56699082, 0.56537007, 0.56564019, 0.56861156, 0.57887628,\n",
      "       0.58076715, 0.5802269 , 0.59886548, 0.60075635, 0.60075635,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57995678, 0.57887628, 0.58265802, 0.56266883, 0.56131821,\n",
      "       0.55834684, 0.56861156, 0.57050243, 0.56888169, 0.57752566,\n",
      "       0.57779579, 0.57725554, 0.57563479, 0.58157753, 0.58184765,\n",
      "       0.58157753, 0.5802269 , 0.58454889, 0.56888169, 0.56509995,\n",
      "       0.56591032, 0.56861156, 0.57104268, 0.56888169, 0.57671529,\n",
      "       0.5813074 , 0.58292815, 0.58427877, 0.58562939, 0.5813074 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61156132, 0.61345219, 0.6169638 , 0.56509995, 0.55726634,\n",
      "       0.56726094, 0.56564019, 0.56996218, 0.56996218, 0.57779579,\n",
      "       0.57860616, 0.58265802, 0.59589411, 0.59562399, 0.5991356 ,\n",
      "       0.61723393, 0.61615343, 0.61831442, 0.56564019, 0.56374932,\n",
      "       0.56509995, 0.56888169, 0.5713128 , 0.56996218, 0.57887628,\n",
      "       0.57725554, 0.58049703, 0.59670448, 0.5991356 , 0.60183684,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61372231, 0.61615343, 0.6180443 , 0.57293355, 0.56104808,\n",
      "       0.56645057, 0.57077256, 0.56942193, 0.56915181, 0.58049703,\n",
      "       0.58427877, 0.5802269 , 0.59373312, 0.59535386, 0.59697461,\n",
      "       0.6091302 , 0.61507293, 0.61858455, 0.56672069, 0.5713128 ,\n",
      "       0.57077256, 0.57725554, 0.57779579, 0.57671529, 0.58265802,\n",
      "       0.58562939, 0.58562939, 0.59778498, 0.59319287, 0.59319287,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.58076715, 0.58076715, 0.58292815, 0.55645597, 0.56645057,\n",
      "       0.56509995, 0.57212318, 0.56699082, 0.57293355, 0.57698541,\n",
      "       0.57995678, 0.58076715, 0.57833603, 0.58427877, 0.57833603,\n",
      "       0.589141  , 0.58887088, 0.58806051, 0.5713128 , 0.57077256,\n",
      "       0.56942193, 0.57266343, 0.57374392, 0.57671529, 0.5823879 ,\n",
      "       0.58698001, 0.58319827, 0.58887088, 0.58887088, 0.58508914,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61723393, 0.61993517, 0.61966505, 0.55942734, 0.56293895,\n",
      "       0.56699082, 0.57401405, 0.56969206, 0.56942193, 0.5802269 ,\n",
      "       0.58535927, 0.58508914, 0.59373312, 0.59481361, 0.59562399,\n",
      "       0.61507293, 0.62344679, 0.62128579, 0.57023231, 0.56618044,\n",
      "       0.5713128 , 0.57374392, 0.57779579, 0.57455429, 0.58184765,\n",
      "       0.58670989, 0.58562939, 0.59481361, 0.59454349, 0.59562399,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61858455, 0.61453269, 0.61399244, 0.55834684, 0.56591032,\n",
      "       0.56077796, 0.56861156, 0.56969206, 0.56834144, 0.58103728,\n",
      "       0.58211777, 0.5834684 , 0.5923825 , 0.59697461, 0.59265262,\n",
      "       0.61291194, 0.61966505, 0.61561318, 0.57077256, 0.57482442,\n",
      "       0.5713128 , 0.57428417, 0.57590492, 0.57590492, 0.58265802,\n",
      "       0.58400864, 0.58698001, 0.59886548, 0.59265262, 0.6002161 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57779579, 0.58292815, 0.5834684 , 0.56320908, 0.56374932,\n",
      "       0.5623987 , 0.56726094, 0.56834144, 0.56564019, 0.58076715,\n",
      "       0.57671529, 0.57968666, 0.58373852, 0.57779579, 0.57968666,\n",
      "       0.58725014, 0.59427337, 0.59049163, 0.57482442, 0.56969206,\n",
      "       0.5713128 , 0.57482442, 0.57671529, 0.57590492, 0.58211777,\n",
      "       0.58049703, 0.58616964, 0.58616964, 0.58698001, 0.59103187,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.62047542, 0.61831442, 0.62317666, 0.56212858, 0.56942193,\n",
      "       0.5645597 , 0.56753106, 0.56726094, 0.57104268, 0.57833603,\n",
      "       0.58157753, 0.57995678, 0.59427337, 0.59643436, 0.59751486,\n",
      "       0.61480281, 0.61966505, 0.62182604, 0.56969206, 0.57104268,\n",
      "       0.57293355, 0.57050243, 0.57482442, 0.57590492, 0.5802269 ,\n",
      "       0.58643976, 0.58616964, 0.59697461, 0.59427337, 0.59778498,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'mean_test_score': array([0.61361214, 0.6154125 , 0.61829349, 0.56400822, 0.56211749,\n",
      "       0.56265747, 0.56796931, 0.56706902, 0.56778903, 0.57580136,\n",
      "       0.57796194, 0.57859225, 0.59488683, 0.59182605, 0.59551712,\n",
      "       0.60947079, 0.61190154, 0.61559256, 0.56346804, 0.56283794,\n",
      "       0.56346809, 0.56256777, 0.56490824, 0.56607873, 0.57544143,\n",
      "       0.57616174, 0.57634173, 0.5937167 , 0.59497711, 0.59380689,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57886218, 0.57976225, 0.58012266, 0.56238749, 0.56184727,\n",
      "       0.56103685, 0.56706892, 0.56814929, 0.56823916, 0.57427109,\n",
      "       0.57562137, 0.57517124, 0.57832169, 0.5808427 , 0.5796725 ,\n",
      "       0.5803026 , 0.57922227, 0.58111302, 0.56445845, 0.56193763,\n",
      "       0.56184768, 0.56436841, 0.56769926, 0.56535862, 0.57544124,\n",
      "       0.57562169, 0.576522  , 0.57931265, 0.58057302, 0.57922237,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61226137, 0.61397187, 0.61676271, 0.56355794, 0.56166687,\n",
      "       0.56472835, 0.56481822, 0.56769916, 0.56742911, 0.57679159,\n",
      "       0.57733177, 0.57976259, 0.5924562 , 0.5920961 , 0.59488695,\n",
      "       0.61514243, 0.61712271, 0.617663  , 0.56085747, 0.56373785,\n",
      "       0.56202764, 0.56562867, 0.56715918, 0.56742911, 0.57688171,\n",
      "       0.5755313 , 0.57688185, 0.59479671, 0.59317663, 0.59497721,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61361182, 0.61631255, 0.61577262, 0.56400873, 0.56238735,\n",
      "       0.56409816, 0.5675192 , 0.56904937, 0.56877929, 0.57589166,\n",
      "       0.57832247, 0.57679181, 0.59182588, 0.59182603, 0.59182617,\n",
      "       0.60974067, 0.61433208, 0.61739298, 0.56427822, 0.56643904,\n",
      "       0.56661903, 0.57202064, 0.57256079, 0.57238066, 0.57598188,\n",
      "       0.57949281, 0.57877267, 0.59407668, 0.58813513, 0.59002549,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57940236, 0.58102266, 0.58102286, 0.55887627, 0.56355806,\n",
      "       0.56463814, 0.56976975, 0.56715879, 0.56832955, 0.57571131,\n",
      "       0.57661175, 0.57715193, 0.57895205, 0.58237324, 0.57949215,\n",
      "       0.58399398, 0.58426401, 0.58246359, 0.5657189 , 0.56553882,\n",
      "       0.56562872, 0.5697698 , 0.56796955, 0.57202059, 0.57706206,\n",
      "       0.57805266, 0.5779623 , 0.58363389, 0.58183355, 0.58111307,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61496239, 0.6184733 , 0.61721304, 0.56211715, 0.56130731,\n",
      "       0.56499838, 0.56895976, 0.5675191 , 0.56895935, 0.57670179,\n",
      "       0.58012291, 0.5796728 , 0.59056564, 0.59200601, 0.5904758 ,\n",
      "       0.61541228, 0.62027396, 0.62009373, 0.56346838, 0.56670863,\n",
      "       0.5657189 , 0.57040001, 0.57076045, 0.57130026, 0.57697199,\n",
      "       0.58030306, 0.57814255, 0.59092581, 0.59218602, 0.59029576,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61748299, 0.61514218, 0.61505212, 0.56121688, 0.56472823,\n",
      "       0.56319748, 0.56760902, 0.56949948, 0.56850917, 0.57544163,\n",
      "       0.57904241, 0.5794026 , 0.59056552, 0.59101602, 0.59065556,\n",
      "       0.61028112, 0.61586278, 0.61496225, 0.56769923, 0.56814968,\n",
      "       0.5677893 , 0.56958991, 0.56995012, 0.57076028, 0.57742215,\n",
      "       0.57931263, 0.57868278, 0.59416679, 0.5913757 , 0.59299669,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.57778178, 0.58192303, 0.58210311, 0.56283763, 0.56049723,\n",
      "       0.56373773, 0.56652869, 0.56886924, 0.56796882, 0.57796208,\n",
      "       0.57634141, 0.57688178, 0.57985271, 0.57904202, 0.58201275,\n",
      "       0.58309364, 0.5858848 , 0.58498429, 0.56913987, 0.566979  ,\n",
      "       0.56769928, 0.56832972, 0.56986018, 0.57121036, 0.57706203,\n",
      "       0.57706189, 0.57967289, 0.58246342, 0.5830036 , 0.58444424,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.61946354, 0.61820311, 0.62144416, 0.56175733, 0.56355832,\n",
      "       0.56346787, 0.56751891, 0.5676089 , 0.56868944, 0.57742176,\n",
      "       0.57733204, 0.57877216, 0.59002559, 0.59218619, 0.59317648,\n",
      "       0.61568231, 0.61847328, 0.61946366, 0.56580878, 0.56670907,\n",
      "       0.5659891 , 0.5686894 , 0.56995002, 0.57265064, 0.57733191,\n",
      "       0.57922283, 0.580213  , 0.59245629, 0.59020562, 0.59227633,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'std_test_score': array([0.00304852, 0.00149529, 0.00308372, 0.00311094, 0.00143753,\n",
      "       0.00086993, 0.002389  , 0.00227825, 0.00051183, 0.00103416,\n",
      "       0.00195271, 0.00192306, 0.00277711, 0.00270583, 0.00318092,\n",
      "       0.00118159, 0.00170194, 0.00260145, 0.00221027, 0.00366343,\n",
      "       0.00305228, 0.00199375, 0.00111911, 0.00182127, 0.00306786,\n",
      "       0.00370358, 0.00278241, 0.00366734, 0.00433058, 0.00493376,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.001093  , 0.00156416, 0.0018756 , 0.00331342, 0.0006662 ,\n",
      "       0.00225583, 0.00117658, 0.00219608, 0.00099213, 0.00232498,\n",
      "       0.00210195, 0.00161546, 0.00237988, 0.0015245 , 0.00172082,\n",
      "       0.00169318, 0.00113249, 0.00282077, 0.00370414, 0.0022361 ,\n",
      "       0.00287272, 0.00430481, 0.00240493, 0.00264271, 0.00151073,\n",
      "       0.00423249, 0.00455124, 0.00351849, 0.0035771 , 0.00171801,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00432807, 0.00475488, 0.00253969, 0.0017144 , 0.00318118,\n",
      "       0.00229372, 0.00228028, 0.00194322, 0.00216309, 0.00074352,\n",
      "       0.00095991, 0.00205034, 0.00245337, 0.00249459, 0.0036005 ,\n",
      "       0.00382538, 0.00381058, 0.00465327, 0.00403721, 0.00253572,\n",
      "       0.00217524, 0.00283299, 0.00326809, 0.00216309, 0.00151428,\n",
      "       0.0013871 , 0.00274213, 0.0020499 , 0.00424954, 0.00486176,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00463107, 0.00297882, 0.00367688, 0.00644798, 0.00145337,\n",
      "       0.00193686, 0.00232413, 0.00124101, 0.0010266 , 0.00337381,\n",
      "       0.00432704, 0.00243148, 0.00204965, 0.00293345, 0.00380377,\n",
      "       0.00399233, 0.00237374, 0.00277687, 0.00204898, 0.00382251,\n",
      "       0.00295555, 0.00370328, 0.00371645, 0.00348272, 0.00475282,\n",
      "       0.00491823, 0.00484968, 0.00270432, 0.00385285, 0.00260123,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00098993, 0.00111719, 0.00134724, 0.00333848, 0.00204828,\n",
      "       0.00114982, 0.00205913, 0.00056389, 0.00351407, 0.00090764,\n",
      "       0.00323364, 0.00274216, 0.00098368, 0.00141774, 0.0013725 ,\n",
      "       0.00364617, 0.00337484, 0.00399582, 0.00407804, 0.00370245,\n",
      "       0.00354322, 0.002274  , 0.00409647, 0.00361583, 0.003924  ,\n",
      "       0.00637391, 0.00370403, 0.00389663, 0.00500659, 0.00286504,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00428163, 0.00442218, 0.00393097, 0.00198026, 0.001159  ,\n",
      "       0.00160639, 0.00465119, 0.00195744, 0.00094068, 0.00347794,\n",
      "       0.00378224, 0.0038694 , 0.00272006, 0.00313435, 0.00364699,\n",
      "       0.00145317, 0.0053446 , 0.00514098, 0.00480311, 0.00085736,\n",
      "       0.00403007, 0.00294999, 0.00517708, 0.0023246 , 0.00392412,\n",
      "       0.00455172, 0.00536696, 0.00397165, 0.00380255, 0.00376762,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00307692, 0.00160251, 0.00161728, 0.00217121, 0.00106594,\n",
      "       0.00203531, 0.0007424 , 0.00100153, 0.00056385, 0.00482206,\n",
      "       0.00219962, 0.00287495, 0.00128952, 0.00445045, 0.0018614 ,\n",
      "       0.00216242, 0.00274453, 0.00225249, 0.00224199, 0.00482292,\n",
      "       0.00257781, 0.00340788, 0.0051566 , 0.0038012 , 0.0037819 ,\n",
      "       0.003813  , 0.00586807, 0.00381465, 0.00248505, 0.00614333,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00165375, 0.00097093, 0.00163776, 0.00124084, 0.00232324,\n",
      "       0.00129398, 0.00092934, 0.00049868, 0.00173641, 0.0019957 ,\n",
      "       0.00233025, 0.00203178, 0.00352301, 0.00149909, 0.00181685,\n",
      "       0.00303872, 0.00596838, 0.00418899, 0.00448276, 0.00215983,\n",
      "       0.00261393, 0.00504761, 0.00494781, 0.00332138, 0.00414344,\n",
      "       0.00243151, 0.00462685, 0.0045737 , 0.00291573, 0.00474093,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00359976, 0.00330838, 0.00478973, 0.00124082, 0.00442417,\n",
      "       0.00162794, 0.00297671, 0.00081001, 0.00183424, 0.00100674,\n",
      "       0.00337556, 0.00086619, 0.00313045, 0.00307588, 0.00338598,\n",
      "       0.00412631, 0.00601274, 0.0067157 , 0.00352162, 0.00308212,\n",
      "       0.00493023, 0.0013955 , 0.00373283, 0.0029678 , 0.00218771,\n",
      "       0.00511385, 0.00422495, 0.00359755, 0.00295141, 0.00411374,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'rank_test_score': array([ 30,  21,   8, 240, 257, 253, 195, 212, 198, 153, 128, 121,  41,\n",
      "        58,  37,  36,  33,  20, 248, 251, 247, 254, 230, 220, 159, 150,\n",
      "       148,  46,  39,  45, 316, 315, 314, 311, 310, 290, 291, 292, 318,\n",
      "       293, 309, 312, 313, 277, 279, 117, 101,  98, 255, 262, 267, 213,\n",
      "       193, 191, 162, 156, 161, 123,  92, 104,  95, 113,  89, 235, 260,\n",
      "       261, 236, 200, 228, 160, 155, 147, 109,  93, 112, 282, 281, 280,\n",
      "       288, 274, 383, 320, 381, 319, 365, 364, 372, 384, 394, 385,  32,\n",
      "        29,  15, 245, 264, 232, 231, 202, 208, 144, 134, 100,  51,  55,\n",
      "        40,  23,  14,  10, 268, 241, 259, 226, 210, 208, 142, 157, 140,\n",
      "        42,  47,  38, 403, 402, 401, 400, 399, 361, 350, 337, 336, 335,\n",
      "       334, 333, 332, 331, 330,  31,  16,  18, 239, 256, 238, 205, 181,\n",
      "       185, 152, 122, 143,  60,  59,  57,  35,  28,  12, 237, 219, 217,\n",
      "       166, 164, 165, 151, 105, 118,  44,  72,  71, 329, 328, 327, 326,\n",
      "       325, 324, 360, 351, 349, 348, 347, 346, 345, 343, 342, 108,  91,\n",
      "        90, 270, 244, 234, 177, 211, 190, 154, 146, 135, 116,  83, 106,\n",
      "        77,  76,  81, 223, 227, 225, 176, 194, 167, 136, 125, 126,  78,\n",
      "        87,  88, 352, 353, 354, 355, 356, 357, 358, 359, 341, 340, 339,\n",
      "       338, 321, 322, 323,  26,   6,  13, 258, 265, 229, 182, 206, 183,\n",
      "       145,  97, 103,  65,  56,  67,  22,   2,   3, 246, 216, 223, 172,\n",
      "       170, 168, 139,  94, 124,  63,  54,  68, 362, 363, 386, 387, 388,\n",
      "       389, 390, 391, 392, 393, 395, 404, 396, 397, 398,  11,  24,  25,\n",
      "       266, 233, 250, 203, 179, 188, 158, 114, 107,  66,  62,  64,  34,\n",
      "        17,  27, 201, 192, 197, 178, 173, 171, 130, 110, 120,  43,  61,\n",
      "        49, 366, 367, 368, 369, 370, 371, 373, 382, 374, 375, 376, 377,\n",
      "       378, 379, 380, 129,  86,  84, 252, 269, 242, 218, 184, 196, 127,\n",
      "       149, 141,  99, 115,  85,  79,  73,  74, 180, 214, 199, 189, 175,\n",
      "       169, 137, 138, 102,  82,  80,  75, 308, 307, 306, 305, 304, 303,\n",
      "       302, 301, 300, 299, 298, 297, 296, 295, 294,   5,   9,   1, 263,\n",
      "       243, 249, 207, 204, 186, 131, 132, 119,  70,  53,  48,  19,   7,\n",
      "         4, 222, 215, 221, 187, 174, 163, 133, 111,  96,  50,  69,  52,\n",
      "       317, 272, 276, 284, 285, 289, 287, 271, 278, 286, 283, 275, 273,\n",
      "       344, 405])}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "params = {\n",
    "    'RF__n_estimators': [50, 100, 150],\n",
    "    'RF__criterion': [\"gini\", \"log_loss\", \"entropy\"],\n",
    "    'RF__max_depth': [None, 5, 10],\n",
    "    'RF__max_features': [\"sqrt\", \"log2\", \"None\"],\n",
    "    'RF__max_leaf_nodes': [None, 8, 10, 16, 32],\n",
    "}\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "pipe = Pipeline(steps=[(\"imputer\", imp), (\"RF\", rf)])\n",
    "\n",
    "grid = GridSearchCV(pipe, params, scoring=\"accuracy\", cv=StratifiedKFold(3))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf6ece41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.618421052631579"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9a17eb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 7 ... 0 1 7]\n",
      "[0 0 0 ... 0 3 7]\n"
     ]
    }
   ],
   "source": [
    "print(grid.predict(X_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b6f81",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d05423c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39437134502923976"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fbaf411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuOUlEQVR4nO3deXxU5fX48c9J2HcICVuAhLDvYEAWWastLhVRFLC2WBeK21dqW8X662Lbbyt+q0VbLaLgrqggqLiVyqIiCGFfwxJBAkhC2Akkmcz5/TE3cYwJmWxzZzLn/XrllZln7jNzhuWec5/73OeKqmKMMSbyRLkdgDHGGHdYAjDGmAhlCcAYYyKUJQBjjIlQlgCMMSZCWQIwxpgIFVACEJExIpIqIntEZPoFthsgIvkiMt6vba6IZIjI1iLbNhORJSKy2/ndtPxfwxhjTFmVmgBEJBp4Crgc6A5MEpHuJWw3A/i4yEsvAGOKeevpwCeq2gn4xHlujDEmSGoEsM1AYI+qpgGIyDxgLLC9yHb3AAuAAf6NqvqpiCQU875jgZHO4xeB5cADFwqkefPmmpBQ3FsZY4wpybp1646qamzR9kASQBvggN/zdOBi/w1EpA0wDhhNkQRwAS1U9TCAqh4WkbjSOiQkJJCSkhLg2xtjjAEQkf3FtQdyDkCKaSu6fsRM4AFVzS9jXKV/uMgUEUkRkZTMzMzKfntjjIlYgRwBpANt/Z7HA4eKbJMMzBMRgObAFSLiUdVFF3jfIyLSyqn+WwEZxW2kqrOB2QDJycm2cJExxlSSQI4A1gKdRCRRRGoBE4F3/TdQ1URVTVDVBGA+cGcpO3+c95jsPJ4MvFOWwI0xxlRMqQlAVT3A3fhm9+wA3lTVbSIyVUSmltZfRF4HVgFdRCRdRG51XnoEuExEdgOXOc+NMcYEiYTTctDJyclqJ4GNMaZsRGSdqiYXbbcrgY0xJkJZAjDGmAgVEQlg3f7jzFqx1+0wjDEmpEREAnhv0yEe+XAnn+6y6wiMMaZARCSA6Zd3pVNcA3711iaOnc11OxxjjAkJEZEA6tSM5omJ/TiZnccDCzYTTjOfjDGmqkREAgDo3roR94/pwpLtR5i39kDpHYwxppqLmAQAcMvQRC7p2Jw/vbedvZln3A7HGGNcFVEJICpKeOyGPtSuGcW0eRvJ9XjdDskYY1wTUQkAoEWjOjxybW+2HDzJzP/ucjscY4xxTcQlAIAxPVsycUBb/r1iL6vTstwOxxhjXBGRCQDgd1d1JyGmPve9sZGT2Xluh2OMMUEXsQmgfu0azJzQl4zTOTy0aItNDTXGRJyITQAAfdo24ZeXdWbx5sMs3HDQ7XCMMSaoIjoBAEwdkcTAhGb8/p1tfJ2V7XY4xhgTNBGfAKKjhMcn9EEEpr2xAU++TQ01xkSGiE8AAPFN6/GXa3qy/usTPLXMVg01xkQGSwCOsX3bMK5fG55cupt1+4+7HY4xxlQ5SwB+Hh7bg1aN6zDtjQ2cPm9TQ40x1ZslAD+N6tRk5oS+HDx+jj++u93tcIwxpkpZAigiOaEZd4/qyIL16SzefMjtcIwxpspYAijGPT/oRN+2Tfjt21s4dOKc2+EYY0yVCCgBiMgYEUkVkT0iMv0C2w0QkXwRGV9aXxHpKyKrRWSjiKSIyMCKfZXKUzM6iicm9iXfq9z35kbyvXaVsDGm+ik1AYhINPAUcDnQHZgkIt1L2G4G8HGAfR8FHlbVvsDvnecho31Mff5wdQ9Wpx3j2c/S3A7HGGMqXSBHAAOBPaqapqq5wDxgbDHb3QMsADIC7KtAI+dxYyDkBtyvvyieK3q15LH/pLIl/aTb4RhjTKUKJAG0AfzvoZjutBUSkTbAOGBWGfpOA/5PRA4AfwceDDjqIBER/jquFzH1a3PvGxvIzvW4HZIxxlSaQBKAFNNWdFB8JvCAquaXoe8dwC9VtS3wS2BOsR8uMsU5R5CSmZkZQLiVq0m9Wjw+oQ9fHT3LX97fEfTPN8aYqhJIAkgH2vo9j+f7wzXJwDwR2QeMB54WkWtK6TsZeNt5/Ba+4aLvUdXZqpqsqsmxsbEBhFv5hiQ1Z8qwDrz25dcs2X7ElRiMMaayBZIA1gKdRCRRRGoBE4F3/TdQ1URVTVDVBGA+cKeqLiql7yFghPN4NLC7ol+mKt33w870aN2IBxZsJuPUebfDMcaYCis1AaiqB7gb3+yeHcCbqrpNRKaKyNTy9HVevh14TEQ2AX8FppT/a1S92jWieWJiX7JzPfx6/ma8NjXUGBPmJJzuhJWcnKwpKSmuxvDy6v38btFW/vDj7vx8aKKrsRhjTCBEZJ2qJhdttyuBy+imi9vxg65x/O3Dnez85pTb4RhjTLlZAigjEWHG+N40qlOTe1/fyPm8ohOfjDEmPFgCKIfmDWrz9+t7k3rkNDM+2ul2OMYYUy6WAMppZJc4bh6SwPMr97FiV/CvTzDGmIqyBFAB0y/vSucWDfj1W5vIOpPjdjjGGFMmlgAqoE7NaJ6Y2I+T2Xk8sGAL4TSjyhhjLAFUULdWjbh/TBf+u+MIr685UHoHY4wJEZYAKsEtQxMZ1qk5f1q8jT0ZZ9wOxxhjAmIJoBJERQl/v74PdWtGM+2NDeR6vG6HZIwxpbIEUElaNKrDI9f1ZuvBUzy+ZJfb4RhjTKksAVSiH/VoyaSBbXnm072s2pvldjjGGHNBlgAq2e+u6k5iTH3ue3MjJ7Pz3A7HGGNKZAmgktWrVYOZE/uSeTqH3y6yqaHGmNBlCaAK9I5vwi8v68z7mw/z9vqDbodjjDHFsgRQRaaOSGJgYjN+/85W9meddTscY4z5HksAVSQ6SvjHhL5ERQnT3tiIJ9+mhhpjQoslgCrUpkld/ndcLzZ8fYJ/Lt3jdjjGmDBVVcvO16iSdzWFru7TmuU7M/jn0t0M79yci9o3czuk0h3ZBmvngNpRizFu++bUeVbuzaLr1b+iR99BlfrelgCC4OGxPVi7/xjT3tjIB/8zjIZ1arodUslUYfF9cGg91GnidjTGRLRzeflE53gYFSV4pPLvQGgJIAga1qnJzAl9uX7WKv7w7jYev6Gv2yGVLG05HFgNVz4GA25zOxpjIlK+V3nkwx08+9lXjOgcyz9v7EezKigc7RxAkFzUvhl3j+7E2+sP8t6mQ26HUzxVWP43aNQG+v3U7WiMiUhnczz84uUUnv3sK24eksCcyck0qqJRA0sAQfQ/ozvSr10THlq4hYMnzrkdzvelLYMDX8Kw+6BGbbejMSbiHDpxjvGzVrEsNZM/je3BH6/uQY3oqttNB/TOIjJGRFJFZI+ITL/AdgNEJF9ExgfSV0TucV7bJiKPlv9rhIca0VHMnNCXfK9y3xsbyfeG0FXCqrD8EWgUb9W/MS7YeOAEY59aSfqxbObePICfDU6o8s8sNQGISDTwFHA50B2YJCLdS9huBvBxIH1FZBQwFuitqj2Av1f424SB9jH1+ePVPfjyq2M88+let8P51t6lVv0b45LFmw8x4ZlV1KkZxdt3DmFE59igfG4gRwADgT2qmqaqucA8fDvuou4BFgAZAfa9A3hEVXMAVNW/X7U2/qJ4ruzVisf/s4st6SfdDqdI9X+T29EYEzFUlX9+spu7X9tArzaNWXTnUDq1aBi0zw8kAbQB/O91mO60FRKRNsA4YFYZ+nYGhonIlyKyQkQGFPfhIjJFRFJEJCUzMzOAcEOfiPC/43oS27A2987bQHaux92A9i6F9DUw/FdW/RsTJDmefO57cxOPLdnFuH5tePX2i4lpENz/f4EkACmmrejg9UzgAVUternahfrWAJoCg4DfAG+KyPe2V9XZqpqsqsmxscE5LAqGJvVq8dgNffgq6yx/XrzDvUAKZ/7EQ1+r/o0JhqwzOfzk2S9ZuOEgv/5hZx6/oQ+1a0QHPY5ArgNIB9r6PY8His5jTAbmOfvv5sAVIuIppW868Lb61kteIyJep2/1KPMDMCSpOVOGd+CZFWmM7BLLj3q0DH4Qez+B9LVw1T+gRq3gf74xEWbXkdPc+uJaMk7l8NSN/bmydyvXYgnkCGAt0ElEEkWkFjAReNd/A1VNVNUEVU0A5gN3quqiUvouAkYDiEhnoBZwtMLfKMz86rIu9GzTiOkLNpNx6nxwP7xg7L9xW6v+jQmCFbsyue7pLzif5+XNXwx2decPASQAVfUAd+Ob3bMDeFNVt4nIVBGZWp6+zstzgQ4ishXfyeHJGoF3T6lVI4qZE/pxLi+fX721CW8wp4bucar/Yb+y6t+YKvbSqn38/Pk1xDerxzt3DaVP2yZuh4SE0z43OTlZU1JS3A6jSryyej//b9FWfndVd269JLHqP1AVnrsUzmTAPessARhTRTz5Xv68eDsvrtrPpd3ieGJiP+rXDu4qPCKyTlWTi7bblcAh4icXt+PSbnHM+HAnOw5X/qJP37PnEziY4sz8sZ2/MVXh1Pk8bn0xhRdX7ef2YYk889PkoO/8L8QSQIgQEWZc15tGdWsybd7GKlv/G3DG/v8KjdtBnxur7nOMiWAHjmUz/t9fsHLPUR65thcPXdmd6KjiJka6xxJACIlpUJu/X9+b1COneeTDnVX3QXv+CwfXWfVvTBVZt/8Y1zy1km9OnuelWwYycWA7t0MqliWAEDOySxw3D0nghS/2sTy1Ci6OLpj338Sqf2OqwqINB5k0+0sa1qnBoruGMqRjc7dDKpElgBA0/fKudGnRkF+/tZmsMzmV++a7l/iq/2G/turfmErk9SqP/yeVaW9spH/7Jiy8cygdYhu4HdYFWQIIQXVqRvPEpL6cOp/HAws2U2kztfyr/75W/RtTWc7n5XPPvA08uXQPNyTH89ItF9O0fugXWJYAQlTXlo14YExX/rsjg1e//Lpy3nT3Et+tHof/BqJD+LaUxoSRjNPnmTB7NR9sOcxvr+jKjOt6U6tGeOxawyPKCPXzIQkM69Scv7y/nT0ZZyr2ZgUzf5q0gz6TKidAYyLc9kOnuOZfK9n1zWlm3XQRU4YnUcySZiHLEkAIi4oSHru+D3VrRnPvvA3kerzlf7Pd/4FDG6z6N6aSfLLjCNfP+gKvwltTB7uzllcFWQIIcXGN6jDjut5sO3SKx5aklu9NCsf+21v1b0wFqSrPfZbGbS+lkBTXgHfuHkrPNo3dDqtcLAGEgR/2aMmkge2Y/WkaX+wtx3p5uz626t+YSpCX7+W3C7fyl/d3MKZHS96YMpgWjeq4HVa5WQIIE7+7qhuJMfW5741NnMjODbxjQfXfNAH6TKyy+Iyp7k5m5zF57hpeX/M1d41K4qkb+1O3VvDX8K9MlgDCRL1aNXhiYj+Onsnhtwu3BD41dNfHcHijVf/GVMC+o2cZ9/RK1u47xmPX9+E3P+pKVIgt61AelgDCSK/4xtz3w858sOUb5q9LL72Df/Xfe0KVx2dMdbQ6LYtrnl7J8excXr1tENddFO92SJXGEkCY+cXwJC5ObMYf393G/qyzF95410dW/RtTAW+mHOCnc74kpn4tFt01lIGJzdwOqVJZAggz0VHCPyb0JTpKuHfeRvLyS5gaWlj9J0JvG/s3piy8XuVvH+7g/vmbGdQhhrfvHEr7mPpuh1XpLAGEodZN6vLXa3ux8cAJ/rl0T/EbpX4Ihzc51X/orD9uTKjLzvUw9ZV1PLMijZ9c3I65Nw+gcd3qeQRte4YwdVXv1izdmcG/lu5meKfmJCf4HZp+p/q3sX9jAvXNyfPc+uJadhw+xR9+3J2bhySE1ZW9ZWVHAGHs4at70KZpXaa9sZHT5/O+fSH1Q/hmM4y436p/YwK0Jf0kY5/6nP1Z2cyZPICfD02s1jt/sAQQ1hrWqcnMCf04fPI8f3hnm6/Rv/rvdYO7ARoTJj7aepjrn/mCGlFRzL9jMKO6xrkdUlBYAghzF7Vvyt2jOvL2hoO8u+kQpH5g1b8xAVJVnl6+h6mvrKdbq0YsumsoXVs2cjusoAkoAYjIGBFJFZE9IjL9AtsNEJF8ERkfaF8R+bWIqIiE7m1zQtw9ozvSr10THlq4mdxP/grNOlj1b0wpcj1efjN/M49+lMrVfVrz+u2DiG1Y2+2wgqrUBCAi0cBTwOVAd2CSiHQvYbsZwMeB9hWRtsBlQCUteB+ZakRH8cSEfoz0rqVW5la8w2zmjzEXcuxsLjfN+ZL569L55aWdeWJiX+rUDO9lHcojkCOAgcAeVU1T1VxgHjC2mO3uARYAGWXo+w/gfqCSbnkVudo1q8ufmywmzduSWcf7ux2OMSFrT8YZxj29ko0HTvDkpH7ce2mnan+ytySBJIA2wAG/5+lOWyERaQOMA2YF2ldErgYOquqmMsZsirNzMU1O7eSz1j/n8f+msTn9hNsRGRNyPt99lHFPr+Rsjod5UwZxdZ/WbofkqkASQHGpsWjFPhN4QFXzA+krIvWAh4Dfl/rhIlNEJEVEUjIzMwMINwJ5vbB8BjRL4pqb7iW2YW3unbeR7FyP25EZEzJe/XI/k59fQ+vGdVl011D6t2vqdkiuCyQBpANt/Z7HA4eKbJMMzBORfcB44GkRueYCfZOARGCT0yceWC8i37uljqrOVtVkVU2OjY0N5DtFntT34cgWGHE/jRvU5fEb+rIv6yx/Xrzd7ciMcV2+V/nTe9t5aOFWhndqzvw7BhPftJ7bYYWEQM4UrgU6iUgicBCYCNzov4GqJhY8FpEXgMWqukhEahTXV1W3AXF+ffYByapajrudRDivF5Y/AjEdoadv8tXgpBh+MTyJWSv2MqJzHGN6ht+t6oypDGdyPPzP6xtYujODW4Ym8tCV3YiuBss4V5ZSE4CqekTkbnyze6KBuaq6TUSmOq8XHfcvtW/lhG4A2LkYjmyFcbO/M/Pnvss68/meTKa/vZl+7ZqE9V2LQtWp83msSTvGqrQs0o9nM6hDDKO7xlXLRcPCUfrxbG57MYXdGWf4yzU9uWlQe7dDCjkS8I1FQkBycrKmpKS4HUbo8HrhmWHgOQ93fvm9qZ97M89w5ZOfMSChGS/+fGC1uIGFm87meFi7z7fDX703iy0HT+JVqFUjiriGtUk/fg6ADs3rM6prHKO6xDEgsSm1a0Te9EK3bfj6OLe/tI4cTz5P/6Q/wzpF9vCxiKxT1eSi7TZZPJztfM9X/V/7bLHz/pNiG/D7q3rw24VbmLvyK24b1sGFIMPX+bx81u8/zhd7s1iVlsWmAyfweJWa0ULftk24e3QnBneIoV+7JtSpGc3+rLMs25nBstRMXl69nzmff0X9WtEM7di8MCG0bGxHYlXtvU2H+NVbm2jZqA7zpgyiY1wDt0MKWXYEEK68Xph1CeTnwF1rIKr4KlNVmfLyOlakZrLorqF0bx05l7mXVa7Hy8YDJ1i1N4tVaUdZ//UJcj1eoqOEXm0aMzgphsEdYkhOaEq9WheunbJzPazam8XSnRks25nBoZPnAejWqhGju8Yyqksc/do1tfHoSqSqPPnJHv7x310MTGjGrJ9eRLP6tdwOKySUdARgCSBcbX8H3vyZr/rvfeFlH7LO5DDmic9oWq8m7959SURe8VgcT76XLQdP8sXeLFanZZGy7zjn8vIRgR6tGzG4QwyDk2IYkNCMhnXKvx68qrLryBmWpWawdGcG6/YfJ9+rNKlXk+GdYhndNY7hnWNtZ1UB5/PyuX/+Zt7ddIjr+sfz12t72tCbH0sA1YnXC7OGQn4e3PVlidW/vxW7Mpk8dw03D0ngj1f3CEKQoSffq+w4fIpVe7P4Yu9R1u47zpkc37USXVo09FX4STFcnNiMJvWqbmd88lwen+3OZNnOTFbsyuDomVxEoF/bJozqEseornH0aN0oYq9OLavM0zn84uUU1n99gvvHdOGOEUn2Z1eEnQOoTna8Cxnb4drnAtr5A4zoHMvPhybw/Mp9jOgcGxHL3Xq9yq6M074hHafKP3Xet8PvEFufsX1bMySpORd3aEbzBsFbBKxx3Zpc1bs1V/VujderbDl4kmWpvqGix5bs4rElu4hrWNtJBrFc0imWBrXtv2pxUr85zS0vrCXrbA6zburPmJ6t3A4prNgRQLgpqP69HrhzdcAJAHyHyWP/tZKsszl8NG14UHd6waCqpB096xvScXb4WWdzAWjXrF7hkM7gpJiQnRabeTqHFbsyWZaawae7Mjl93kPNaGFAQjNGd41jZJc4kmLrW4ULLEvN4J7XNlCvVjRzJg+gV3xjt0MKWTYEVF1sWwhv3QzXzYFe40vdvKid35zi6n+tZFjH5jw3OTmsdySqyoFj51iVdtQ3U2dvFhmncwBo1bhO4UnbwUkxYXnlZ16+l/X7j7M0NYPlOzNJPXIa8CWzUV1iGdk1jsEdYiLunI6q8sIX+/jz4u10a9WI5yYn06pxXbfDCmmWAKoDrxf+PQQ0v8zVv7/nV37Fw+9t58/X9OSnYXZxzKET55xZOr4d/sETvrn3zRvUZnBSDEOcnX77mHphndyKk348m+WpmSzbmcHKvUc5n+elTs0ohiQVTDONDctEVxaefC8Pv7edl1fv54fdW/CPCX2pb8NjpbJzANXBjncgc4ev+i/nzh/g5iEJLEvN5C+LtzO4QzM6xjWsxCArV8bp84Xj96v2ZrEvKxuApvVqMqhDDL8Y0YEhSTEkxTaodjv8ouKb1uOmQe25aVB7zuflszoti+WpmSzd6ZtdBNC5RYPCE8kXtW9Kzejqc9O/k+fyuPu19Xy2+yi/GNGBB37U1S5urCA7AggXhdW/F+5cVaEEAJBx6jxjnviMlo3qsPCuISEzZe7Y2Vy+TMsqvPhqT8YZABrWqcHFiTGFwzpdWza0//yOgnMfvovQMljz1THy8pWGdWowvFMsI7vEMrJLXFjf7errrGxueXEt+46e5a/jenHDgLaldzKF7Agg3G1fVCnVf4G4RnWYcV1vbn8phcf/s4sHr+hW8RjL4eS5PNZ8daxwaubOb3zj3PVqRTMgoRnXXxTP4KQYerRubBdNlUBESIptQFJsA24b1oEzOR4+332U5am+hPD+lsMA9I5vXHh00LtN47BJoGv3HeMXL6/Dq8rLt17M4KQYt0OqNuwIIBx4vfDvwaBaKdW/v98u3MJrX37Nq7ddzNCOVX9b5rM5HtbsO8Zqp8Lf6qynU7tGFMkJTZ2Tts3pHd+4Wg1fuEVV2X74VOESFRu+Po5XIaZ+LUZ08V2RPLxzLI3rlv9Ct6q0YF06D769hfimdZlz8wASm9tCe+VhJ4HD2dYFMP8WGD8Xel5XqW+dnevhqn9+TnZOPh9NG1bpF0Cdz8tn3f7jfLH3KKv2ZrE5/SQer1IrOoq+7ZoUztLp165JyAxDVWfHz+by6W7fieTluzI5kZ1HdJRwUbumvhPJXWPp0qKh6+dTvF7l8SW7+NeyPQxJiuHfP7mIxvVCM0mFA0sA4cqb7xv7B7jji0qt/gtsPXiScU+v5NJuLXj6J/0r9J8/x5PPxq9PsMoZx9/49Qly833r6fSJL1hPpzkXtW9K3Vq2w3dTvlfZeOBE4bmDbYdOAdC6cR1Gdo1jdJc4hnSMKXXdo8p2LjefX721kQ+2fMOkgW3509iedjRYQZYAwlUVVv/+/r18LzM+2smj43tzQ3LgJ9jynPV0Cq62Tdl/jPN5XkSgZ+vGDEmKYZCzno5dzRrajpw6z3JnvaLPdx/lbG4+tWpEMahDDKO6xAblXgcZp85z20spbDl4koeu6MatlyS6fjRSHVgCCEfefHh6MIjAHasgquqqoHyv8pPnVrM5/SQf/M8wEkoYa833KtsPnSq8+GrtV8c4m+u7FXTXlg2dufjNGZjYLGTHlU3pcj1e1u47xrKdGSxNzSAt8yxQtfc62HboJLe9mMLJc3k8ObEfl3ZvUWnvHeksAYSjLfNhwa0w/nnoeW2Vf9yhE+cYM/NTOsQ24K2pg6kZHYXXq6QeOe3M0slizVffrqfTMa5B4Rj+xYnNiKlmS0uYb/nf62BVWha5Hm+l3utgyfYj3DtvA03q1uS5yQNs2fJKZgkg3BRW/1HO2H9wxkDf33yYu15bz1W9W+FVZXXaMY456+m0j/FbT6dDDHEhup6OqVrncvP5Yu9RZwG7zMKrsctzrwNV5dnP0vjbhzvp3aYxz/4s2f5dVQG7DiDcbFsIR1Ph+heCtvMHuLJ3K5anxvPWunTaNKnLqC5xvuUVkmJo3cTWWzFQt1Y0P+jWgh90a4GqsjvjTOGNb2atSOOpZXsDutdBrsfL7xZt5Y2UA1zZqxWP3dAn4tY1cpsdAYQibz48PQgkOqjVfwFPvpfMMzm0bFTHTsCZMjl5Lo/Pdx9l6c6MC97r4OS5PKa+so7Vace4Z3RHfnlp57C5MC0c2RBQOCkY+7/+Begxzu1ojCmXovc62JR+EoC4hrWpGR1F5ukcZozvxbh+8S5HWv1ZAggXBdV/VA2YujLo1b8xVcX/Xgfpx8/xuyu7kZzQzO2wIkJJCSCgvYuIjBGRVBHZIyLTL7DdABHJF5HxpfUVkf8TkZ0isllEFopIkzJ+p+pp69twdBeMeMB2/qZaiW1Ym/EXxfPUjf15566htvMPAaXuYUQkGngKuBzoDkwSke4lbDcD+DjAvkuAnqraG9gFPFixr1INePNhxQyI6wHdrnY7GmNMNRdIiTkQ2KOqaaqaC8wDxhaz3T3AAiAjkL6q+h9V9TjbrQZsIHDrAsjaDSOt+jfGVL1A9jJtgAN+z9OdtkIi0gYYB8wqa1/HLcCHAcRSfflX/11/7HY0xpgIEEgCKG5uVtEzxzOBB1Q1v6x9ReQhwAO8WuyHi0wRkRQRScnMzAwg3DC1dQFk7bHq3xgTNIFcCJYO+K8OFg8cKrJNMjDPmTPeHLhCRDyl9RWRycBVwA+0hOlIqjobmA2+WUABxBt+8j2+6r9FT6v+jTFBE0gCWAt0EpFE4CAwEbjRfwNVTSx4LCIvAItVdZGI1Cipr4iMAR4ARqhqdiV8l/BVUP3f8LJV/8aYoCk1AaiqR0Tuxje7JxqYq6rbRGSq83rRcf9S+zov/wuoDSxxjhxWq+rUCn2bcJTvgU8fdar/q9yOxhgTQQJaC0hVPwA+KNJW7I5fVW8ura/T3jHgKKuzrfN91f+EV6z6N8YEle1x3JTvgRWPQote0OVKt6MxxkQYWw3UTVvnw7G9Vv0bY1xhex23FMz8adnLxv6NMa6wIwC3bHkLjqXBhFd9t3w0xpggsyMANxTM/GnZC7ra2L8xxh12BOCGLW/6qv+Jr1n1b4xxjR0BBFvBzJ+WvaDLFW5HY4yJYHYEEGyb34DjX1n1b4xxnR0BBFO+Bz79P2jZ26p/Y4zr7AggmAqr/9et+jfGuM6OAIIlP88386dVH+hyudvRGGOMHQEEzeY34Pg+mDTPqn9jTEiwI4BgyM/zjf236gOdx7gdjTHGAHYEEByb5ln1b4wJOXYEUNUKq/++Vv0bY0KKJYCqtmkenNgPIx+06t8YE1IsAVSlguq/dT/o/CO3ozHGmO+wBFCVNr1u1b8xJmRZAqgq/tV/px+6HY0xxnyPJYCqsvE1OPG1Vf/GmJBlCaAqeHLhs79D6/5W/RtjQlZACUBExohIqojsEZHpF9hugIjki8j40vqKSDMRWSIiu53fTSv2VULIptet+jfGhLxSE4CIRANPAZcD3YFJItK9hO1mAB8H2Hc68ImqdgI+cZ6HP08ufPp3aHMRdLrM7WiMMaZEgRwBDAT2qGqaquYC84CxxWx3D7AAyAiw71jgRefxi8A1ZQ8/BG16DU5a9W+MCX2BJIA2wAG/5+lOWyERaQOMA2aVoW8LVT0M4PyOCzzsEOXJhU8f81X/HS91OxpjjLmgQBJAcWWsFnk+E3hAVfPL0ffCHy4yRURSRCQlMzOzLF2Db+OrVv0bY8JGIIvBpQNt/Z7HA4eKbJMMzBPfTq85cIWIeErpe0REWqnqYRFpxXeHjgqp6mxgNkBycnKZkkdQeXLhs8egTbJV/8aYsBDIEcBaoJOIJIpILWAi8K7/BqqaqKoJqpoAzAfuVNVFpfR9F5jsPJ4MvFPRL+Oqja/CyQNW/RtjwkapRwCq6hGRu/HN7okG5qrqNhGZ6rxedNy/1L7Oy48Ab4rIrcDXwPUV+you+k71/wO3ozHGmIAEdD8AVf0A+KBIW7E7flW9ubS+TnsWUD32lhtf8VX/P55p1b8xJmzYlcAVVTDzJ34AJFWPfGaMiQyWACpqw8twKh1GTrfq3xgTViwBVIQnBz57HOIHWvVvjAk7lgAqYsMrVv0bY8KWJYDy8uT4Zv7ED4Sk0W5HY4wxZWYJoLw2vAynDsIom/dvjAlPlgDKo2Dsv+3F0GGU29EYY0y5WAIoj/Uv+ap/G/s3xoQxSwBlVVj9D7Lq3xgT1iwBlNX6l+D0Iav+jTFhzxJAWeSd96v+R7odjTHGVIglgLLY8LKv+reZP8aYasASQKAKqv92gyFxhNvRGGNMhVkCCJSN/RtjqhlLAIHIOw+fPw7thlj1b4ypNiwBBGL9S3D6sFX/xphqxRJAab5T/Q93OxpjjKk0Ad0RLKKtf9FX/V8726p/Y0y1YkcAF5J3zjfzp/1QSBjmdjTGGFOpLAFcyLoX4cw3NvZvjKmWLAGUJO8cfP4PaH+Jjf0bY6olOwdQknUv+Kr/655zOxJjjKkSAR0BiMgYEUkVkT0iMr2Y18eKyGYR2SgiKSJyid9r94rIVhHZJiLT/Nr7ishqvz4DK+UbVYbvVP829m+MqZ5KTQAiEg08BVwOdAcmiUj3Ipt9AvRR1b7ALcBzTt+ewO3AQKAPcJWIdHL6PAo87PT5vfM8NKx7Ac4c8Y39G2NMNRXIEcBAYI+qpqlqLjAPGOu/gaqeUVV1ntYHCh53A1araraqeoAVwLiCbkAj53Fj4FD5v0YlKqj+E4ZZ9W+MqdYCOQfQBjjg9zwduLjoRiIyDvgbEAdc6TRvBf5XRGKAc8AVQIrz2jTgYxH5O75ENKQc8Ve+lOd91f/4uW5HYowxVSqQI4Di5j/q9xpUF6pqV+Aa4M9O2w5gBrAE+AjYBHicLncAv1TVtsAvgTnFfrjIFOccQUpmZmYA4VZA3jlYOdNX/SdcUurmxhgTzgJJAOlAW7/n8VxguEZVPwWSRKS583yOqvZX1eHAMWC3s+lk4G3n8Vv4hpqKe7/ZqpqsqsmxsbEBhFsBKXNt7N8YEzECSQBrgU4ikigitYCJwLv+G4hIRxHflVIi0h+oBWQ5z+Oc3+2Aa4HXnW6HgIKlNUfzbWJwR242fD7Tqn9jTMQo9RyAqnpE5G7gYyAamKuq20RkqvP6LOA64GcikodvrH+C30nhBc45gDzgLlU97rTfDjwhIjWA88CUyvxiZbbueTibAde/4GoYxhgTLPLtfjr0JScna0pKSukbllVuNjzRB+K6wuT3Kv/9jTHGRSKyTlWTi7bblcDgG/s/mwEjX3Q7EmOMCRpbCyg32zfzJ3EEtA+NmajGGBMMlgBS5sDZTJv5Y4yJOJGdAHLPwsonrPo3xkSkyE4AKXOd6v9BtyMxxpigi9wEkHvWN++/w0hoP9jtaIwxJugiNwGsnQPZR636N8ZErMhMAAVj/x1GQbtBbkdjjDGuiMwEsPY5q/6NMREv8hJAQfWfNBrafW9Va2OMiRiRlwDWPgfZWTDC5v0bYyJbZCWAnDNW/RtjjCOyEkBB9W9j/8YYE0EJIOcMfPEkJP0A2hZ77xljjIkokZMA1j5r1b8xxviJjASQcwZWPgkdL4W2A9yOxhhjQkJkJIC1z8K5Yzbzxxhj/ERGAmjQAvrdZNW/Mcb4iYw7gvW90fdjjDGmUGQcARhjjPkeSwDGGBOhLAEYY0yECigBiMgYEUkVkT0i8r2pNCIyVkQ2i8hGEUkRkUv8XrtXRLaKyDYRmVak3z3O+24TkUcr/G2MMcYErNSTwCISDTwFXAakA2tF5F1V3e632SfAu6qqItIbeBPoKiI9gduBgUAu8JGIvK+qu0VkFDAW6K2qOSISV7lfzRhjzIUEcgQwENijqmmqmgvMw7fjLqSqZ1RVnaf1gYLH3YDVqpqtqh5gBTDOee0O4BFVzXHeI6NiX8UYY0xZBJIA2gAH/J6nO23fISLjRGQn8D5wi9O8FRguIjEiUg+4AmjrvNYZGCYiX4rIChGxSfrGGBNEgSQAKaZNv9egulBVuwLXAH922nYAM4AlwEfAJsDjdKkBNAUGAb8B3hSR732WiExxziukZGZmBhCuMcaYQARyIVg631btAPHAoZI2VtVPRSRJRJqr6lFVnQPMARCRvzrvV/C+bztDR2tExAs0BzKLvN9sYLbTP1NE9gf21SqsOXA0SJ9VmcIx7nCMGSzuYArHmCF04m5fXGMgCWAt0ElEEoGDwETgO5fVikhHYK9zErg/UAvIcl6LU9UMEWkHXAsMdrotAkYDy0Wks9Pngn9QqhobQLyVQkRSVDU5WJ9XWcIx7nCMGSzuYArHmCH04y41AaiqR0TuBj4GooG5qrpNRKY6r88CrgN+JiJ5wDlggt9J4QUiEgPkAXep6nGnfS4wV0S24pshNNmvjzHGmCoW0FpAqvoB8EGRtll+j2fgG+svru+wEtpzgZsCjtQYY0ylsiuBSzbb7QDKKRzjDseYweIOpnCMGUI8brFRF2OMiUx2BGCMMREqYhKAiMwVkQznpHNBWzMRWSIiu53fTf1ee9BZ+yhVRH7k136RiGxxXnuyuGsXKjnutiKyTER2OGsm3RvqsYtIHRFZIyKbnJgfDvWYi8QfLSIbRGRxuMQtIvucz9soIinhELeINBGR+SKy0/n3PTgMYu7i/BkX/JwSkWmhHneJVDUifoDhQH9gq1/bo8B05/F0YIbzuDu+i9ZqA4nAXiDaeW0NvqmsAnwIXF7FcbcC+juPGwK7nPhCNnbn/Rs4j2sCX+K74C9kYy4S/33Aa8DiMPp3sg9oXqQtpOMGXgRucx7XApqEesxF4o8GvsE3xz5s4v7Odwj2B7r5AyTw3QSQCrRyHrcCUp3HDwIP+m33sfMX1QrY6dc+CXgmyN/hHXwL84VF7EA9YD1wcTjEjO9Cx0/wXaNSkADCIe59fD8BhGzcQCPgK5zzkOEQczHf4YfAynCL2/8nYoaAStBCVQ8DOL8LViQtaf2jNnx7JbN/e1CISALQD19FHdKxO8MoG4EMYImqhnzMjpnA/YDXry0c4lbgPyKyTkSmOG2hHHcHfFf9P+8Mtz0nIvVDPOaiJgKvO4/DKe5CkZ4ASlLS+kcBrYtUFUSkAbAAmKaqpy60aTFtQY9dVfNVtS++inqg+JYGL0lIxCwiVwEZqrou0C7FtLn172SoqvYHLgfuEpHhF9g2FOKugW9I9t+q2g84i2/opCShEHMhEakFXA28VdqmxbS5ui/xF+kJ4IiItAJwfhcsSV3S+kfpzuOi7VVKRGri2/m/qqpvO81hEbuqngCWA2MI/ZiHAleLyD58y56PFpFXwiBuVPWQ8zsDWIhvGfdQjjsdSHeODAHm40sIoRyzv8uB9ap6xHkeLnF/R6QngHeByc7jyfjG1wvaJ4pIbfGtgdQJWOMc2p0WkUHOGfuf+fWpEs7nzAF2qOrj4RC7iMSKSBPncV3gUmBnKMcMoKoPqmq8qibgO7xfqqo3hXrcIlJfRBoWPMY3Nr01lONW1W+AAyLSxWn6AbA9lGMuYhLfDv8UxBcOcX9XsE86uPWD7y/rML41idKBW4EYfCf8dju/m/lt/xC+M/ap+J2dB5Lx/efaC/yLIiexqiDuS/AdGm4GNjo/V4Ry7EBvYIMT81bg9057yMZczHcYybcngUM6bnzj6Zucn23AQ2ESd18gxfl3sgjf8vAhHbPzefXwLXbZ2K8t5OMu7seuBDbGmAgV6UNAxhgTsSwBGGNMhLIEYIwxEcoSgDHGRChLAMYYE6EsARhjTISyBGCMMRHKEoAxxkSo/w8DKy5lQMcAIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(svm, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da1596",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8063069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(8, )))\n",
    "#     for i in range(hp.Int(\"n_layers\", 1, 3)):\n",
    "    model.add(Dense(hp.Int(\"n_neurons\", 64, 208, 16), activation=\"softmax\"))\n",
    "    model.add(Dense(5, activation=\"softmax\"))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-3, 1e-4, 1e-5])\n",
    "    hp_beta_1 = hp.Choice(\"beta_1\", values=[0.9, 0.85, 0.95])\n",
    "    hp_beta_2 = hp.Choice(\"beta_2\", values=[0.999, 0.99, 0.9999])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate, beta_1=hp_beta_1, beta_2=hp_beta_2), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27666ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_a(act=\"softmax\", opt=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(208, activation=act, input_shape=(8, )))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81a7ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_b(act=\"softmax\", opt=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(96, activation=act, input_shape=(8, )))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddf4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_c(act=\"softmax\", opt=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.95, beta_2=0.99)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(196, activation=act, input_shape=(8, )))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853f672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 Complete [00h 01m 24s]\n",
      "val_accuracy: 0.41184258460998535\n",
      "\n",
      "Best val_accuracy So Far: 0.5853893160820007\n",
      "Total elapsed time: 02h 56m 46s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10)\n",
    "tuner = RandomSearch(build_model, objective=\"val_accuracy\", max_trials=100, project_name=\"no_back\", overwrite=False)\n",
    "tuner.search(x=X_train, y=y_train, epochs=120, batch_size=10, validation_data=(X_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e43bf94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\no_back\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 192\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.5853893160820007\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 208\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "Score: 0.5838247537612915\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 96\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "Score: 0.5831026434898376\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 128\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.9999\n",
      "Score: 0.5826212763786316\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 112\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "Score: 0.5797328352928162\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 96\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "Score: 0.5793717503547668\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 80\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.578649640083313\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 160\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "Score: 0.5781682729721069\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 64\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.5768443942070007\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 192\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.85\n",
      "beta_2: 0.99\n",
      "Score: 0.5760019421577454\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72cec58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "140491e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59653f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.4723 - accuracy: 0.4008 - val_loss: 1.4240 - val_accuracy: 0.4132\n",
      "Epoch 2/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4116 - accuracy: 0.4149 - val_loss: 1.4121 - val_accuracy: 0.4132\n",
      "Epoch 3/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4051 - accuracy: 0.4149 - val_loss: 1.4113 - val_accuracy: 0.4132\n",
      "Epoch 4/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3962 - accuracy: 0.4150 - val_loss: 1.3879 - val_accuracy: 0.4135\n",
      "Epoch 5/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3735 - accuracy: 0.4191 - val_loss: 1.3587 - val_accuracy: 0.4253\n",
      "Epoch 6/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3458 - accuracy: 0.4352 - val_loss: 1.3298 - val_accuracy: 0.4455\n",
      "Epoch 7/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3184 - accuracy: 0.4523 - val_loss: 1.3134 - val_accuracy: 0.4748\n",
      "Epoch 8/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2946 - accuracy: 0.4592 - val_loss: 1.2828 - val_accuracy: 0.4710\n",
      "Epoch 9/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2761 - accuracy: 0.4641 - val_loss: 1.2955 - val_accuracy: 0.4707\n",
      "Epoch 10/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2599 - accuracy: 0.4675 - val_loss: 1.2514 - val_accuracy: 0.4757\n",
      "Epoch 11/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2477 - accuracy: 0.4726 - val_loss: 1.2403 - val_accuracy: 0.4834\n",
      "Epoch 12/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2366 - accuracy: 0.4840 - val_loss: 1.2468 - val_accuracy: 0.4932\n",
      "Epoch 13/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2291 - accuracy: 0.4921 - val_loss: 1.2241 - val_accuracy: 0.4994\n",
      "Epoch 14/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2208 - accuracy: 0.4964 - val_loss: 1.2218 - val_accuracy: 0.5036\n",
      "Epoch 15/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2167 - accuracy: 0.4986 - val_loss: 1.2163 - val_accuracy: 0.5095\n",
      "Epoch 16/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2153 - accuracy: 0.4980 - val_loss: 1.2077 - val_accuracy: 0.5190\n",
      "Epoch 17/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2095 - accuracy: 0.5083 - val_loss: 1.2027 - val_accuracy: 0.5163\n",
      "Epoch 18/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2006 - accuracy: 0.5099 - val_loss: 1.2047 - val_accuracy: 0.5207\n",
      "Epoch 19/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1933 - accuracy: 0.5127 - val_loss: 1.1869 - val_accuracy: 0.5216\n",
      "Epoch 20/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1885 - accuracy: 0.5162 - val_loss: 1.1840 - val_accuracy: 0.5124\n",
      "Epoch 21/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1846 - accuracy: 0.5157 - val_loss: 1.1742 - val_accuracy: 0.5350\n",
      "Epoch 22/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1791 - accuracy: 0.5208 - val_loss: 1.1762 - val_accuracy: 0.5178\n",
      "Epoch 23/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1733 - accuracy: 0.5220 - val_loss: 1.1790 - val_accuracy: 0.5320\n",
      "Epoch 24/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1700 - accuracy: 0.5229 - val_loss: 1.1628 - val_accuracy: 0.5418\n",
      "Epoch 25/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1689 - accuracy: 0.5246 - val_loss: 1.1663 - val_accuracy: 0.5270\n",
      "Epoch 26/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1660 - accuracy: 0.5278 - val_loss: 1.1641 - val_accuracy: 0.5264\n",
      "Epoch 27/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1658 - accuracy: 0.5245 - val_loss: 1.1670 - val_accuracy: 0.5353\n",
      "Epoch 28/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1581 - accuracy: 0.5305 - val_loss: 1.1604 - val_accuracy: 0.5388\n",
      "Epoch 29/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1586 - accuracy: 0.5273 - val_loss: 1.1507 - val_accuracy: 0.5400\n",
      "Epoch 30/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1554 - accuracy: 0.5325 - val_loss: 1.1525 - val_accuracy: 0.5365\n",
      "Epoch 31/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1519 - accuracy: 0.5315 - val_loss: 1.1571 - val_accuracy: 0.5539\n",
      "Epoch 32/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1555 - accuracy: 0.5278 - val_loss: 1.1599 - val_accuracy: 0.5362\n",
      "Epoch 33/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1533 - accuracy: 0.5286 - val_loss: 1.1479 - val_accuracy: 0.5495\n",
      "Epoch 34/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1477 - accuracy: 0.5308 - val_loss: 1.1440 - val_accuracy: 0.5477\n",
      "Epoch 35/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1442 - accuracy: 0.5332 - val_loss: 1.1567 - val_accuracy: 0.5406\n",
      "Epoch 36/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1465 - accuracy: 0.5336 - val_loss: 1.1379 - val_accuracy: 0.5427\n",
      "Epoch 37/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1389 - accuracy: 0.5383 - val_loss: 1.1377 - val_accuracy: 0.5486\n",
      "Epoch 38/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1388 - accuracy: 0.5348 - val_loss: 1.1391 - val_accuracy: 0.5519\n",
      "Epoch 39/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1373 - accuracy: 0.5348 - val_loss: 1.1385 - val_accuracy: 0.5522\n",
      "Epoch 40/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1357 - accuracy: 0.5382 - val_loss: 1.1346 - val_accuracy: 0.5563\n",
      "Epoch 41/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1352 - accuracy: 0.5362 - val_loss: 1.1444 - val_accuracy: 0.5486\n",
      "Epoch 42/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1340 - accuracy: 0.5390 - val_loss: 1.1809 - val_accuracy: 0.5175\n",
      "Epoch 43/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1359 - accuracy: 0.5376 - val_loss: 1.1335 - val_accuracy: 0.5525\n",
      "Epoch 44/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1288 - accuracy: 0.5452 - val_loss: 1.1289 - val_accuracy: 0.5554\n",
      "Epoch 45/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1269 - accuracy: 0.5453 - val_loss: 1.1256 - val_accuracy: 0.5566\n",
      "Epoch 46/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1255 - accuracy: 0.5439 - val_loss: 1.1573 - val_accuracy: 0.5329\n",
      "Epoch 47/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1245 - accuracy: 0.5451 - val_loss: 1.1220 - val_accuracy: 0.5560\n",
      "Epoch 48/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1248 - accuracy: 0.5428 - val_loss: 1.1464 - val_accuracy: 0.5433\n",
      "Epoch 49/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1240 - accuracy: 0.5439 - val_loss: 1.1378 - val_accuracy: 0.5525\n",
      "Epoch 50/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1202 - accuracy: 0.5483 - val_loss: 1.1235 - val_accuracy: 0.5619\n",
      "Epoch 51/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1194 - accuracy: 0.5499 - val_loss: 1.1539 - val_accuracy: 0.5465\n",
      "Epoch 52/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1278 - accuracy: 0.5387 - val_loss: 1.1459 - val_accuracy: 0.5400\n",
      "Epoch 53/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1221 - accuracy: 0.5448 - val_loss: 1.1224 - val_accuracy: 0.5640\n",
      "Epoch 54/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1160 - accuracy: 0.5487 - val_loss: 1.1267 - val_accuracy: 0.5572\n",
      "Epoch 55/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1170 - accuracy: 0.5504 - val_loss: 1.1476 - val_accuracy: 0.5439\n",
      "Epoch 56/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1142 - accuracy: 0.5501 - val_loss: 1.1179 - val_accuracy: 0.5697\n",
      "Epoch 57/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1088 - accuracy: 0.5557 - val_loss: 1.1187 - val_accuracy: 0.5619\n",
      "Epoch 58/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1112 - accuracy: 0.5535 - val_loss: 1.1915 - val_accuracy: 0.5083\n",
      "Epoch 59/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1091 - accuracy: 0.5538 - val_loss: 1.1179 - val_accuracy: 0.5714\n",
      "Epoch 60/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1076 - accuracy: 0.5527 - val_loss: 1.1498 - val_accuracy: 0.5412\n",
      "Epoch 61/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1146 - accuracy: 0.5525 - val_loss: 1.1211 - val_accuracy: 0.5575\n",
      "Epoch 62/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1104 - accuracy: 0.5505 - val_loss: 1.1091 - val_accuracy: 0.5714\n",
      "Epoch 63/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1062 - accuracy: 0.5548 - val_loss: 1.1076 - val_accuracy: 0.5735\n",
      "Epoch 64/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1042 - accuracy: 0.5554 - val_loss: 1.1080 - val_accuracy: 0.5732\n",
      "Epoch 65/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1075 - accuracy: 0.5544 - val_loss: 1.1223 - val_accuracy: 0.5608\n",
      "Epoch 66/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1074 - accuracy: 0.5537 - val_loss: 1.1073 - val_accuracy: 0.5705\n",
      "Epoch 67/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1111 - accuracy: 0.5539 - val_loss: 1.1230 - val_accuracy: 0.5578\n",
      "Epoch 68/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1041 - accuracy: 0.5561 - val_loss: 1.1240 - val_accuracy: 0.5711\n",
      "Epoch 69/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1033 - accuracy: 0.5590 - val_loss: 1.1088 - val_accuracy: 0.5723\n",
      "Epoch 70/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1081 - accuracy: 0.5562 - val_loss: 1.1286 - val_accuracy: 0.5611\n",
      "Epoch 71/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1042 - accuracy: 0.5588 - val_loss: 1.1067 - val_accuracy: 0.5682\n",
      "Epoch 72/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1025 - accuracy: 0.5576 - val_loss: 1.1211 - val_accuracy: 0.5625\n",
      "Epoch 73/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1002 - accuracy: 0.5598 - val_loss: 1.1145 - val_accuracy: 0.5667\n",
      "Epoch 74/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0989 - accuracy: 0.5611 - val_loss: 1.1012 - val_accuracy: 0.5744\n",
      "Epoch 75/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0981 - accuracy: 0.5616 - val_loss: 1.1187 - val_accuracy: 0.5697\n",
      "Epoch 76/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1039 - accuracy: 0.5584 - val_loss: 1.1195 - val_accuracy: 0.5619\n",
      "Epoch 77/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0985 - accuracy: 0.5624 - val_loss: 1.1230 - val_accuracy: 0.5590\n",
      "Epoch 78/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0942 - accuracy: 0.5622 - val_loss: 1.1022 - val_accuracy: 0.5797\n",
      "Epoch 79/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0922 - accuracy: 0.5643 - val_loss: 1.1004 - val_accuracy: 0.5774\n",
      "Epoch 80/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0954 - accuracy: 0.5645 - val_loss: 1.1008 - val_accuracy: 0.5788\n",
      "Epoch 81/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1016 - accuracy: 0.5576 - val_loss: 1.1055 - val_accuracy: 0.5732\n",
      "Epoch 82/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0962 - accuracy: 0.5630 - val_loss: 1.0972 - val_accuracy: 0.5753\n",
      "Epoch 83/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0996 - accuracy: 0.5584 - val_loss: 1.0991 - val_accuracy: 0.5741\n",
      "Epoch 84/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0977 - accuracy: 0.5584 - val_loss: 1.0989 - val_accuracy: 0.5711\n",
      "Epoch 85/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0972 - accuracy: 0.5618 - val_loss: 1.1222 - val_accuracy: 0.5631\n",
      "Epoch 86/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0929 - accuracy: 0.5625 - val_loss: 1.1277 - val_accuracy: 0.5584\n",
      "Epoch 87/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0921 - accuracy: 0.5587 - val_loss: 1.1214 - val_accuracy: 0.5750\n",
      "Epoch 88/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0917 - accuracy: 0.5614 - val_loss: 1.0920 - val_accuracy: 0.5723\n",
      "Epoch 89/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0885 - accuracy: 0.5629 - val_loss: 1.0979 - val_accuracy: 0.5827\n",
      "Epoch 90/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0900 - accuracy: 0.5634 - val_loss: 1.1018 - val_accuracy: 0.5779\n",
      "Epoch 91/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0904 - accuracy: 0.5649 - val_loss: 1.0959 - val_accuracy: 0.5785\n",
      "Epoch 92/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0878 - accuracy: 0.5652 - val_loss: 1.0945 - val_accuracy: 0.5782\n",
      "Epoch 93/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0879 - accuracy: 0.5637 - val_loss: 1.0938 - val_accuracy: 0.5676\n",
      "Epoch 94/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0848 - accuracy: 0.5637 - val_loss: 1.0865 - val_accuracy: 0.5750\n",
      "Epoch 95/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0902 - accuracy: 0.5614 - val_loss: 1.0971 - val_accuracy: 0.5723\n",
      "Epoch 96/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0824 - accuracy: 0.5680 - val_loss: 1.1174 - val_accuracy: 0.5634\n",
      "Epoch 97/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0853 - accuracy: 0.5661 - val_loss: 1.1092 - val_accuracy: 0.5765\n",
      "Epoch 98/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0820 - accuracy: 0.5665 - val_loss: 1.0941 - val_accuracy: 0.5797\n",
      "Epoch 99/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0805 - accuracy: 0.5658 - val_loss: 1.0930 - val_accuracy: 0.5815\n",
      "Epoch 100/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0784 - accuracy: 0.5654 - val_loss: 1.0829 - val_accuracy: 0.5774\n",
      "Epoch 101/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0774 - accuracy: 0.5656 - val_loss: 1.0873 - val_accuracy: 0.5848\n",
      "Epoch 102/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0799 - accuracy: 0.5643 - val_loss: 1.0875 - val_accuracy: 0.5845\n",
      "Epoch 103/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0835 - accuracy: 0.5655 - val_loss: 1.0874 - val_accuracy: 0.5697\n",
      "Epoch 104/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0816 - accuracy: 0.5668 - val_loss: 1.0780 - val_accuracy: 0.5836\n",
      "Epoch 105/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0804 - accuracy: 0.5666 - val_loss: 1.0885 - val_accuracy: 0.5738\n",
      "Epoch 106/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0834 - accuracy: 0.5651 - val_loss: 1.0833 - val_accuracy: 0.5756\n",
      "Epoch 107/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0768 - accuracy: 0.5700 - val_loss: 1.1173 - val_accuracy: 0.5628\n",
      "Epoch 108/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0835 - accuracy: 0.5643 - val_loss: 1.1044 - val_accuracy: 0.5563\n",
      "Epoch 109/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0744 - accuracy: 0.5688 - val_loss: 1.0876 - val_accuracy: 0.5711\n",
      "Epoch 110/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0775 - accuracy: 0.5680 - val_loss: 1.1124 - val_accuracy: 0.5697\n",
      "Epoch 111/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0738 - accuracy: 0.5688 - val_loss: 1.0879 - val_accuracy: 0.5679\n",
      "Epoch 112/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0751 - accuracy: 0.5684 - val_loss: 1.1099 - val_accuracy: 0.5702\n",
      "Epoch 113/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0726 - accuracy: 0.5657 - val_loss: 1.0885 - val_accuracy: 0.5842\n",
      "Epoch 114/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0791 - accuracy: 0.5645 - val_loss: 1.0810 - val_accuracy: 0.5756\n",
      "Epoch 115/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0777 - accuracy: 0.5688 - val_loss: 1.0778 - val_accuracy: 0.5791\n",
      "Epoch 116/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0733 - accuracy: 0.5697 - val_loss: 1.1065 - val_accuracy: 0.5705\n",
      "Epoch 117/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0742 - accuracy: 0.5682 - val_loss: 1.0759 - val_accuracy: 0.5791\n",
      "Epoch 118/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0752 - accuracy: 0.5665 - val_loss: 1.0841 - val_accuracy: 0.5771\n",
      "Epoch 119/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0683 - accuracy: 0.5706 - val_loss: 1.0733 - val_accuracy: 0.5777\n",
      "Epoch 120/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0703 - accuracy: 0.5685 - val_loss: 1.0772 - val_accuracy: 0.5741\n",
      "Epoch 121/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0692 - accuracy: 0.5702 - val_loss: 1.0751 - val_accuracy: 0.5797\n",
      "Epoch 122/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0759 - accuracy: 0.5665 - val_loss: 1.0925 - val_accuracy: 0.5705\n",
      "Epoch 123/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0712 - accuracy: 0.5691 - val_loss: 1.0847 - val_accuracy: 0.5756\n",
      "Epoch 124/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0719 - accuracy: 0.5684 - val_loss: 1.0778 - val_accuracy: 0.5791\n",
      "Epoch 125/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0703 - accuracy: 0.5709 - val_loss: 1.0734 - val_accuracy: 0.5768\n",
      "Epoch 126/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0730 - accuracy: 0.5677 - val_loss: 1.0709 - val_accuracy: 0.5883\n",
      "Epoch 127/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0688 - accuracy: 0.5694 - val_loss: 1.0746 - val_accuracy: 0.5762\n",
      "Epoch 128/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0713 - accuracy: 0.5698 - val_loss: 1.0869 - val_accuracy: 0.5661\n",
      "Epoch 129/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0723 - accuracy: 0.5689 - val_loss: 1.0774 - val_accuracy: 0.5797\n",
      "Epoch 130/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0696 - accuracy: 0.5688 - val_loss: 1.0692 - val_accuracy: 0.5771\n",
      "Epoch 131/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0689 - accuracy: 0.5696 - val_loss: 1.0708 - val_accuracy: 0.5788\n",
      "Epoch 132/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0700 - accuracy: 0.5720 - val_loss: 1.0759 - val_accuracy: 0.5791\n",
      "Epoch 133/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0702 - accuracy: 0.5674 - val_loss: 1.0708 - val_accuracy: 0.5800\n",
      "Epoch 134/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0691 - accuracy: 0.5720 - val_loss: 1.0768 - val_accuracy: 0.5738\n",
      "Epoch 135/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0673 - accuracy: 0.5705 - val_loss: 1.0793 - val_accuracy: 0.5726\n",
      "Epoch 136/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0655 - accuracy: 0.5698 - val_loss: 1.0670 - val_accuracy: 0.5797\n",
      "Epoch 137/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0673 - accuracy: 0.5691 - val_loss: 1.0712 - val_accuracy: 0.5809\n",
      "Epoch 138/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0661 - accuracy: 0.5719 - val_loss: 1.0817 - val_accuracy: 0.5735\n",
      "Epoch 139/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0743 - accuracy: 0.5664 - val_loss: 1.0960 - val_accuracy: 0.5738\n",
      "Epoch 140/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0670 - accuracy: 0.5714 - val_loss: 1.0855 - val_accuracy: 0.5699\n",
      "Epoch 141/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0671 - accuracy: 0.5726 - val_loss: 1.0756 - val_accuracy: 0.5753\n",
      "Epoch 142/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0636 - accuracy: 0.5734 - val_loss: 1.0709 - val_accuracy: 0.5777\n",
      "Epoch 143/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0688 - accuracy: 0.5694 - val_loss: 1.0729 - val_accuracy: 0.5827\n",
      "Epoch 144/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0647 - accuracy: 0.5728 - val_loss: 1.0679 - val_accuracy: 0.5821\n",
      "Epoch 145/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0669 - accuracy: 0.5708 - val_loss: 1.0666 - val_accuracy: 0.5818\n",
      "Epoch 146/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0639 - accuracy: 0.5725 - val_loss: 1.0654 - val_accuracy: 0.5803\n",
      "Epoch 147/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0617 - accuracy: 0.5742 - val_loss: 1.0765 - val_accuracy: 0.5747\n",
      "Epoch 148/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0689 - accuracy: 0.5686 - val_loss: 1.0688 - val_accuracy: 0.5860\n",
      "Epoch 149/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0615 - accuracy: 0.5745 - val_loss: 1.0738 - val_accuracy: 0.5854\n",
      "Epoch 150/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0608 - accuracy: 0.5751 - val_loss: 1.0674 - val_accuracy: 0.5880\n",
      "Epoch 151/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0611 - accuracy: 0.5737 - val_loss: 1.0706 - val_accuracy: 0.5851\n",
      "Epoch 152/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0588 - accuracy: 0.5730 - val_loss: 1.0648 - val_accuracy: 0.5830\n",
      "Epoch 153/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0633 - accuracy: 0.5726 - val_loss: 1.0700 - val_accuracy: 0.5771\n",
      "Epoch 154/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0597 - accuracy: 0.5757 - val_loss: 1.0592 - val_accuracy: 0.5821\n",
      "Epoch 155/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0584 - accuracy: 0.5768 - val_loss: 1.0647 - val_accuracy: 0.5765\n",
      "Epoch 156/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0632 - accuracy: 0.5737 - val_loss: 1.0745 - val_accuracy: 0.5836\n",
      "Epoch 157/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0602 - accuracy: 0.5766 - val_loss: 1.0825 - val_accuracy: 0.5827\n",
      "Epoch 158/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0653 - accuracy: 0.5708 - val_loss: 1.0826 - val_accuracy: 0.5741\n",
      "Epoch 159/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0581 - accuracy: 0.5766 - val_loss: 1.0625 - val_accuracy: 0.5854\n",
      "Epoch 160/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0597 - accuracy: 0.5755 - val_loss: 1.0666 - val_accuracy: 0.5744\n",
      "Epoch 161/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0576 - accuracy: 0.5778 - val_loss: 1.0573 - val_accuracy: 0.5854\n",
      "Epoch 162/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0570 - accuracy: 0.5768 - val_loss: 1.0694 - val_accuracy: 0.5815\n",
      "Epoch 163/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0569 - accuracy: 0.5764 - val_loss: 1.0920 - val_accuracy: 0.5765\n",
      "Epoch 164/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0561 - accuracy: 0.5751 - val_loss: 1.0571 - val_accuracy: 0.5860\n",
      "Epoch 165/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0633 - accuracy: 0.5732 - val_loss: 1.0688 - val_accuracy: 0.5836\n",
      "Epoch 166/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0582 - accuracy: 0.5754 - val_loss: 1.0568 - val_accuracy: 0.5865\n",
      "Epoch 167/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0529 - accuracy: 0.5785 - val_loss: 1.0661 - val_accuracy: 0.5851\n",
      "Epoch 168/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0543 - accuracy: 0.5797 - val_loss: 1.0700 - val_accuracy: 0.5969\n",
      "Epoch 169/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0554 - accuracy: 0.5748 - val_loss: 1.0561 - val_accuracy: 0.5913\n",
      "Epoch 170/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0538 - accuracy: 0.5741 - val_loss: 1.0634 - val_accuracy: 0.5818\n",
      "Epoch 171/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0555 - accuracy: 0.5788 - val_loss: 1.0716 - val_accuracy: 0.5851\n",
      "Epoch 172/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0520 - accuracy: 0.5805 - val_loss: 1.0765 - val_accuracy: 0.5943\n",
      "Epoch 173/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0543 - accuracy: 0.5768 - val_loss: 1.0825 - val_accuracy: 0.5791\n",
      "Epoch 174/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0503 - accuracy: 0.5816 - val_loss: 1.0667 - val_accuracy: 0.5975\n",
      "Epoch 175/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0550 - accuracy: 0.5796 - val_loss: 1.0595 - val_accuracy: 0.5851\n",
      "Epoch 176/400\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0527 - accuracy: 0.5761 - val_loss: 1.0579 - val_accuracy: 0.5857\n",
      "Epoch 177/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0483 - accuracy: 0.5788 - val_loss: 1.1016 - val_accuracy: 0.5622\n",
      "Epoch 178/400\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0510 - accuracy: 0.5771 - val_loss: 1.0670 - val_accuracy: 0.5762\n",
      "Epoch 179/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0488 - accuracy: 0.5784 - val_loss: 1.0646 - val_accuracy: 0.5851\n",
      "Epoch 180/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0578 - accuracy: 0.5737 - val_loss: 1.0664 - val_accuracy: 0.5880\n",
      "Epoch 181/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0518 - accuracy: 0.5781 - val_loss: 1.0574 - val_accuracy: 0.5818\n",
      "Epoch 182/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0478 - accuracy: 0.5786 - val_loss: 1.0637 - val_accuracy: 0.5771\n",
      "Epoch 183/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0557 - accuracy: 0.5776 - val_loss: 1.0644 - val_accuracy: 0.5857\n",
      "Epoch 184/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0482 - accuracy: 0.5800 - val_loss: 1.0603 - val_accuracy: 0.5871\n",
      "Epoch 185/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0535 - accuracy: 0.5788 - val_loss: 1.0647 - val_accuracy: 0.5862\n",
      "Epoch 186/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0480 - accuracy: 0.5799 - val_loss: 1.0540 - val_accuracy: 0.5874\n",
      "Epoch 187/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0496 - accuracy: 0.5812 - val_loss: 1.0626 - val_accuracy: 0.5809\n",
      "Epoch 188/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0476 - accuracy: 0.5828 - val_loss: 1.0530 - val_accuracy: 0.5880\n",
      "Epoch 189/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0475 - accuracy: 0.5820 - val_loss: 1.0567 - val_accuracy: 0.5842\n",
      "Epoch 190/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0486 - accuracy: 0.5786 - val_loss: 1.0662 - val_accuracy: 0.5860\n",
      "Epoch 191/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0462 - accuracy: 0.5827 - val_loss: 1.0776 - val_accuracy: 0.5756\n",
      "Epoch 192/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0507 - accuracy: 0.5774 - val_loss: 1.0744 - val_accuracy: 0.5862\n",
      "Epoch 193/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0476 - accuracy: 0.5829 - val_loss: 1.0886 - val_accuracy: 0.5726\n",
      "Epoch 194/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0494 - accuracy: 0.5811 - val_loss: 1.0717 - val_accuracy: 0.5771\n",
      "Epoch 195/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0447 - accuracy: 0.5797 - val_loss: 1.0485 - val_accuracy: 0.5860\n",
      "Epoch 196/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0419 - accuracy: 0.5815 - val_loss: 1.0846 - val_accuracy: 0.5806\n",
      "Epoch 197/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0436 - accuracy: 0.5825 - val_loss: 1.0733 - val_accuracy: 0.5862\n",
      "Epoch 198/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0507 - accuracy: 0.5777 - val_loss: 1.0667 - val_accuracy: 0.5762\n",
      "Epoch 199/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0460 - accuracy: 0.5807 - val_loss: 1.0555 - val_accuracy: 0.5874\n",
      "Epoch 200/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0435 - accuracy: 0.5840 - val_loss: 1.0649 - val_accuracy: 0.5785\n",
      "Epoch 201/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0455 - accuracy: 0.5777 - val_loss: 1.0652 - val_accuracy: 0.5919\n",
      "Epoch 202/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0478 - accuracy: 0.5806 - val_loss: 1.0559 - val_accuracy: 0.5791\n",
      "Epoch 203/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0388 - accuracy: 0.5832 - val_loss: 1.0614 - val_accuracy: 0.5862\n",
      "Epoch 204/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0441 - accuracy: 0.5809 - val_loss: 1.0633 - val_accuracy: 0.5886\n",
      "Epoch 205/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0442 - accuracy: 0.5823 - val_loss: 1.0510 - val_accuracy: 0.5889\n",
      "Epoch 206/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0430 - accuracy: 0.5794 - val_loss: 1.0627 - val_accuracy: 0.5848\n",
      "Epoch 207/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0470 - accuracy: 0.5789 - val_loss: 1.0561 - val_accuracy: 0.5948\n",
      "Epoch 208/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0456 - accuracy: 0.5820 - val_loss: 1.0461 - val_accuracy: 0.5860\n",
      "Epoch 209/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0473 - accuracy: 0.5758 - val_loss: 1.0806 - val_accuracy: 0.5821\n",
      "Epoch 210/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0443 - accuracy: 0.5785 - val_loss: 1.0640 - val_accuracy: 0.5747\n",
      "Epoch 211/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0419 - accuracy: 0.5844 - val_loss: 1.0491 - val_accuracy: 0.5937\n",
      "Epoch 212/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0440 - accuracy: 0.5803 - val_loss: 1.0506 - val_accuracy: 0.5833\n",
      "Epoch 213/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0461 - accuracy: 0.5806 - val_loss: 1.0888 - val_accuracy: 0.5774\n",
      "Epoch 214/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0416 - accuracy: 0.5789 - val_loss: 1.0637 - val_accuracy: 0.5836\n",
      "Epoch 215/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0455 - accuracy: 0.5789 - val_loss: 1.0725 - val_accuracy: 0.5717\n",
      "Epoch 216/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0424 - accuracy: 0.5799 - val_loss: 1.0548 - val_accuracy: 0.5904\n",
      "Epoch 217/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0411 - accuracy: 0.5809 - val_loss: 1.0549 - val_accuracy: 0.5898\n",
      "Epoch 218/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0448 - accuracy: 0.5819 - val_loss: 1.0518 - val_accuracy: 0.5931\n",
      "Epoch 219/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0435 - accuracy: 0.5788 - val_loss: 1.0513 - val_accuracy: 0.5910\n",
      "Epoch 220/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0392 - accuracy: 0.5821 - val_loss: 1.0438 - val_accuracy: 0.5874\n",
      "Epoch 221/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0416 - accuracy: 0.5816 - val_loss: 1.0510 - val_accuracy: 0.5827\n",
      "Epoch 222/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0394 - accuracy: 0.5822 - val_loss: 1.0536 - val_accuracy: 0.5809\n",
      "Epoch 223/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0375 - accuracy: 0.5817 - val_loss: 1.0512 - val_accuracy: 0.5815\n",
      "Epoch 224/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0356 - accuracy: 0.5834 - val_loss: 1.0508 - val_accuracy: 0.5865\n",
      "Epoch 225/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0387 - accuracy: 0.5825 - val_loss: 1.0770 - val_accuracy: 0.5874\n",
      "Epoch 226/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0416 - accuracy: 0.5808 - val_loss: 1.0790 - val_accuracy: 0.5732\n",
      "Epoch 227/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0417 - accuracy: 0.5843 - val_loss: 1.0770 - val_accuracy: 0.5871\n",
      "Epoch 228/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0441 - accuracy: 0.5803 - val_loss: 1.0528 - val_accuracy: 0.5788\n",
      "Epoch 229/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0385 - accuracy: 0.5825 - val_loss: 1.0495 - val_accuracy: 0.5934\n",
      "Epoch 230/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0354 - accuracy: 0.5827 - val_loss: 1.0457 - val_accuracy: 0.5874\n",
      "Epoch 231/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0361 - accuracy: 0.5829 - val_loss: 1.0794 - val_accuracy: 0.5682\n",
      "Epoch 232/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0409 - accuracy: 0.5838 - val_loss: 1.0540 - val_accuracy: 0.5937\n",
      "Epoch 233/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0362 - accuracy: 0.5848 - val_loss: 1.0687 - val_accuracy: 0.5765\n",
      "Epoch 234/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0454 - accuracy: 0.5808 - val_loss: 1.0735 - val_accuracy: 0.5824\n",
      "Epoch 235/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0361 - accuracy: 0.5822 - val_loss: 1.0470 - val_accuracy: 0.5913\n",
      "Epoch 236/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0357 - accuracy: 0.5849 - val_loss: 1.0783 - val_accuracy: 0.5830\n",
      "Epoch 237/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0372 - accuracy: 0.5800 - val_loss: 1.0605 - val_accuracy: 0.5857\n",
      "Epoch 238/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0380 - accuracy: 0.5815 - val_loss: 1.0579 - val_accuracy: 0.5845\n",
      "Epoch 239/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0349 - accuracy: 0.5837 - val_loss: 1.0442 - val_accuracy: 0.5928\n",
      "Epoch 240/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0346 - accuracy: 0.5868 - val_loss: 1.0439 - val_accuracy: 0.5854\n",
      "Epoch 241/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0362 - accuracy: 0.5861 - val_loss: 1.0932 - val_accuracy: 0.5676\n",
      "Epoch 242/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0395 - accuracy: 0.5814 - val_loss: 1.0430 - val_accuracy: 0.5916\n",
      "Epoch 243/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0443 - accuracy: 0.5811 - val_loss: 1.0540 - val_accuracy: 0.5830\n",
      "Epoch 244/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0364 - accuracy: 0.5839 - val_loss: 1.0648 - val_accuracy: 0.5845\n",
      "Epoch 245/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0395 - accuracy: 0.5819 - val_loss: 1.0635 - val_accuracy: 0.5857\n",
      "Epoch 246/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0356 - accuracy: 0.5864 - val_loss: 1.0492 - val_accuracy: 0.5948\n",
      "Epoch 247/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0399 - accuracy: 0.5829 - val_loss: 1.0633 - val_accuracy: 0.5774\n",
      "Epoch 248/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0347 - accuracy: 0.5830 - val_loss: 1.0455 - val_accuracy: 0.5919\n",
      "Epoch 249/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0380 - accuracy: 0.5854 - val_loss: 1.0532 - val_accuracy: 0.5812\n",
      "Epoch 250/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0324 - accuracy: 0.5843 - val_loss: 1.0725 - val_accuracy: 0.5824\n",
      "Epoch 251/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0354 - accuracy: 0.5814 - val_loss: 1.0471 - val_accuracy: 0.5874\n",
      "Epoch 252/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5851 - val_loss: 1.0555 - val_accuracy: 0.5904\n",
      "Epoch 253/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0297 - accuracy: 0.5843 - val_loss: 1.0782 - val_accuracy: 0.5762\n",
      "Epoch 254/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0355 - accuracy: 0.5835 - val_loss: 1.0586 - val_accuracy: 0.5922\n",
      "Epoch 255/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0395 - accuracy: 0.5828 - val_loss: 1.0599 - val_accuracy: 0.5925\n",
      "Epoch 256/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0335 - accuracy: 0.5856 - val_loss: 1.0411 - val_accuracy: 0.5862\n",
      "Epoch 257/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0314 - accuracy: 0.5860 - val_loss: 1.0480 - val_accuracy: 0.5842\n",
      "Epoch 258/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0362 - accuracy: 0.5850 - val_loss: 1.0412 - val_accuracy: 0.5916\n",
      "Epoch 259/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0322 - accuracy: 0.5849 - val_loss: 1.0621 - val_accuracy: 0.5738\n",
      "Epoch 260/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0318 - accuracy: 0.5851 - val_loss: 1.0561 - val_accuracy: 0.5874\n",
      "Epoch 261/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0343 - accuracy: 0.5826 - val_loss: 1.0441 - val_accuracy: 0.5845\n",
      "Epoch 262/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0315 - accuracy: 0.5826 - val_loss: 1.0462 - val_accuracy: 0.5848\n",
      "Epoch 263/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0342 - accuracy: 0.5843 - val_loss: 1.0635 - val_accuracy: 0.5741\n",
      "Epoch 264/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0375 - accuracy: 0.5846 - val_loss: 1.0530 - val_accuracy: 0.5809\n",
      "Epoch 265/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0270 - accuracy: 0.5849 - val_loss: 1.0805 - val_accuracy: 0.5735\n",
      "Epoch 266/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0318 - accuracy: 0.5833 - val_loss: 1.0427 - val_accuracy: 0.5892\n",
      "Epoch 267/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0342 - accuracy: 0.5848 - val_loss: 1.0586 - val_accuracy: 0.5868\n",
      "Epoch 268/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0337 - accuracy: 0.5819 - val_loss: 1.0716 - val_accuracy: 0.5889\n",
      "Epoch 269/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0363 - accuracy: 0.5831 - val_loss: 1.0504 - val_accuracy: 0.5839\n",
      "Epoch 270/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0330 - accuracy: 0.5842 - val_loss: 1.0464 - val_accuracy: 0.5836\n",
      "Epoch 271/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0347 - accuracy: 0.5829 - val_loss: 1.0766 - val_accuracy: 0.5779\n",
      "Epoch 272/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0318 - accuracy: 0.5857 - val_loss: 1.0494 - val_accuracy: 0.5907\n",
      "Epoch 273/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0363 - accuracy: 0.5851 - val_loss: 1.0418 - val_accuracy: 0.5839\n",
      "Epoch 274/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0360 - accuracy: 0.5824 - val_loss: 1.0511 - val_accuracy: 0.5954\n",
      "Epoch 275/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0337 - accuracy: 0.5868 - val_loss: 1.0662 - val_accuracy: 0.5702\n",
      "Epoch 276/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0310 - accuracy: 0.5857 - val_loss: 1.0644 - val_accuracy: 0.5812\n",
      "Epoch 277/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0401 - accuracy: 0.5821 - val_loss: 1.0424 - val_accuracy: 0.5860\n",
      "Epoch 278/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0273 - accuracy: 0.5850 - val_loss: 1.0457 - val_accuracy: 0.5812\n",
      "Epoch 279/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0350 - accuracy: 0.5822 - val_loss: 1.0538 - val_accuracy: 0.5782\n",
      "Epoch 280/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0294 - accuracy: 0.5837 - val_loss: 1.0438 - val_accuracy: 0.5842\n",
      "Epoch 281/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0299 - accuracy: 0.5836 - val_loss: 1.0554 - val_accuracy: 0.5839\n",
      "Epoch 282/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0323 - accuracy: 0.5848 - val_loss: 1.0509 - val_accuracy: 0.5865\n",
      "Epoch 283/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0321 - accuracy: 0.5807 - val_loss: 1.0372 - val_accuracy: 0.5913\n",
      "Epoch 284/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0292 - accuracy: 0.5857 - val_loss: 1.0471 - val_accuracy: 0.5877\n",
      "Epoch 285/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0277 - accuracy: 0.5865 - val_loss: 1.0649 - val_accuracy: 0.5794\n",
      "Epoch 286/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0287 - accuracy: 0.5871 - val_loss: 1.0621 - val_accuracy: 0.5851\n",
      "Epoch 287/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0231 - accuracy: 0.5890 - val_loss: 1.0440 - val_accuracy: 0.5913\n",
      "Epoch 288/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0277 - accuracy: 0.5866 - val_loss: 1.0471 - val_accuracy: 0.5854\n",
      "Epoch 289/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0277 - accuracy: 0.5874 - val_loss: 1.0411 - val_accuracy: 0.5898\n",
      "Epoch 290/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0300 - accuracy: 0.5843 - val_loss: 1.0693 - val_accuracy: 0.5800\n",
      "Epoch 291/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0292 - accuracy: 0.5858 - val_loss: 1.0464 - val_accuracy: 0.5931\n",
      "Epoch 292/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0287 - accuracy: 0.5858 - val_loss: 1.0416 - val_accuracy: 0.5860\n",
      "Epoch 293/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0275 - accuracy: 0.5871 - val_loss: 1.0562 - val_accuracy: 0.5868\n",
      "Epoch 294/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0284 - accuracy: 0.5839 - val_loss: 1.0372 - val_accuracy: 0.5860\n",
      "Epoch 295/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0280 - accuracy: 0.5863 - val_loss: 1.0657 - val_accuracy: 0.5868\n",
      "Epoch 296/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0285 - accuracy: 0.5845 - val_loss: 1.0542 - val_accuracy: 0.5907\n",
      "Epoch 297/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0268 - accuracy: 0.5846 - val_loss: 1.0445 - val_accuracy: 0.5827\n",
      "Epoch 298/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0254 - accuracy: 0.5860 - val_loss: 1.0417 - val_accuracy: 0.5877\n",
      "Epoch 299/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0318 - accuracy: 0.5844 - val_loss: 1.0879 - val_accuracy: 0.5803\n",
      "Epoch 300/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0322 - accuracy: 0.5823 - val_loss: 1.0484 - val_accuracy: 0.5904\n",
      "Epoch 301/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0287 - accuracy: 0.5848 - val_loss: 1.0392 - val_accuracy: 0.5874\n",
      "Epoch 302/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0255 - accuracy: 0.5858 - val_loss: 1.0554 - val_accuracy: 0.5928\n",
      "Epoch 303/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0283 - accuracy: 0.5862 - val_loss: 1.0390 - val_accuracy: 0.5919\n",
      "Epoch 304/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0306 - accuracy: 0.5828 - val_loss: 1.0377 - val_accuracy: 0.5910\n",
      "Epoch 305/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0304 - accuracy: 0.5871 - val_loss: 1.0424 - val_accuracy: 0.5886\n",
      "Epoch 306/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0308 - accuracy: 0.5847 - val_loss: 1.0437 - val_accuracy: 0.5857\n",
      "Epoch 307/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0218 - accuracy: 0.5886 - val_loss: 1.0353 - val_accuracy: 0.5857\n",
      "Epoch 308/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0253 - accuracy: 0.5868 - val_loss: 1.0434 - val_accuracy: 0.5910\n",
      "Epoch 309/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0258 - accuracy: 0.5833 - val_loss: 1.0463 - val_accuracy: 0.5874\n",
      "Epoch 310/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0254 - accuracy: 0.5873 - val_loss: 1.0409 - val_accuracy: 0.5901\n",
      "Epoch 311/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0242 - accuracy: 0.5874 - val_loss: 1.0558 - val_accuracy: 0.5777\n",
      "Epoch 312/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0274 - accuracy: 0.5850 - val_loss: 1.0551 - val_accuracy: 0.5871\n",
      "Epoch 313/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0292 - accuracy: 0.5829 - val_loss: 1.0381 - val_accuracy: 0.5904\n",
      "Epoch 314/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0244 - accuracy: 0.5872 - val_loss: 1.0616 - val_accuracy: 0.5862\n",
      "Epoch 315/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0284 - accuracy: 0.5871 - val_loss: 1.0576 - val_accuracy: 0.5768\n",
      "Epoch 316/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0280 - accuracy: 0.5862 - val_loss: 1.0902 - val_accuracy: 0.5756\n",
      "Epoch 317/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0335 - accuracy: 0.5860 - val_loss: 1.0502 - val_accuracy: 0.5865\n",
      "Epoch 318/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0237 - accuracy: 0.5883 - val_loss: 1.0586 - val_accuracy: 0.5839\n",
      "Epoch 319/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0253 - accuracy: 0.5868 - val_loss: 1.0644 - val_accuracy: 0.5910\n",
      "Epoch 320/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0285 - accuracy: 0.5881 - val_loss: 1.0478 - val_accuracy: 0.5791\n",
      "Epoch 321/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0293 - accuracy: 0.5824 - val_loss: 1.0694 - val_accuracy: 0.5768\n",
      "Epoch 322/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0238 - accuracy: 0.5838 - val_loss: 1.0476 - val_accuracy: 0.5871\n",
      "Epoch 323/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0264 - accuracy: 0.5868 - val_loss: 1.0450 - val_accuracy: 0.5880\n",
      "Epoch 324/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0297 - accuracy: 0.5834 - val_loss: 1.0497 - val_accuracy: 0.5925\n",
      "Epoch 325/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0258 - accuracy: 0.5855 - val_loss: 1.0524 - val_accuracy: 0.5922\n",
      "Epoch 326/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0257 - accuracy: 0.5880 - val_loss: 1.0361 - val_accuracy: 0.5862\n",
      "Epoch 327/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0211 - accuracy: 0.5886 - val_loss: 1.0373 - val_accuracy: 0.5842\n",
      "Epoch 328/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0284 - accuracy: 0.5861 - val_loss: 1.0575 - val_accuracy: 0.5945\n",
      "Epoch 329/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0234 - accuracy: 0.5880 - val_loss: 1.0496 - val_accuracy: 0.5845\n",
      "Epoch 330/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0194 - accuracy: 0.5878 - val_loss: 1.0382 - val_accuracy: 0.5842\n",
      "Epoch 331/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0279 - accuracy: 0.5877 - val_loss: 1.0459 - val_accuracy: 0.5892\n",
      "Epoch 332/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0282 - accuracy: 0.5869 - val_loss: 1.0420 - val_accuracy: 0.5839\n",
      "Epoch 333/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0234 - accuracy: 0.5899 - val_loss: 1.0447 - val_accuracy: 0.5812\n",
      "Epoch 334/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0220 - accuracy: 0.5881 - val_loss: 1.0502 - val_accuracy: 0.5815\n",
      "Epoch 335/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0220 - accuracy: 0.5891 - val_loss: 1.0428 - val_accuracy: 0.5821\n",
      "Epoch 336/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0236 - accuracy: 0.5866 - val_loss: 1.0702 - val_accuracy: 0.5830\n",
      "Epoch 337/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0251 - accuracy: 0.5847 - val_loss: 1.0444 - val_accuracy: 0.5874\n",
      "Epoch 338/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0269 - accuracy: 0.5851 - val_loss: 1.0578 - val_accuracy: 0.5806\n",
      "Epoch 339/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0247 - accuracy: 0.5894 - val_loss: 1.0514 - val_accuracy: 0.5800\n",
      "Epoch 340/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0244 - accuracy: 0.5872 - val_loss: 1.0357 - val_accuracy: 0.5860\n",
      "Epoch 341/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0221 - accuracy: 0.5888 - val_loss: 1.0483 - val_accuracy: 0.5883\n",
      "Epoch 342/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0213 - accuracy: 0.5867 - val_loss: 1.0384 - val_accuracy: 0.5892\n",
      "Epoch 343/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0238 - accuracy: 0.5881 - val_loss: 1.0459 - val_accuracy: 0.5833\n",
      "Epoch 344/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0233 - accuracy: 0.5864 - val_loss: 1.0655 - val_accuracy: 0.5865\n",
      "Epoch 345/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0222 - accuracy: 0.5902 - val_loss: 1.0556 - val_accuracy: 0.5886\n",
      "Epoch 346/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0236 - accuracy: 0.5861 - val_loss: 1.0642 - val_accuracy: 0.5753\n",
      "Epoch 347/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0212 - accuracy: 0.5906 - val_loss: 1.0402 - val_accuracy: 0.5910\n",
      "Epoch 348/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0235 - accuracy: 0.5868 - val_loss: 1.0425 - val_accuracy: 0.5898\n",
      "Epoch 349/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0239 - accuracy: 0.5869 - val_loss: 1.0491 - val_accuracy: 0.5857\n",
      "Epoch 350/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0231 - accuracy: 0.5860 - val_loss: 1.0493 - val_accuracy: 0.5913\n",
      "Epoch 351/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0231 - accuracy: 0.5861 - val_loss: 1.0449 - val_accuracy: 0.5910\n",
      "Epoch 352/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0249 - accuracy: 0.5874 - val_loss: 1.0663 - val_accuracy: 0.5815\n",
      "Epoch 353/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0286 - accuracy: 0.5851 - val_loss: 1.0515 - val_accuracy: 0.5845\n",
      "Epoch 354/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0239 - accuracy: 0.5866 - val_loss: 1.0755 - val_accuracy: 0.5794\n",
      "Epoch 355/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0292 - accuracy: 0.5844 - val_loss: 1.0447 - val_accuracy: 0.5857\n",
      "Epoch 356/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0228 - accuracy: 0.5876 - val_loss: 1.0428 - val_accuracy: 0.5877\n",
      "Epoch 357/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0207 - accuracy: 0.5892 - val_loss: 1.0499 - val_accuracy: 0.5848\n",
      "Epoch 358/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0238 - accuracy: 0.5863 - val_loss: 1.0521 - val_accuracy: 0.5777\n",
      "Epoch 359/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0215 - accuracy: 0.5895 - val_loss: 1.0461 - val_accuracy: 0.5827\n",
      "Epoch 360/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0198 - accuracy: 0.5878 - val_loss: 1.0420 - val_accuracy: 0.5910\n",
      "Epoch 361/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0252 - accuracy: 0.5866 - val_loss: 1.0446 - val_accuracy: 0.5913\n",
      "Epoch 362/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0187 - accuracy: 0.5889 - val_loss: 1.0418 - val_accuracy: 0.5871\n",
      "Epoch 363/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0206 - accuracy: 0.5873 - val_loss: 1.0381 - val_accuracy: 0.5913\n",
      "Epoch 364/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0203 - accuracy: 0.5897 - val_loss: 1.0463 - val_accuracy: 0.5910\n",
      "Epoch 365/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0259 - accuracy: 0.5877 - val_loss: 1.0460 - val_accuracy: 0.5824\n",
      "Epoch 366/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0266 - accuracy: 0.5860 - val_loss: 1.0456 - val_accuracy: 0.5821\n",
      "Epoch 367/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0226 - accuracy: 0.5888 - val_loss: 1.0696 - val_accuracy: 0.5782\n",
      "Epoch 368/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0223 - accuracy: 0.5860 - val_loss: 1.0861 - val_accuracy: 0.5771\n",
      "Epoch 369/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0224 - accuracy: 0.5891 - val_loss: 1.0620 - val_accuracy: 0.5913\n",
      "Epoch 370/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0234 - accuracy: 0.5866 - val_loss: 1.0495 - val_accuracy: 0.5934\n",
      "Epoch 371/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0235 - accuracy: 0.5888 - val_loss: 1.0447 - val_accuracy: 0.5886\n",
      "Epoch 372/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0224 - accuracy: 0.5878 - val_loss: 1.0536 - val_accuracy: 0.5868\n",
      "Epoch 373/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0223 - accuracy: 0.5879 - val_loss: 1.0559 - val_accuracy: 0.5800\n",
      "Epoch 374/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0226 - accuracy: 0.5900 - val_loss: 1.0448 - val_accuracy: 0.5880\n",
      "Epoch 375/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0238 - accuracy: 0.5903 - val_loss: 1.0463 - val_accuracy: 0.5851\n",
      "Epoch 376/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0227 - accuracy: 0.5872 - val_loss: 1.0403 - val_accuracy: 0.5901\n",
      "Epoch 377/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0162 - accuracy: 0.5914 - val_loss: 1.0387 - val_accuracy: 0.5957\n",
      "Epoch 378/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0242 - accuracy: 0.5889 - val_loss: 1.0389 - val_accuracy: 0.5833\n",
      "Epoch 379/400\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0198 - accuracy: 0.5879 - val_loss: 1.0394 - val_accuracy: 0.5922\n",
      "Epoch 380/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0218 - accuracy: 0.5855 - val_loss: 1.0413 - val_accuracy: 0.5892\n",
      "Epoch 381/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0229 - accuracy: 0.5899 - val_loss: 1.0646 - val_accuracy: 0.5809\n",
      "Epoch 382/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0240 - accuracy: 0.5877 - val_loss: 1.0445 - val_accuracy: 0.5818\n",
      "Epoch 383/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0197 - accuracy: 0.5871 - val_loss: 1.0525 - val_accuracy: 0.5806\n",
      "Epoch 384/400\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0196 - accuracy: 0.5910 - val_loss: 1.0435 - val_accuracy: 0.5913\n",
      "Epoch 385/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0201 - accuracy: 0.5886 - val_loss: 1.0464 - val_accuracy: 0.5951\n",
      "Epoch 386/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0198 - accuracy: 0.5904 - val_loss: 1.0535 - val_accuracy: 0.5945\n",
      "Epoch 387/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0223 - accuracy: 0.5874 - val_loss: 1.0440 - val_accuracy: 0.5889\n",
      "Epoch 388/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0251 - accuracy: 0.5891 - val_loss: 1.0414 - val_accuracy: 0.5895\n",
      "Epoch 389/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0224 - accuracy: 0.5885 - val_loss: 1.0442 - val_accuracy: 0.5907\n",
      "Epoch 390/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0160 - accuracy: 0.5894 - val_loss: 1.0459 - val_accuracy: 0.5910\n",
      "Epoch 391/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0204 - accuracy: 0.5903 - val_loss: 1.0429 - val_accuracy: 0.5868\n",
      "Epoch 392/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0201 - accuracy: 0.5893 - val_loss: 1.0601 - val_accuracy: 0.5916\n",
      "Epoch 393/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0250 - accuracy: 0.5869 - val_loss: 1.0543 - val_accuracy: 0.5830\n",
      "Epoch 394/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0313 - accuracy: 0.5856 - val_loss: 1.0337 - val_accuracy: 0.5904\n",
      "Epoch 395/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0164 - accuracy: 0.5897 - val_loss: 1.0390 - val_accuracy: 0.5943\n",
      "Epoch 396/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0232 - accuracy: 0.5857 - val_loss: 1.0462 - val_accuracy: 0.5937\n",
      "Epoch 397/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0185 - accuracy: 0.5883 - val_loss: 1.0411 - val_accuracy: 0.5928\n",
      "Epoch 398/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0197 - accuracy: 0.5897 - val_loss: 1.0382 - val_accuracy: 0.5895\n",
      "Epoch 399/400\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0226 - accuracy: 0.5881 - val_loss: 1.0436 - val_accuracy: 0.5871\n",
      "Epoch 400/400\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0210 - accuracy: 0.5861 - val_loss: 1.0521 - val_accuracy: 0.5842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=400, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f34a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a53aa430",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_epoch = history.history[\"val_accuracy\"]\n",
    "best_epoch = val_acc_epoch.index(max(val_acc_epoch)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98024ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.4657 - accuracy: 0.3993 - val_loss: 1.4206 - val_accuracy: 0.4132\n",
      "Epoch 2/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.4106 - accuracy: 0.4149 - val_loss: 1.4122 - val_accuracy: 0.4132\n",
      "Epoch 3/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.4058 - accuracy: 0.4149 - val_loss: 1.4140 - val_accuracy: 0.4132\n",
      "Epoch 4/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.4022 - accuracy: 0.4149 - val_loss: 1.4100 - val_accuracy: 0.4132\n",
      "Epoch 5/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3991 - accuracy: 0.4149 - val_loss: 1.4013 - val_accuracy: 0.4132\n",
      "Epoch 6/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3871 - accuracy: 0.4151 - val_loss: 1.3862 - val_accuracy: 0.4111\n",
      "Epoch 7/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3576 - accuracy: 0.4162 - val_loss: 1.3393 - val_accuracy: 0.4123\n",
      "Epoch 8/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3199 - accuracy: 0.4250 - val_loss: 1.3004 - val_accuracy: 0.4271\n",
      "Epoch 9/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2890 - accuracy: 0.4393 - val_loss: 1.2914 - val_accuracy: 0.4644\n",
      "Epoch 10/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2689 - accuracy: 0.4532 - val_loss: 1.2627 - val_accuracy: 0.4641\n",
      "Epoch 11/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2522 - accuracy: 0.4738 - val_loss: 1.2417 - val_accuracy: 0.4852\n",
      "Epoch 12/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2369 - accuracy: 0.4879 - val_loss: 1.2314 - val_accuracy: 0.4982\n",
      "Epoch 13/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2343 - accuracy: 0.4924 - val_loss: 1.2256 - val_accuracy: 0.5133\n",
      "Epoch 14/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2197 - accuracy: 0.5064 - val_loss: 1.2143 - val_accuracy: 0.5154\n",
      "Epoch 15/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2142 - accuracy: 0.5104 - val_loss: 1.2166 - val_accuracy: 0.4944\n",
      "Epoch 16/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2074 - accuracy: 0.5162 - val_loss: 1.2143 - val_accuracy: 0.5101\n",
      "Epoch 17/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1986 - accuracy: 0.5177 - val_loss: 1.2046 - val_accuracy: 0.5252\n",
      "Epoch 18/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1874 - accuracy: 0.5248 - val_loss: 1.1770 - val_accuracy: 0.5495\n",
      "Epoch 19/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1740 - accuracy: 0.5313 - val_loss: 1.1704 - val_accuracy: 0.5382\n",
      "Epoch 20/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1643 - accuracy: 0.5407 - val_loss: 1.2073 - val_accuracy: 0.5175\n",
      "Epoch 21/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1585 - accuracy: 0.5377 - val_loss: 1.1593 - val_accuracy: 0.5456\n",
      "Epoch 22/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1488 - accuracy: 0.5426 - val_loss: 1.1724 - val_accuracy: 0.5305\n",
      "Epoch 23/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1459 - accuracy: 0.5425 - val_loss: 1.1456 - val_accuracy: 0.5539\n",
      "Epoch 24/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1453 - accuracy: 0.5372 - val_loss: 1.1403 - val_accuracy: 0.5605\n",
      "Epoch 25/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1397 - accuracy: 0.5462 - val_loss: 1.1311 - val_accuracy: 0.5631\n",
      "Epoch 26/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1352 - accuracy: 0.5474 - val_loss: 1.1276 - val_accuracy: 0.5637\n",
      "Epoch 27/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1335 - accuracy: 0.5482 - val_loss: 1.1339 - val_accuracy: 0.5584\n",
      "Epoch 28/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1250 - accuracy: 0.5504 - val_loss: 1.1288 - val_accuracy: 0.5673\n",
      "Epoch 29/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1234 - accuracy: 0.5494 - val_loss: 1.1246 - val_accuracy: 0.5599\n",
      "Epoch 30/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1220 - accuracy: 0.5478 - val_loss: 1.1229 - val_accuracy: 0.5614\n",
      "Epoch 31/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1224 - accuracy: 0.5477 - val_loss: 1.1163 - val_accuracy: 0.5673\n",
      "Epoch 32/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1161 - accuracy: 0.5534 - val_loss: 1.1182 - val_accuracy: 0.5702\n",
      "Epoch 33/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1135 - accuracy: 0.5534 - val_loss: 1.1141 - val_accuracy: 0.5655\n",
      "Epoch 34/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1092 - accuracy: 0.5565 - val_loss: 1.1199 - val_accuracy: 0.5628\n",
      "Epoch 35/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1065 - accuracy: 0.5565 - val_loss: 1.1115 - val_accuracy: 0.5735\n",
      "Epoch 36/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1104 - accuracy: 0.5536 - val_loss: 1.1224 - val_accuracy: 0.5676\n",
      "Epoch 37/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1027 - accuracy: 0.5584 - val_loss: 1.1050 - val_accuracy: 0.5699\n",
      "Epoch 38/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1030 - accuracy: 0.5590 - val_loss: 1.1061 - val_accuracy: 0.5593\n",
      "Epoch 39/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1027 - accuracy: 0.5568 - val_loss: 1.0961 - val_accuracy: 0.5762\n",
      "Epoch 40/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0978 - accuracy: 0.5590 - val_loss: 1.1041 - val_accuracy: 0.5702\n",
      "Epoch 41/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0973 - accuracy: 0.5600 - val_loss: 1.0989 - val_accuracy: 0.5699\n",
      "Epoch 42/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0938 - accuracy: 0.5625 - val_loss: 1.1059 - val_accuracy: 0.5625\n",
      "Epoch 43/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0951 - accuracy: 0.5612 - val_loss: 1.0940 - val_accuracy: 0.5753\n",
      "Epoch 44/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0936 - accuracy: 0.5565 - val_loss: 1.0903 - val_accuracy: 0.5803\n",
      "Epoch 45/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.5626 - val_loss: 1.0973 - val_accuracy: 0.5581\n",
      "Epoch 46/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0856 - accuracy: 0.5657 - val_loss: 1.0965 - val_accuracy: 0.5625\n",
      "Epoch 47/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0844 - accuracy: 0.5632 - val_loss: 1.0917 - val_accuracy: 0.5788\n",
      "Epoch 48/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0869 - accuracy: 0.5624 - val_loss: 1.1118 - val_accuracy: 0.5522\n",
      "Epoch 49/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0810 - accuracy: 0.5679 - val_loss: 1.0873 - val_accuracy: 0.5685\n",
      "Epoch 50/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0861 - accuracy: 0.5624 - val_loss: 1.0982 - val_accuracy: 0.5569\n",
      "Epoch 51/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0823 - accuracy: 0.5633 - val_loss: 1.1170 - val_accuracy: 0.5667\n",
      "Epoch 52/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0773 - accuracy: 0.5674 - val_loss: 1.1097 - val_accuracy: 0.5599\n",
      "Epoch 53/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0793 - accuracy: 0.5626 - val_loss: 1.0797 - val_accuracy: 0.5753\n",
      "Epoch 54/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0795 - accuracy: 0.5663 - val_loss: 1.0830 - val_accuracy: 0.5676\n",
      "Epoch 55/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0776 - accuracy: 0.5638 - val_loss: 1.0820 - val_accuracy: 0.5714\n",
      "Epoch 56/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0785 - accuracy: 0.5657 - val_loss: 1.1218 - val_accuracy: 0.5560\n",
      "Epoch 57/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0786 - accuracy: 0.5657 - val_loss: 1.0809 - val_accuracy: 0.5637\n",
      "Epoch 58/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0738 - accuracy: 0.5702 - val_loss: 1.0869 - val_accuracy: 0.5673\n",
      "Epoch 59/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0733 - accuracy: 0.5688 - val_loss: 1.0783 - val_accuracy: 0.5785\n",
      "Epoch 60/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0761 - accuracy: 0.5688 - val_loss: 1.0932 - val_accuracy: 0.5667\n",
      "Epoch 61/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0752 - accuracy: 0.5663 - val_loss: 1.0768 - val_accuracy: 0.5815\n",
      "Epoch 62/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0716 - accuracy: 0.5666 - val_loss: 1.0705 - val_accuracy: 0.5794\n",
      "Epoch 63/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0712 - accuracy: 0.5656 - val_loss: 1.0887 - val_accuracy: 0.5779\n",
      "Epoch 64/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0763 - accuracy: 0.5645 - val_loss: 1.1072 - val_accuracy: 0.5655\n",
      "Epoch 65/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0739 - accuracy: 0.5676 - val_loss: 1.0711 - val_accuracy: 0.5815\n",
      "Epoch 66/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0719 - accuracy: 0.5675 - val_loss: 1.0782 - val_accuracy: 0.5750\n",
      "Epoch 67/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0678 - accuracy: 0.5698 - val_loss: 1.0749 - val_accuracy: 0.5809\n",
      "Epoch 68/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0675 - accuracy: 0.5700 - val_loss: 1.0712 - val_accuracy: 0.5842\n",
      "Epoch 69/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0680 - accuracy: 0.5701 - val_loss: 1.0974 - val_accuracy: 0.5741\n",
      "Epoch 70/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0710 - accuracy: 0.5656 - val_loss: 1.0737 - val_accuracy: 0.5774\n",
      "Epoch 71/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0666 - accuracy: 0.5728 - val_loss: 1.0658 - val_accuracy: 0.5824\n",
      "Epoch 72/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0653 - accuracy: 0.5665 - val_loss: 1.0833 - val_accuracy: 0.5726\n",
      "Epoch 73/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0709 - accuracy: 0.5697 - val_loss: 1.0827 - val_accuracy: 0.5726\n",
      "Epoch 74/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0680 - accuracy: 0.5688 - val_loss: 1.0778 - val_accuracy: 0.5812\n",
      "Epoch 75/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0641 - accuracy: 0.5694 - val_loss: 1.1081 - val_accuracy: 0.5611\n",
      "Epoch 76/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0644 - accuracy: 0.5723 - val_loss: 1.0782 - val_accuracy: 0.5774\n",
      "Epoch 77/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0676 - accuracy: 0.5734 - val_loss: 1.0787 - val_accuracy: 0.5809\n",
      "Epoch 78/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0607 - accuracy: 0.5709 - val_loss: 1.0872 - val_accuracy: 0.5679\n",
      "Epoch 79/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0675 - accuracy: 0.5697 - val_loss: 1.0860 - val_accuracy: 0.5619\n",
      "Epoch 80/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0623 - accuracy: 0.5764 - val_loss: 1.0863 - val_accuracy: 0.5652\n",
      "Epoch 81/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0634 - accuracy: 0.5731 - val_loss: 1.0646 - val_accuracy: 0.5756\n",
      "Epoch 82/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0639 - accuracy: 0.5697 - val_loss: 1.0728 - val_accuracy: 0.5824\n",
      "Epoch 83/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0632 - accuracy: 0.5735 - val_loss: 1.0918 - val_accuracy: 0.5699\n",
      "Epoch 84/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0577 - accuracy: 0.5743 - val_loss: 1.0641 - val_accuracy: 0.5877\n",
      "Epoch 85/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0638 - accuracy: 0.5703 - val_loss: 1.0723 - val_accuracy: 0.5732\n",
      "Epoch 86/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0593 - accuracy: 0.5746 - val_loss: 1.0627 - val_accuracy: 0.5827\n",
      "Epoch 87/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0628 - accuracy: 0.5736 - val_loss: 1.0659 - val_accuracy: 0.5830\n",
      "Epoch 88/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0622 - accuracy: 0.5715 - val_loss: 1.0627 - val_accuracy: 0.5836\n",
      "Epoch 89/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0586 - accuracy: 0.5721 - val_loss: 1.0635 - val_accuracy: 0.5768\n",
      "Epoch 90/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0599 - accuracy: 0.5740 - val_loss: 1.1091 - val_accuracy: 0.5513\n",
      "Epoch 91/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0680 - accuracy: 0.5694 - val_loss: 1.0935 - val_accuracy: 0.5560\n",
      "Epoch 92/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0573 - accuracy: 0.5758 - val_loss: 1.0764 - val_accuracy: 0.5744\n",
      "Epoch 93/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0569 - accuracy: 0.5720 - val_loss: 1.0607 - val_accuracy: 0.5797\n",
      "Epoch 94/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0574 - accuracy: 0.5727 - val_loss: 1.0790 - val_accuracy: 0.5714\n",
      "Epoch 95/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0552 - accuracy: 0.5743 - val_loss: 1.0769 - val_accuracy: 0.5777\n",
      "Epoch 96/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0524 - accuracy: 0.5789 - val_loss: 1.0641 - val_accuracy: 0.5782\n",
      "Epoch 97/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0525 - accuracy: 0.5740 - val_loss: 1.0673 - val_accuracy: 0.5785\n",
      "Epoch 98/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0540 - accuracy: 0.5731 - val_loss: 1.0769 - val_accuracy: 0.5705\n",
      "Epoch 99/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0618 - accuracy: 0.5713 - val_loss: 1.0713 - val_accuracy: 0.5765\n",
      "Epoch 100/174\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0617 - accuracy: 0.5737 - val_loss: 1.0716 - val_accuracy: 0.5865\n",
      "Epoch 101/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0530 - accuracy: 0.5740 - val_loss: 1.0586 - val_accuracy: 0.5836\n",
      "Epoch 102/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0559 - accuracy: 0.5758 - val_loss: 1.0701 - val_accuracy: 0.5729\n",
      "Epoch 103/174\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0540 - accuracy: 0.5720 - val_loss: 1.0543 - val_accuracy: 0.5865\n",
      "Epoch 104/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0534 - accuracy: 0.5740 - val_loss: 1.0602 - val_accuracy: 0.5809\n",
      "Epoch 105/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0522 - accuracy: 0.5733 - val_loss: 1.0746 - val_accuracy: 0.5717\n",
      "Epoch 106/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0539 - accuracy: 0.5745 - val_loss: 1.0609 - val_accuracy: 0.5768\n",
      "Epoch 107/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0535 - accuracy: 0.5743 - val_loss: 1.0722 - val_accuracy: 0.5782\n",
      "Epoch 108/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0500 - accuracy: 0.5752 - val_loss: 1.0724 - val_accuracy: 0.5862\n",
      "Epoch 109/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0541 - accuracy: 0.5737 - val_loss: 1.0646 - val_accuracy: 0.5886\n",
      "Epoch 110/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0484 - accuracy: 0.5768 - val_loss: 1.0576 - val_accuracy: 0.5916\n",
      "Epoch 111/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0550 - accuracy: 0.5751 - val_loss: 1.0583 - val_accuracy: 0.5827\n",
      "Epoch 112/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0485 - accuracy: 0.5771 - val_loss: 1.0537 - val_accuracy: 0.5862\n",
      "Epoch 113/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0476 - accuracy: 0.5792 - val_loss: 1.0765 - val_accuracy: 0.5682\n",
      "Epoch 114/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0512 - accuracy: 0.5758 - val_loss: 1.0644 - val_accuracy: 0.5777\n",
      "Epoch 115/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0495 - accuracy: 0.5787 - val_loss: 1.0693 - val_accuracy: 0.5702\n",
      "Epoch 116/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0511 - accuracy: 0.5741 - val_loss: 1.0831 - val_accuracy: 0.5809\n",
      "Epoch 117/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0523 - accuracy: 0.5737 - val_loss: 1.0656 - val_accuracy: 0.5830\n",
      "Epoch 118/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0533 - accuracy: 0.5738 - val_loss: 1.0668 - val_accuracy: 0.5779\n",
      "Epoch 119/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0520 - accuracy: 0.5766 - val_loss: 1.0560 - val_accuracy: 0.5925\n",
      "Epoch 120/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0475 - accuracy: 0.5777 - val_loss: 1.0604 - val_accuracy: 0.5848\n",
      "Epoch 121/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0482 - accuracy: 0.5776 - val_loss: 1.0507 - val_accuracy: 0.5827\n",
      "Epoch 122/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0466 - accuracy: 0.5746 - val_loss: 1.0589 - val_accuracy: 0.5928\n",
      "Epoch 123/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0484 - accuracy: 0.5765 - val_loss: 1.0554 - val_accuracy: 0.5922\n",
      "Epoch 124/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0491 - accuracy: 0.5771 - val_loss: 1.0695 - val_accuracy: 0.5779\n",
      "Epoch 125/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0473 - accuracy: 0.5794 - val_loss: 1.0924 - val_accuracy: 0.5750\n",
      "Epoch 126/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0496 - accuracy: 0.5757 - val_loss: 1.0518 - val_accuracy: 0.5818\n",
      "Epoch 127/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0482 - accuracy: 0.5775 - val_loss: 1.0742 - val_accuracy: 0.5797\n",
      "Epoch 128/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0505 - accuracy: 0.5772 - val_loss: 1.0470 - val_accuracy: 0.5874\n",
      "Epoch 129/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0478 - accuracy: 0.5777 - val_loss: 1.0618 - val_accuracy: 0.5868\n",
      "Epoch 130/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0496 - accuracy: 0.5787 - val_loss: 1.0477 - val_accuracy: 0.5836\n",
      "Epoch 131/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0444 - accuracy: 0.5791 - val_loss: 1.0625 - val_accuracy: 0.5889\n",
      "Epoch 132/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0486 - accuracy: 0.5757 - val_loss: 1.0663 - val_accuracy: 0.5815\n",
      "Epoch 133/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0400 - accuracy: 0.5809 - val_loss: 1.0487 - val_accuracy: 0.5871\n",
      "Epoch 134/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0455 - accuracy: 0.5779 - val_loss: 1.0621 - val_accuracy: 0.5931\n",
      "Epoch 135/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0440 - accuracy: 0.5803 - val_loss: 1.0543 - val_accuracy: 0.5845\n",
      "Epoch 136/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0499 - accuracy: 0.5728 - val_loss: 1.0527 - val_accuracy: 0.5860\n",
      "Epoch 137/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0510 - accuracy: 0.5756 - val_loss: 1.0670 - val_accuracy: 0.5771\n",
      "Epoch 138/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0437 - accuracy: 0.5807 - val_loss: 1.1141 - val_accuracy: 0.5578\n",
      "Epoch 139/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0436 - accuracy: 0.5764 - val_loss: 1.0522 - val_accuracy: 0.5886\n",
      "Epoch 140/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0420 - accuracy: 0.5788 - val_loss: 1.0467 - val_accuracy: 0.5883\n",
      "Epoch 141/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0429 - accuracy: 0.5794 - val_loss: 1.0612 - val_accuracy: 0.5889\n",
      "Epoch 142/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0453 - accuracy: 0.5793 - val_loss: 1.0446 - val_accuracy: 0.5865\n",
      "Epoch 143/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0428 - accuracy: 0.5811 - val_loss: 1.0528 - val_accuracy: 0.5821\n",
      "Epoch 144/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0482 - accuracy: 0.5801 - val_loss: 1.0433 - val_accuracy: 0.5868\n",
      "Epoch 145/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0450 - accuracy: 0.5773 - val_loss: 1.0525 - val_accuracy: 0.5901\n",
      "Epoch 146/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0391 - accuracy: 0.5814 - val_loss: 1.0512 - val_accuracy: 0.5824\n",
      "Epoch 147/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0414 - accuracy: 0.5791 - val_loss: 1.0952 - val_accuracy: 0.5649\n",
      "Epoch 148/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0464 - accuracy: 0.5782 - val_loss: 1.0646 - val_accuracy: 0.5765\n",
      "Epoch 149/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0407 - accuracy: 0.5809 - val_loss: 1.0439 - val_accuracy: 0.5857\n",
      "Epoch 150/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0393 - accuracy: 0.5826 - val_loss: 1.0680 - val_accuracy: 0.5782\n",
      "Epoch 151/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0393 - accuracy: 0.5824 - val_loss: 1.1019 - val_accuracy: 0.5655\n",
      "Epoch 152/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0415 - accuracy: 0.5802 - val_loss: 1.0456 - val_accuracy: 0.5931\n",
      "Epoch 153/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0430 - accuracy: 0.5803 - val_loss: 1.0424 - val_accuracy: 0.5862\n",
      "Epoch 154/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0363 - accuracy: 0.5833 - val_loss: 1.0464 - val_accuracy: 0.5895\n",
      "Epoch 155/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0368 - accuracy: 0.5809 - val_loss: 1.0785 - val_accuracy: 0.5774\n",
      "Epoch 156/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0370 - accuracy: 0.5810 - val_loss: 1.0474 - val_accuracy: 0.5928\n",
      "Epoch 157/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0398 - accuracy: 0.5805 - val_loss: 1.0477 - val_accuracy: 0.5824\n",
      "Epoch 158/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0392 - accuracy: 0.5791 - val_loss: 1.0469 - val_accuracy: 0.5836\n",
      "Epoch 159/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0373 - accuracy: 0.5801 - val_loss: 1.0529 - val_accuracy: 0.5898\n",
      "Epoch 160/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0382 - accuracy: 0.5822 - val_loss: 1.0483 - val_accuracy: 0.5815\n",
      "Epoch 161/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0380 - accuracy: 0.5829 - val_loss: 1.0427 - val_accuracy: 0.5857\n",
      "Epoch 162/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0475 - accuracy: 0.5786 - val_loss: 1.0508 - val_accuracy: 0.5910\n",
      "Epoch 163/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0398 - accuracy: 0.5831 - val_loss: 1.0464 - val_accuracy: 0.5830\n",
      "Epoch 164/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0371 - accuracy: 0.5839 - val_loss: 1.0691 - val_accuracy: 0.5765\n",
      "Epoch 165/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0431 - accuracy: 0.5809 - val_loss: 1.0458 - val_accuracy: 0.5922\n",
      "Epoch 166/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0407 - accuracy: 0.5814 - val_loss: 1.0458 - val_accuracy: 0.5824\n",
      "Epoch 167/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0351 - accuracy: 0.5849 - val_loss: 1.0498 - val_accuracy: 0.5851\n",
      "Epoch 168/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0416 - accuracy: 0.5828 - val_loss: 1.0414 - val_accuracy: 0.5851\n",
      "Epoch 169/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0374 - accuracy: 0.5787 - val_loss: 1.0412 - val_accuracy: 0.5860\n",
      "Epoch 170/174\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0362 - accuracy: 0.5829 - val_loss: 1.0506 - val_accuracy: 0.5845\n",
      "Epoch 171/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0361 - accuracy: 0.5822 - val_loss: 1.0444 - val_accuracy: 0.5889\n",
      "Epoch 172/174\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0348 - accuracy: 0.5823 - val_loss: 1.0520 - val_accuracy: 0.5889\n",
      "Epoch 173/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0366 - accuracy: 0.5808 - val_loss: 1.0396 - val_accuracy: 0.5901\n",
      "Epoch 174/174\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0329 - accuracy: 0.5852 - val_loss: 1.0546 - val_accuracy: 0.5851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a80bfa370>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f38298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 0s 1ms/step\n",
      "(array([0, 1, 2, 3], dtype=int64), array([4337, 1962,    4, 2006], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4], dtype=int64), array([3422, 1974,  601, 1734,  578], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4], dtype=int64), array([6993, 3910, 1197, 3571, 1197], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.argmax(model.predict(X_test), axis=1), return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1ce9c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5744373570826814"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf54550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model_d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4501cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\no_back\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 192\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.5853893160820007\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 208\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "Score: 0.5838247537612915\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 96\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "Score: 0.5831026434898376\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 128\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.9999\n",
      "Score: 0.5826212763786316\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 112\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "Score: 0.5797328352928162\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 96\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "Score: 0.5793717503547668\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 80\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.578649640083313\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 160\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "Score: 0.5781682729721069\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 64\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.5768443942070007\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_neurons: 192\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.85\n",
      "beta_2: 0.99\n",
      "Score: 0.5760019421577454\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b5fdf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 1.4226 - accuracy: 0.4108 - val_loss: 1.4114 - val_accuracy: 0.4132\n",
      "Epoch 2/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4066 - accuracy: 0.4149 - val_loss: 1.4110 - val_accuracy: 0.4132\n",
      "Epoch 3/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4057 - accuracy: 0.4149 - val_loss: 1.4086 - val_accuracy: 0.4132\n",
      "Epoch 4/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4001 - accuracy: 0.4149 - val_loss: 1.4019 - val_accuracy: 0.4132\n",
      "Epoch 5/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3840 - accuracy: 0.4149 - val_loss: 1.3733 - val_accuracy: 0.4132\n",
      "Epoch 6/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3560 - accuracy: 0.4180 - val_loss: 1.3400 - val_accuracy: 0.4188\n",
      "Epoch 7/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3265 - accuracy: 0.4301 - val_loss: 1.3116 - val_accuracy: 0.4431\n",
      "Epoch 8/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3029 - accuracy: 0.4467 - val_loss: 1.2893 - val_accuracy: 0.4603\n",
      "Epoch 9/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2807 - accuracy: 0.4689 - val_loss: 1.2683 - val_accuracy: 0.4775\n",
      "Epoch 10/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2651 - accuracy: 0.4782 - val_loss: 1.2686 - val_accuracy: 0.4884\n",
      "Epoch 11/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2486 - accuracy: 0.4942 - val_loss: 1.2355 - val_accuracy: 0.5086\n",
      "Epoch 12/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2337 - accuracy: 0.5019 - val_loss: 1.2329 - val_accuracy: 0.5003\n",
      "Epoch 13/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2242 - accuracy: 0.5084 - val_loss: 1.2160 - val_accuracy: 0.5249\n",
      "Epoch 14/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2188 - accuracy: 0.5104 - val_loss: 1.2137 - val_accuracy: 0.5130\n",
      "Epoch 15/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2058 - accuracy: 0.5164 - val_loss: 1.2053 - val_accuracy: 0.5258\n",
      "Epoch 16/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.1986 - accuracy: 0.5162 - val_loss: 1.2288 - val_accuracy: 0.5068\n",
      "Epoch 17/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.1887 - accuracy: 0.5210 - val_loss: 1.1913 - val_accuracy: 0.5317\n",
      "Epoch 18/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1846 - accuracy: 0.5207 - val_loss: 1.1789 - val_accuracy: 0.5480\n",
      "Epoch 19/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1777 - accuracy: 0.5244 - val_loss: 1.1705 - val_accuracy: 0.5436\n",
      "Epoch 20/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1767 - accuracy: 0.5256 - val_loss: 1.1669 - val_accuracy: 0.5533\n",
      "Epoch 21/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1711 - accuracy: 0.5262 - val_loss: 1.1934 - val_accuracy: 0.5353\n",
      "Epoch 22/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1697 - accuracy: 0.5315 - val_loss: 1.1610 - val_accuracy: 0.5430\n",
      "Epoch 23/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1655 - accuracy: 0.5337 - val_loss: 1.1655 - val_accuracy: 0.5462\n",
      "Epoch 24/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1636 - accuracy: 0.5302 - val_loss: 1.1669 - val_accuracy: 0.5317\n",
      "Epoch 25/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1583 - accuracy: 0.5335 - val_loss: 1.2037 - val_accuracy: 0.5222\n",
      "Epoch 26/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1582 - accuracy: 0.5348 - val_loss: 1.1630 - val_accuracy: 0.5376\n",
      "Epoch 27/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1569 - accuracy: 0.5325 - val_loss: 1.1599 - val_accuracy: 0.5412\n",
      "Epoch 28/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1518 - accuracy: 0.5394 - val_loss: 1.1458 - val_accuracy: 0.5480\n",
      "Epoch 29/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1558 - accuracy: 0.5400 - val_loss: 1.1590 - val_accuracy: 0.5522\n",
      "Epoch 30/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1483 - accuracy: 0.5400 - val_loss: 1.1412 - val_accuracy: 0.5699\n",
      "Epoch 31/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1478 - accuracy: 0.5399 - val_loss: 1.1448 - val_accuracy: 0.5542\n",
      "Epoch 32/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1439 - accuracy: 0.5431 - val_loss: 1.1377 - val_accuracy: 0.5643\n",
      "Epoch 33/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1431 - accuracy: 0.5439 - val_loss: 1.1401 - val_accuracy: 0.5640\n",
      "Epoch 34/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1413 - accuracy: 0.5456 - val_loss: 1.1367 - val_accuracy: 0.5702\n",
      "Epoch 35/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1402 - accuracy: 0.5455 - val_loss: 1.1549 - val_accuracy: 0.5477\n",
      "Epoch 36/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1388 - accuracy: 0.5469 - val_loss: 1.1342 - val_accuracy: 0.5575\n",
      "Epoch 37/250\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1366 - accuracy: 0.5491 - val_loss: 1.1351 - val_accuracy: 0.5676\n",
      "Epoch 38/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1357 - accuracy: 0.5491 - val_loss: 1.1280 - val_accuracy: 0.5643\n",
      "Epoch 39/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1319 - accuracy: 0.5556 - val_loss: 1.1288 - val_accuracy: 0.5685\n",
      "Epoch 40/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1362 - accuracy: 0.5514 - val_loss: 1.1419 - val_accuracy: 0.5599\n",
      "Epoch 41/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1332 - accuracy: 0.5477 - val_loss: 1.1251 - val_accuracy: 0.5711\n",
      "Epoch 42/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1322 - accuracy: 0.5502 - val_loss: 1.1252 - val_accuracy: 0.5661\n",
      "Epoch 43/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1281 - accuracy: 0.5516 - val_loss: 1.1366 - val_accuracy: 0.5531\n",
      "Epoch 44/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1282 - accuracy: 0.5538 - val_loss: 1.1923 - val_accuracy: 0.5332\n",
      "Epoch 45/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1294 - accuracy: 0.5525 - val_loss: 1.1339 - val_accuracy: 0.5664\n",
      "Epoch 46/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1248 - accuracy: 0.5522 - val_loss: 1.1147 - val_accuracy: 0.5670\n",
      "Epoch 47/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1256 - accuracy: 0.5537 - val_loss: 1.1210 - val_accuracy: 0.5750\n",
      "Epoch 48/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1182 - accuracy: 0.5565 - val_loss: 1.1368 - val_accuracy: 0.5501\n",
      "Epoch 49/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1215 - accuracy: 0.5511 - val_loss: 1.1121 - val_accuracy: 0.5711\n",
      "Epoch 50/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1184 - accuracy: 0.5525 - val_loss: 1.1298 - val_accuracy: 0.5608\n",
      "Epoch 51/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1155 - accuracy: 0.5542 - val_loss: 1.1034 - val_accuracy: 0.5688\n",
      "Epoch 52/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1147 - accuracy: 0.5545 - val_loss: 1.1403 - val_accuracy: 0.5329\n",
      "Epoch 53/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1131 - accuracy: 0.5553 - val_loss: 1.1648 - val_accuracy: 0.5498\n",
      "Epoch 54/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1135 - accuracy: 0.5554 - val_loss: 1.1052 - val_accuracy: 0.5762\n",
      "Epoch 55/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1070 - accuracy: 0.5593 - val_loss: 1.1021 - val_accuracy: 0.5732\n",
      "Epoch 56/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1073 - accuracy: 0.5596 - val_loss: 1.1077 - val_accuracy: 0.5658\n",
      "Epoch 57/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1066 - accuracy: 0.5575 - val_loss: 1.0979 - val_accuracy: 0.5699\n",
      "Epoch 58/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1063 - accuracy: 0.5562 - val_loss: 1.0976 - val_accuracy: 0.5774\n",
      "Epoch 59/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1010 - accuracy: 0.5617 - val_loss: 1.1017 - val_accuracy: 0.5619\n",
      "Epoch 60/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1057 - accuracy: 0.5595 - val_loss: 1.0981 - val_accuracy: 0.5723\n",
      "Epoch 61/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1041 - accuracy: 0.5567 - val_loss: 1.1123 - val_accuracy: 0.5575\n",
      "Epoch 62/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1033 - accuracy: 0.5589 - val_loss: 1.1045 - val_accuracy: 0.5673\n",
      "Epoch 63/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1007 - accuracy: 0.5580 - val_loss: 1.1024 - val_accuracy: 0.5625\n",
      "Epoch 64/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1045 - accuracy: 0.5577 - val_loss: 1.1289 - val_accuracy: 0.5670\n",
      "Epoch 65/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0973 - accuracy: 0.5615 - val_loss: 1.0974 - val_accuracy: 0.5744\n",
      "Epoch 66/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0962 - accuracy: 0.5628 - val_loss: 1.0901 - val_accuracy: 0.5765\n",
      "Epoch 67/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0982 - accuracy: 0.5620 - val_loss: 1.1136 - val_accuracy: 0.5477\n",
      "Epoch 68/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0960 - accuracy: 0.5631 - val_loss: 1.1099 - val_accuracy: 0.5682\n",
      "Epoch 69/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0955 - accuracy: 0.5640 - val_loss: 1.0914 - val_accuracy: 0.5797\n",
      "Epoch 70/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0945 - accuracy: 0.5659 - val_loss: 1.0889 - val_accuracy: 0.5714\n",
      "Epoch 71/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0972 - accuracy: 0.5603 - val_loss: 1.0873 - val_accuracy: 0.5732\n",
      "Epoch 72/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0910 - accuracy: 0.5657 - val_loss: 1.0999 - val_accuracy: 0.5676\n",
      "Epoch 73/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0948 - accuracy: 0.5619 - val_loss: 1.1233 - val_accuracy: 0.5397\n",
      "Epoch 74/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0916 - accuracy: 0.5629 - val_loss: 1.0880 - val_accuracy: 0.5691\n",
      "Epoch 75/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0932 - accuracy: 0.5650 - val_loss: 1.0840 - val_accuracy: 0.5744\n",
      "Epoch 76/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0900 - accuracy: 0.5651 - val_loss: 1.0999 - val_accuracy: 0.5685\n",
      "Epoch 77/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0890 - accuracy: 0.5651 - val_loss: 1.0820 - val_accuracy: 0.5771\n",
      "Epoch 78/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0901 - accuracy: 0.5643 - val_loss: 1.0838 - val_accuracy: 0.5821\n",
      "Epoch 79/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0909 - accuracy: 0.5657 - val_loss: 1.0992 - val_accuracy: 0.5791\n",
      "Epoch 80/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0932 - accuracy: 0.5624 - val_loss: 1.0977 - val_accuracy: 0.5673\n",
      "Epoch 81/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0874 - accuracy: 0.5655 - val_loss: 1.1215 - val_accuracy: 0.5498\n",
      "Epoch 82/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0886 - accuracy: 0.5649 - val_loss: 1.0961 - val_accuracy: 0.5717\n",
      "Epoch 83/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0892 - accuracy: 0.5666 - val_loss: 1.0938 - val_accuracy: 0.5839\n",
      "Epoch 84/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0859 - accuracy: 0.5648 - val_loss: 1.0805 - val_accuracy: 0.5833\n",
      "Epoch 85/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0871 - accuracy: 0.5701 - val_loss: 1.0970 - val_accuracy: 0.5631\n",
      "Epoch 86/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0892 - accuracy: 0.5650 - val_loss: 1.0845 - val_accuracy: 0.5738\n",
      "Epoch 87/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0823 - accuracy: 0.5674 - val_loss: 1.0892 - val_accuracy: 0.5643\n",
      "Epoch 88/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0822 - accuracy: 0.5694 - val_loss: 1.0790 - val_accuracy: 0.5705\n",
      "Epoch 89/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0841 - accuracy: 0.5670 - val_loss: 1.0954 - val_accuracy: 0.5744\n",
      "Epoch 90/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0824 - accuracy: 0.5668 - val_loss: 1.0768 - val_accuracy: 0.5871\n",
      "Epoch 91/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0800 - accuracy: 0.5685 - val_loss: 1.0889 - val_accuracy: 0.5673\n",
      "Epoch 92/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0830 - accuracy: 0.5655 - val_loss: 1.0759 - val_accuracy: 0.5717\n",
      "Epoch 93/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0813 - accuracy: 0.5664 - val_loss: 1.0824 - val_accuracy: 0.5854\n",
      "Epoch 94/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0824 - accuracy: 0.5683 - val_loss: 1.0734 - val_accuracy: 0.5874\n",
      "Epoch 95/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0769 - accuracy: 0.5686 - val_loss: 1.0754 - val_accuracy: 0.5806\n",
      "Epoch 96/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0785 - accuracy: 0.5700 - val_loss: 1.0840 - val_accuracy: 0.5833\n",
      "Epoch 97/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0799 - accuracy: 0.5702 - val_loss: 1.0958 - val_accuracy: 0.5643\n",
      "Epoch 98/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0767 - accuracy: 0.5688 - val_loss: 1.0678 - val_accuracy: 0.5794\n",
      "Epoch 99/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0785 - accuracy: 0.5678 - val_loss: 1.0746 - val_accuracy: 0.5830\n",
      "Epoch 100/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0775 - accuracy: 0.5680 - val_loss: 1.0839 - val_accuracy: 0.5812\n",
      "Epoch 101/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.5680 - val_loss: 1.0915 - val_accuracy: 0.5637\n",
      "Epoch 102/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0758 - accuracy: 0.5679 - val_loss: 1.0748 - val_accuracy: 0.5777\n",
      "Epoch 103/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0753 - accuracy: 0.5684 - val_loss: 1.0836 - val_accuracy: 0.5744\n",
      "Epoch 104/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0728 - accuracy: 0.5726 - val_loss: 1.0687 - val_accuracy: 0.5827\n",
      "Epoch 105/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0738 - accuracy: 0.5691 - val_loss: 1.0862 - val_accuracy: 0.5779\n",
      "Epoch 106/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0720 - accuracy: 0.5721 - val_loss: 1.0835 - val_accuracy: 0.5857\n",
      "Epoch 107/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0747 - accuracy: 0.5726 - val_loss: 1.0676 - val_accuracy: 0.5806\n",
      "Epoch 108/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0734 - accuracy: 0.5719 - val_loss: 1.0759 - val_accuracy: 0.5658\n",
      "Epoch 109/250\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0721 - accuracy: 0.5711 - val_loss: 1.0862 - val_accuracy: 0.5726\n",
      "Epoch 110/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0716 - accuracy: 0.5707 - val_loss: 1.0921 - val_accuracy: 0.5791\n",
      "Epoch 111/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0681 - accuracy: 0.5701 - val_loss: 1.0882 - val_accuracy: 0.5782\n",
      "Epoch 112/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0686 - accuracy: 0.5742 - val_loss: 1.0776 - val_accuracy: 0.5851\n",
      "Epoch 113/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0705 - accuracy: 0.5700 - val_loss: 1.0676 - val_accuracy: 0.5871\n",
      "Epoch 114/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0670 - accuracy: 0.5711 - val_loss: 1.0693 - val_accuracy: 0.5750\n",
      "Epoch 115/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0653 - accuracy: 0.5714 - val_loss: 1.0803 - val_accuracy: 0.5803\n",
      "Epoch 116/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0669 - accuracy: 0.5716 - val_loss: 1.0862 - val_accuracy: 0.5797\n",
      "Epoch 117/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0670 - accuracy: 0.5725 - val_loss: 1.0628 - val_accuracy: 0.5877\n",
      "Epoch 118/250\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0645 - accuracy: 0.5743 - val_loss: 1.0694 - val_accuracy: 0.5723\n",
      "Epoch 119/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0668 - accuracy: 0.5726 - val_loss: 1.0904 - val_accuracy: 0.5771\n",
      "Epoch 120/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0661 - accuracy: 0.5756 - val_loss: 1.0647 - val_accuracy: 0.5901\n",
      "Epoch 121/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0615 - accuracy: 0.5739 - val_loss: 1.0744 - val_accuracy: 0.5812\n",
      "Epoch 122/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0645 - accuracy: 0.5717 - val_loss: 1.0696 - val_accuracy: 0.5865\n",
      "Epoch 123/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0613 - accuracy: 0.5740 - val_loss: 1.0597 - val_accuracy: 0.5830\n",
      "Epoch 124/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0587 - accuracy: 0.5754 - val_loss: 1.0558 - val_accuracy: 0.5892\n",
      "Epoch 125/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0630 - accuracy: 0.5688 - val_loss: 1.0615 - val_accuracy: 0.5910\n",
      "Epoch 126/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0632 - accuracy: 0.5700 - val_loss: 1.0685 - val_accuracy: 0.5800\n",
      "Epoch 127/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0646 - accuracy: 0.5731 - val_loss: 1.0627 - val_accuracy: 0.5821\n",
      "Epoch 128/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0573 - accuracy: 0.5751 - val_loss: 1.0625 - val_accuracy: 0.5907\n",
      "Epoch 129/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0599 - accuracy: 0.5764 - val_loss: 1.0590 - val_accuracy: 0.5860\n",
      "Epoch 130/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0572 - accuracy: 0.5757 - val_loss: 1.0819 - val_accuracy: 0.5824\n",
      "Epoch 131/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0598 - accuracy: 0.5771 - val_loss: 1.0612 - val_accuracy: 0.5788\n",
      "Epoch 132/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0595 - accuracy: 0.5746 - val_loss: 1.1219 - val_accuracy: 0.5554\n",
      "Epoch 133/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0595 - accuracy: 0.5743 - val_loss: 1.0516 - val_accuracy: 0.5865\n",
      "Epoch 134/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0588 - accuracy: 0.5768 - val_loss: 1.0536 - val_accuracy: 0.5898\n",
      "Epoch 135/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0558 - accuracy: 0.5765 - val_loss: 1.0712 - val_accuracy: 0.5815\n",
      "Epoch 136/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0552 - accuracy: 0.5778 - val_loss: 1.0749 - val_accuracy: 0.5934\n",
      "Epoch 137/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0573 - accuracy: 0.5755 - val_loss: 1.0580 - val_accuracy: 0.5845\n",
      "Epoch 138/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0564 - accuracy: 0.5746 - val_loss: 1.0780 - val_accuracy: 0.5839\n",
      "Epoch 139/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0572 - accuracy: 0.5741 - val_loss: 1.0786 - val_accuracy: 0.5729\n",
      "Epoch 140/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0545 - accuracy: 0.5775 - val_loss: 1.0580 - val_accuracy: 0.5785\n",
      "Epoch 141/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0567 - accuracy: 0.5747 - val_loss: 1.0850 - val_accuracy: 0.5848\n",
      "Epoch 142/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0585 - accuracy: 0.5748 - val_loss: 1.0804 - val_accuracy: 0.5771\n",
      "Epoch 143/250\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0532 - accuracy: 0.5780 - val_loss: 1.0797 - val_accuracy: 0.5892\n",
      "Epoch 144/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0585 - accuracy: 0.5750 - val_loss: 1.0512 - val_accuracy: 0.5916\n",
      "Epoch 145/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0535 - accuracy: 0.5767 - val_loss: 1.0522 - val_accuracy: 0.5895\n",
      "Epoch 146/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0554 - accuracy: 0.5788 - val_loss: 1.0823 - val_accuracy: 0.5699\n",
      "Epoch 147/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0565 - accuracy: 0.5754 - val_loss: 1.0616 - val_accuracy: 0.5934\n",
      "Epoch 148/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0565 - accuracy: 0.5768 - val_loss: 1.0623 - val_accuracy: 0.5830\n",
      "Epoch 149/250\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0540 - accuracy: 0.5777 - val_loss: 1.0624 - val_accuracy: 0.5925\n",
      "Epoch 150/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0533 - accuracy: 0.5757 - val_loss: 1.0690 - val_accuracy: 0.5809\n",
      "Epoch 151/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0544 - accuracy: 0.5769 - val_loss: 1.0546 - val_accuracy: 0.5806\n",
      "Epoch 152/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0497 - accuracy: 0.5787 - val_loss: 1.0676 - val_accuracy: 0.5791\n",
      "Epoch 153/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0541 - accuracy: 0.5759 - val_loss: 1.0474 - val_accuracy: 0.5916\n",
      "Epoch 154/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0525 - accuracy: 0.5768 - val_loss: 1.0662 - val_accuracy: 0.5922\n",
      "Epoch 155/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0534 - accuracy: 0.5770 - val_loss: 1.0656 - val_accuracy: 0.5815\n",
      "Epoch 156/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0488 - accuracy: 0.5788 - val_loss: 1.0499 - val_accuracy: 0.5889\n",
      "Epoch 157/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0518 - accuracy: 0.5800 - val_loss: 1.0535 - val_accuracy: 0.5833\n",
      "Epoch 158/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0463 - accuracy: 0.5794 - val_loss: 1.0456 - val_accuracy: 0.5922\n",
      "Epoch 159/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0489 - accuracy: 0.5784 - val_loss: 1.0552 - val_accuracy: 0.5960\n",
      "Epoch 160/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0491 - accuracy: 0.5786 - val_loss: 1.0501 - val_accuracy: 0.5892\n",
      "Epoch 161/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0454 - accuracy: 0.5796 - val_loss: 1.0471 - val_accuracy: 0.5913\n",
      "Epoch 162/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0487 - accuracy: 0.5786 - val_loss: 1.0555 - val_accuracy: 0.5886\n",
      "Epoch 163/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0494 - accuracy: 0.5788 - val_loss: 1.0537 - val_accuracy: 0.5904\n",
      "Epoch 164/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0450 - accuracy: 0.5820 - val_loss: 1.0443 - val_accuracy: 0.5889\n",
      "Epoch 165/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0452 - accuracy: 0.5829 - val_loss: 1.0565 - val_accuracy: 0.5830\n",
      "Epoch 166/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0434 - accuracy: 0.5817 - val_loss: 1.0598 - val_accuracy: 0.5836\n",
      "Epoch 167/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0449 - accuracy: 0.5803 - val_loss: 1.0543 - val_accuracy: 0.5860\n",
      "Epoch 168/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0452 - accuracy: 0.5809 - val_loss: 1.0440 - val_accuracy: 0.5951\n",
      "Epoch 169/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0447 - accuracy: 0.5822 - val_loss: 1.0502 - val_accuracy: 0.5972\n",
      "Epoch 170/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0452 - accuracy: 0.5813 - val_loss: 1.0481 - val_accuracy: 0.5865\n",
      "Epoch 171/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0448 - accuracy: 0.5817 - val_loss: 1.0482 - val_accuracy: 0.5848\n",
      "Epoch 172/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0449 - accuracy: 0.5806 - val_loss: 1.0559 - val_accuracy: 0.5854\n",
      "Epoch 173/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0455 - accuracy: 0.5815 - val_loss: 1.0558 - val_accuracy: 0.5940\n",
      "Epoch 174/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0440 - accuracy: 0.5798 - val_loss: 1.0518 - val_accuracy: 0.5937\n",
      "Epoch 175/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0426 - accuracy: 0.5831 - val_loss: 1.0661 - val_accuracy: 0.5830\n",
      "Epoch 176/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0411 - accuracy: 0.5829 - val_loss: 1.0513 - val_accuracy: 0.5824\n",
      "Epoch 177/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0432 - accuracy: 0.5820 - val_loss: 1.0506 - val_accuracy: 0.5945\n",
      "Epoch 178/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0434 - accuracy: 0.5799 - val_loss: 1.0391 - val_accuracy: 0.5934\n",
      "Epoch 179/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0419 - accuracy: 0.5829 - val_loss: 1.0525 - val_accuracy: 0.5937\n",
      "Epoch 180/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0391 - accuracy: 0.5842 - val_loss: 1.0452 - val_accuracy: 0.5871\n",
      "Epoch 181/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0439 - accuracy: 0.5794 - val_loss: 1.0608 - val_accuracy: 0.5943\n",
      "Epoch 182/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0403 - accuracy: 0.5828 - val_loss: 1.0454 - val_accuracy: 0.5883\n",
      "Epoch 183/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0399 - accuracy: 0.5832 - val_loss: 1.0412 - val_accuracy: 0.5969\n",
      "Epoch 184/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0388 - accuracy: 0.5826 - val_loss: 1.0527 - val_accuracy: 0.5788\n",
      "Epoch 185/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0413 - accuracy: 0.5852 - val_loss: 1.0636 - val_accuracy: 0.5782\n",
      "Epoch 186/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0384 - accuracy: 0.5844 - val_loss: 1.0506 - val_accuracy: 0.5842\n",
      "Epoch 187/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0397 - accuracy: 0.5824 - val_loss: 1.0471 - val_accuracy: 0.5954\n",
      "Epoch 188/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0418 - accuracy: 0.5829 - val_loss: 1.0418 - val_accuracy: 0.5922\n",
      "Epoch 189/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0457 - accuracy: 0.5786 - val_loss: 1.0470 - val_accuracy: 0.5845\n",
      "Epoch 190/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0390 - accuracy: 0.5874 - val_loss: 1.0457 - val_accuracy: 0.5975\n",
      "Epoch 191/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0393 - accuracy: 0.5837 - val_loss: 1.0598 - val_accuracy: 0.5806\n",
      "Epoch 192/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0402 - accuracy: 0.5871 - val_loss: 1.0368 - val_accuracy: 0.5919\n",
      "Epoch 193/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0383 - accuracy: 0.5823 - val_loss: 1.0582 - val_accuracy: 0.5862\n",
      "Epoch 194/250\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.0384 - accuracy: 0.5840 - val_loss: 1.0575 - val_accuracy: 0.5845\n",
      "Epoch 195/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0392 - accuracy: 0.5823 - val_loss: 1.0494 - val_accuracy: 0.5848\n",
      "Epoch 196/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0424 - accuracy: 0.5829 - val_loss: 1.0558 - val_accuracy: 0.5886\n",
      "Epoch 197/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0379 - accuracy: 0.5848 - val_loss: 1.0450 - val_accuracy: 0.5886\n",
      "Epoch 198/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0408 - accuracy: 0.5810 - val_loss: 1.0406 - val_accuracy: 0.5883\n",
      "Epoch 199/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0382 - accuracy: 0.5822 - val_loss: 1.0515 - val_accuracy: 0.5842\n",
      "Epoch 200/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0364 - accuracy: 0.5841 - val_loss: 1.0369 - val_accuracy: 0.5948\n",
      "Epoch 201/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0348 - accuracy: 0.5859 - val_loss: 1.0433 - val_accuracy: 0.5916\n",
      "Epoch 202/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0378 - accuracy: 0.5849 - val_loss: 1.0546 - val_accuracy: 0.5960\n",
      "Epoch 203/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0353 - accuracy: 0.5843 - val_loss: 1.0521 - val_accuracy: 0.5925\n",
      "Epoch 204/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0347 - accuracy: 0.5843 - val_loss: 1.0486 - val_accuracy: 0.5880\n",
      "Epoch 205/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0339 - accuracy: 0.5832 - val_loss: 1.0491 - val_accuracy: 0.5913\n",
      "Epoch 206/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0359 - accuracy: 0.5830 - val_loss: 1.0659 - val_accuracy: 0.5904\n",
      "Epoch 207/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0397 - accuracy: 0.5785 - val_loss: 1.0387 - val_accuracy: 0.5981\n",
      "Epoch 208/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0371 - accuracy: 0.5823 - val_loss: 1.0328 - val_accuracy: 0.5919\n",
      "Epoch 209/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0372 - accuracy: 0.5834 - val_loss: 1.0444 - val_accuracy: 0.5981\n",
      "Epoch 210/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0355 - accuracy: 0.5829 - val_loss: 1.0351 - val_accuracy: 0.5945\n",
      "Epoch 211/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0341 - accuracy: 0.5843 - val_loss: 1.0479 - val_accuracy: 0.5948\n",
      "Epoch 212/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0319 - accuracy: 0.5836 - val_loss: 1.0456 - val_accuracy: 0.5877\n",
      "Epoch 213/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0355 - accuracy: 0.5846 - val_loss: 1.0365 - val_accuracy: 0.5954\n",
      "Epoch 214/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0339 - accuracy: 0.5849 - val_loss: 1.0343 - val_accuracy: 0.5945\n",
      "Epoch 215/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0362 - accuracy: 0.5849 - val_loss: 1.0451 - val_accuracy: 0.5937\n",
      "Epoch 216/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0323 - accuracy: 0.5814 - val_loss: 1.0513 - val_accuracy: 0.5945\n",
      "Epoch 217/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0316 - accuracy: 0.5819 - val_loss: 1.0385 - val_accuracy: 0.5913\n",
      "Epoch 218/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0369 - accuracy: 0.5854 - val_loss: 1.0523 - val_accuracy: 0.5919\n",
      "Epoch 219/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0329 - accuracy: 0.5870 - val_loss: 1.0365 - val_accuracy: 0.5919\n",
      "Epoch 220/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0327 - accuracy: 0.5835 - val_loss: 1.0314 - val_accuracy: 0.5945\n",
      "Epoch 221/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0328 - accuracy: 0.5837 - val_loss: 1.0401 - val_accuracy: 0.5975\n",
      "Epoch 222/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0345 - accuracy: 0.5831 - val_loss: 1.0584 - val_accuracy: 0.5889\n",
      "Epoch 223/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0363 - accuracy: 0.5856 - val_loss: 1.0409 - val_accuracy: 0.5877\n",
      "Epoch 224/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0370 - accuracy: 0.5822 - val_loss: 1.1075 - val_accuracy: 0.5664\n",
      "Epoch 225/250\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0335 - accuracy: 0.5844 - val_loss: 1.0593 - val_accuracy: 0.5830\n",
      "Epoch 226/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0309 - accuracy: 0.5843 - val_loss: 1.0410 - val_accuracy: 0.5966\n",
      "Epoch 227/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0327 - accuracy: 0.5868 - val_loss: 1.1445 - val_accuracy: 0.5477\n",
      "Epoch 228/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0334 - accuracy: 0.5880 - val_loss: 1.0386 - val_accuracy: 0.5978\n",
      "Epoch 229/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0304 - accuracy: 0.5884 - val_loss: 1.0553 - val_accuracy: 0.5842\n",
      "Epoch 230/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0344 - accuracy: 0.5846 - val_loss: 1.0369 - val_accuracy: 0.5889\n",
      "Epoch 231/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0302 - accuracy: 0.5855 - val_loss: 1.0344 - val_accuracy: 0.5928\n",
      "Epoch 232/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0349 - accuracy: 0.5837 - val_loss: 1.0467 - val_accuracy: 0.5874\n",
      "Epoch 233/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0292 - accuracy: 0.5843 - val_loss: 1.0341 - val_accuracy: 0.6002\n",
      "Epoch 234/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0303 - accuracy: 0.5883 - val_loss: 1.0325 - val_accuracy: 0.5948\n",
      "Epoch 235/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0291 - accuracy: 0.5867 - val_loss: 1.0377 - val_accuracy: 0.5922\n",
      "Epoch 236/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0336 - accuracy: 0.5822 - val_loss: 1.0342 - val_accuracy: 0.5913\n",
      "Epoch 237/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0311 - accuracy: 0.5859 - val_loss: 1.0528 - val_accuracy: 0.5842\n",
      "Epoch 238/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0301 - accuracy: 0.5841 - val_loss: 1.0303 - val_accuracy: 0.5913\n",
      "Epoch 239/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0313 - accuracy: 0.5858 - val_loss: 1.0406 - val_accuracy: 0.5990\n",
      "Epoch 240/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0304 - accuracy: 0.5868 - val_loss: 1.0383 - val_accuracy: 0.5951\n",
      "Epoch 241/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0315 - accuracy: 0.5870 - val_loss: 1.0418 - val_accuracy: 0.5937\n",
      "Epoch 242/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0355 - accuracy: 0.5856 - val_loss: 1.0448 - val_accuracy: 0.5937\n",
      "Epoch 243/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0291 - accuracy: 0.5847 - val_loss: 1.0649 - val_accuracy: 0.5800\n",
      "Epoch 244/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0290 - accuracy: 0.5849 - val_loss: 1.0419 - val_accuracy: 0.5963\n",
      "Epoch 245/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0305 - accuracy: 0.5838 - val_loss: 1.0327 - val_accuracy: 0.5943\n",
      "Epoch 246/250\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.0338 - accuracy: 0.5833 - val_loss: 1.0364 - val_accuracy: 0.5895\n",
      "Epoch 247/250\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0296 - accuracy: 0.5854 - val_loss: 1.0368 - val_accuracy: 0.5860\n",
      "Epoch 248/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0281 - accuracy: 0.5851 - val_loss: 1.0483 - val_accuracy: 0.5898\n",
      "Epoch 249/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0287 - accuracy: 0.5857 - val_loss: 1.0337 - val_accuracy: 0.5889\n",
      "Epoch 250/250\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0302 - accuracy: 0.5858 - val_loss: 1.0406 - val_accuracy: 0.5922\n"
     ]
    }
   ],
   "source": [
    "model_a = build_model_a()\n",
    "model_b = build_model_b()\n",
    "\n",
    "hist1 = model_a.fit(X_train, y_train, epochs=250, validation_split=0.2)\n",
    "hist2 = model_b.fit(X_train, y_train, epochs=250, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2899e224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(hist1.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0a187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.4207 - accuracy: 0.4149 - val_loss: 1.4119 - val_accuracy: 0.4132\n",
      "Epoch 2/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4064 - accuracy: 0.4149 - val_loss: 1.4111 - val_accuracy: 0.4132\n",
      "Epoch 3/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4048 - accuracy: 0.4149 - val_loss: 1.4080 - val_accuracy: 0.4132\n",
      "Epoch 4/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.4016 - accuracy: 0.4149 - val_loss: 1.4096 - val_accuracy: 0.4132\n",
      "Epoch 5/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3985 - accuracy: 0.4149 - val_loss: 1.4065 - val_accuracy: 0.4132\n",
      "Epoch 6/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3967 - accuracy: 0.4149 - val_loss: 1.4017 - val_accuracy: 0.4132\n",
      "Epoch 7/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3908 - accuracy: 0.4160 - val_loss: 1.3958 - val_accuracy: 0.4152\n",
      "Epoch 8/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3795 - accuracy: 0.4207 - val_loss: 1.3807 - val_accuracy: 0.4247\n",
      "Epoch 9/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3589 - accuracy: 0.4297 - val_loss: 1.3519 - val_accuracy: 0.4366\n",
      "Epoch 10/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3363 - accuracy: 0.4461 - val_loss: 1.3215 - val_accuracy: 0.4585\n",
      "Epoch 11/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.3096 - accuracy: 0.4594 - val_loss: 1.3105 - val_accuracy: 0.4677\n",
      "Epoch 12/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2837 - accuracy: 0.4656 - val_loss: 1.2743 - val_accuracy: 0.4887\n",
      "Epoch 13/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2597 - accuracy: 0.4862 - val_loss: 1.2557 - val_accuracy: 0.4849\n",
      "Epoch 14/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2454 - accuracy: 0.4984 - val_loss: 1.2538 - val_accuracy: 0.4947\n",
      "Epoch 15/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.2358 - accuracy: 0.5041 - val_loss: 1.2441 - val_accuracy: 0.4953\n",
      "Epoch 16/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2270 - accuracy: 0.5062 - val_loss: 1.2156 - val_accuracy: 0.5074\n",
      "Epoch 17/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2161 - accuracy: 0.5099 - val_loss: 1.2070 - val_accuracy: 0.5311\n",
      "Epoch 18/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.2050 - accuracy: 0.5202 - val_loss: 1.2016 - val_accuracy: 0.5130\n",
      "Epoch 19/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1974 - accuracy: 0.5229 - val_loss: 1.1886 - val_accuracy: 0.5403\n",
      "Epoch 20/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1886 - accuracy: 0.5277 - val_loss: 1.1812 - val_accuracy: 0.5400\n",
      "Epoch 21/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1863 - accuracy: 0.5277 - val_loss: 1.1854 - val_accuracy: 0.5439\n",
      "Epoch 22/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1767 - accuracy: 0.5346 - val_loss: 1.2095 - val_accuracy: 0.5086\n",
      "Epoch 23/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1739 - accuracy: 0.5325 - val_loss: 1.1698 - val_accuracy: 0.5397\n",
      "Epoch 24/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1694 - accuracy: 0.5376 - val_loss: 1.1825 - val_accuracy: 0.5193\n",
      "Epoch 25/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1641 - accuracy: 0.5408 - val_loss: 1.1545 - val_accuracy: 0.5539\n",
      "Epoch 26/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1514 - accuracy: 0.5431 - val_loss: 1.1449 - val_accuracy: 0.5602\n",
      "Epoch 27/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1480 - accuracy: 0.5400 - val_loss: 1.1427 - val_accuracy: 0.5510\n",
      "Epoch 28/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1403 - accuracy: 0.5493 - val_loss: 1.1360 - val_accuracy: 0.5649\n",
      "Epoch 29/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1407 - accuracy: 0.5452 - val_loss: 1.1420 - val_accuracy: 0.5628\n",
      "Epoch 30/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1347 - accuracy: 0.5457 - val_loss: 1.1401 - val_accuracy: 0.5637\n",
      "Epoch 31/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1312 - accuracy: 0.5478 - val_loss: 1.1280 - val_accuracy: 0.5697\n",
      "Epoch 32/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1273 - accuracy: 0.5518 - val_loss: 1.1324 - val_accuracy: 0.5619\n",
      "Epoch 33/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.1264 - accuracy: 0.5504 - val_loss: 1.1173 - val_accuracy: 0.5720\n",
      "Epoch 34/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1223 - accuracy: 0.5528 - val_loss: 1.1204 - val_accuracy: 0.5634\n",
      "Epoch 35/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1207 - accuracy: 0.5530 - val_loss: 1.1493 - val_accuracy: 0.5412\n",
      "Epoch 36/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1201 - accuracy: 0.5537 - val_loss: 1.1186 - val_accuracy: 0.5708\n",
      "Epoch 37/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1148 - accuracy: 0.5534 - val_loss: 1.1143 - val_accuracy: 0.5691\n",
      "Epoch 38/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1157 - accuracy: 0.5541 - val_loss: 1.1072 - val_accuracy: 0.5705\n",
      "Epoch 39/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1134 - accuracy: 0.5520 - val_loss: 1.1207 - val_accuracy: 0.5708\n",
      "Epoch 40/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1112 - accuracy: 0.5571 - val_loss: 1.1101 - val_accuracy: 0.5694\n",
      "Epoch 41/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1075 - accuracy: 0.5584 - val_loss: 1.1012 - val_accuracy: 0.5691\n",
      "Epoch 42/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1065 - accuracy: 0.5543 - val_loss: 1.1011 - val_accuracy: 0.5726\n",
      "Epoch 43/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.1030 - accuracy: 0.5598 - val_loss: 1.1062 - val_accuracy: 0.5711\n",
      "Epoch 44/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1036 - accuracy: 0.5574 - val_loss: 1.1040 - val_accuracy: 0.5676\n",
      "Epoch 45/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1029 - accuracy: 0.5551 - val_loss: 1.1199 - val_accuracy: 0.5495\n",
      "Epoch 46/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1014 - accuracy: 0.5582 - val_loss: 1.1478 - val_accuracy: 0.5370\n",
      "Epoch 47/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0973 - accuracy: 0.5622 - val_loss: 1.1053 - val_accuracy: 0.5699\n",
      "Epoch 48/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0995 - accuracy: 0.5591 - val_loss: 1.0936 - val_accuracy: 0.5791\n",
      "Epoch 49/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0984 - accuracy: 0.5599 - val_loss: 1.1029 - val_accuracy: 0.5655\n",
      "Epoch 50/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0951 - accuracy: 0.5587 - val_loss: 1.0954 - val_accuracy: 0.5726\n",
      "Epoch 51/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0923 - accuracy: 0.5621 - val_loss: 1.0896 - val_accuracy: 0.5723\n",
      "Epoch 52/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0926 - accuracy: 0.5611 - val_loss: 1.1058 - val_accuracy: 0.5708\n",
      "Epoch 53/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0907 - accuracy: 0.5629 - val_loss: 1.1163 - val_accuracy: 0.5599\n",
      "Epoch 54/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0899 - accuracy: 0.5637 - val_loss: 1.0807 - val_accuracy: 0.5774\n",
      "Epoch 55/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0850 - accuracy: 0.5620 - val_loss: 1.0937 - val_accuracy: 0.5762\n",
      "Epoch 56/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0845 - accuracy: 0.5657 - val_loss: 1.0876 - val_accuracy: 0.5670\n",
      "Epoch 57/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0840 - accuracy: 0.5628 - val_loss: 1.0976 - val_accuracy: 0.5563\n",
      "Epoch 58/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0851 - accuracy: 0.5604 - val_loss: 1.1040 - val_accuracy: 0.5673\n",
      "Epoch 59/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0845 - accuracy: 0.5653 - val_loss: 1.1081 - val_accuracy: 0.5533\n",
      "Epoch 60/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0827 - accuracy: 0.5664 - val_loss: 1.0851 - val_accuracy: 0.5771\n",
      "Epoch 61/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.5673 - val_loss: 1.0853 - val_accuracy: 0.5779\n",
      "Epoch 62/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0786 - accuracy: 0.5663 - val_loss: 1.1002 - val_accuracy: 0.5587\n",
      "Epoch 63/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0753 - accuracy: 0.5700 - val_loss: 1.0750 - val_accuracy: 0.5809\n",
      "Epoch 64/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0808 - accuracy: 0.5640 - val_loss: 1.0881 - val_accuracy: 0.5779\n",
      "Epoch 65/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0753 - accuracy: 0.5662 - val_loss: 1.0810 - val_accuracy: 0.5744\n",
      "Epoch 66/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0762 - accuracy: 0.5666 - val_loss: 1.0719 - val_accuracy: 0.5750\n",
      "Epoch 67/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0762 - accuracy: 0.5670 - val_loss: 1.1084 - val_accuracy: 0.5625\n",
      "Epoch 68/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0732 - accuracy: 0.5665 - val_loss: 1.0705 - val_accuracy: 0.5699\n",
      "Epoch 69/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0763 - accuracy: 0.5681 - val_loss: 1.0698 - val_accuracy: 0.5821\n",
      "Epoch 70/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0744 - accuracy: 0.5677 - val_loss: 1.0747 - val_accuracy: 0.5877\n",
      "Epoch 71/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0686 - accuracy: 0.5695 - val_loss: 1.0967 - val_accuracy: 0.5732\n",
      "Epoch 72/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0727 - accuracy: 0.5691 - val_loss: 1.0757 - val_accuracy: 0.5833\n",
      "Epoch 73/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0704 - accuracy: 0.5692 - val_loss: 1.0763 - val_accuracy: 0.5702\n",
      "Epoch 74/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0708 - accuracy: 0.5714 - val_loss: 1.0744 - val_accuracy: 0.5842\n",
      "Epoch 75/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0725 - accuracy: 0.5699 - val_loss: 1.0646 - val_accuracy: 0.5815\n",
      "Epoch 76/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0717 - accuracy: 0.5700 - val_loss: 1.0851 - val_accuracy: 0.5788\n",
      "Epoch 77/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0659 - accuracy: 0.5689 - val_loss: 1.0867 - val_accuracy: 0.5800\n",
      "Epoch 78/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0689 - accuracy: 0.5701 - val_loss: 1.0787 - val_accuracy: 0.5685\n",
      "Epoch 79/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0658 - accuracy: 0.5697 - val_loss: 1.0717 - val_accuracy: 0.5717\n",
      "Epoch 80/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0696 - accuracy: 0.5698 - val_loss: 1.0772 - val_accuracy: 0.5753\n",
      "Epoch 81/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0666 - accuracy: 0.5689 - val_loss: 1.0719 - val_accuracy: 0.5821\n",
      "Epoch 82/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0644 - accuracy: 0.5714 - val_loss: 1.1084 - val_accuracy: 0.5714\n",
      "Epoch 83/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.5720 - val_loss: 1.0696 - val_accuracy: 0.5720\n",
      "Epoch 84/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0646 - accuracy: 0.5694 - val_loss: 1.0616 - val_accuracy: 0.5818\n",
      "Epoch 85/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0623 - accuracy: 0.5716 - val_loss: 1.0587 - val_accuracy: 0.5827\n",
      "Epoch 86/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0632 - accuracy: 0.5710 - val_loss: 1.0806 - val_accuracy: 0.5800\n",
      "Epoch 87/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0629 - accuracy: 0.5732 - val_loss: 1.0683 - val_accuracy: 0.5777\n",
      "Epoch 88/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0637 - accuracy: 0.5714 - val_loss: 1.0747 - val_accuracy: 0.5694\n",
      "Epoch 89/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0627 - accuracy: 0.5699 - val_loss: 1.0683 - val_accuracy: 0.5827\n",
      "Epoch 90/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0653 - accuracy: 0.5711 - val_loss: 1.0599 - val_accuracy: 0.5836\n",
      "Epoch 91/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0620 - accuracy: 0.5726 - val_loss: 1.0759 - val_accuracy: 0.5883\n",
      "Epoch 92/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0625 - accuracy: 0.5704 - val_loss: 1.0671 - val_accuracy: 0.5774\n",
      "Epoch 93/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0616 - accuracy: 0.5723 - val_loss: 1.0591 - val_accuracy: 0.5874\n",
      "Epoch 94/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0592 - accuracy: 0.5742 - val_loss: 1.0682 - val_accuracy: 0.5851\n",
      "Epoch 95/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0585 - accuracy: 0.5754 - val_loss: 1.0723 - val_accuracy: 0.5821\n",
      "Epoch 96/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0547 - accuracy: 0.5726 - val_loss: 1.0643 - val_accuracy: 0.5747\n",
      "Epoch 97/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0579 - accuracy: 0.5740 - val_loss: 1.0739 - val_accuracy: 0.5824\n",
      "Epoch 98/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0570 - accuracy: 0.5757 - val_loss: 1.0959 - val_accuracy: 0.5608\n",
      "Epoch 99/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0547 - accuracy: 0.5768 - val_loss: 1.0641 - val_accuracy: 0.5865\n",
      "Epoch 100/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0586 - accuracy: 0.5723 - val_loss: 1.0910 - val_accuracy: 0.5702\n",
      "Epoch 101/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0589 - accuracy: 0.5745 - val_loss: 1.0619 - val_accuracy: 0.5771\n",
      "Epoch 102/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0584 - accuracy: 0.5734 - val_loss: 1.0810 - val_accuracy: 0.5797\n",
      "Epoch 103/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0564 - accuracy: 0.5741 - val_loss: 1.0714 - val_accuracy: 0.5836\n",
      "Epoch 104/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0548 - accuracy: 0.5782 - val_loss: 1.0616 - val_accuracy: 0.5848\n",
      "Epoch 105/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0552 - accuracy: 0.5746 - val_loss: 1.0796 - val_accuracy: 0.5679\n",
      "Epoch 106/215\n",
      "422/422 [==============================] - 1s 4ms/step - loss: 1.0580 - accuracy: 0.5743 - val_loss: 1.1234 - val_accuracy: 0.5557\n",
      "Epoch 107/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0538 - accuracy: 0.5786 - val_loss: 1.0722 - val_accuracy: 0.5762\n",
      "Epoch 108/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0570 - accuracy: 0.5782 - val_loss: 1.0940 - val_accuracy: 0.5744\n",
      "Epoch 109/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0516 - accuracy: 0.5747 - val_loss: 1.0651 - val_accuracy: 0.5756\n",
      "Epoch 110/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0551 - accuracy: 0.5760 - val_loss: 1.0649 - val_accuracy: 0.5898\n",
      "Epoch 111/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0532 - accuracy: 0.5744 - val_loss: 1.0578 - val_accuracy: 0.5898\n",
      "Epoch 112/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0522 - accuracy: 0.5751 - val_loss: 1.0718 - val_accuracy: 0.5694\n",
      "Epoch 113/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0519 - accuracy: 0.5745 - val_loss: 1.0571 - val_accuracy: 0.5806\n",
      "Epoch 114/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0498 - accuracy: 0.5771 - val_loss: 1.0677 - val_accuracy: 0.5788\n",
      "Epoch 115/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0525 - accuracy: 0.5763 - val_loss: 1.0737 - val_accuracy: 0.5768\n",
      "Epoch 116/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0532 - accuracy: 0.5769 - val_loss: 1.0651 - val_accuracy: 0.5860\n",
      "Epoch 117/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0526 - accuracy: 0.5754 - val_loss: 1.0855 - val_accuracy: 0.5821\n",
      "Epoch 118/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0523 - accuracy: 0.5775 - val_loss: 1.0628 - val_accuracy: 0.5747\n",
      "Epoch 119/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0531 - accuracy: 0.5745 - val_loss: 1.1131 - val_accuracy: 0.5614\n",
      "Epoch 120/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0506 - accuracy: 0.5777 - val_loss: 1.0663 - val_accuracy: 0.5732\n",
      "Epoch 121/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0474 - accuracy: 0.5782 - val_loss: 1.0500 - val_accuracy: 0.5901\n",
      "Epoch 122/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0490 - accuracy: 0.5773 - val_loss: 1.0535 - val_accuracy: 0.5913\n",
      "Epoch 123/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0487 - accuracy: 0.5762 - val_loss: 1.0745 - val_accuracy: 0.5815\n",
      "Epoch 124/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0491 - accuracy: 0.5790 - val_loss: 1.0541 - val_accuracy: 0.5839\n",
      "Epoch 125/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0431 - accuracy: 0.5809 - val_loss: 1.0494 - val_accuracy: 0.5854\n",
      "Epoch 126/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0507 - accuracy: 0.5783 - val_loss: 1.0574 - val_accuracy: 0.5765\n",
      "Epoch 127/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0495 - accuracy: 0.5777 - val_loss: 1.0688 - val_accuracy: 0.5741\n",
      "Epoch 128/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0461 - accuracy: 0.5822 - val_loss: 1.0885 - val_accuracy: 0.5765\n",
      "Epoch 129/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0481 - accuracy: 0.5789 - val_loss: 1.0610 - val_accuracy: 0.5777\n",
      "Epoch 130/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0470 - accuracy: 0.5785 - val_loss: 1.0535 - val_accuracy: 0.5889\n",
      "Epoch 131/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0492 - accuracy: 0.5807 - val_loss: 1.0551 - val_accuracy: 0.5877\n",
      "Epoch 132/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0449 - accuracy: 0.5788 - val_loss: 1.0574 - val_accuracy: 0.5913\n",
      "Epoch 133/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0506 - accuracy: 0.5783 - val_loss: 1.0597 - val_accuracy: 0.5877\n",
      "Epoch 134/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0440 - accuracy: 0.5795 - val_loss: 1.1142 - val_accuracy: 0.5560\n",
      "Epoch 135/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0461 - accuracy: 0.5776 - val_loss: 1.0553 - val_accuracy: 0.5865\n",
      "Epoch 136/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0448 - accuracy: 0.5789 - val_loss: 1.0529 - val_accuracy: 0.5785\n",
      "Epoch 137/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0426 - accuracy: 0.5809 - val_loss: 1.0785 - val_accuracy: 0.5720\n",
      "Epoch 138/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0427 - accuracy: 0.5794 - val_loss: 1.0567 - val_accuracy: 0.5913\n",
      "Epoch 139/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0469 - accuracy: 0.5794 - val_loss: 1.0651 - val_accuracy: 0.5836\n",
      "Epoch 140/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0409 - accuracy: 0.5786 - val_loss: 1.0439 - val_accuracy: 0.5895\n",
      "Epoch 141/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0492 - accuracy: 0.5794 - val_loss: 1.0699 - val_accuracy: 0.5788\n",
      "Epoch 142/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0422 - accuracy: 0.5802 - val_loss: 1.0770 - val_accuracy: 0.5851\n",
      "Epoch 143/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0423 - accuracy: 0.5784 - val_loss: 1.0623 - val_accuracy: 0.5768\n",
      "Epoch 144/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0412 - accuracy: 0.5810 - val_loss: 1.1179 - val_accuracy: 0.5637\n",
      "Epoch 145/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0454 - accuracy: 0.5800 - val_loss: 1.0571 - val_accuracy: 0.5851\n",
      "Epoch 146/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0412 - accuracy: 0.5825 - val_loss: 1.0590 - val_accuracy: 0.5762\n",
      "Epoch 147/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0409 - accuracy: 0.5809 - val_loss: 1.0533 - val_accuracy: 0.5916\n",
      "Epoch 148/215\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0435 - accuracy: 0.5789 - val_loss: 1.0444 - val_accuracy: 0.5865\n",
      "Epoch 149/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0411 - accuracy: 0.5832 - val_loss: 1.0767 - val_accuracy: 0.5682\n",
      "Epoch 150/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0393 - accuracy: 0.5822 - val_loss: 1.0462 - val_accuracy: 0.5865\n",
      "Epoch 151/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0429 - accuracy: 0.5806 - val_loss: 1.0547 - val_accuracy: 0.5791\n",
      "Epoch 152/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0434 - accuracy: 0.5803 - val_loss: 1.0470 - val_accuracy: 0.5824\n",
      "Epoch 153/215\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.0378 - accuracy: 0.5826 - val_loss: 1.0645 - val_accuracy: 0.5762\n",
      "Epoch 154/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0408 - accuracy: 0.5804 - val_loss: 1.0636 - val_accuracy: 0.5845\n",
      "Epoch 155/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0409 - accuracy: 0.5827 - val_loss: 1.0621 - val_accuracy: 0.5744\n",
      "Epoch 156/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0384 - accuracy: 0.5825 - val_loss: 1.0857 - val_accuracy: 0.5643\n",
      "Epoch 157/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0385 - accuracy: 0.5819 - val_loss: 1.0520 - val_accuracy: 0.5833\n",
      "Epoch 158/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0400 - accuracy: 0.5803 - val_loss: 1.0462 - val_accuracy: 0.5892\n",
      "Epoch 159/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0430 - accuracy: 0.5778 - val_loss: 1.0554 - val_accuracy: 0.5788\n",
      "Epoch 160/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0378 - accuracy: 0.5820 - val_loss: 1.0433 - val_accuracy: 0.5877\n",
      "Epoch 161/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0387 - accuracy: 0.5807 - val_loss: 1.0428 - val_accuracy: 0.5874\n",
      "Epoch 162/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0364 - accuracy: 0.5843 - val_loss: 1.0507 - val_accuracy: 0.5910\n",
      "Epoch 163/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0355 - accuracy: 0.5814 - val_loss: 1.0630 - val_accuracy: 0.5741\n",
      "Epoch 164/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0371 - accuracy: 0.5831 - val_loss: 1.0714 - val_accuracy: 0.5809\n",
      "Epoch 165/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0362 - accuracy: 0.5820 - val_loss: 1.0447 - val_accuracy: 0.5910\n",
      "Epoch 166/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0356 - accuracy: 0.5829 - val_loss: 1.0650 - val_accuracy: 0.5785\n",
      "Epoch 167/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0399 - accuracy: 0.5786 - val_loss: 1.0624 - val_accuracy: 0.5726\n",
      "Epoch 168/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0355 - accuracy: 0.5840 - val_loss: 1.0852 - val_accuracy: 0.5771\n",
      "Epoch 169/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0360 - accuracy: 0.5808 - val_loss: 1.0456 - val_accuracy: 0.5913\n",
      "Epoch 170/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0458 - accuracy: 0.5789 - val_loss: 1.0402 - val_accuracy: 0.5848\n",
      "Epoch 171/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0352 - accuracy: 0.5800 - val_loss: 1.0470 - val_accuracy: 0.5898\n",
      "Epoch 172/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0395 - accuracy: 0.5834 - val_loss: 1.0456 - val_accuracy: 0.5960\n",
      "Epoch 173/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0372 - accuracy: 0.5835 - val_loss: 1.0598 - val_accuracy: 0.5779\n",
      "Epoch 174/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0352 - accuracy: 0.5816 - val_loss: 1.0366 - val_accuracy: 0.5895\n",
      "Epoch 175/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0381 - accuracy: 0.5802 - val_loss: 1.0623 - val_accuracy: 0.5782\n",
      "Epoch 176/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0365 - accuracy: 0.5828 - val_loss: 1.0436 - val_accuracy: 0.5919\n",
      "Epoch 177/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0358 - accuracy: 0.5792 - val_loss: 1.0417 - val_accuracy: 0.5862\n",
      "Epoch 178/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5831 - val_loss: 1.0627 - val_accuracy: 0.5845\n",
      "Epoch 179/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5818 - val_loss: 1.0553 - val_accuracy: 0.5771\n",
      "Epoch 180/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0389 - accuracy: 0.5810 - val_loss: 1.0469 - val_accuracy: 0.5803\n",
      "Epoch 181/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0346 - accuracy: 0.5872 - val_loss: 1.0408 - val_accuracy: 0.5857\n",
      "Epoch 182/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0334 - accuracy: 0.5824 - val_loss: 1.0452 - val_accuracy: 0.5862\n",
      "Epoch 183/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0354 - accuracy: 0.5822 - val_loss: 1.0404 - val_accuracy: 0.5868\n",
      "Epoch 184/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0327 - accuracy: 0.5814 - val_loss: 1.0643 - val_accuracy: 0.5848\n",
      "Epoch 185/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0291 - accuracy: 0.5826 - val_loss: 1.0632 - val_accuracy: 0.5697\n",
      "Epoch 186/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0365 - accuracy: 0.5841 - val_loss: 1.0429 - val_accuracy: 0.5901\n",
      "Epoch 187/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0346 - accuracy: 0.5818 - val_loss: 1.0703 - val_accuracy: 0.5744\n",
      "Epoch 188/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0308 - accuracy: 0.5825 - val_loss: 1.0554 - val_accuracy: 0.5791\n",
      "Epoch 189/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0304 - accuracy: 0.5834 - val_loss: 1.0399 - val_accuracy: 0.5928\n",
      "Epoch 190/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0357 - accuracy: 0.5824 - val_loss: 1.0439 - val_accuracy: 0.5895\n",
      "Epoch 191/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0333 - accuracy: 0.5818 - val_loss: 1.0737 - val_accuracy: 0.5753\n",
      "Epoch 192/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0316 - accuracy: 0.5855 - val_loss: 1.0687 - val_accuracy: 0.5854\n",
      "Epoch 193/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0333 - accuracy: 0.5854 - val_loss: 1.0518 - val_accuracy: 0.5919\n",
      "Epoch 194/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0289 - accuracy: 0.5830 - val_loss: 1.0470 - val_accuracy: 0.5857\n",
      "Epoch 195/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0303 - accuracy: 0.5817 - val_loss: 1.0476 - val_accuracy: 0.5871\n",
      "Epoch 196/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0282 - accuracy: 0.5875 - val_loss: 1.0415 - val_accuracy: 0.5874\n",
      "Epoch 197/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0309 - accuracy: 0.5841 - val_loss: 1.0487 - val_accuracy: 0.5922\n",
      "Epoch 198/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0297 - accuracy: 0.5875 - val_loss: 1.0568 - val_accuracy: 0.5889\n",
      "Epoch 199/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0300 - accuracy: 0.5847 - val_loss: 1.0439 - val_accuracy: 0.5857\n",
      "Epoch 200/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0311 - accuracy: 0.5809 - val_loss: 1.0684 - val_accuracy: 0.5771\n",
      "Epoch 201/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0300 - accuracy: 0.5831 - val_loss: 1.0475 - val_accuracy: 0.5785\n",
      "Epoch 202/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0307 - accuracy: 0.5851 - val_loss: 1.0667 - val_accuracy: 0.5880\n",
      "Epoch 203/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0313 - accuracy: 0.5805 - val_loss: 1.0945 - val_accuracy: 0.5717\n",
      "Epoch 204/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0284 - accuracy: 0.5860 - val_loss: 1.0467 - val_accuracy: 0.5868\n",
      "Epoch 205/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0296 - accuracy: 0.5844 - val_loss: 1.0345 - val_accuracy: 0.5895\n",
      "Epoch 206/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0311 - accuracy: 0.5837 - val_loss: 1.0378 - val_accuracy: 0.5868\n",
      "Epoch 207/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0298 - accuracy: 0.5850 - val_loss: 1.0497 - val_accuracy: 0.5836\n",
      "Epoch 208/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0308 - accuracy: 0.5847 - val_loss: 1.0446 - val_accuracy: 0.5824\n",
      "Epoch 209/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0301 - accuracy: 0.5840 - val_loss: 1.0534 - val_accuracy: 0.5868\n",
      "Epoch 210/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0318 - accuracy: 0.5857 - val_loss: 1.0356 - val_accuracy: 0.5910\n",
      "Epoch 211/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0257 - accuracy: 0.5845 - val_loss: 1.0353 - val_accuracy: 0.5913\n",
      "Epoch 212/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0253 - accuracy: 0.5866 - val_loss: 1.0474 - val_accuracy: 0.5868\n",
      "Epoch 213/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0274 - accuracy: 0.5833 - val_loss: 1.0544 - val_accuracy: 0.5851\n",
      "Epoch 214/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0314 - accuracy: 0.5828 - val_loss: 1.0579 - val_accuracy: 0.5931\n",
      "Epoch 215/215\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 1.0302 - accuracy: 0.5838 - val_loss: 1.0359 - val_accuracy: 0.5860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a94158340>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_epoch = hist1.history[\"val_accuracy\"]\n",
    "best_epoch = val_acc_epoch.index(max(val_acc_epoch)) + 1\n",
    "\n",
    "model_a = build_model_a()\n",
    "model_a.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323d6b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(hist2.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abef339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/233\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 1.4190 - accuracy: 0.4147 - val_loss: 1.4108 - val_accuracy: 0.4132\n",
      "Epoch 2/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.4057 - accuracy: 0.4137 - val_loss: 1.4083 - val_accuracy: 0.4132\n",
      "Epoch 3/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3986 - accuracy: 0.4157 - val_loss: 1.4137 - val_accuracy: 0.4132\n",
      "Epoch 4/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3964 - accuracy: 0.4183 - val_loss: 1.3964 - val_accuracy: 0.4241\n",
      "Epoch 5/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.3888 - accuracy: 0.4223 - val_loss: 1.3921 - val_accuracy: 0.4185\n",
      "Epoch 6/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.3813 - accuracy: 0.4303 - val_loss: 1.3834 - val_accuracy: 0.4203\n",
      "Epoch 7/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.3678 - accuracy: 0.4391 - val_loss: 1.3593 - val_accuracy: 0.4422\n",
      "Epoch 8/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.3498 - accuracy: 0.4489 - val_loss: 1.3487 - val_accuracy: 0.4398\n",
      "Epoch 9/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.3345 - accuracy: 0.4569 - val_loss: 1.3510 - val_accuracy: 0.4369\n",
      "Epoch 10/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.3157 - accuracy: 0.4654 - val_loss: 1.3038 - val_accuracy: 0.4822\n",
      "Epoch 11/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2997 - accuracy: 0.4689 - val_loss: 1.2883 - val_accuracy: 0.4819\n",
      "Epoch 12/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.2844 - accuracy: 0.4742 - val_loss: 1.2786 - val_accuracy: 0.4754\n",
      "Epoch 13/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.2762 - accuracy: 0.4722 - val_loss: 1.2687 - val_accuracy: 0.4772\n",
      "Epoch 14/233\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 1.2654 - accuracy: 0.4749 - val_loss: 1.2580 - val_accuracy: 0.4849\n",
      "Epoch 15/233\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.2554 - accuracy: 0.4749 - val_loss: 1.2578 - val_accuracy: 0.4745\n",
      "Epoch 16/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2543 - accuracy: 0.4709 - val_loss: 1.2462 - val_accuracy: 0.4804\n",
      "Epoch 17/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2463 - accuracy: 0.4728 - val_loss: 1.2390 - val_accuracy: 0.4825\n",
      "Epoch 18/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2421 - accuracy: 0.4765 - val_loss: 1.2411 - val_accuracy: 0.4858\n",
      "Epoch 19/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2346 - accuracy: 0.4785 - val_loss: 1.2280 - val_accuracy: 0.4887\n",
      "Epoch 20/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2280 - accuracy: 0.4850 - val_loss: 1.2182 - val_accuracy: 0.4979\n",
      "Epoch 21/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2220 - accuracy: 0.4881 - val_loss: 1.2218 - val_accuracy: 0.5027\n",
      "Epoch 22/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2164 - accuracy: 0.4926 - val_loss: 1.2117 - val_accuracy: 0.5098\n",
      "Epoch 23/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2123 - accuracy: 0.4961 - val_loss: 1.2053 - val_accuracy: 0.5116\n",
      "Epoch 24/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2076 - accuracy: 0.4960 - val_loss: 1.2082 - val_accuracy: 0.4988\n",
      "Epoch 25/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2022 - accuracy: 0.5010 - val_loss: 1.2028 - val_accuracy: 0.5255\n",
      "Epoch 26/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.2013 - accuracy: 0.5032 - val_loss: 1.2011 - val_accuracy: 0.5240\n",
      "Epoch 27/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1992 - accuracy: 0.5064 - val_loss: 1.2463 - val_accuracy: 0.4944\n",
      "Epoch 28/233\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.1969 - accuracy: 0.5044 - val_loss: 1.1907 - val_accuracy: 0.5264\n",
      "Epoch 29/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.1906 - accuracy: 0.5098 - val_loss: 1.1931 - val_accuracy: 0.5065\n",
      "Epoch 30/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.1959 - accuracy: 0.5067 - val_loss: 1.2034 - val_accuracy: 0.5012\n",
      "Epoch 31/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1914 - accuracy: 0.5102 - val_loss: 1.1891 - val_accuracy: 0.5353\n",
      "Epoch 32/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1877 - accuracy: 0.5119 - val_loss: 1.1858 - val_accuracy: 0.5338\n",
      "Epoch 33/233\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.1842 - accuracy: 0.5171 - val_loss: 1.2003 - val_accuracy: 0.5276\n",
      "Epoch 34/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1846 - accuracy: 0.5178 - val_loss: 1.1799 - val_accuracy: 0.5237\n",
      "Epoch 35/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1837 - accuracy: 0.5147 - val_loss: 1.1974 - val_accuracy: 0.5059\n",
      "Epoch 36/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1824 - accuracy: 0.5136 - val_loss: 1.1855 - val_accuracy: 0.5341\n",
      "Epoch 37/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1812 - accuracy: 0.5122 - val_loss: 1.1743 - val_accuracy: 0.5302\n",
      "Epoch 38/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1829 - accuracy: 0.5136 - val_loss: 1.1945 - val_accuracy: 0.5249\n",
      "Epoch 39/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1770 - accuracy: 0.5164 - val_loss: 1.1739 - val_accuracy: 0.5302\n",
      "Epoch 40/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1771 - accuracy: 0.5199 - val_loss: 1.1685 - val_accuracy: 0.5344\n",
      "Epoch 41/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1730 - accuracy: 0.5219 - val_loss: 1.1685 - val_accuracy: 0.5362\n",
      "Epoch 42/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1745 - accuracy: 0.5199 - val_loss: 1.1713 - val_accuracy: 0.5397\n",
      "Epoch 43/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1734 - accuracy: 0.5213 - val_loss: 1.1793 - val_accuracy: 0.5332\n",
      "Epoch 44/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1727 - accuracy: 0.5213 - val_loss: 1.1672 - val_accuracy: 0.5427\n",
      "Epoch 45/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1709 - accuracy: 0.5201 - val_loss: 1.1724 - val_accuracy: 0.5406\n",
      "Epoch 46/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1663 - accuracy: 0.5256 - val_loss: 1.1790 - val_accuracy: 0.5317\n",
      "Epoch 47/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1662 - accuracy: 0.5256 - val_loss: 1.1651 - val_accuracy: 0.5356\n",
      "Epoch 48/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1675 - accuracy: 0.5227 - val_loss: 1.1700 - val_accuracy: 0.5468\n",
      "Epoch 49/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1649 - accuracy: 0.5265 - val_loss: 1.1764 - val_accuracy: 0.5264\n",
      "Epoch 50/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1708 - accuracy: 0.5218 - val_loss: 1.1827 - val_accuracy: 0.5296\n",
      "Epoch 51/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1627 - accuracy: 0.5271 - val_loss: 1.1664 - val_accuracy: 0.5293\n",
      "Epoch 52/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1629 - accuracy: 0.5264 - val_loss: 1.1632 - val_accuracy: 0.5320\n",
      "Epoch 53/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.1611 - accuracy: 0.5282 - val_loss: 1.1741 - val_accuracy: 0.5231\n",
      "Epoch 54/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.1656 - accuracy: 0.5222 - val_loss: 1.1727 - val_accuracy: 0.5400\n",
      "Epoch 55/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1629 - accuracy: 0.5292 - val_loss: 1.1591 - val_accuracy: 0.5453\n",
      "Epoch 56/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1628 - accuracy: 0.5233 - val_loss: 1.1568 - val_accuracy: 0.5382\n",
      "Epoch 57/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1585 - accuracy: 0.5273 - val_loss: 1.1643 - val_accuracy: 0.5474\n",
      "Epoch 58/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1571 - accuracy: 0.5282 - val_loss: 1.1646 - val_accuracy: 0.5418\n",
      "Epoch 59/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1584 - accuracy: 0.5302 - val_loss: 1.1726 - val_accuracy: 0.5370\n",
      "Epoch 60/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1587 - accuracy: 0.5305 - val_loss: 1.1657 - val_accuracy: 0.5409\n",
      "Epoch 61/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1549 - accuracy: 0.5272 - val_loss: 1.1556 - val_accuracy: 0.5347\n",
      "Epoch 62/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1590 - accuracy: 0.5269 - val_loss: 1.1576 - val_accuracy: 0.5329\n",
      "Epoch 63/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1525 - accuracy: 0.5289 - val_loss: 1.1560 - val_accuracy: 0.5486\n",
      "Epoch 64/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1511 - accuracy: 0.5358 - val_loss: 1.1496 - val_accuracy: 0.5590\n",
      "Epoch 65/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1420 - accuracy: 0.5388 - val_loss: 1.1452 - val_accuracy: 0.5590\n",
      "Epoch 66/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1434 - accuracy: 0.5396 - val_loss: 1.1569 - val_accuracy: 0.5486\n",
      "Epoch 67/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1378 - accuracy: 0.5456 - val_loss: 1.1341 - val_accuracy: 0.5649\n",
      "Epoch 68/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1345 - accuracy: 0.5470 - val_loss: 1.1708 - val_accuracy: 0.5320\n",
      "Epoch 69/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1280 - accuracy: 0.5438 - val_loss: 1.1223 - val_accuracy: 0.5655\n",
      "Epoch 70/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1195 - accuracy: 0.5488 - val_loss: 1.1319 - val_accuracy: 0.5637\n",
      "Epoch 71/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1223 - accuracy: 0.5460 - val_loss: 1.1530 - val_accuracy: 0.5368\n",
      "Epoch 72/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1123 - accuracy: 0.5525 - val_loss: 1.1331 - val_accuracy: 0.5507\n",
      "Epoch 73/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1126 - accuracy: 0.5519 - val_loss: 1.1142 - val_accuracy: 0.5673\n",
      "Epoch 74/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1104 - accuracy: 0.5520 - val_loss: 1.1321 - val_accuracy: 0.5516\n",
      "Epoch 75/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1076 - accuracy: 0.5530 - val_loss: 1.1249 - val_accuracy: 0.5477\n",
      "Epoch 76/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1062 - accuracy: 0.5544 - val_loss: 1.1157 - val_accuracy: 0.5510\n",
      "Epoch 77/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1048 - accuracy: 0.5525 - val_loss: 1.1313 - val_accuracy: 0.5578\n",
      "Epoch 78/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1047 - accuracy: 0.5531 - val_loss: 1.1007 - val_accuracy: 0.5685\n",
      "Epoch 79/233\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 1.1034 - accuracy: 0.5559 - val_loss: 1.1224 - val_accuracy: 0.5551\n",
      "Epoch 80/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.1056 - accuracy: 0.5530 - val_loss: 1.1185 - val_accuracy: 0.5652\n",
      "Epoch 81/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0966 - accuracy: 0.5553 - val_loss: 1.1133 - val_accuracy: 0.5705\n",
      "Epoch 82/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0975 - accuracy: 0.5599 - val_loss: 1.1042 - val_accuracy: 0.5756\n",
      "Epoch 83/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0935 - accuracy: 0.5587 - val_loss: 1.0927 - val_accuracy: 0.5765\n",
      "Epoch 84/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0929 - accuracy: 0.5599 - val_loss: 1.0978 - val_accuracy: 0.5771\n",
      "Epoch 85/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0955 - accuracy: 0.5593 - val_loss: 1.1175 - val_accuracy: 0.5664\n",
      "Epoch 86/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0922 - accuracy: 0.5604 - val_loss: 1.0938 - val_accuracy: 0.5806\n",
      "Epoch 87/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0916 - accuracy: 0.5605 - val_loss: 1.0972 - val_accuracy: 0.5714\n",
      "Epoch 88/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0932 - accuracy: 0.5601 - val_loss: 1.1103 - val_accuracy: 0.5708\n",
      "Epoch 89/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0885 - accuracy: 0.5625 - val_loss: 1.0939 - val_accuracy: 0.5782\n",
      "Epoch 90/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0888 - accuracy: 0.5640 - val_loss: 1.1119 - val_accuracy: 0.5634\n",
      "Epoch 91/233\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 1.0869 - accuracy: 0.5632 - val_loss: 1.1151 - val_accuracy: 0.5699\n",
      "Epoch 92/233\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.0898 - accuracy: 0.5606 - val_loss: 1.0923 - val_accuracy: 0.5720\n",
      "Epoch 93/233\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.0873 - accuracy: 0.5634 - val_loss: 1.0858 - val_accuracy: 0.5741\n",
      "Epoch 94/233\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 1.0853 - accuracy: 0.5637 - val_loss: 1.0990 - val_accuracy: 0.5697\n",
      "Epoch 95/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0888 - accuracy: 0.5579 - val_loss: 1.0838 - val_accuracy: 0.5771\n",
      "Epoch 96/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0893 - accuracy: 0.5594 - val_loss: 1.0869 - val_accuracy: 0.5744\n",
      "Epoch 97/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0873 - accuracy: 0.5611 - val_loss: 1.0965 - val_accuracy: 0.5768\n",
      "Epoch 98/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0868 - accuracy: 0.5611 - val_loss: 1.0826 - val_accuracy: 0.5815\n",
      "Epoch 99/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0875 - accuracy: 0.5622 - val_loss: 1.0898 - val_accuracy: 0.5756\n",
      "Epoch 100/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0838 - accuracy: 0.5604 - val_loss: 1.1188 - val_accuracy: 0.5539\n",
      "Epoch 101/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0854 - accuracy: 0.5646 - val_loss: 1.0966 - val_accuracy: 0.5726\n",
      "Epoch 102/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0822 - accuracy: 0.5656 - val_loss: 1.0878 - val_accuracy: 0.5765\n",
      "Epoch 103/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0814 - accuracy: 0.5624 - val_loss: 1.0892 - val_accuracy: 0.5797\n",
      "Epoch 104/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0820 - accuracy: 0.5677 - val_loss: 1.0902 - val_accuracy: 0.5782\n",
      "Epoch 105/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0847 - accuracy: 0.5626 - val_loss: 1.0959 - val_accuracy: 0.5658\n",
      "Epoch 106/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0825 - accuracy: 0.5658 - val_loss: 1.1097 - val_accuracy: 0.5634\n",
      "Epoch 107/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0806 - accuracy: 0.5645 - val_loss: 1.0831 - val_accuracy: 0.5833\n",
      "Epoch 108/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0830 - accuracy: 0.5642 - val_loss: 1.0943 - val_accuracy: 0.5806\n",
      "Epoch 109/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0853 - accuracy: 0.5611 - val_loss: 1.0825 - val_accuracy: 0.5800\n",
      "Epoch 110/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0810 - accuracy: 0.5655 - val_loss: 1.0826 - val_accuracy: 0.5741\n",
      "Epoch 111/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0840 - accuracy: 0.5622 - val_loss: 1.0849 - val_accuracy: 0.5806\n",
      "Epoch 112/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0776 - accuracy: 0.5674 - val_loss: 1.0930 - val_accuracy: 0.5803\n",
      "Epoch 113/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0808 - accuracy: 0.5637 - val_loss: 1.0883 - val_accuracy: 0.5777\n",
      "Epoch 114/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0771 - accuracy: 0.5655 - val_loss: 1.0816 - val_accuracy: 0.5806\n",
      "Epoch 115/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0789 - accuracy: 0.5660 - val_loss: 1.0859 - val_accuracy: 0.5661\n",
      "Epoch 116/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0815 - accuracy: 0.5622 - val_loss: 1.0743 - val_accuracy: 0.5762\n",
      "Epoch 117/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0755 - accuracy: 0.5671 - val_loss: 1.0891 - val_accuracy: 0.5753\n",
      "Epoch 118/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0771 - accuracy: 0.5672 - val_loss: 1.0847 - val_accuracy: 0.5797\n",
      "Epoch 119/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0757 - accuracy: 0.5632 - val_loss: 1.1144 - val_accuracy: 0.5596\n",
      "Epoch 120/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0769 - accuracy: 0.5647 - val_loss: 1.0865 - val_accuracy: 0.5774\n",
      "Epoch 121/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0752 - accuracy: 0.5685 - val_loss: 1.0951 - val_accuracy: 0.5658\n",
      "Epoch 122/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0738 - accuracy: 0.5652 - val_loss: 1.0798 - val_accuracy: 0.5785\n",
      "Epoch 123/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0744 - accuracy: 0.5648 - val_loss: 1.0797 - val_accuracy: 0.5797\n",
      "Epoch 124/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0775 - accuracy: 0.5648 - val_loss: 1.0719 - val_accuracy: 0.5797\n",
      "Epoch 125/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0745 - accuracy: 0.5633 - val_loss: 1.0939 - val_accuracy: 0.5667\n",
      "Epoch 126/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0770 - accuracy: 0.5665 - val_loss: 1.0783 - val_accuracy: 0.5821\n",
      "Epoch 127/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0736 - accuracy: 0.5668 - val_loss: 1.0721 - val_accuracy: 0.5756\n",
      "Epoch 128/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0734 - accuracy: 0.5657 - val_loss: 1.0755 - val_accuracy: 0.5800\n",
      "Epoch 129/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0731 - accuracy: 0.5668 - val_loss: 1.1011 - val_accuracy: 0.5628\n",
      "Epoch 130/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0722 - accuracy: 0.5676 - val_loss: 1.0946 - val_accuracy: 0.5685\n",
      "Epoch 131/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0722 - accuracy: 0.5677 - val_loss: 1.0686 - val_accuracy: 0.5779\n",
      "Epoch 132/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0730 - accuracy: 0.5670 - val_loss: 1.0720 - val_accuracy: 0.5827\n",
      "Epoch 133/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0716 - accuracy: 0.5683 - val_loss: 1.1404 - val_accuracy: 0.5477\n",
      "Epoch 134/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0734 - accuracy: 0.5645 - val_loss: 1.0687 - val_accuracy: 0.5809\n",
      "Epoch 135/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0696 - accuracy: 0.5665 - val_loss: 1.0727 - val_accuracy: 0.5759\n",
      "Epoch 136/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0677 - accuracy: 0.5675 - val_loss: 1.0877 - val_accuracy: 0.5723\n",
      "Epoch 137/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0658 - accuracy: 0.5677 - val_loss: 1.1937 - val_accuracy: 0.5098\n",
      "Epoch 138/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0696 - accuracy: 0.5668 - val_loss: 1.0671 - val_accuracy: 0.5782\n",
      "Epoch 139/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0675 - accuracy: 0.5694 - val_loss: 1.0668 - val_accuracy: 0.5833\n",
      "Epoch 140/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0737 - accuracy: 0.5658 - val_loss: 1.0753 - val_accuracy: 0.5848\n",
      "Epoch 141/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0686 - accuracy: 0.5667 - val_loss: 1.0767 - val_accuracy: 0.5815\n",
      "Epoch 142/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0669 - accuracy: 0.5716 - val_loss: 1.0826 - val_accuracy: 0.5717\n",
      "Epoch 143/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0700 - accuracy: 0.5710 - val_loss: 1.0742 - val_accuracy: 0.5824\n",
      "Epoch 144/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0662 - accuracy: 0.5686 - val_loss: 1.0767 - val_accuracy: 0.5851\n",
      "Epoch 145/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0626 - accuracy: 0.5699 - val_loss: 1.0693 - val_accuracy: 0.5777\n",
      "Epoch 146/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0646 - accuracy: 0.5711 - val_loss: 1.0651 - val_accuracy: 0.5800\n",
      "Epoch 147/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0648 - accuracy: 0.5697 - val_loss: 1.0643 - val_accuracy: 0.5842\n",
      "Epoch 148/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0626 - accuracy: 0.5703 - val_loss: 1.0831 - val_accuracy: 0.5765\n",
      "Epoch 149/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0630 - accuracy: 0.5706 - val_loss: 1.0686 - val_accuracy: 0.5803\n",
      "Epoch 150/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0662 - accuracy: 0.5691 - val_loss: 1.0612 - val_accuracy: 0.5806\n",
      "Epoch 151/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0646 - accuracy: 0.5709 - val_loss: 1.0734 - val_accuracy: 0.5806\n",
      "Epoch 152/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0611 - accuracy: 0.5721 - val_loss: 1.0745 - val_accuracy: 0.5759\n",
      "Epoch 153/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0645 - accuracy: 0.5720 - val_loss: 1.0594 - val_accuracy: 0.5812\n",
      "Epoch 154/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0632 - accuracy: 0.5700 - val_loss: 1.0656 - val_accuracy: 0.5836\n",
      "Epoch 155/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0652 - accuracy: 0.5696 - val_loss: 1.1325 - val_accuracy: 0.5516\n",
      "Epoch 156/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0638 - accuracy: 0.5701 - val_loss: 1.0651 - val_accuracy: 0.5774\n",
      "Epoch 157/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0586 - accuracy: 0.5697 - val_loss: 1.0661 - val_accuracy: 0.5797\n",
      "Epoch 158/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0648 - accuracy: 0.5685 - val_loss: 1.0616 - val_accuracy: 0.5779\n",
      "Epoch 159/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0645 - accuracy: 0.5705 - val_loss: 1.0643 - val_accuracy: 0.5827\n",
      "Epoch 160/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0598 - accuracy: 0.5711 - val_loss: 1.0603 - val_accuracy: 0.5865\n",
      "Epoch 161/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0590 - accuracy: 0.5725 - val_loss: 1.0607 - val_accuracy: 0.5904\n",
      "Epoch 162/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0599 - accuracy: 0.5728 - val_loss: 1.0567 - val_accuracy: 0.5848\n",
      "Epoch 163/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0599 - accuracy: 0.5714 - val_loss: 1.0617 - val_accuracy: 0.5845\n",
      "Epoch 164/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0551 - accuracy: 0.5744 - val_loss: 1.0667 - val_accuracy: 0.5788\n",
      "Epoch 165/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0608 - accuracy: 0.5715 - val_loss: 1.0843 - val_accuracy: 0.5664\n",
      "Epoch 166/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0578 - accuracy: 0.5754 - val_loss: 1.0631 - val_accuracy: 0.5854\n",
      "Epoch 167/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0576 - accuracy: 0.5720 - val_loss: 1.0836 - val_accuracy: 0.5774\n",
      "Epoch 168/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0543 - accuracy: 0.5767 - val_loss: 1.0575 - val_accuracy: 0.5827\n",
      "Epoch 169/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0580 - accuracy: 0.5725 - val_loss: 1.0547 - val_accuracy: 0.5877\n",
      "Epoch 170/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0544 - accuracy: 0.5723 - val_loss: 1.0768 - val_accuracy: 0.5711\n",
      "Epoch 171/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0627 - accuracy: 0.5708 - val_loss: 1.0662 - val_accuracy: 0.5809\n",
      "Epoch 172/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0549 - accuracy: 0.5760 - val_loss: 1.0625 - val_accuracy: 0.5797\n",
      "Epoch 173/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0555 - accuracy: 0.5705 - val_loss: 1.0648 - val_accuracy: 0.5842\n",
      "Epoch 174/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0545 - accuracy: 0.5728 - val_loss: 1.0671 - val_accuracy: 0.5794\n",
      "Epoch 175/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0544 - accuracy: 0.5727 - val_loss: 1.0501 - val_accuracy: 0.5868\n",
      "Epoch 176/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0587 - accuracy: 0.5723 - val_loss: 1.0530 - val_accuracy: 0.5886\n",
      "Epoch 177/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0514 - accuracy: 0.5739 - val_loss: 1.0590 - val_accuracy: 0.5779\n",
      "Epoch 178/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0535 - accuracy: 0.5743 - val_loss: 1.0541 - val_accuracy: 0.5871\n",
      "Epoch 179/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0527 - accuracy: 0.5751 - val_loss: 1.0561 - val_accuracy: 0.5765\n",
      "Epoch 180/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0544 - accuracy: 0.5726 - val_loss: 1.0565 - val_accuracy: 0.5889\n",
      "Epoch 181/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0510 - accuracy: 0.5760 - val_loss: 1.0607 - val_accuracy: 0.5862\n",
      "Epoch 182/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0525 - accuracy: 0.5777 - val_loss: 1.0508 - val_accuracy: 0.5836\n",
      "Epoch 183/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0492 - accuracy: 0.5720 - val_loss: 1.0758 - val_accuracy: 0.5806\n",
      "Epoch 184/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0521 - accuracy: 0.5734 - val_loss: 1.0693 - val_accuracy: 0.5886\n",
      "Epoch 185/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0488 - accuracy: 0.5780 - val_loss: 1.0547 - val_accuracy: 0.5836\n",
      "Epoch 186/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0475 - accuracy: 0.5783 - val_loss: 1.0480 - val_accuracy: 0.5848\n",
      "Epoch 187/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0551 - accuracy: 0.5743 - val_loss: 1.0525 - val_accuracy: 0.5860\n",
      "Epoch 188/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0503 - accuracy: 0.5771 - val_loss: 1.0602 - val_accuracy: 0.5860\n",
      "Epoch 189/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0482 - accuracy: 0.5740 - val_loss: 1.0579 - val_accuracy: 0.5919\n",
      "Epoch 190/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0516 - accuracy: 0.5728 - val_loss: 1.0617 - val_accuracy: 0.5827\n",
      "Epoch 191/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0487 - accuracy: 0.5737 - val_loss: 1.0548 - val_accuracy: 0.5868\n",
      "Epoch 192/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0481 - accuracy: 0.5725 - val_loss: 1.0623 - val_accuracy: 0.5842\n",
      "Epoch 193/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0472 - accuracy: 0.5752 - val_loss: 1.1132 - val_accuracy: 0.5667\n",
      "Epoch 194/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0518 - accuracy: 0.5767 - val_loss: 1.0711 - val_accuracy: 0.5812\n",
      "Epoch 195/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0481 - accuracy: 0.5792 - val_loss: 1.0591 - val_accuracy: 0.5836\n",
      "Epoch 196/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0473 - accuracy: 0.5768 - val_loss: 1.0499 - val_accuracy: 0.5928\n",
      "Epoch 197/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0470 - accuracy: 0.5777 - val_loss: 1.0628 - val_accuracy: 0.5785\n",
      "Epoch 198/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0525 - accuracy: 0.5746 - val_loss: 1.0546 - val_accuracy: 0.5892\n",
      "Epoch 199/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0506 - accuracy: 0.5740 - val_loss: 1.0500 - val_accuracy: 0.5803\n",
      "Epoch 200/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0496 - accuracy: 0.5741 - val_loss: 1.0577 - val_accuracy: 0.5904\n",
      "Epoch 201/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0489 - accuracy: 0.5740 - val_loss: 1.0516 - val_accuracy: 0.5833\n",
      "Epoch 202/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0474 - accuracy: 0.5767 - val_loss: 1.0447 - val_accuracy: 0.5916\n",
      "Epoch 203/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0465 - accuracy: 0.5767 - val_loss: 1.0552 - val_accuracy: 0.5877\n",
      "Epoch 204/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0480 - accuracy: 0.5746 - val_loss: 1.0539 - val_accuracy: 0.5862\n",
      "Epoch 205/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0462 - accuracy: 0.5736 - val_loss: 1.0484 - val_accuracy: 0.5925\n",
      "Epoch 206/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0440 - accuracy: 0.5757 - val_loss: 1.0433 - val_accuracy: 0.5945\n",
      "Epoch 207/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0443 - accuracy: 0.5794 - val_loss: 1.0468 - val_accuracy: 0.5948\n",
      "Epoch 208/233\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 1.0424 - accuracy: 0.5795 - val_loss: 1.0719 - val_accuracy: 0.5883\n",
      "Epoch 209/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0412 - accuracy: 0.5792 - val_loss: 1.0535 - val_accuracy: 0.5833\n",
      "Epoch 210/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0427 - accuracy: 0.5792 - val_loss: 1.1196 - val_accuracy: 0.5504\n",
      "Epoch 211/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0436 - accuracy: 0.5748 - val_loss: 1.0415 - val_accuracy: 0.5919\n",
      "Epoch 212/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0451 - accuracy: 0.5797 - val_loss: 1.0609 - val_accuracy: 0.5860\n",
      "Epoch 213/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0448 - accuracy: 0.5760 - val_loss: 1.0603 - val_accuracy: 0.5812\n",
      "Epoch 214/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0400 - accuracy: 0.5803 - val_loss: 1.0599 - val_accuracy: 0.5851\n",
      "Epoch 215/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0504 - accuracy: 0.5781 - val_loss: 1.0433 - val_accuracy: 0.5892\n",
      "Epoch 216/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0420 - accuracy: 0.5775 - val_loss: 1.0558 - val_accuracy: 0.5827\n",
      "Epoch 217/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0421 - accuracy: 0.5803 - val_loss: 1.0501 - val_accuracy: 0.5883\n",
      "Epoch 218/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0400 - accuracy: 0.5787 - val_loss: 1.0600 - val_accuracy: 0.5848\n",
      "Epoch 219/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0423 - accuracy: 0.5781 - val_loss: 1.0478 - val_accuracy: 0.5913\n",
      "Epoch 220/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0429 - accuracy: 0.5779 - val_loss: 1.0417 - val_accuracy: 0.5907\n",
      "Epoch 221/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0438 - accuracy: 0.5780 - val_loss: 1.0475 - val_accuracy: 0.5945\n",
      "Epoch 222/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0394 - accuracy: 0.5764 - val_loss: 1.0469 - val_accuracy: 0.5791\n",
      "Epoch 223/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0428 - accuracy: 0.5804 - val_loss: 1.0832 - val_accuracy: 0.5762\n",
      "Epoch 224/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0427 - accuracy: 0.5794 - val_loss: 1.0465 - val_accuracy: 0.5937\n",
      "Epoch 225/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0415 - accuracy: 0.5773 - val_loss: 1.0628 - val_accuracy: 0.5871\n",
      "Epoch 226/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0407 - accuracy: 0.5767 - val_loss: 1.0409 - val_accuracy: 0.5916\n",
      "Epoch 227/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0380 - accuracy: 0.5791 - val_loss: 1.0456 - val_accuracy: 0.5865\n",
      "Epoch 228/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0425 - accuracy: 0.5795 - val_loss: 1.0440 - val_accuracy: 0.5883\n",
      "Epoch 229/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0415 - accuracy: 0.5809 - val_loss: 1.0390 - val_accuracy: 0.5910\n",
      "Epoch 230/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0387 - accuracy: 0.5806 - val_loss: 1.0414 - val_accuracy: 0.5907\n",
      "Epoch 231/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0445 - accuracy: 0.5790 - val_loss: 1.0440 - val_accuracy: 0.5865\n",
      "Epoch 232/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0371 - accuracy: 0.5803 - val_loss: 1.0679 - val_accuracy: 0.5803\n",
      "Epoch 233/233\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 1.0363 - accuracy: 0.5774 - val_loss: 1.0557 - val_accuracy: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a84205dc0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_epoch = hist2.history[\"val_accuracy\"]\n",
    "best_epoch = val_acc_epoch.index(max(val_acc_epoch)) + 1\n",
    "\n",
    "model_b = build_model_b()\n",
    "model_b.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "219ea844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 1s 3ms/step - loss: 1.0472 - accuracy: 0.5744\n",
      "[1.0472266674041748, 0.5744373798370361]\n",
      "260/260 [==============================] - 1s 2ms/step - loss: 1.0313 - accuracy: 0.5765\n",
      "[1.0312726497650146, 0.5764833092689514]\n",
      "260/260 [==============================] - 1s 2ms/step - loss: 1.0570 - accuracy: 0.5696\n",
      "[1.0569791793823242, 0.5696232914924622]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, y_test))\n",
    "print(model_a.evaluate(X_test, y_test))\n",
    "print(model_b.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e98cb18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 0s 1ms/step\n",
      "(array([0, 1, 2, 3, 4], dtype=int64), array([4389, 2241,    9, 1665,    5], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.argmax(model_b.predict(X_test), axis=1), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "518081fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564087134432543"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=10000, learning_rate=\"adaptive\")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ccb7f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(mlp, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aed4108c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 6, 7], dtype=int64),\n",
       " array([2845, 1476,   13,   18, 1120], dtype=int64))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mlp.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c12eaa",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "148fc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-233bc4989a44>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  a = KerasClassifier(build_model_a, epochs=400, batch_size=10)\n",
      "<ipython-input-100-233bc4989a44>:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  b = KerasClassifier(build_model_b, epochs=400, batch_size=10)\n",
      "<ipython-input-100-233bc4989a44>:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  c = KerasClassifier(build_model_c, epochs=400, batch_size=10)\n"
     ]
    }
   ],
   "source": [
    "a = KerasClassifier(build_model_a, epochs=400, batch_size=10)\n",
    "a._estimator_type = \"classifier\"\n",
    "b = KerasClassifier(build_model_b, epochs=400, batch_size=10)\n",
    "b._estimator_type = \"classifier\"\n",
    "c = KerasClassifier(build_model_c, epochs=400, batch_size=10)\n",
    "c._estimator_type = \"classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd0e348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = VotingClassifier([(\"a\", a), (\"b\", b), (\"c\", c)], voting=\"hard\", weights=[0.37, 0.33, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "864149bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.5836 - accuracy: 0.3984\n",
      "Epoch 2/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5716 - accuracy: 0.3989\n",
      "Epoch 3/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5707 - accuracy: 0.3989\n",
      "Epoch 4/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5706 - accuracy: 0.3989\n",
      "Epoch 5/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5703 - accuracy: 0.3989\n",
      "Epoch 6/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5701 - accuracy: 0.3989\n",
      "Epoch 7/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5699 - accuracy: 0.3989\n",
      "Epoch 8/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5685 - accuracy: 0.3989\n",
      "Epoch 9/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5652 - accuracy: 0.3994\n",
      "Epoch 10/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5642 - accuracy: 0.3994\n",
      "Epoch 11/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5573 - accuracy: 0.4002\n",
      "Epoch 12/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5528 - accuracy: 0.4012\n",
      "Epoch 13/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5479 - accuracy: 0.4039\n",
      "Epoch 14/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5444 - accuracy: 0.4062\n",
      "Epoch 15/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5403 - accuracy: 0.4059\n",
      "Epoch 16/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5366 - accuracy: 0.4135\n",
      "Epoch 17/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5272 - accuracy: 0.4168\n",
      "Epoch 18/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5160 - accuracy: 0.4224\n",
      "Epoch 19/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5049 - accuracy: 0.4310\n",
      "Epoch 20/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4943 - accuracy: 0.4372\n",
      "Epoch 21/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4829 - accuracy: 0.4424\n",
      "Epoch 22/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4688 - accuracy: 0.4476\n",
      "Epoch 23/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4560 - accuracy: 0.4503\n",
      "Epoch 24/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4402 - accuracy: 0.4582\n",
      "Epoch 25/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4276 - accuracy: 0.4598\n",
      "Epoch 26/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4209 - accuracy: 0.4635\n",
      "Epoch 27/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4087 - accuracy: 0.4649\n",
      "Epoch 28/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4046 - accuracy: 0.4665\n",
      "Epoch 29/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3937 - accuracy: 0.4690\n",
      "Epoch 30/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3905 - accuracy: 0.4680\n",
      "Epoch 31/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3837 - accuracy: 0.4716\n",
      "Epoch 32/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3693 - accuracy: 0.4765\n",
      "Epoch 33/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3661 - accuracy: 0.4791\n",
      "Epoch 34/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3559 - accuracy: 0.4860\n",
      "Epoch 35/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3498 - accuracy: 0.4909\n",
      "Epoch 36/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3473 - accuracy: 0.4855\n",
      "Epoch 37/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3373 - accuracy: 0.4980\n",
      "Epoch 38/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3341 - accuracy: 0.5057\n",
      "Epoch 39/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3300 - accuracy: 0.4989\n",
      "Epoch 40/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3225 - accuracy: 0.5037\n",
      "Epoch 41/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3196 - accuracy: 0.5140\n",
      "Epoch 42/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3193 - accuracy: 0.5133\n",
      "Epoch 43/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3157 - accuracy: 0.5110\n",
      "Epoch 44/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3135 - accuracy: 0.5144\n",
      "Epoch 45/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3062 - accuracy: 0.5169\n",
      "Epoch 46/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3038 - accuracy: 0.5212\n",
      "Epoch 47/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2986 - accuracy: 0.5274\n",
      "Epoch 48/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2974 - accuracy: 0.5241\n",
      "Epoch 49/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2993 - accuracy: 0.5273\n",
      "Epoch 50/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2941 - accuracy: 0.5297\n",
      "Epoch 51/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2920 - accuracy: 0.5288\n",
      "Epoch 52/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2952 - accuracy: 0.5298\n",
      "Epoch 53/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2901 - accuracy: 0.5266\n",
      "Epoch 54/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2872 - accuracy: 0.5309\n",
      "Epoch 55/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2907 - accuracy: 0.5345\n",
      "Epoch 56/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2834 - accuracy: 0.5336\n",
      "Epoch 57/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2894 - accuracy: 0.5321\n",
      "Epoch 58/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2785 - accuracy: 0.5391\n",
      "Epoch 59/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2773 - accuracy: 0.5430\n",
      "Epoch 60/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2772 - accuracy: 0.5402\n",
      "Epoch 61/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2780 - accuracy: 0.5393\n",
      "Epoch 62/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2783 - accuracy: 0.5395\n",
      "Epoch 63/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2740 - accuracy: 0.5398\n",
      "Epoch 64/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2663 - accuracy: 0.5494\n",
      "Epoch 65/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2725 - accuracy: 0.5437\n",
      "Epoch 66/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2719 - accuracy: 0.5460\n",
      "Epoch 67/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2722 - accuracy: 0.5506\n",
      "Epoch 68/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2677 - accuracy: 0.5451\n",
      "Epoch 69/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2702 - accuracy: 0.5474\n",
      "Epoch 70/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2636 - accuracy: 0.5492\n",
      "Epoch 71/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2810 - accuracy: 0.5426\n",
      "Epoch 72/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2651 - accuracy: 0.5499\n",
      "Epoch 73/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2683 - accuracy: 0.5469\n",
      "Epoch 74/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2625 - accuracy: 0.5504\n",
      "Epoch 75/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2589 - accuracy: 0.5555\n",
      "Epoch 76/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2610 - accuracy: 0.5559\n",
      "Epoch 77/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2618 - accuracy: 0.5504\n",
      "Epoch 78/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2592 - accuracy: 0.5484\n",
      "Epoch 79/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2574 - accuracy: 0.5561\n",
      "Epoch 80/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2526 - accuracy: 0.5585\n",
      "Epoch 81/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2601 - accuracy: 0.5491\n",
      "Epoch 82/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2596 - accuracy: 0.5518\n",
      "Epoch 83/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2546 - accuracy: 0.5567\n",
      "Epoch 84/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2574 - accuracy: 0.5541\n",
      "Epoch 85/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2569 - accuracy: 0.5535\n",
      "Epoch 86/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2520 - accuracy: 0.5563\n",
      "Epoch 87/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2520 - accuracy: 0.5565\n",
      "Epoch 88/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2460 - accuracy: 0.5618\n",
      "Epoch 89/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2487 - accuracy: 0.5580\n",
      "Epoch 90/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2486 - accuracy: 0.5586\n",
      "Epoch 91/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2541 - accuracy: 0.5546\n",
      "Epoch 92/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2436 - accuracy: 0.5592\n",
      "Epoch 93/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2431 - accuracy: 0.5597\n",
      "Epoch 94/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2428 - accuracy: 0.5580\n",
      "Epoch 95/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2537 - accuracy: 0.5544\n",
      "Epoch 96/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2505 - accuracy: 0.5580\n",
      "Epoch 97/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2432 - accuracy: 0.5594\n",
      "Epoch 98/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2424 - accuracy: 0.5557\n",
      "Epoch 99/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2413 - accuracy: 0.5657\n",
      "Epoch 100/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2474 - accuracy: 0.5592\n",
      "Epoch 101/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2441 - accuracy: 0.5584\n",
      "Epoch 102/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2383 - accuracy: 0.5609\n",
      "Epoch 103/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2399 - accuracy: 0.5645\n",
      "Epoch 104/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2411 - accuracy: 0.5578\n",
      "Epoch 105/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2413 - accuracy: 0.5582\n",
      "Epoch 106/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2427 - accuracy: 0.5604\n",
      "Epoch 107/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2379 - accuracy: 0.5647\n",
      "Epoch 108/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2436 - accuracy: 0.5581\n",
      "Epoch 109/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2337 - accuracy: 0.5598\n",
      "Epoch 110/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2302 - accuracy: 0.5609\n",
      "Epoch 111/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2351 - accuracy: 0.5615\n",
      "Epoch 112/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2332 - accuracy: 0.5614\n",
      "Epoch 113/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2323 - accuracy: 0.5601\n",
      "Epoch 114/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2328 - accuracy: 0.5627\n",
      "Epoch 115/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2342 - accuracy: 0.5606\n",
      "Epoch 116/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2284 - accuracy: 0.5634\n",
      "Epoch 117/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2295 - accuracy: 0.5663\n",
      "Epoch 118/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2254 - accuracy: 0.5635\n",
      "Epoch 119/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2326 - accuracy: 0.5628\n",
      "Epoch 120/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2196 - accuracy: 0.5682\n",
      "Epoch 121/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2247 - accuracy: 0.5671\n",
      "Epoch 122/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2234 - accuracy: 0.5678\n",
      "Epoch 123/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2267 - accuracy: 0.5573\n",
      "Epoch 124/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2253 - accuracy: 0.5639\n",
      "Epoch 125/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2289 - accuracy: 0.5617\n",
      "Epoch 126/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2184 - accuracy: 0.5654\n",
      "Epoch 127/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2225 - accuracy: 0.5591\n",
      "Epoch 128/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2183 - accuracy: 0.5680\n",
      "Epoch 129/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2141 - accuracy: 0.5683\n",
      "Epoch 130/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2202 - accuracy: 0.5652\n",
      "Epoch 131/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2214 - accuracy: 0.5612\n",
      "Epoch 132/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2161 - accuracy: 0.5653\n",
      "Epoch 133/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2125 - accuracy: 0.5670\n",
      "Epoch 134/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2148 - accuracy: 0.5692\n",
      "Epoch 135/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2143 - accuracy: 0.5668\n",
      "Epoch 136/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2094 - accuracy: 0.5664\n",
      "Epoch 137/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2081 - accuracy: 0.5668\n",
      "Epoch 138/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2123 - accuracy: 0.5649\n",
      "Epoch 139/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2038 - accuracy: 0.5699\n",
      "Epoch 140/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2079 - accuracy: 0.5679\n",
      "Epoch 141/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2063 - accuracy: 0.5666\n",
      "Epoch 142/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2080 - accuracy: 0.5694\n",
      "Epoch 143/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2098 - accuracy: 0.5678\n",
      "Epoch 144/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2043 - accuracy: 0.5675\n",
      "Epoch 145/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2061 - accuracy: 0.5643\n",
      "Epoch 146/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2116 - accuracy: 0.5682\n",
      "Epoch 147/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2075 - accuracy: 0.5684\n",
      "Epoch 148/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2003 - accuracy: 0.5723\n",
      "Epoch 149/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2018 - accuracy: 0.5699\n",
      "Epoch 150/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1978 - accuracy: 0.5700\n",
      "Epoch 151/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2029 - accuracy: 0.5700\n",
      "Epoch 152/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2044 - accuracy: 0.5668\n",
      "Epoch 153/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2003 - accuracy: 0.5735\n",
      "Epoch 154/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2014 - accuracy: 0.5708\n",
      "Epoch 155/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1999 - accuracy: 0.5701\n",
      "Epoch 156/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2053 - accuracy: 0.5703\n",
      "Epoch 157/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1992 - accuracy: 0.5724\n",
      "Epoch 158/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2059 - accuracy: 0.5732\n",
      "Epoch 159/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1946 - accuracy: 0.5730\n",
      "Epoch 160/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1982 - accuracy: 0.5724\n",
      "Epoch 161/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1938 - accuracy: 0.5766\n",
      "Epoch 162/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1944 - accuracy: 0.5783\n",
      "Epoch 163/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1936 - accuracy: 0.5745\n",
      "Epoch 164/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1929 - accuracy: 0.5707\n",
      "Epoch 165/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1986 - accuracy: 0.5715\n",
      "Epoch 166/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1932 - accuracy: 0.5729\n",
      "Epoch 167/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1935 - accuracy: 0.5729\n",
      "Epoch 168/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1872 - accuracy: 0.5764\n",
      "Epoch 169/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1891 - accuracy: 0.5776\n",
      "Epoch 170/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1905 - accuracy: 0.5758\n",
      "Epoch 171/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1947 - accuracy: 0.5729\n",
      "Epoch 172/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1881 - accuracy: 0.5730\n",
      "Epoch 173/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1885 - accuracy: 0.5758\n",
      "Epoch 174/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1874 - accuracy: 0.5747\n",
      "Epoch 175/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1926 - accuracy: 0.5705\n",
      "Epoch 176/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1824 - accuracy: 0.5776\n",
      "Epoch 177/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1864 - accuracy: 0.5751\n",
      "Epoch 178/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1840 - accuracy: 0.5736\n",
      "Epoch 179/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1852 - accuracy: 0.5764\n",
      "Epoch 180/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1839 - accuracy: 0.5778\n",
      "Epoch 181/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1854 - accuracy: 0.5749\n",
      "Epoch 182/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1796 - accuracy: 0.5773\n",
      "Epoch 183/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1878 - accuracy: 0.5756\n",
      "Epoch 184/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1810 - accuracy: 0.5786\n",
      "Epoch 185/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1788 - accuracy: 0.5755\n",
      "Epoch 186/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1800 - accuracy: 0.5790\n",
      "Epoch 187/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1812 - accuracy: 0.5796\n",
      "Epoch 188/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1783 - accuracy: 0.5808\n",
      "Epoch 189/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1823 - accuracy: 0.5841\n",
      "Epoch 190/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1830 - accuracy: 0.5782\n",
      "Epoch 191/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1767 - accuracy: 0.5802\n",
      "Epoch 192/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1779 - accuracy: 0.5813\n",
      "Epoch 193/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1759 - accuracy: 0.5810\n",
      "Epoch 194/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1743 - accuracy: 0.5826\n",
      "Epoch 195/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1805 - accuracy: 0.5829\n",
      "Epoch 196/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1804 - accuracy: 0.5819\n",
      "Epoch 197/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1742 - accuracy: 0.5835\n",
      "Epoch 198/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1739 - accuracy: 0.5796\n",
      "Epoch 199/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1768 - accuracy: 0.5812\n",
      "Epoch 200/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1726 - accuracy: 0.5845\n",
      "Epoch 201/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1771 - accuracy: 0.5835\n",
      "Epoch 202/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1705 - accuracy: 0.5871\n",
      "Epoch 203/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1715 - accuracy: 0.5849\n",
      "Epoch 204/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1776 - accuracy: 0.5796\n",
      "Epoch 205/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1676 - accuracy: 0.5886\n",
      "Epoch 206/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1712 - accuracy: 0.5845\n",
      "Epoch 207/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1724 - accuracy: 0.5869\n",
      "Epoch 208/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1680 - accuracy: 0.5861\n",
      "Epoch 209/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1742 - accuracy: 0.5841\n",
      "Epoch 210/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1721 - accuracy: 0.5853\n",
      "Epoch 211/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1773 - accuracy: 0.5870\n",
      "Epoch 212/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1640 - accuracy: 0.5860\n",
      "Epoch 213/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1767 - accuracy: 0.5838\n",
      "Epoch 214/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1705 - accuracy: 0.5868\n",
      "Epoch 215/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1667 - accuracy: 0.5882\n",
      "Epoch 216/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1728 - accuracy: 0.5867\n",
      "Epoch 217/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1673 - accuracy: 0.5877\n",
      "Epoch 218/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1762 - accuracy: 0.5884\n",
      "Epoch 219/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1709 - accuracy: 0.5857\n",
      "Epoch 220/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1657 - accuracy: 0.5862\n",
      "Epoch 221/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1708 - accuracy: 0.5880\n",
      "Epoch 222/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1706 - accuracy: 0.5863\n",
      "Epoch 223/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1666 - accuracy: 0.5858\n",
      "Epoch 224/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1690 - accuracy: 0.5866\n",
      "Epoch 225/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1640 - accuracy: 0.5881\n",
      "Epoch 226/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1684 - accuracy: 0.5884\n",
      "Epoch 227/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1690 - accuracy: 0.5889\n",
      "Epoch 228/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1649 - accuracy: 0.5826\n",
      "Epoch 229/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1623 - accuracy: 0.5885\n",
      "Epoch 230/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1706 - accuracy: 0.5837\n",
      "Epoch 231/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1664 - accuracy: 0.5858\n",
      "Epoch 232/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1638 - accuracy: 0.5908\n",
      "Epoch 233/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1654 - accuracy: 0.5881\n",
      "Epoch 234/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1629 - accuracy: 0.5913\n",
      "Epoch 235/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1581 - accuracy: 0.5896\n",
      "Epoch 236/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1624 - accuracy: 0.5867\n",
      "Epoch 237/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1654 - accuracy: 0.5911\n",
      "Epoch 238/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1668 - accuracy: 0.5887\n",
      "Epoch 239/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1634 - accuracy: 0.5921\n",
      "Epoch 240/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1619 - accuracy: 0.5911\n",
      "Epoch 241/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1688 - accuracy: 0.5853\n",
      "Epoch 242/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1607 - accuracy: 0.5912\n",
      "Epoch 243/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1653 - accuracy: 0.5917\n",
      "Epoch 244/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1654 - accuracy: 0.5863\n",
      "Epoch 245/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1632 - accuracy: 0.5883\n",
      "Epoch 246/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1629 - accuracy: 0.5905\n",
      "Epoch 247/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1575 - accuracy: 0.5916\n",
      "Epoch 248/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1621 - accuracy: 0.5923\n",
      "Epoch 249/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1594 - accuracy: 0.5924\n",
      "Epoch 250/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1606 - accuracy: 0.5889\n",
      "Epoch 251/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1667 - accuracy: 0.5887\n",
      "Epoch 252/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1661 - accuracy: 0.5879\n",
      "Epoch 253/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1630 - accuracy: 0.5902\n",
      "Epoch 254/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1605 - accuracy: 0.5940\n",
      "Epoch 255/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1667 - accuracy: 0.5905\n",
      "Epoch 256/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1610 - accuracy: 0.5927\n",
      "Epoch 257/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1578 - accuracy: 0.5933\n",
      "Epoch 258/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1653 - accuracy: 0.5889\n",
      "Epoch 259/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1571 - accuracy: 0.5932\n",
      "Epoch 260/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1575 - accuracy: 0.5933\n",
      "Epoch 261/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1594 - accuracy: 0.5921\n",
      "Epoch 262/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1527 - accuracy: 0.5969\n",
      "Epoch 263/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1558 - accuracy: 0.5935\n",
      "Epoch 264/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1574 - accuracy: 0.5954\n",
      "Epoch 265/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1541 - accuracy: 0.5959\n",
      "Epoch 266/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1552 - accuracy: 0.5925\n",
      "Epoch 267/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1537 - accuracy: 0.5925\n",
      "Epoch 268/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1552 - accuracy: 0.5923\n",
      "Epoch 269/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1583 - accuracy: 0.5898\n",
      "Epoch 270/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1529 - accuracy: 0.5957\n",
      "Epoch 271/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1582 - accuracy: 0.5945\n",
      "Epoch 272/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1570 - accuracy: 0.5945\n",
      "Epoch 273/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1622 - accuracy: 0.5899\n",
      "Epoch 274/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1618 - accuracy: 0.5908\n",
      "Epoch 275/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1595 - accuracy: 0.5961\n",
      "Epoch 276/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1543 - accuracy: 0.5926\n",
      "Epoch 277/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1540 - accuracy: 0.5929\n",
      "Epoch 278/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1607 - accuracy: 0.5908\n",
      "Epoch 279/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1583 - accuracy: 0.5927\n",
      "Epoch 280/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1503 - accuracy: 0.5943\n",
      "Epoch 281/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1583 - accuracy: 0.5916\n",
      "Epoch 282/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1525 - accuracy: 0.5979\n",
      "Epoch 283/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1592 - accuracy: 0.5889\n",
      "Epoch 284/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1595 - accuracy: 0.5905\n",
      "Epoch 285/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1554 - accuracy: 0.5936\n",
      "Epoch 286/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1571 - accuracy: 0.5932\n",
      "Epoch 287/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1493 - accuracy: 0.5952\n",
      "Epoch 288/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1563 - accuracy: 0.5925\n",
      "Epoch 289/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1577 - accuracy: 0.5902\n",
      "Epoch 290/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1546 - accuracy: 0.5960\n",
      "Epoch 291/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1510 - accuracy: 0.5992\n",
      "Epoch 292/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1579 - accuracy: 0.5916\n",
      "Epoch 293/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1554 - accuracy: 0.5915\n",
      "Epoch 294/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1532 - accuracy: 0.5951\n",
      "Epoch 295/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1487 - accuracy: 0.5952\n",
      "Epoch 296/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1522 - accuracy: 0.5951\n",
      "Epoch 297/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1542 - accuracy: 0.5953\n",
      "Epoch 298/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1504 - accuracy: 0.5958\n",
      "Epoch 299/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1546 - accuracy: 0.5929\n",
      "Epoch 300/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1520 - accuracy: 0.5916\n",
      "Epoch 301/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1487 - accuracy: 0.5971\n",
      "Epoch 302/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1506 - accuracy: 0.5991\n",
      "Epoch 303/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1531 - accuracy: 0.5947\n",
      "Epoch 304/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1526 - accuracy: 0.5928\n",
      "Epoch 305/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1538 - accuracy: 0.5942\n",
      "Epoch 306/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1527 - accuracy: 0.5939\n",
      "Epoch 307/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1533 - accuracy: 0.5915\n",
      "Epoch 308/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1536 - accuracy: 0.5957\n",
      "Epoch 309/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1497 - accuracy: 0.5960\n",
      "Epoch 310/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1539 - accuracy: 0.5967\n",
      "Epoch 311/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1548 - accuracy: 0.5950\n",
      "Epoch 312/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1559 - accuracy: 0.5955\n",
      "Epoch 313/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1503 - accuracy: 0.5976\n",
      "Epoch 314/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1559 - accuracy: 0.5960\n",
      "Epoch 315/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1551 - accuracy: 0.5940\n",
      "Epoch 316/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1509 - accuracy: 0.5980\n",
      "Epoch 317/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1473 - accuracy: 0.5970\n",
      "Epoch 318/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1454 - accuracy: 0.5982\n",
      "Epoch 319/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1462 - accuracy: 0.5972\n",
      "Epoch 320/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1526 - accuracy: 0.5948\n",
      "Epoch 321/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1448 - accuracy: 0.5979\n",
      "Epoch 322/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1474 - accuracy: 0.5999\n",
      "Epoch 323/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1478 - accuracy: 0.5985\n",
      "Epoch 324/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1455 - accuracy: 0.5979\n",
      "Epoch 325/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1462 - accuracy: 0.5988\n",
      "Epoch 326/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1520 - accuracy: 0.5946\n",
      "Epoch 327/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1481 - accuracy: 0.5991\n",
      "Epoch 328/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1434 - accuracy: 0.6002\n",
      "Epoch 329/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1475 - accuracy: 0.5973\n",
      "Epoch 330/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1470 - accuracy: 0.5959\n",
      "Epoch 331/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1448 - accuracy: 0.5969\n",
      "Epoch 332/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1486 - accuracy: 0.5987\n",
      "Epoch 333/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1502 - accuracy: 0.5955\n",
      "Epoch 334/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1482 - accuracy: 0.5970\n",
      "Epoch 335/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1498 - accuracy: 0.5950\n",
      "Epoch 336/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1601 - accuracy: 0.5907\n",
      "Epoch 337/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1465 - accuracy: 0.5980\n",
      "Epoch 338/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1483 - accuracy: 0.5952\n",
      "Epoch 339/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1449 - accuracy: 0.5998\n",
      "Epoch 340/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1449 - accuracy: 0.5969\n",
      "Epoch 341/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1459 - accuracy: 0.5966\n",
      "Epoch 342/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1436 - accuracy: 0.5956\n",
      "Epoch 343/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1514 - accuracy: 0.5997\n",
      "Epoch 344/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1526 - accuracy: 0.5967\n",
      "Epoch 345/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1502 - accuracy: 0.5972\n",
      "Epoch 346/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1467 - accuracy: 0.5977\n",
      "Epoch 347/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1442 - accuracy: 0.5951\n",
      "Epoch 348/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1466 - accuracy: 0.6001\n",
      "Epoch 349/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1422 - accuracy: 0.5997\n",
      "Epoch 350/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1443 - accuracy: 0.5984\n",
      "Epoch 351/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1450 - accuracy: 0.5992\n",
      "Epoch 352/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1489 - accuracy: 0.5949\n",
      "Epoch 353/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1465 - accuracy: 0.5976\n",
      "Epoch 354/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1506 - accuracy: 0.5954\n",
      "Epoch 355/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1471 - accuracy: 0.6009\n",
      "Epoch 356/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1502 - accuracy: 0.5963\n",
      "Epoch 357/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1456 - accuracy: 0.6004\n",
      "Epoch 358/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1434 - accuracy: 0.6006\n",
      "Epoch 359/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1482 - accuracy: 0.5997\n",
      "Epoch 360/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1449 - accuracy: 0.5972\n",
      "Epoch 361/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1485 - accuracy: 0.5975\n",
      "Epoch 362/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1509 - accuracy: 0.5958\n",
      "Epoch 363/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1464 - accuracy: 0.6016\n",
      "Epoch 364/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1430 - accuracy: 0.5998\n",
      "Epoch 365/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1468 - accuracy: 0.5987\n",
      "Epoch 366/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1424 - accuracy: 0.6001\n",
      "Epoch 367/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1426 - accuracy: 0.5990\n",
      "Epoch 368/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1420 - accuracy: 0.5981\n",
      "Epoch 369/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1450 - accuracy: 0.5974\n",
      "Epoch 370/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1434 - accuracy: 0.5975\n",
      "Epoch 371/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1432 - accuracy: 0.6010\n",
      "Epoch 372/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1468 - accuracy: 0.5968\n",
      "Epoch 373/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1419 - accuracy: 0.6030\n",
      "Epoch 374/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1429 - accuracy: 0.6010\n",
      "Epoch 375/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1447 - accuracy: 0.5991\n",
      "Epoch 376/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1492 - accuracy: 0.5998\n",
      "Epoch 377/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1486 - accuracy: 0.5958\n",
      "Epoch 378/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1467 - accuracy: 0.5996\n",
      "Epoch 379/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1395 - accuracy: 0.6003\n",
      "Epoch 380/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1450 - accuracy: 0.6008\n",
      "Epoch 381/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1421 - accuracy: 0.6010\n",
      "Epoch 382/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1451 - accuracy: 0.6015\n",
      "Epoch 383/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1444 - accuracy: 0.5987\n",
      "Epoch 384/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1439 - accuracy: 0.5997\n",
      "Epoch 385/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1432 - accuracy: 0.6002\n",
      "Epoch 386/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1461 - accuracy: 0.5964\n",
      "Epoch 387/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1444 - accuracy: 0.5988\n",
      "Epoch 388/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1380 - accuracy: 0.6024\n",
      "Epoch 389/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1443 - accuracy: 0.5993\n",
      "Epoch 390/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1448 - accuracy: 0.6011\n",
      "Epoch 391/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1441 - accuracy: 0.5989\n",
      "Epoch 392/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1460 - accuracy: 0.5974\n",
      "Epoch 393/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1476 - accuracy: 0.5973\n",
      "Epoch 394/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1459 - accuracy: 0.6005\n",
      "Epoch 395/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1426 - accuracy: 0.6001\n",
      "Epoch 396/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1453 - accuracy: 0.5988\n",
      "Epoch 397/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1387 - accuracy: 0.6049\n",
      "Epoch 398/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1427 - accuracy: 0.5980\n",
      "Epoch 399/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1367 - accuracy: 0.5992\n",
      "Epoch 400/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1493 - accuracy: 0.5953\n",
      "Epoch 1/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.6619 - accuracy: 0.3979\n",
      "Epoch 2/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.5581 - accuracy: 0.3992\n",
      "Epoch 3/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.5390 - accuracy: 0.4069\n",
      "Epoch 4/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5224 - accuracy: 0.4115\n",
      "Epoch 5/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4994 - accuracy: 0.4281\n",
      "Epoch 6/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.4730 - accuracy: 0.4450\n",
      "Epoch 7/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.4481 - accuracy: 0.4608\n",
      "Epoch 8/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.4238 - accuracy: 0.4754\n",
      "Epoch 9/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4006 - accuracy: 0.4869\n",
      "Epoch 10/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3812 - accuracy: 0.4910\n",
      "Epoch 11/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3633 - accuracy: 0.5079\n",
      "Epoch 12/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3513 - accuracy: 0.5062\n",
      "Epoch 13/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3395 - accuracy: 0.5122\n",
      "Epoch 14/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3278 - accuracy: 0.5173\n",
      "Epoch 15/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3233 - accuracy: 0.5230\n",
      "Epoch 16/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3185 - accuracy: 0.5205\n",
      "Epoch 17/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3111 - accuracy: 0.5236\n",
      "Epoch 18/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.3035 - accuracy: 0.5257\n",
      "Epoch 19/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2990 - accuracy: 0.5329\n",
      "Epoch 20/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2959 - accuracy: 0.5284\n",
      "Epoch 21/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2876 - accuracy: 0.5359\n",
      "Epoch 22/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2847 - accuracy: 0.5382\n",
      "Epoch 23/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2793 - accuracy: 0.5348\n",
      "Epoch 24/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2732 - accuracy: 0.5403\n",
      "Epoch 25/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2758 - accuracy: 0.5396\n",
      "Epoch 26/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2741 - accuracy: 0.5416\n",
      "Epoch 27/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2674 - accuracy: 0.5426\n",
      "Epoch 28/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2636 - accuracy: 0.5438\n",
      "Epoch 29/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2609 - accuracy: 0.5457\n",
      "Epoch 30/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2571 - accuracy: 0.5477\n",
      "Epoch 31/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2561 - accuracy: 0.5476\n",
      "Epoch 32/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2556 - accuracy: 0.5446\n",
      "Epoch 33/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2531 - accuracy: 0.5507\n",
      "Epoch 34/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2524 - accuracy: 0.5478\n",
      "Epoch 35/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2545 - accuracy: 0.5457\n",
      "Epoch 36/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2468 - accuracy: 0.5469\n",
      "Epoch 37/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2519 - accuracy: 0.5454\n",
      "Epoch 38/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2462 - accuracy: 0.5497\n",
      "Epoch 39/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2423 - accuracy: 0.5530\n",
      "Epoch 40/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2403 - accuracy: 0.5533\n",
      "Epoch 41/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2407 - accuracy: 0.5476\n",
      "Epoch 42/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2401 - accuracy: 0.5564\n",
      "Epoch 43/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.2353 - accuracy: 0.5576\n",
      "Epoch 44/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.2319 - accuracy: 0.5564\n",
      "Epoch 45/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2316 - accuracy: 0.5583\n",
      "Epoch 46/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2305 - accuracy: 0.5570\n",
      "Epoch 47/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2242 - accuracy: 0.5644\n",
      "Epoch 48/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2251 - accuracy: 0.5631\n",
      "Epoch 49/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2180 - accuracy: 0.5675\n",
      "Epoch 50/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.2178 - accuracy: 0.5689\n",
      "Epoch 51/400\n",
      "1111/1111 [==============================] - 5s 5ms/step - loss: 1.2138 - accuracy: 0.5731\n",
      "Epoch 52/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2136 - accuracy: 0.5718\n",
      "Epoch 53/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2109 - accuracy: 0.5675\n",
      "Epoch 54/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2079 - accuracy: 0.5692\n",
      "Epoch 55/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.2089 - accuracy: 0.5720\n",
      "Epoch 56/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2080 - accuracy: 0.5703\n",
      "Epoch 57/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2050 - accuracy: 0.5715\n",
      "Epoch 58/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2036 - accuracy: 0.5738\n",
      "Epoch 59/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2024 - accuracy: 0.5699\n",
      "Epoch 60/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2006 - accuracy: 0.5722\n",
      "Epoch 61/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1981 - accuracy: 0.5769\n",
      "Epoch 62/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1983 - accuracy: 0.5708\n",
      "Epoch 63/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1963 - accuracy: 0.5728\n",
      "Epoch 64/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1922 - accuracy: 0.5781\n",
      "Epoch 65/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1899 - accuracy: 0.5794\n",
      "Epoch 66/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1940 - accuracy: 0.5773\n",
      "Epoch 67/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1865 - accuracy: 0.5791\n",
      "Epoch 68/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1883 - accuracy: 0.5808\n",
      "Epoch 69/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1899 - accuracy: 0.5756\n",
      "Epoch 70/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1843 - accuracy: 0.5812\n",
      "Epoch 71/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1866 - accuracy: 0.5782\n",
      "Epoch 72/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1862 - accuracy: 0.5783\n",
      "Epoch 73/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1839 - accuracy: 0.5842\n",
      "Epoch 74/400\n",
      "1111/1111 [==============================] - 5s 5ms/step - loss: 1.1839 - accuracy: 0.5783\n",
      "Epoch 75/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1815 - accuracy: 0.5807\n",
      "Epoch 76/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1814 - accuracy: 0.5808\n",
      "Epoch 77/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1772 - accuracy: 0.5801\n",
      "Epoch 78/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1798 - accuracy: 0.5828\n",
      "Epoch 79/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1813 - accuracy: 0.5837\n",
      "Epoch 80/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1801 - accuracy: 0.5767\n",
      "Epoch 81/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1750 - accuracy: 0.5829\n",
      "Epoch 82/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1737 - accuracy: 0.5830\n",
      "Epoch 83/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1737 - accuracy: 0.5797\n",
      "Epoch 84/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1761 - accuracy: 0.5790\n",
      "Epoch 85/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1733 - accuracy: 0.5812\n",
      "Epoch 86/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1731 - accuracy: 0.5825\n",
      "Epoch 87/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1703 - accuracy: 0.5852\n",
      "Epoch 88/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1733 - accuracy: 0.5848\n",
      "Epoch 89/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1691 - accuracy: 0.5866\n",
      "Epoch 90/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1688 - accuracy: 0.5840\n",
      "Epoch 91/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1669 - accuracy: 0.5854\n",
      "Epoch 92/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1704 - accuracy: 0.5843\n",
      "Epoch 93/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1668 - accuracy: 0.5867\n",
      "Epoch 94/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1680 - accuracy: 0.5841\n",
      "Epoch 95/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1699 - accuracy: 0.5867\n",
      "Epoch 96/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1666 - accuracy: 0.5823\n",
      "Epoch 97/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1674 - accuracy: 0.5810\n",
      "Epoch 98/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1649 - accuracy: 0.5898\n",
      "Epoch 99/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1664 - accuracy: 0.5871\n",
      "Epoch 100/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1612 - accuracy: 0.5875\n",
      "Epoch 101/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1639 - accuracy: 0.5871\n",
      "Epoch 102/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1631 - accuracy: 0.5871\n",
      "Epoch 103/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1634 - accuracy: 0.5927\n",
      "Epoch 104/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1627 - accuracy: 0.5876\n",
      "Epoch 105/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1646 - accuracy: 0.5853\n",
      "Epoch 106/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1601 - accuracy: 0.5916\n",
      "Epoch 107/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1573 - accuracy: 0.5901\n",
      "Epoch 108/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1570 - accuracy: 0.5927\n",
      "Epoch 109/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1599 - accuracy: 0.5906\n",
      "Epoch 110/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1625 - accuracy: 0.5862\n",
      "Epoch 111/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1610 - accuracy: 0.5837\n",
      "Epoch 112/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1566 - accuracy: 0.5892\n",
      "Epoch 113/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1590 - accuracy: 0.5891\n",
      "Epoch 114/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1585 - accuracy: 0.5887\n",
      "Epoch 115/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1548 - accuracy: 0.5937\n",
      "Epoch 116/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1559 - accuracy: 0.5867\n",
      "Epoch 117/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1557 - accuracy: 0.5909\n",
      "Epoch 118/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1563 - accuracy: 0.5887\n",
      "Epoch 119/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1554 - accuracy: 0.5908\n",
      "Epoch 120/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1567 - accuracy: 0.5875\n",
      "Epoch 121/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1540 - accuracy: 0.5907\n",
      "Epoch 122/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1518 - accuracy: 0.5938\n",
      "Epoch 123/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1538 - accuracy: 0.5910\n",
      "Epoch 124/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1545 - accuracy: 0.5906\n",
      "Epoch 125/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1518 - accuracy: 0.5892\n",
      "Epoch 126/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1541 - accuracy: 0.5898\n",
      "Epoch 127/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1574 - accuracy: 0.5875\n",
      "Epoch 128/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1519 - accuracy: 0.5904\n",
      "Epoch 129/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1492 - accuracy: 0.5913\n",
      "Epoch 130/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1486 - accuracy: 0.5912\n",
      "Epoch 131/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1488 - accuracy: 0.5905\n",
      "Epoch 132/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1517 - accuracy: 0.5927\n",
      "Epoch 133/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1505 - accuracy: 0.5929\n",
      "Epoch 134/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1473 - accuracy: 0.5946\n",
      "Epoch 135/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1489 - accuracy: 0.5927\n",
      "Epoch 136/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1487 - accuracy: 0.5895\n",
      "Epoch 137/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1490 - accuracy: 0.5915\n",
      "Epoch 138/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1472 - accuracy: 0.5950\n",
      "Epoch 139/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1504 - accuracy: 0.5933\n",
      "Epoch 140/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1476 - accuracy: 0.5950\n",
      "Epoch 141/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1465 - accuracy: 0.5952\n",
      "Epoch 142/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1455 - accuracy: 0.5960\n",
      "Epoch 143/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1461 - accuracy: 0.5953\n",
      "Epoch 144/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1454 - accuracy: 0.5944\n",
      "Epoch 145/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1457 - accuracy: 0.5952\n",
      "Epoch 146/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1444 - accuracy: 0.5903\n",
      "Epoch 147/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1475 - accuracy: 0.5919\n",
      "Epoch 148/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1429 - accuracy: 0.5949\n",
      "Epoch 149/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1406 - accuracy: 0.5925\n",
      "Epoch 150/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1439 - accuracy: 0.5948\n",
      "Epoch 151/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1434 - accuracy: 0.5949\n",
      "Epoch 152/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1416 - accuracy: 0.5937\n",
      "Epoch 153/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1451 - accuracy: 0.5960\n",
      "Epoch 154/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1443 - accuracy: 0.5934\n",
      "Epoch 155/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1416 - accuracy: 0.5938\n",
      "Epoch 156/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1454 - accuracy: 0.5952\n",
      "Epoch 157/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1419 - accuracy: 0.5954\n",
      "Epoch 158/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1437 - accuracy: 0.5958\n",
      "Epoch 159/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1444 - accuracy: 0.5922\n",
      "Epoch 160/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1416 - accuracy: 0.5964\n",
      "Epoch 161/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1396 - accuracy: 0.5944\n",
      "Epoch 162/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1398 - accuracy: 0.5936\n",
      "Epoch 163/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1437 - accuracy: 0.5952\n",
      "Epoch 164/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1389 - accuracy: 0.5955\n",
      "Epoch 165/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1406 - accuracy: 0.5960\n",
      "Epoch 166/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1363 - accuracy: 0.5997\n",
      "Epoch 167/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1394 - accuracy: 0.5987\n",
      "Epoch 168/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1397 - accuracy: 0.5972\n",
      "Epoch 169/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1409 - accuracy: 0.5934\n",
      "Epoch 170/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1410 - accuracy: 0.5978\n",
      "Epoch 171/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1396 - accuracy: 0.5998\n",
      "Epoch 172/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1364 - accuracy: 0.5961\n",
      "Epoch 173/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1400 - accuracy: 0.5973\n",
      "Epoch 174/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1378 - accuracy: 0.5961\n",
      "Epoch 175/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1385 - accuracy: 0.5976\n",
      "Epoch 176/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1375 - accuracy: 0.5951\n",
      "Epoch 177/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1373 - accuracy: 0.5974\n",
      "Epoch 178/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1356 - accuracy: 0.6008\n",
      "Epoch 179/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1373 - accuracy: 0.5988\n",
      "Epoch 180/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1401 - accuracy: 0.5972\n",
      "Epoch 181/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1349 - accuracy: 0.6008\n",
      "Epoch 182/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1379 - accuracy: 0.5987\n",
      "Epoch 183/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1352 - accuracy: 0.5988\n",
      "Epoch 184/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1339 - accuracy: 0.5989\n",
      "Epoch 185/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1361 - accuracy: 0.5981\n",
      "Epoch 186/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1344 - accuracy: 0.5958\n",
      "Epoch 187/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1376 - accuracy: 0.5988\n",
      "Epoch 188/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1338 - accuracy: 0.5992\n",
      "Epoch 189/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1345 - accuracy: 0.5974\n",
      "Epoch 190/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1338 - accuracy: 0.6000\n",
      "Epoch 191/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1348 - accuracy: 0.5986\n",
      "Epoch 192/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1382 - accuracy: 0.5952\n",
      "Epoch 193/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1361 - accuracy: 0.5961\n",
      "Epoch 194/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1354 - accuracy: 0.5989\n",
      "Epoch 195/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1377 - accuracy: 0.5975\n",
      "Epoch 196/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1317 - accuracy: 0.5999\n",
      "Epoch 197/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1350 - accuracy: 0.6000\n",
      "Epoch 198/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1322 - accuracy: 0.6006\n",
      "Epoch 199/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1394 - accuracy: 0.6001\n",
      "Epoch 200/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1329 - accuracy: 0.5998\n",
      "Epoch 201/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1337 - accuracy: 0.5988\n",
      "Epoch 202/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1371 - accuracy: 0.5947\n",
      "Epoch 203/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1350 - accuracy: 0.5992\n",
      "Epoch 204/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1331 - accuracy: 0.5997\n",
      "Epoch 205/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1327 - accuracy: 0.5957\n",
      "Epoch 206/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1343 - accuracy: 0.5985\n",
      "Epoch 207/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1296 - accuracy: 0.6003\n",
      "Epoch 208/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1316 - accuracy: 0.5994\n",
      "Epoch 209/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1321 - accuracy: 0.5987\n",
      "Epoch 210/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1300 - accuracy: 0.6033\n",
      "Epoch 211/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1315 - accuracy: 0.5987\n",
      "Epoch 212/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1309 - accuracy: 0.6019\n",
      "Epoch 213/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1282 - accuracy: 0.5985\n",
      "Epoch 214/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1338 - accuracy: 0.5984\n",
      "Epoch 215/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1301 - accuracy: 0.5996\n",
      "Epoch 216/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1279 - accuracy: 0.6014\n",
      "Epoch 217/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1299 - accuracy: 0.6010\n",
      "Epoch 218/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1281 - accuracy: 0.6018\n",
      "Epoch 219/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1347 - accuracy: 0.5988\n",
      "Epoch 220/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1288 - accuracy: 0.6020\n",
      "Epoch 221/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1274 - accuracy: 0.6011\n",
      "Epoch 222/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1294 - accuracy: 0.6012\n",
      "Epoch 223/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1311 - accuracy: 0.6001\n",
      "Epoch 224/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1335 - accuracy: 0.5958\n",
      "Epoch 225/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1274 - accuracy: 0.6000\n",
      "Epoch 226/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1288 - accuracy: 0.6021\n",
      "Epoch 227/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1268 - accuracy: 0.5988\n",
      "Epoch 228/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1295 - accuracy: 0.6006\n",
      "Epoch 229/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1261 - accuracy: 0.6017\n",
      "Epoch 230/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1292 - accuracy: 0.5984\n",
      "Epoch 231/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1243 - accuracy: 0.6050\n",
      "Epoch 232/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1298 - accuracy: 0.6012\n",
      "Epoch 233/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1262 - accuracy: 0.6023\n",
      "Epoch 234/400\n",
      "1111/1111 [==============================] - 6s 5ms/step - loss: 1.1290 - accuracy: 0.6008\n",
      "Epoch 235/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1302 - accuracy: 0.6005\n",
      "Epoch 236/400\n",
      "1111/1111 [==============================] - 5s 5ms/step - loss: 1.1287 - accuracy: 0.5999\n",
      "Epoch 237/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1264 - accuracy: 0.5997\n",
      "Epoch 238/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1256 - accuracy: 0.6004\n",
      "Epoch 239/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1279 - accuracy: 0.6010\n",
      "Epoch 240/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1287 - accuracy: 0.6016\n",
      "Epoch 241/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1299 - accuracy: 0.6002\n",
      "Epoch 242/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1302 - accuracy: 0.6000\n",
      "Epoch 243/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1278 - accuracy: 0.5970\n",
      "Epoch 244/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1276 - accuracy: 0.6042\n",
      "Epoch 245/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1229 - accuracy: 0.6015\n",
      "Epoch 246/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1287 - accuracy: 0.6028\n",
      "Epoch 247/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1248 - accuracy: 0.6033\n",
      "Epoch 248/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1294 - accuracy: 0.5980\n",
      "Epoch 249/400\n",
      "1111/1111 [==============================] - 5s 4ms/step - loss: 1.1283 - accuracy: 0.6013\n",
      "Epoch 250/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1260 - accuracy: 0.6002\n",
      "Epoch 251/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1279 - accuracy: 0.6006\n",
      "Epoch 252/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1243 - accuracy: 0.6020\n",
      "Epoch 253/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1289 - accuracy: 0.6012\n",
      "Epoch 254/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1307 - accuracy: 0.5995\n",
      "Epoch 255/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1295 - accuracy: 0.6009\n",
      "Epoch 256/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1260 - accuracy: 0.6020\n",
      "Epoch 257/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1228 - accuracy: 0.6042\n",
      "Epoch 258/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1281 - accuracy: 0.6000\n",
      "Epoch 259/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1286 - accuracy: 0.5997\n",
      "Epoch 260/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1246 - accuracy: 0.6027\n",
      "Epoch 261/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1266 - accuracy: 0.6002\n",
      "Epoch 262/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1232 - accuracy: 0.6036\n",
      "Epoch 263/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1232 - accuracy: 0.6014\n",
      "Epoch 264/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1260 - accuracy: 0.5998\n",
      "Epoch 265/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1212 - accuracy: 0.6046\n",
      "Epoch 266/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1274 - accuracy: 0.6023\n",
      "Epoch 267/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1261 - accuracy: 0.6025\n",
      "Epoch 268/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1226 - accuracy: 0.6046\n",
      "Epoch 269/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1197 - accuracy: 0.6024\n",
      "Epoch 270/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1220 - accuracy: 0.6013\n",
      "Epoch 271/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1244 - accuracy: 0.6033\n",
      "Epoch 272/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1237 - accuracy: 0.6004\n",
      "Epoch 273/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1211 - accuracy: 0.6039\n",
      "Epoch 274/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1287 - accuracy: 0.6036\n",
      "Epoch 275/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1213 - accuracy: 0.6040\n",
      "Epoch 276/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1220 - accuracy: 0.6015\n",
      "Epoch 277/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1236 - accuracy: 0.6023\n",
      "Epoch 278/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1197 - accuracy: 0.6073\n",
      "Epoch 279/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1219 - accuracy: 0.6001\n",
      "Epoch 280/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1225 - accuracy: 0.6005\n",
      "Epoch 281/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1230 - accuracy: 0.6075\n",
      "Epoch 282/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1245 - accuracy: 0.6031\n",
      "Epoch 283/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1212 - accuracy: 0.6061\n",
      "Epoch 284/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1228 - accuracy: 0.6029\n",
      "Epoch 285/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1206 - accuracy: 0.6079\n",
      "Epoch 286/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1230 - accuracy: 0.6041\n",
      "Epoch 287/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1250 - accuracy: 0.5994\n",
      "Epoch 288/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1231 - accuracy: 0.6018\n",
      "Epoch 289/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1203 - accuracy: 0.6071\n",
      "Epoch 290/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1233 - accuracy: 0.6023\n",
      "Epoch 291/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1210 - accuracy: 0.6041\n",
      "Epoch 292/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1221 - accuracy: 0.6045\n",
      "Epoch 293/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1239 - accuracy: 0.6013\n",
      "Epoch 294/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1177 - accuracy: 0.6045\n",
      "Epoch 295/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1228 - accuracy: 0.6013\n",
      "Epoch 296/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1202 - accuracy: 0.6041\n",
      "Epoch 297/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1207 - accuracy: 0.6060\n",
      "Epoch 298/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1191 - accuracy: 0.6051\n",
      "Epoch 299/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1225 - accuracy: 0.6041\n",
      "Epoch 300/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1266 - accuracy: 0.6006\n",
      "Epoch 301/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1198 - accuracy: 0.6039\n",
      "Epoch 302/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1196 - accuracy: 0.6018\n",
      "Epoch 303/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1212 - accuracy: 0.6030\n",
      "Epoch 304/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1171 - accuracy: 0.6051\n",
      "Epoch 305/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1209 - accuracy: 0.6036\n",
      "Epoch 306/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1212 - accuracy: 0.6024\n",
      "Epoch 307/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1189 - accuracy: 0.6061\n",
      "Epoch 308/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1182 - accuracy: 0.6079\n",
      "Epoch 309/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1190 - accuracy: 0.6049\n",
      "Epoch 310/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1214 - accuracy: 0.6006\n",
      "Epoch 311/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1221 - accuracy: 0.6015\n",
      "Epoch 312/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1223 - accuracy: 0.6044\n",
      "Epoch 313/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1197 - accuracy: 0.6055\n",
      "Epoch 314/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1181 - accuracy: 0.6038\n",
      "Epoch 315/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1208 - accuracy: 0.6025\n",
      "Epoch 316/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1144 - accuracy: 0.6060\n",
      "Epoch 317/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1215 - accuracy: 0.6024\n",
      "Epoch 318/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1191 - accuracy: 0.6068\n",
      "Epoch 319/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1167 - accuracy: 0.6053\n",
      "Epoch 320/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1168 - accuracy: 0.6068\n",
      "Epoch 321/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1154 - accuracy: 0.6072\n",
      "Epoch 322/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1199 - accuracy: 0.6024\n",
      "Epoch 323/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1185 - accuracy: 0.6033\n",
      "Epoch 324/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1168 - accuracy: 0.6037\n",
      "Epoch 325/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1169 - accuracy: 0.6084\n",
      "Epoch 326/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1140 - accuracy: 0.6079\n",
      "Epoch 327/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1175 - accuracy: 0.6054\n",
      "Epoch 328/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1161 - accuracy: 0.6079\n",
      "Epoch 329/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1141 - accuracy: 0.6048\n",
      "Epoch 330/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1176 - accuracy: 0.6071\n",
      "Epoch 331/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1210 - accuracy: 0.6059\n",
      "Epoch 332/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1158 - accuracy: 0.6051\n",
      "Epoch 333/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1162 - accuracy: 0.6023\n",
      "Epoch 334/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1181 - accuracy: 0.6042\n",
      "Epoch 335/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1166 - accuracy: 0.6052\n",
      "Epoch 336/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1177 - accuracy: 0.6050\n",
      "Epoch 337/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1209 - accuracy: 0.6038\n",
      "Epoch 338/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1152 - accuracy: 0.6033\n",
      "Epoch 339/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1166 - accuracy: 0.6044\n",
      "Epoch 340/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1138 - accuracy: 0.6066\n",
      "Epoch 341/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1194 - accuracy: 0.6066\n",
      "Epoch 342/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1169 - accuracy: 0.6054\n",
      "Epoch 343/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1154 - accuracy: 0.6065\n",
      "Epoch 344/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1200 - accuracy: 0.6056\n",
      "Epoch 345/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1144 - accuracy: 0.6059\n",
      "Epoch 346/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1144 - accuracy: 0.6073\n",
      "Epoch 347/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1127 - accuracy: 0.6055\n",
      "Epoch 348/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1163 - accuracy: 0.6054\n",
      "Epoch 349/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1175 - accuracy: 0.6085\n",
      "Epoch 350/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1155 - accuracy: 0.6041\n",
      "Epoch 351/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1132 - accuracy: 0.6057\n",
      "Epoch 352/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1154 - accuracy: 0.6096\n",
      "Epoch 353/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1139 - accuracy: 0.6062\n",
      "Epoch 354/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1136 - accuracy: 0.6059\n",
      "Epoch 355/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1115 - accuracy: 0.6055\n",
      "Epoch 356/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1160 - accuracy: 0.6046\n",
      "Epoch 357/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1152 - accuracy: 0.6052\n",
      "Epoch 358/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1158 - accuracy: 0.6023\n",
      "Epoch 359/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1159 - accuracy: 0.6045\n",
      "Epoch 360/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1133 - accuracy: 0.6096\n",
      "Epoch 361/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1134 - accuracy: 0.6080\n",
      "Epoch 362/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1141 - accuracy: 0.6062\n",
      "Epoch 363/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1121 - accuracy: 0.6072\n",
      "Epoch 364/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1123 - accuracy: 0.6060\n",
      "Epoch 365/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1118 - accuracy: 0.6059\n",
      "Epoch 366/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1133 - accuracy: 0.6058\n",
      "Epoch 367/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1122 - accuracy: 0.6041\n",
      "Epoch 368/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1154 - accuracy: 0.6075\n",
      "Epoch 369/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1139 - accuracy: 0.6079\n",
      "Epoch 370/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1147 - accuracy: 0.6075\n",
      "Epoch 371/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1150 - accuracy: 0.6092\n",
      "Epoch 372/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1129 - accuracy: 0.6090\n",
      "Epoch 373/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1131 - accuracy: 0.6051\n",
      "Epoch 374/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1138 - accuracy: 0.6062\n",
      "Epoch 375/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1146 - accuracy: 0.6048\n",
      "Epoch 376/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1140 - accuracy: 0.6067\n",
      "Epoch 377/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1175 - accuracy: 0.6063\n",
      "Epoch 378/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1132 - accuracy: 0.6082\n",
      "Epoch 379/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1133 - accuracy: 0.6056\n",
      "Epoch 380/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1084 - accuracy: 0.6083\n",
      "Epoch 381/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1130 - accuracy: 0.6093\n",
      "Epoch 382/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1106 - accuracy: 0.6097\n",
      "Epoch 383/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1126 - accuracy: 0.6069\n",
      "Epoch 384/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1104 - accuracy: 0.6057\n",
      "Epoch 385/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1088 - accuracy: 0.6103\n",
      "Epoch 386/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1104 - accuracy: 0.6062\n",
      "Epoch 387/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1116 - accuracy: 0.6076\n",
      "Epoch 388/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1115 - accuracy: 0.6057\n",
      "Epoch 389/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1074 - accuracy: 0.6099\n",
      "Epoch 390/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1111 - accuracy: 0.6097\n",
      "Epoch 391/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1108 - accuracy: 0.6083\n",
      "Epoch 392/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1108 - accuracy: 0.6096\n",
      "Epoch 393/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1106 - accuracy: 0.6064\n",
      "Epoch 394/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1083 - accuracy: 0.6117\n",
      "Epoch 395/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1123 - accuracy: 0.6066\n",
      "Epoch 396/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1108 - accuracy: 0.6071\n",
      "Epoch 397/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1131 - accuracy: 0.6052\n",
      "Epoch 398/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1078 - accuracy: 0.6108\n",
      "Epoch 399/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1101 - accuracy: 0.6078\n",
      "Epoch 400/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1133 - accuracy: 0.6099\n",
      "Epoch 1/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.6659 - accuracy: 0.3967\n",
      "Epoch 2/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5626 - accuracy: 0.3994\n",
      "Epoch 3/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5450 - accuracy: 0.4030\n",
      "Epoch 4/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5292 - accuracy: 0.4100\n",
      "Epoch 5/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.5085 - accuracy: 0.4158\n",
      "Epoch 6/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4891 - accuracy: 0.4306\n",
      "Epoch 7/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4615 - accuracy: 0.4533\n",
      "Epoch 8/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4324 - accuracy: 0.4780\n",
      "Epoch 9/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.4051 - accuracy: 0.4869\n",
      "Epoch 10/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3813 - accuracy: 0.5031\n",
      "Epoch 11/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3570 - accuracy: 0.5096\n",
      "Epoch 12/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3412 - accuracy: 0.5196\n",
      "Epoch 13/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3225 - accuracy: 0.5282\n",
      "Epoch 14/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3177 - accuracy: 0.5300\n",
      "Epoch 15/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.3022 - accuracy: 0.5345\n",
      "Epoch 16/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2901 - accuracy: 0.5378\n",
      "Epoch 17/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.2848 - accuracy: 0.5432\n",
      "Epoch 18/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2742 - accuracy: 0.5506\n",
      "Epoch 19/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2673 - accuracy: 0.5514\n",
      "Epoch 20/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2614 - accuracy: 0.5531\n",
      "Epoch 21/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2583 - accuracy: 0.5537\n",
      "Epoch 22/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2529 - accuracy: 0.5565\n",
      "Epoch 23/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2505 - accuracy: 0.5565\n",
      "Epoch 24/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2464 - accuracy: 0.5583\n",
      "Epoch 25/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2435 - accuracy: 0.5590\n",
      "Epoch 26/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2430 - accuracy: 0.5601\n",
      "Epoch 27/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2349 - accuracy: 0.5652\n",
      "Epoch 28/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2324 - accuracy: 0.5680\n",
      "Epoch 29/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2269 - accuracy: 0.5703\n",
      "Epoch 30/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2253 - accuracy: 0.5700\n",
      "Epoch 31/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2244 - accuracy: 0.5695\n",
      "Epoch 32/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2260 - accuracy: 0.5714\n",
      "Epoch 33/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2214 - accuracy: 0.5704\n",
      "Epoch 34/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2192 - accuracy: 0.5732\n",
      "Epoch 35/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2210 - accuracy: 0.5696\n",
      "Epoch 36/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2200 - accuracy: 0.5711\n",
      "Epoch 37/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2130 - accuracy: 0.5742\n",
      "Epoch 38/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2108 - accuracy: 0.5782\n",
      "Epoch 39/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2114 - accuracy: 0.5755\n",
      "Epoch 40/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2094 - accuracy: 0.5767\n",
      "Epoch 41/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2077 - accuracy: 0.5763\n",
      "Epoch 42/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2091 - accuracy: 0.5717\n",
      "Epoch 43/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2072 - accuracy: 0.5743\n",
      "Epoch 44/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2134 - accuracy: 0.5729\n",
      "Epoch 45/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2041 - accuracy: 0.5761\n",
      "Epoch 46/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2040 - accuracy: 0.5781\n",
      "Epoch 47/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.2023 - accuracy: 0.5796\n",
      "Epoch 48/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1994 - accuracy: 0.5762\n",
      "Epoch 49/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1965 - accuracy: 0.5778\n",
      "Epoch 50/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1974 - accuracy: 0.5786\n",
      "Epoch 51/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1945 - accuracy: 0.5823\n",
      "Epoch 52/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1990 - accuracy: 0.5794\n",
      "Epoch 53/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1974 - accuracy: 0.5772\n",
      "Epoch 54/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1927 - accuracy: 0.5790\n",
      "Epoch 55/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1915 - accuracy: 0.5814\n",
      "Epoch 56/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1914 - accuracy: 0.5811\n",
      "Epoch 57/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1935 - accuracy: 0.5809\n",
      "Epoch 58/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1927 - accuracy: 0.5781\n",
      "Epoch 59/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1872 - accuracy: 0.5832\n",
      "Epoch 60/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1843 - accuracy: 0.5847\n",
      "Epoch 61/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1906 - accuracy: 0.5818\n",
      "Epoch 62/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1862 - accuracy: 0.5808\n",
      "Epoch 63/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1853 - accuracy: 0.5829\n",
      "Epoch 64/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1826 - accuracy: 0.5848\n",
      "Epoch 65/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1819 - accuracy: 0.5853\n",
      "Epoch 66/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1789 - accuracy: 0.5837\n",
      "Epoch 67/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1790 - accuracy: 0.5866\n",
      "Epoch 68/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1831 - accuracy: 0.5813\n",
      "Epoch 69/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1807 - accuracy: 0.5831\n",
      "Epoch 70/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1852 - accuracy: 0.5782\n",
      "Epoch 71/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1742 - accuracy: 0.5878\n",
      "Epoch 72/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1826 - accuracy: 0.5771\n",
      "Epoch 73/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1773 - accuracy: 0.5844\n",
      "Epoch 74/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1749 - accuracy: 0.5866\n",
      "Epoch 75/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1796 - accuracy: 0.5827\n",
      "Epoch 76/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1761 - accuracy: 0.5845\n",
      "Epoch 77/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1763 - accuracy: 0.5862\n",
      "Epoch 78/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1792 - accuracy: 0.5873\n",
      "Epoch 79/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1752 - accuracy: 0.5843\n",
      "Epoch 80/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1752 - accuracy: 0.5820\n",
      "Epoch 81/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1720 - accuracy: 0.5857\n",
      "Epoch 82/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1718 - accuracy: 0.5844\n",
      "Epoch 83/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1663 - accuracy: 0.5907\n",
      "Epoch 84/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1713 - accuracy: 0.5844\n",
      "Epoch 85/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1759 - accuracy: 0.5843\n",
      "Epoch 86/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1698 - accuracy: 0.5894\n",
      "Epoch 87/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1707 - accuracy: 0.5825\n",
      "Epoch 88/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1672 - accuracy: 0.5867\n",
      "Epoch 89/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1677 - accuracy: 0.5887\n",
      "Epoch 90/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1662 - accuracy: 0.5896\n",
      "Epoch 91/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1684 - accuracy: 0.5872\n",
      "Epoch 92/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1647 - accuracy: 0.5928\n",
      "Epoch 93/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1628 - accuracy: 0.5889\n",
      "Epoch 94/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1639 - accuracy: 0.5884\n",
      "Epoch 95/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1646 - accuracy: 0.5896\n",
      "Epoch 96/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1606 - accuracy: 0.5935\n",
      "Epoch 97/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1599 - accuracy: 0.5912\n",
      "Epoch 98/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1612 - accuracy: 0.5936\n",
      "Epoch 99/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1662 - accuracy: 0.5857\n",
      "Epoch 100/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1591 - accuracy: 0.5910\n",
      "Epoch 101/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1608 - accuracy: 0.5882\n",
      "Epoch 102/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1598 - accuracy: 0.5863\n",
      "Epoch 103/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1586 - accuracy: 0.5920\n",
      "Epoch 104/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1613 - accuracy: 0.5925\n",
      "Epoch 105/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1593 - accuracy: 0.5914\n",
      "Epoch 106/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1563 - accuracy: 0.5903\n",
      "Epoch 107/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1634 - accuracy: 0.5845\n",
      "Epoch 108/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1619 - accuracy: 0.5923\n",
      "Epoch 109/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1576 - accuracy: 0.5904\n",
      "Epoch 110/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1578 - accuracy: 0.5931\n",
      "Epoch 111/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1572 - accuracy: 0.5908\n",
      "Epoch 112/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1513 - accuracy: 0.5924\n",
      "Epoch 113/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1556 - accuracy: 0.5910\n",
      "Epoch 114/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1512 - accuracy: 0.5895\n",
      "Epoch 115/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1550 - accuracy: 0.5897\n",
      "Epoch 116/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1506 - accuracy: 0.5942\n",
      "Epoch 117/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1498 - accuracy: 0.5925\n",
      "Epoch 118/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1499 - accuracy: 0.5935\n",
      "Epoch 119/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1585 - accuracy: 0.5882\n",
      "Epoch 120/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1503 - accuracy: 0.5916\n",
      "Epoch 121/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1498 - accuracy: 0.5933\n",
      "Epoch 122/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1549 - accuracy: 0.5925\n",
      "Epoch 123/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1511 - accuracy: 0.5949\n",
      "Epoch 124/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1488 - accuracy: 0.5935\n",
      "Epoch 125/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1534 - accuracy: 0.5912\n",
      "Epoch 126/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1514 - accuracy: 0.5897\n",
      "Epoch 127/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1516 - accuracy: 0.5942\n",
      "Epoch 128/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1498 - accuracy: 0.5940\n",
      "Epoch 129/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1512 - accuracy: 0.5967\n",
      "Epoch 130/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1473 - accuracy: 0.5947\n",
      "Epoch 131/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1533 - accuracy: 0.5906\n",
      "Epoch 132/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1487 - accuracy: 0.5916\n",
      "Epoch 133/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1461 - accuracy: 0.5925\n",
      "Epoch 134/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1525 - accuracy: 0.5911\n",
      "Epoch 135/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1510 - accuracy: 0.5917\n",
      "Epoch 136/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1447 - accuracy: 0.5971\n",
      "Epoch 137/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1453 - accuracy: 0.5934\n",
      "Epoch 138/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1461 - accuracy: 0.5909\n",
      "Epoch 139/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1429 - accuracy: 0.5947\n",
      "Epoch 140/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1431 - accuracy: 0.5928\n",
      "Epoch 141/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1451 - accuracy: 0.5927\n",
      "Epoch 142/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1458 - accuracy: 0.5917\n",
      "Epoch 143/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1440 - accuracy: 0.5934\n",
      "Epoch 144/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1394 - accuracy: 0.5978\n",
      "Epoch 145/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1464 - accuracy: 0.5959\n",
      "Epoch 146/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1375 - accuracy: 0.5973\n",
      "Epoch 147/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1415 - accuracy: 0.5903\n",
      "Epoch 148/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1404 - accuracy: 0.5981\n",
      "Epoch 149/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1440 - accuracy: 0.5959\n",
      "Epoch 150/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1413 - accuracy: 0.5963\n",
      "Epoch 151/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1396 - accuracy: 0.5958\n",
      "Epoch 152/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1426 - accuracy: 0.5974\n",
      "Epoch 153/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1418 - accuracy: 0.5955\n",
      "Epoch 154/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1379 - accuracy: 0.6010\n",
      "Epoch 155/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1405 - accuracy: 0.5971\n",
      "Epoch 156/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1366 - accuracy: 0.5968\n",
      "Epoch 157/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1468 - accuracy: 0.5936\n",
      "Epoch 158/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1345 - accuracy: 0.5988\n",
      "Epoch 159/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1371 - accuracy: 0.5974\n",
      "Epoch 160/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1397 - accuracy: 0.5958\n",
      "Epoch 161/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1413 - accuracy: 0.5915\n",
      "Epoch 162/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1423 - accuracy: 0.5970\n",
      "Epoch 163/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1424 - accuracy: 0.5962\n",
      "Epoch 164/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1390 - accuracy: 0.5934\n",
      "Epoch 165/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1334 - accuracy: 0.5980\n",
      "Epoch 166/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1372 - accuracy: 0.5957\n",
      "Epoch 167/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1386 - accuracy: 0.5963\n",
      "Epoch 168/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1366 - accuracy: 0.5967\n",
      "Epoch 169/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1402 - accuracy: 0.5975\n",
      "Epoch 170/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1338 - accuracy: 0.5972\n",
      "Epoch 171/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1387 - accuracy: 0.5944\n",
      "Epoch 172/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1358 - accuracy: 0.5988\n",
      "Epoch 173/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1362 - accuracy: 0.6004\n",
      "Epoch 174/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1339 - accuracy: 0.5973\n",
      "Epoch 175/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1353 - accuracy: 0.5999\n",
      "Epoch 176/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1344 - accuracy: 0.5957\n",
      "Epoch 177/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1422 - accuracy: 0.5933\n",
      "Epoch 178/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1332 - accuracy: 0.5980\n",
      "Epoch 179/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1367 - accuracy: 0.5992\n",
      "Epoch 180/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1344 - accuracy: 0.5990\n",
      "Epoch 181/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1313 - accuracy: 0.6010\n",
      "Epoch 182/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1337 - accuracy: 0.6000\n",
      "Epoch 183/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1362 - accuracy: 0.5961\n",
      "Epoch 184/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1349 - accuracy: 0.5992\n",
      "Epoch 185/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1353 - accuracy: 0.5962\n",
      "Epoch 186/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1362 - accuracy: 0.5965\n",
      "Epoch 187/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1300 - accuracy: 0.6007\n",
      "Epoch 188/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1300 - accuracy: 0.6006\n",
      "Epoch 189/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1283 - accuracy: 0.6026\n",
      "Epoch 190/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1373 - accuracy: 0.5961\n",
      "Epoch 191/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1347 - accuracy: 0.5977\n",
      "Epoch 192/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1356 - accuracy: 0.5963\n",
      "Epoch 193/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1342 - accuracy: 0.6003\n",
      "Epoch 194/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1280 - accuracy: 0.6043\n",
      "Epoch 195/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1319 - accuracy: 0.5980\n",
      "Epoch 196/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1267 - accuracy: 0.6014\n",
      "Epoch 197/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1325 - accuracy: 0.5985\n",
      "Epoch 198/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1308 - accuracy: 0.6043\n",
      "Epoch 199/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1291 - accuracy: 0.6016\n",
      "Epoch 200/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1293 - accuracy: 0.5993\n",
      "Epoch 201/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1305 - accuracy: 0.6002\n",
      "Epoch 202/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1351 - accuracy: 0.5970\n",
      "Epoch 203/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1366 - accuracy: 0.6015\n",
      "Epoch 204/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1312 - accuracy: 0.5989\n",
      "Epoch 205/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1270 - accuracy: 0.6000\n",
      "Epoch 206/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1262 - accuracy: 0.6017\n",
      "Epoch 207/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1255 - accuracy: 0.5997\n",
      "Epoch 208/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1254 - accuracy: 0.5997\n",
      "Epoch 209/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1236 - accuracy: 0.6041\n",
      "Epoch 210/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1285 - accuracy: 0.6014\n",
      "Epoch 211/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1236 - accuracy: 0.6000\n",
      "Epoch 212/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1249 - accuracy: 0.6005\n",
      "Epoch 213/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1250 - accuracy: 0.6006\n",
      "Epoch 214/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1246 - accuracy: 0.6012\n",
      "Epoch 215/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1301 - accuracy: 0.6012\n",
      "Epoch 216/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1324 - accuracy: 0.5994\n",
      "Epoch 217/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1303 - accuracy: 0.5959\n",
      "Epoch 218/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1256 - accuracy: 0.5998\n",
      "Epoch 219/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1285 - accuracy: 0.5997\n",
      "Epoch 220/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1259 - accuracy: 0.6015\n",
      "Epoch 221/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1257 - accuracy: 0.5998\n",
      "Epoch 222/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1272 - accuracy: 0.5991\n",
      "Epoch 223/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1291 - accuracy: 0.5985\n",
      "Epoch 224/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1241 - accuracy: 0.6008\n",
      "Epoch 225/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1237 - accuracy: 0.6013\n",
      "Epoch 226/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1288 - accuracy: 0.6024\n",
      "Epoch 227/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1275 - accuracy: 0.6013\n",
      "Epoch 228/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1296 - accuracy: 0.5964\n",
      "Epoch 229/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1260 - accuracy: 0.6015\n",
      "Epoch 230/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1215 - accuracy: 0.6063\n",
      "Epoch 231/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1247 - accuracy: 0.6015\n",
      "Epoch 232/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1246 - accuracy: 0.6041\n",
      "Epoch 233/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1235 - accuracy: 0.6018\n",
      "Epoch 234/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1226 - accuracy: 0.6028\n",
      "Epoch 235/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1244 - accuracy: 0.6007\n",
      "Epoch 236/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1185 - accuracy: 0.6041\n",
      "Epoch 237/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1231 - accuracy: 0.6015\n",
      "Epoch 238/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1261 - accuracy: 0.6036\n",
      "Epoch 239/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1217 - accuracy: 0.6000\n",
      "Epoch 240/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1245 - accuracy: 0.5995\n",
      "Epoch 241/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1215 - accuracy: 0.5990\n",
      "Epoch 242/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1204 - accuracy: 0.6023\n",
      "Epoch 243/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1210 - accuracy: 0.6008\n",
      "Epoch 244/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1217 - accuracy: 0.6023\n",
      "Epoch 245/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1246 - accuracy: 0.6046\n",
      "Epoch 246/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1233 - accuracy: 0.6017\n",
      "Epoch 247/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1235 - accuracy: 0.6015\n",
      "Epoch 248/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1199 - accuracy: 0.6051\n",
      "Epoch 249/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1218 - accuracy: 0.6024\n",
      "Epoch 250/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1275 - accuracy: 0.6022\n",
      "Epoch 251/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1196 - accuracy: 0.6008\n",
      "Epoch 252/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1184 - accuracy: 0.6021\n",
      "Epoch 253/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1231 - accuracy: 0.6035\n",
      "Epoch 254/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1228 - accuracy: 0.6021\n",
      "Epoch 255/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1175 - accuracy: 0.6020\n",
      "Epoch 256/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1173 - accuracy: 0.6060\n",
      "Epoch 257/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1219 - accuracy: 0.6022\n",
      "Epoch 258/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1195 - accuracy: 0.6020\n",
      "Epoch 259/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1180 - accuracy: 0.6028\n",
      "Epoch 260/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1225 - accuracy: 0.6023\n",
      "Epoch 261/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1179 - accuracy: 0.6039\n",
      "Epoch 262/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1203 - accuracy: 0.6050\n",
      "Epoch 263/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1167 - accuracy: 0.6031\n",
      "Epoch 264/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1188 - accuracy: 0.6044\n",
      "Epoch 265/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1223 - accuracy: 0.6043\n",
      "Epoch 266/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1197 - accuracy: 0.6011\n",
      "Epoch 267/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1167 - accuracy: 0.6055\n",
      "Epoch 268/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1207 - accuracy: 0.5996\n",
      "Epoch 269/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1173 - accuracy: 0.6079\n",
      "Epoch 270/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1153 - accuracy: 0.6013\n",
      "Epoch 271/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1167 - accuracy: 0.6061\n",
      "Epoch 272/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1217 - accuracy: 0.6043\n",
      "Epoch 273/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1196 - accuracy: 0.6036\n",
      "Epoch 274/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1172 - accuracy: 0.6036\n",
      "Epoch 275/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1211 - accuracy: 0.6005\n",
      "Epoch 276/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1205 - accuracy: 0.6006\n",
      "Epoch 277/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1181 - accuracy: 0.6056\n",
      "Epoch 278/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1217 - accuracy: 0.6056\n",
      "Epoch 279/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1144 - accuracy: 0.6046\n",
      "Epoch 280/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1117 - accuracy: 0.6061\n",
      "Epoch 281/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1152 - accuracy: 0.6026\n",
      "Epoch 282/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1195 - accuracy: 0.6033\n",
      "Epoch 283/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1150 - accuracy: 0.6097\n",
      "Epoch 284/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1206 - accuracy: 0.6033\n",
      "Epoch 285/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1153 - accuracy: 0.6048\n",
      "Epoch 286/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1186 - accuracy: 0.6022\n",
      "Epoch 287/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1132 - accuracy: 0.6038\n",
      "Epoch 288/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1160 - accuracy: 0.6051\n",
      "Epoch 289/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1190 - accuracy: 0.6021\n",
      "Epoch 290/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1171 - accuracy: 0.6028\n",
      "Epoch 291/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1160 - accuracy: 0.6038\n",
      "Epoch 292/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1165 - accuracy: 0.6012\n",
      "Epoch 293/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1151 - accuracy: 0.6069\n",
      "Epoch 294/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1145 - accuracy: 0.6050\n",
      "Epoch 295/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1150 - accuracy: 0.6062\n",
      "Epoch 296/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1152 - accuracy: 0.6025\n",
      "Epoch 297/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1153 - accuracy: 0.6038\n",
      "Epoch 298/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1169 - accuracy: 0.6056\n",
      "Epoch 299/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1169 - accuracy: 0.6057\n",
      "Epoch 300/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1165 - accuracy: 0.6046\n",
      "Epoch 301/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1158 - accuracy: 0.6025\n",
      "Epoch 302/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1184 - accuracy: 0.6030\n",
      "Epoch 303/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1126 - accuracy: 0.6069\n",
      "Epoch 304/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1169 - accuracy: 0.6088\n",
      "Epoch 305/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1260 - accuracy: 0.6012\n",
      "Epoch 306/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1157 - accuracy: 0.6035\n",
      "Epoch 307/400\n",
      "1111/1111 [==============================] - 3s 2ms/step - loss: 1.1157 - accuracy: 0.6049\n",
      "Epoch 308/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1146 - accuracy: 0.6052\n",
      "Epoch 309/400\n",
      "1111/1111 [==============================] - 162s 146ms/step - loss: 1.1156 - accuracy: 0.6060\n",
      "Epoch 310/400\n",
      "1111/1111 [==============================] - 4s 4ms/step - loss: 1.1187 - accuracy: 0.6042\n",
      "Epoch 311/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1176 - accuracy: 0.6029\n",
      "Epoch 312/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1108 - accuracy: 0.6070\n",
      "Epoch 313/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1161 - accuracy: 0.6067\n",
      "Epoch 314/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1113 - accuracy: 0.6060\n",
      "Epoch 315/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1119 - accuracy: 0.6058\n",
      "Epoch 316/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1120 - accuracy: 0.6069\n",
      "Epoch 317/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1125 - accuracy: 0.6071\n",
      "Epoch 318/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1168 - accuracy: 0.6026\n",
      "Epoch 319/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1104 - accuracy: 0.6057\n",
      "Epoch 320/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1159 - accuracy: 0.6063\n",
      "Epoch 321/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1140 - accuracy: 0.6070\n",
      "Epoch 322/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1107 - accuracy: 0.6082\n",
      "Epoch 323/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1178 - accuracy: 0.6088\n",
      "Epoch 324/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1147 - accuracy: 0.6059\n",
      "Epoch 325/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1095 - accuracy: 0.6074\n",
      "Epoch 326/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1095 - accuracy: 0.6087\n",
      "Epoch 327/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1138 - accuracy: 0.6032\n",
      "Epoch 328/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1131 - accuracy: 0.6084\n",
      "Epoch 329/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1100 - accuracy: 0.6060\n",
      "Epoch 330/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1134 - accuracy: 0.6065\n",
      "Epoch 331/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1156 - accuracy: 0.6048\n",
      "Epoch 332/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1158 - accuracy: 0.6090\n",
      "Epoch 333/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1128 - accuracy: 0.6055\n",
      "Epoch 334/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1139 - accuracy: 0.6032\n",
      "Epoch 335/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1139 - accuracy: 0.6054\n",
      "Epoch 336/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1134 - accuracy: 0.6048\n",
      "Epoch 337/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1123 - accuracy: 0.6084\n",
      "Epoch 338/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1123 - accuracy: 0.6070\n",
      "Epoch 339/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1102 - accuracy: 0.6050\n",
      "Epoch 340/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1062 - accuracy: 0.6077\n",
      "Epoch 341/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1138 - accuracy: 0.6074\n",
      "Epoch 342/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1100 - accuracy: 0.6088\n",
      "Epoch 343/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1090 - accuracy: 0.6092\n",
      "Epoch 344/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1086 - accuracy: 0.6062\n",
      "Epoch 345/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1075 - accuracy: 0.6081\n",
      "Epoch 346/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1138 - accuracy: 0.6074\n",
      "Epoch 347/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1112 - accuracy: 0.6082\n",
      "Epoch 348/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1064 - accuracy: 0.6090\n",
      "Epoch 349/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1133 - accuracy: 0.6078\n",
      "Epoch 350/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1087 - accuracy: 0.6091\n",
      "Epoch 351/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1077 - accuracy: 0.6062\n",
      "Epoch 352/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1106 - accuracy: 0.6085\n",
      "Epoch 353/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1085 - accuracy: 0.6121\n",
      "Epoch 354/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1090 - accuracy: 0.6067\n",
      "Epoch 355/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1130 - accuracy: 0.6087\n",
      "Epoch 356/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1075 - accuracy: 0.6087\n",
      "Epoch 357/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1098 - accuracy: 0.6072\n",
      "Epoch 358/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1071 - accuracy: 0.6083\n",
      "Epoch 359/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1107 - accuracy: 0.6062\n",
      "Epoch 360/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1057 - accuracy: 0.6087\n",
      "Epoch 361/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1123 - accuracy: 0.6035\n",
      "Epoch 362/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1098 - accuracy: 0.6071\n",
      "Epoch 363/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1067 - accuracy: 0.6077\n",
      "Epoch 364/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1100 - accuracy: 0.6067\n",
      "Epoch 365/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1062 - accuracy: 0.6079\n",
      "Epoch 366/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1115 - accuracy: 0.6074\n",
      "Epoch 367/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1103 - accuracy: 0.6066\n",
      "Epoch 368/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1116 - accuracy: 0.6086\n",
      "Epoch 369/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1117 - accuracy: 0.6068\n",
      "Epoch 370/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1109 - accuracy: 0.6081\n",
      "Epoch 371/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1104 - accuracy: 0.6095\n",
      "Epoch 372/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1051 - accuracy: 0.6093\n",
      "Epoch 373/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1088 - accuracy: 0.6070\n",
      "Epoch 374/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1038 - accuracy: 0.6090\n",
      "Epoch 375/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1044 - accuracy: 0.6102\n",
      "Epoch 376/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1124 - accuracy: 0.6040\n",
      "Epoch 377/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1115 - accuracy: 0.6040\n",
      "Epoch 378/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1116 - accuracy: 0.6054\n",
      "Epoch 379/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1124 - accuracy: 0.6046\n",
      "Epoch 380/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1096 - accuracy: 0.6084\n",
      "Epoch 381/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1120 - accuracy: 0.6095\n",
      "Epoch 382/400\n",
      "1111/1111 [==============================] - 4s 3ms/step - loss: 1.1085 - accuracy: 0.6059\n",
      "Epoch 383/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1048 - accuracy: 0.6081\n",
      "Epoch 384/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1061 - accuracy: 0.6116\n",
      "Epoch 385/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1080 - accuracy: 0.6068\n",
      "Epoch 386/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1108 - accuracy: 0.6069\n",
      "Epoch 387/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1108 - accuracy: 0.6067\n",
      "Epoch 388/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1081 - accuracy: 0.6076\n",
      "Epoch 389/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1060 - accuracy: 0.6071\n",
      "Epoch 390/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1094 - accuracy: 0.6113\n",
      "Epoch 391/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1088 - accuracy: 0.6088\n",
      "Epoch 392/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1090 - accuracy: 0.6088\n",
      "Epoch 393/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1020 - accuracy: 0.6090\n",
      "Epoch 394/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1100 - accuracy: 0.6071\n",
      "Epoch 395/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1109 - accuracy: 0.6088\n",
      "Epoch 396/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1058 - accuracy: 0.6097\n",
      "Epoch 397/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1060 - accuracy: 0.6099\n",
      "Epoch 398/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1059 - accuracy: 0.6075\n",
      "Epoch 399/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1060 - accuracy: 0.6120\n",
      "Epoch 400/400\n",
      "1111/1111 [==============================] - 3s 3ms/step - loss: 1.1062 - accuracy: 0.6066\n",
      "171/171 [==============================] - 0s 1ms/step\n",
      "171/171 [==============================] - 0s 981us/step\n",
      "171/171 [==============================] - 0s 965us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5975877192982456"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(X_train, y_train)\n",
    "\n",
    "ens.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e656c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 1ms/step\n",
      "171/171 [==============================] - 0s 970us/step\n",
      "171/171 [==============================] - 0s 939us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 5, 6, 7], dtype=int64),\n",
       " array([2450, 1638,   12,    4,   61, 1307], dtype=int64))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ens.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c277315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 2ms/step\n",
      "171/171 [==============================] - 0s 891us/step\n",
      "171/171 [==============================] - 0s 932us/step\n",
      "[0 1 1 ... 0 1 7]\n",
      "[0 0 0 ... 0 3 7]\n"
     ]
    }
   ],
   "source": [
    "print(ens.predict(X_test))\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
