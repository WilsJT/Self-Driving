{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c5cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV, learning_curve, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16ea9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>45</th>\n",
       "      <th>60</th>\n",
       "      <th>90</th>\n",
       "      <th>120</th>\n",
       "      <th>135</th>\n",
       "      <th>150</th>\n",
       "      <th>speed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.442252</td>\n",
       "      <td>-0.169266</td>\n",
       "      <td>-0.728503</td>\n",
       "      <td>-1.127933</td>\n",
       "      <td>-0.801854</td>\n",
       "      <td>-0.169266</td>\n",
       "      <td>1.554570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.497866</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.730413</td>\n",
       "      <td>-1.140428</td>\n",
       "      <td>-0.805707</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>1.491395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.480616</td>\n",
       "      <td>-0.167738</td>\n",
       "      <td>-0.747360</td>\n",
       "      <td>-1.173858</td>\n",
       "      <td>-0.747360</td>\n",
       "      <td>-0.148480</td>\n",
       "      <td>1.504180</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29050</th>\n",
       "      <td>1.395053</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>-0.808261</td>\n",
       "      <td>-1.203214</td>\n",
       "      <td>-0.808261</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>1.515073</td>\n",
       "      <td>358</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29051</th>\n",
       "      <td>1.463368</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>-0.801349</td>\n",
       "      <td>-1.193423</td>\n",
       "      <td>-0.801349</td>\n",
       "      <td>-0.065307</td>\n",
       "      <td>1.463368</td>\n",
       "      <td>367</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29052</th>\n",
       "      <td>1.286868</td>\n",
       "      <td>-0.089803</td>\n",
       "      <td>-0.800793</td>\n",
       "      <td>-1.205045</td>\n",
       "      <td>-0.800793</td>\n",
       "      <td>-0.003265</td>\n",
       "      <td>1.612830</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29053</th>\n",
       "      <td>1.367514</td>\n",
       "      <td>-0.096175</td>\n",
       "      <td>-0.805693</td>\n",
       "      <td>-1.215923</td>\n",
       "      <td>-0.757765</td>\n",
       "      <td>-0.046524</td>\n",
       "      <td>1.554566</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29054</th>\n",
       "      <td>2.206032</td>\n",
       "      <td>0.312789</td>\n",
       "      <td>-0.536776</td>\n",
       "      <td>-1.045008</td>\n",
       "      <td>-0.536776</td>\n",
       "      <td>0.178806</td>\n",
       "      <td>-0.579067</td>\n",
       "      <td>295</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29055 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             30        45        60        90       120       135       150  \\\n",
       "0      1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357  1.491395   \n",
       "1      1.442252 -0.169266 -0.728503 -1.127933 -0.801854 -0.169266  1.554570   \n",
       "2      1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357  1.491395   \n",
       "3      1.497866 -0.156357 -0.730413 -1.140428 -0.805707 -0.156357  1.491395   \n",
       "4      1.480616 -0.167738 -0.747360 -1.173858 -0.747360 -0.148480  1.504180   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29050  1.395053 -0.045195 -0.808261 -1.203214 -0.808261 -0.045195  1.515073   \n",
       "29051  1.463368 -0.065307 -0.801349 -1.193423 -0.801349 -0.065307  1.463368   \n",
       "29052  1.286868 -0.089803 -0.800793 -1.205045 -0.800793 -0.003265  1.612830   \n",
       "29053  1.367514 -0.096175 -0.805693 -1.215923 -0.757765 -0.046524  1.554566   \n",
       "29054  2.206032  0.312789 -0.536776 -1.045008 -0.536776  0.178806 -0.579067   \n",
       "\n",
       "       speed  label  \n",
       "0          0      0  \n",
       "1          0      0  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4         23      0  \n",
       "...      ...    ...  \n",
       "29050    358      2  \n",
       "29051    367      2  \n",
       "29052    323      2  \n",
       "29053    323      2  \n",
       "29054    295      2  \n",
       "\n",
       "[29055 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./self-driving-data.csv\")\n",
    "df.drop([\"Unnamed: 0\"], inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b0eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df[\"label\"])\n",
    "data = np.array(df[[\"30\", \"45\", \"60\", \"90\", \"120\", \"135\", \"150\", \"speed\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f38d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1c6dc",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ecfec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3778287621232662"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "KNN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506f9b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(KNN, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0be2acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.01233697, 0.01129897, 0.01200128, 0.01066883, 0.01199698,\n",
      "       0.01201256, 0.012012  , 0.01199985, 0.01066645, 0.00799982,\n",
      "       0.01066629, 0.01199992, 0.01199985, 0.01199873, 0.01200088,\n",
      "       0.01066629, 0.01165644, 0.01066637, 0.00936468, 0.01066486,\n",
      "       0.01117229, 0.0086573 , 0.00933417, 0.01600115, 0.00968687,\n",
      "       0.01000182, 0.01199992, 0.00933385, 0.01199913, 0.01066669,\n",
      "       0.01066669, 0.00896835, 0.00931446, 0.00841085, 0.00999053,\n",
      "       0.01000349, 0.00863957, 0.00866103, 0.0093267 , 0.01045696,\n",
      "       0.01066661, 0.00853705, 0.00800069, 0.00932471, 0.00997615,\n",
      "       0.0093147 , 0.00898147, 0.00965492, 0.00831509, 0.01000166,\n",
      "       0.00934045, 0.01097242, 0.0090669 , 0.01098212, 0.01556683,\n",
      "       0.0209473 , 0.01732071, 0.01631594, 0.01665076, 0.01774311,\n",
      "       0.01600051, 0.01663923, 0.01605447, 0.01866539, 0.01600003,\n",
      "       0.01601275, 0.0169603 , 0.01868065, 0.01600011, 0.01600035,\n",
      "       0.01599979, 0.01865625, 0.01530782, 0.01558963, 0.01598756,\n",
      "       0.01599979, 0.01334453, 0.01587343, 0.01526817, 0.01599995,\n",
      "       0.01599916, 0.01466664, 0.01303625, 0.01597786, 0.01432006,\n",
      "       0.01542807, 0.01333181, 0.01334397, 0.01466544, 0.01464033,\n",
      "       0.01238736, 0.01363079, 0.01363516, 0.01200207, 0.01363683,\n",
      "       0.01300844, 0.01200136, 0.01468587, 0.01231893, 0.01286507,\n",
      "       0.01533111, 0.01200064, 0.01200008, 0.01201232, 0.0147748 ,\n",
      "       0.01234849, 0.01200143, 0.01333348]), 'std_fit_time': array([4.76259876e-04, 1.62318189e-03, 2.36823788e-06, 1.88503210e-03,\n",
      "       2.55304629e-06, 1.78270928e-05, 1.61949231e-05, 0.00000000e+00,\n",
      "       1.88570620e-03, 1.12391596e-07, 1.88559397e-03, 1.12391596e-07,\n",
      "       1.94667955e-07, 1.58547857e-06, 1.29616312e-06, 1.88559381e-03,\n",
      "       3.30199733e-03, 1.88565000e-03, 9.71390701e-04, 1.88492116e-03,\n",
      "       2.32856652e-03, 9.29030972e-04, 1.88626820e-03, 5.65886067e-03,\n",
      "       1.69114917e-03, 1.61938010e-03, 9.19964862e-07, 1.88784168e-03,\n",
      "       1.87730977e-06, 1.88570620e-03, 1.88553761e-03, 1.39530979e-03,\n",
      "       9.29029932e-04, 5.98920769e-04, 1.61968895e-03, 1.61841560e-03,\n",
      "       4.54096084e-04, 4.70064989e-04, 1.23156258e-03, 1.45913959e-03,\n",
      "       1.88514424e-03, 1.39020906e-03, 3.21251280e-06, 1.24885776e-03,\n",
      "       1.43122633e-03, 1.89734684e-03, 8.06130154e-04, 1.69614591e-03,\n",
      "       4.70567614e-04, 1.61850060e-03, 1.29195480e-03, 8.27276656e-04,\n",
      "       8.12521104e-04, 8.27464080e-04, 6.13658238e-04, 1.47244918e-03,\n",
      "       1.89492161e-03, 4.47768796e-04, 8.94406728e-04, 1.67184670e-03,\n",
      "       6.74349576e-07, 9.04134199e-04, 7.80000106e-05, 1.88469493e-03,\n",
      "       1.94667955e-07, 1.56660339e-05, 1.49036511e-05, 1.86682450e-03,\n",
      "       1.12391596e-07, 2.24783192e-07, 1.94667955e-07, 1.87844206e-03,\n",
      "       4.89971946e-04, 5.44531344e-04, 1.79826554e-05, 1.94667955e-07,\n",
      "       1.87744154e-03, 7.00105755e-04, 5.24901134e-04, 2.97360213e-07,\n",
      "       5.94720425e-07, 1.88553761e-03, 1.54766917e-03, 3.11888198e-05,\n",
      "       1.69438022e-03, 4.21550253e-04, 1.88553781e-03, 1.87819011e-03,\n",
      "       1.88789784e-03, 1.86738333e-03, 5.47852843e-04, 4.71147018e-04,\n",
      "       1.22585445e-03, 2.97360213e-07, 1.68744027e-03, 7.97961431e-04,\n",
      "       2.54064677e-06, 1.87494688e-03, 4.57167002e-04, 1.22343875e-03,\n",
      "       2.45498012e-03, 5.45186135e-06, 5.15042996e-07, 1.59607938e-05,\n",
      "       1.96181291e-03, 4.93230529e-04, 1.36730278e-06, 1.88536906e-03]), 'mean_score_time': array([0.1918323 , 0.1938591 , 0.20047021, 0.19733278, 0.20538147,\n",
      "       0.20742901, 0.24533256, 0.19332194, 0.26168092, 0.2026666 ,\n",
      "       0.27409577, 0.20791594, 0.25067949, 0.24533319, 0.25882792,\n",
      "       0.26145871, 0.28301581, 0.27474078, 0.19996381, 0.19751493,\n",
      "       0.20318651, 0.2044882 , 0.2095232 , 0.22463981, 0.27050281,\n",
      "       0.1997331 , 0.28137342, 0.20482087, 0.29529937, 0.21222464,\n",
      "       0.27333307, 0.28309711, 0.29097692, 0.28372025, 0.30017805,\n",
      "       0.28984094, 0.20474156, 0.20547311, 0.23245986, 0.22386932,\n",
      "       0.21738625, 0.23629657, 0.29230762, 0.22565476, 0.31607572,\n",
      "       0.20823367, 0.32716529, 0.2296629 , 0.30300959, 0.29751245,\n",
      "       0.3210996 , 0.3409222 , 0.34882379, 0.35618854, 0.17897495,\n",
      "       0.19221385, 0.17866103, 0.17729553, 0.18029118, 0.17288971,\n",
      "       0.15671404, 0.16882976, 0.16096425, 0.1733338 , 0.1643095 ,\n",
      "       0.17200581, 0.16474112, 0.16244968, 0.16352669, 0.16411471,\n",
      "       0.16991043, 0.15885989, 0.17095256, 0.17329884, 0.16543659,\n",
      "       0.16942541, 0.17047795, 0.17313798, 0.16499805, 0.16413967,\n",
      "       0.16746489, 0.16854827, 0.17487852, 0.17323232, 0.15807915,\n",
      "       0.17727121, 0.16613642, 0.16398311, 0.16445541, 0.17052301,\n",
      "       0.1699005 , 0.17427993, 0.17778071, 0.16620795, 0.18719562,\n",
      "       0.17711401, 0.16695166, 0.19114963, 0.16970809, 0.18060994,\n",
      "       0.19687009, 0.16504264, 0.16737715, 0.16159566, 0.15981762,\n",
      "       0.16309174, 0.16542999, 0.16862392]), 'std_score_time': array([0.00369624, 0.00331207, 0.00332977, 0.0018852 , 0.00185173,\n",
      "       0.00262609, 0.00377102, 0.00376239, 0.00404038, 0.00188571,\n",
      "       0.00920074, 0.00325335, 0.00497265, 0.00496156, 0.0039994 ,\n",
      "       0.00386309, 0.010751  , 0.00178085, 0.00673216, 0.00630937,\n",
      "       0.00246308, 0.00610193, 0.00174681, 0.01663789, 0.00484505,\n",
      "       0.00586062, 0.00510749, 0.00233429, 0.00559232, 0.00597395,\n",
      "       0.00188447, 0.01135856, 0.00639392, 0.01087794, 0.00892151,\n",
      "       0.00695736, 0.0047209 , 0.00299371, 0.02537717, 0.01960018,\n",
      "       0.00194249, 0.02169207, 0.00385103, 0.00651438, 0.01429258,\n",
      "       0.00273012, 0.00817911, 0.00716425, 0.00221967, 0.00498165,\n",
      "       0.00836035, 0.0076307 , 0.00370091, 0.02442986, 0.01102304,\n",
      "       0.00901696, 0.00156065, 0.00228698, 0.00296606, 0.00215029,\n",
      "       0.00204163, 0.00149094, 0.00085006, 0.00149499, 0.00043816,\n",
      "       0.00044117, 0.00197553, 0.00304038, 0.00241452, 0.00016321,\n",
      "       0.00165019, 0.00203634, 0.0044926 , 0.00233879, 0.00113599,\n",
      "       0.00215403, 0.00179032, 0.00158908, 0.00537541, 0.00176774,\n",
      "       0.00375608, 0.00077573, 0.00416206, 0.00565676, 0.00201713,\n",
      "       0.008187  , 0.00314364, 0.00324202, 0.0039351 , 0.00269888,\n",
      "       0.00510647, 0.0049152 , 0.00530933, 0.00184822, 0.01080693,\n",
      "       0.00422778, 0.00235617, 0.02049567, 0.00757022, 0.02159985,\n",
      "       0.02136732, 0.00221952, 0.00257055, 0.00200947, 0.00047849,\n",
      "       0.00342049, 0.00182218, 0.00088306]), 'param_algorithm': masked_array(data=['ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
      "                   'ball_tree', 'ball_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
      "                   'kd_tree', 'kd_tree'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_leaf_size': masked_array(data=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "                   32, 32, 32, 32, 32, 32, 32, 32, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32,\n",
      "                   32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "                   32, 32],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_metric': masked_array(data=['euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
      "                   'euclidean', 'euclidean', 'minkowski', 'minkowski',\n",
      "                   'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
      "                   'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
      "                   'manhattan', 'manhattan', 'euclidean', 'euclidean',\n",
      "                   'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
      "                   'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
      "                   'minkowski', 'minkowski', 'manhattan', 'manhattan',\n",
      "                   'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
      "                   'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
      "                   'euclidean', 'euclidean', 'minkowski', 'minkowski',\n",
      "                   'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
      "                   'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
      "                   'manhattan', 'manhattan', 'euclidean', 'euclidean',\n",
      "                   'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
      "                   'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
      "                   'minkowski', 'minkowski', 'manhattan', 'manhattan',\n",
      "                   'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
      "                   'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
      "                   'euclidean', 'euclidean', 'minkowski', 'minkowski',\n",
      "                   'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
      "                   'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
      "                   'manhattan', 'manhattan', 'euclidean', 'euclidean',\n",
      "                   'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
      "                   'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
      "                   'minkowski', 'minkowski', 'manhattan', 'manhattan',\n",
      "                   'manhattan', 'manhattan', 'manhattan', 'manhattan'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_neighbors': masked_array(data=[3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7,\n",
      "                   3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7,\n",
      "                   3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7,\n",
      "                   3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7,\n",
      "                   3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7,\n",
      "                   3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7, 3, 3, 5, 5, 7, 7],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_p': masked_array(data=[1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
      "                   1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
      "                   1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
      "                   1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
      "                   1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n",
      "                   1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'ball_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 8, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 16, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 3, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 5, 'p': 2}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 1}, {'algorithm': 'kd_tree', 'leaf_size': 32, 'metric': 'manhattan', 'n_neighbors': 7, 'p': 2}], 'split0_test_score': array([0.36507937, 0.36507937, 0.36723686, 0.36723686, 0.36970257,\n",
      "       0.36970257, 0.36430883, 0.36507937, 0.37309293, 0.36723686,\n",
      "       0.38064417, 0.36970257, 0.36430883, 0.36430883, 0.37309293,\n",
      "       0.37309293, 0.38064417, 0.38064417, 0.36507937, 0.36507937,\n",
      "       0.36723686, 0.36723686, 0.36970257, 0.36970257, 0.36430883,\n",
      "       0.36507937, 0.37309293, 0.36723686, 0.38064417, 0.36970257,\n",
      "       0.36430883, 0.36430883, 0.37309293, 0.37309293, 0.38064417,\n",
      "       0.38064417, 0.36507937, 0.36507937, 0.36723686, 0.36723686,\n",
      "       0.36970257, 0.36970257, 0.36430883, 0.36507937, 0.37309293,\n",
      "       0.36723686, 0.38064417, 0.36970257, 0.36430883, 0.36430883,\n",
      "       0.37309293, 0.37309293, 0.38064417, 0.38064417, 0.36507937,\n",
      "       0.36507937, 0.36723686, 0.36723686, 0.36970257, 0.36970257,\n",
      "       0.36430883, 0.36507937, 0.37309293, 0.36723686, 0.38064417,\n",
      "       0.36970257, 0.36430883, 0.36430883, 0.37309293, 0.37309293,\n",
      "       0.38064417, 0.38064417, 0.36507937, 0.36507937, 0.36723686,\n",
      "       0.36723686, 0.36970257, 0.36970257, 0.36430883, 0.36507937,\n",
      "       0.37309293, 0.36723686, 0.38064417, 0.36970257, 0.36430883,\n",
      "       0.36430883, 0.37309293, 0.37309293, 0.38064417, 0.38064417,\n",
      "       0.36507937, 0.36507937, 0.36723686, 0.36723686, 0.36970257,\n",
      "       0.36970257, 0.36430883, 0.36507937, 0.37309293, 0.36723686,\n",
      "       0.38064417, 0.36970257, 0.36430883, 0.36430883, 0.37309293,\n",
      "       0.37309293, 0.38064417, 0.38064417]), 'split1_test_score': array([0.37016489, 0.37016489, 0.36877793, 0.36877793, 0.37848667,\n",
      "       0.37848667, 0.37447989, 0.37016489, 0.36985668, 0.36877793,\n",
      "       0.39004469, 0.37848667, 0.37447989, 0.37447989, 0.36985668,\n",
      "       0.36985668, 0.39004469, 0.39004469, 0.37016489, 0.37016489,\n",
      "       0.36877793, 0.36877793, 0.37848667, 0.37848667, 0.37447989,\n",
      "       0.37016489, 0.36985668, 0.36877793, 0.39004469, 0.37848667,\n",
      "       0.37447989, 0.37447989, 0.36985668, 0.36985668, 0.39004469,\n",
      "       0.39004469, 0.37016489, 0.37016489, 0.36877793, 0.36877793,\n",
      "       0.37848667, 0.37848667, 0.37447989, 0.37016489, 0.36985668,\n",
      "       0.36877793, 0.39004469, 0.37848667, 0.37447989, 0.37447989,\n",
      "       0.36985668, 0.36985668, 0.39004469, 0.39004469, 0.37016489,\n",
      "       0.37016489, 0.36877793, 0.36877793, 0.37848667, 0.37848667,\n",
      "       0.37447989, 0.37016489, 0.36985668, 0.36877793, 0.39004469,\n",
      "       0.37848667, 0.37447989, 0.37447989, 0.36985668, 0.36985668,\n",
      "       0.39004469, 0.39004469, 0.37016489, 0.37016489, 0.36877793,\n",
      "       0.36877793, 0.37848667, 0.37848667, 0.37447989, 0.37016489,\n",
      "       0.36985668, 0.36877793, 0.39004469, 0.37848667, 0.37447989,\n",
      "       0.37447989, 0.36985668, 0.36985668, 0.39004469, 0.39004469,\n",
      "       0.37016489, 0.37016489, 0.36877793, 0.36877793, 0.37848667,\n",
      "       0.37848667, 0.37447989, 0.37016489, 0.36985668, 0.36877793,\n",
      "       0.39004469, 0.37848667, 0.37447989, 0.37447989, 0.36985668,\n",
      "       0.36985668, 0.39004469, 0.39004469]), 'split2_test_score': array([0.3654439 , 0.3654439 , 0.36652281, 0.36652281, 0.36883477,\n",
      "       0.36883477, 0.37253391, 0.3654439 , 0.37792848, 0.36652281,\n",
      "       0.37469174, 0.36883477, 0.37253391, 0.37253391, 0.37792848,\n",
      "       0.37792848, 0.37469174, 0.37469174, 0.3654439 , 0.3654439 ,\n",
      "       0.36652281, 0.36652281, 0.36883477, 0.36883477, 0.37253391,\n",
      "       0.3654439 , 0.37792848, 0.36652281, 0.37469174, 0.36883477,\n",
      "       0.37253391, 0.37253391, 0.37792848, 0.37792848, 0.37469174,\n",
      "       0.37469174, 0.3654439 , 0.3654439 , 0.36652281, 0.36652281,\n",
      "       0.36883477, 0.36883477, 0.37253391, 0.3654439 , 0.37792848,\n",
      "       0.36652281, 0.37469174, 0.36883477, 0.37253391, 0.37253391,\n",
      "       0.37792848, 0.37792848, 0.37469174, 0.37469174, 0.3654439 ,\n",
      "       0.3654439 , 0.36652281, 0.36652281, 0.36883477, 0.36883477,\n",
      "       0.37253391, 0.3654439 , 0.37792848, 0.36652281, 0.37469174,\n",
      "       0.36883477, 0.37253391, 0.37253391, 0.37792848, 0.37792848,\n",
      "       0.37469174, 0.37469174, 0.3654439 , 0.3654439 , 0.36652281,\n",
      "       0.36652281, 0.36883477, 0.36883477, 0.37253391, 0.3654439 ,\n",
      "       0.37792848, 0.36652281, 0.37469174, 0.36883477, 0.37253391,\n",
      "       0.37253391, 0.37792848, 0.37792848, 0.37469174, 0.37469174,\n",
      "       0.3654439 , 0.3654439 , 0.36652281, 0.36652281, 0.36883477,\n",
      "       0.36883477, 0.37253391, 0.3654439 , 0.37792848, 0.36652281,\n",
      "       0.37469174, 0.36883477, 0.37253391, 0.37253391, 0.37792848,\n",
      "       0.37792848, 0.37469174, 0.37469174]), 'mean_test_score': array([0.36689605, 0.36689605, 0.36751254, 0.36751254, 0.37234134,\n",
      "       0.37234134, 0.37044088, 0.36689605, 0.37362603, 0.36751254,\n",
      "       0.38179353, 0.37234134, 0.37044088, 0.37044088, 0.37362603,\n",
      "       0.37362603, 0.38179353, 0.38179353, 0.36689605, 0.36689605,\n",
      "       0.36751254, 0.36751254, 0.37234134, 0.37234134, 0.37044088,\n",
      "       0.36689605, 0.37362603, 0.36751254, 0.38179353, 0.37234134,\n",
      "       0.37044088, 0.37044088, 0.37362603, 0.37362603, 0.38179353,\n",
      "       0.38179353, 0.36689605, 0.36689605, 0.36751254, 0.36751254,\n",
      "       0.37234134, 0.37234134, 0.37044088, 0.36689605, 0.37362603,\n",
      "       0.36751254, 0.38179353, 0.37234134, 0.37044088, 0.37044088,\n",
      "       0.37362603, 0.37362603, 0.38179353, 0.38179353, 0.36689605,\n",
      "       0.36689605, 0.36751254, 0.36751254, 0.37234134, 0.37234134,\n",
      "       0.37044088, 0.36689605, 0.37362603, 0.36751254, 0.38179353,\n",
      "       0.37234134, 0.37044088, 0.37044088, 0.37362603, 0.37362603,\n",
      "       0.38179353, 0.38179353, 0.36689605, 0.36689605, 0.36751254,\n",
      "       0.36751254, 0.37234134, 0.37234134, 0.37044088, 0.36689605,\n",
      "       0.37362603, 0.36751254, 0.38179353, 0.37234134, 0.37044088,\n",
      "       0.37044088, 0.37362603, 0.37362603, 0.38179353, 0.38179353,\n",
      "       0.36689605, 0.36689605, 0.36751254, 0.36751254, 0.37234134,\n",
      "       0.37234134, 0.37044088, 0.36689605, 0.37362603, 0.36751254,\n",
      "       0.38179353, 0.37234134, 0.37044088, 0.37044088, 0.37362603,\n",
      "       0.37362603, 0.38179353, 0.38179353]), 'std_test_score': array([0.00231621, 0.00231621, 0.00094106, 0.00094106, 0.00435982,\n",
      "       0.00435982, 0.00440819, 0.00231621, 0.00331679, 0.00094106,\n",
      "       0.00632029, 0.00435982, 0.00440819, 0.00440819, 0.00331679,\n",
      "       0.00331679, 0.00632029, 0.00632029, 0.00231621, 0.00231621,\n",
      "       0.00094106, 0.00094106, 0.00435982, 0.00435982, 0.00440819,\n",
      "       0.00231621, 0.00331679, 0.00094106, 0.00632029, 0.00435982,\n",
      "       0.00440819, 0.00440819, 0.00331679, 0.00331679, 0.00632029,\n",
      "       0.00632029, 0.00231621, 0.00231621, 0.00094106, 0.00094106,\n",
      "       0.00435982, 0.00435982, 0.00440819, 0.00231621, 0.00331679,\n",
      "       0.00094106, 0.00632029, 0.00435982, 0.00440819, 0.00440819,\n",
      "       0.00331679, 0.00331679, 0.00632029, 0.00632029, 0.00231621,\n",
      "       0.00231621, 0.00094106, 0.00094106, 0.00435982, 0.00435982,\n",
      "       0.00440819, 0.00231621, 0.00331679, 0.00094106, 0.00632029,\n",
      "       0.00435982, 0.00440819, 0.00440819, 0.00331679, 0.00331679,\n",
      "       0.00632029, 0.00632029, 0.00231621, 0.00231621, 0.00094106,\n",
      "       0.00094106, 0.00435982, 0.00435982, 0.00440819, 0.00231621,\n",
      "       0.00331679, 0.00094106, 0.00632029, 0.00435982, 0.00440819,\n",
      "       0.00440819, 0.00331679, 0.00331679, 0.00632029, 0.00632029,\n",
      "       0.00231621, 0.00231621, 0.00094106, 0.00094106, 0.00435982,\n",
      "       0.00435982, 0.00440819, 0.00231621, 0.00331679, 0.00094106,\n",
      "       0.00632029, 0.00435982, 0.00440819, 0.00440819, 0.00331679,\n",
      "       0.00331679, 0.00632029, 0.00632029]), 'rank_test_score': array([91, 91, 73, 73, 37, 37, 55, 91, 19, 73,  1, 37, 55, 55, 19, 19,  1,\n",
      "        1, 91, 91, 73, 73, 37, 37, 55, 91, 19, 73,  1, 37, 55, 55, 19, 19,\n",
      "        1,  1, 91, 91, 73, 73, 37, 37, 55, 91, 19, 73,  1, 37, 55, 55, 19,\n",
      "       19,  1,  1, 91, 91, 73, 73, 37, 37, 55, 91, 19, 73,  1, 37, 55, 55,\n",
      "       19, 19,  1,  1, 91, 91, 73, 73, 37, 37, 55, 91, 19, 73,  1, 37, 55,\n",
      "       55, 19, 19,  1,  1, 91, 91, 73, 73, 37, 37, 55, 91, 19, 73,  1, 37,\n",
      "       55, 55, 19, 19,  1,  1])}\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'algorithm': [\"ball_tree\", \"kd_tree\"],\n",
    "    'leaf_size': [8, 16, 32],\n",
    "    'metric': [\"euclidean\", \"minkowski\", \"manhattan\"],\n",
    "    'p': [1, 2],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNN, params, scoring=\"accuracy\", cv=StratifiedKFold(3))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "437486b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=8, n_neighbors=7, p=1)\n",
      "0.3938888309521327\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73e2bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int64),\n",
       " array([  45, 5750, 1378, 1713,  480,  173,   31,   16,    3], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(grid.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b96e1",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f929ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5697152987798519"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822028b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int64),\n",
       " array([  98, 3750, 2087, 2476,  803,  292,   46,   34,    3], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rf.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a65b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(rf, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8e06df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "405 fits failed out of a total of 1215.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "405 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 317, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\wilso\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.55691959 0.55953968 0.56015616 0.48746535 0.49131838 0.48854438\n",
      " 0.49188336 0.49481161 0.49470892 0.50410964 0.50303108 0.50179802\n",
      " 0.52270637 0.52332275 0.52296319 0.55640614 0.56031045 0.560259\n",
      " 0.48499962 0.49090732 0.49136963 0.49450325 0.49429781 0.49352725\n",
      " 0.50318512 0.50220892 0.50261999 0.52280902 0.52378502 0.52352822\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.50914427 0.50893879 0.50837364\n",
      " 0.49116408 0.48977724 0.4881847  0.49481149 0.49578762 0.49434921\n",
      " 0.50143851 0.50164401 0.500822   0.50863069 0.5079626  0.50832238\n",
      " 0.50991476 0.51155865 0.51083945 0.49049646 0.48741435 0.49260267\n",
      " 0.49203763 0.49455465 0.49547933 0.50328773 0.50395562 0.50400686\n",
      " 0.51217504 0.51227798 0.5109936         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.5526045  0.55342655 0.55476208 0.48957172 0.49198608 0.48952047\n",
      " 0.49553076 0.49465744 0.49496571 0.50215758 0.50236313 0.50236306\n",
      " 0.52147345 0.52219258 0.52121655 0.55686823 0.55923145 0.5583581\n",
      " 0.48674639 0.49214024 0.49121557 0.49666083 0.49424647 0.4956334\n",
      " 0.50246578 0.50267124 0.50457203 0.52255212 0.52270633 0.52239795\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.5583068  0.56046429 0.56493372\n",
      " 0.48160885 0.48268783 0.48551312 0.49352728 0.49080478 0.49378424\n",
      " 0.50380146 0.5015926  0.50195212 0.5252748  0.52291171 0.52095964\n",
      " 0.55645732 0.55902622 0.56149186 0.48833896 0.49085594 0.49059914\n",
      " 0.49450328 0.49393829 0.4961471  0.50344171 0.50282534 0.50400684\n",
      " 0.52537751 0.52291158 0.52666168        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.50904152 0.5102232  0.50791133 0.48191738 0.48371552 0.48294452\n",
      " 0.49198635 0.49378416 0.49193487 0.49969185 0.49886984 0.50190073\n",
      " 0.50965792 0.50929832 0.50827096 0.51202083 0.51289418 0.51227779\n",
      " 0.49234575 0.49337307 0.49188353 0.49255117 0.49681496 0.49522254\n",
      " 0.49876696 0.50220891 0.50513709 0.51258602 0.51263723 0.51309971\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.55635443 0.5564059  0.55671426\n",
      " 0.48582168 0.48227696 0.4859246  0.49265401 0.48936615 0.49542788\n",
      " 0.50457195 0.50210626 0.50380134 0.52157615 0.52131925 0.52301439\n",
      " 0.55769001 0.55876894 0.5603101  0.48602713 0.48813337 0.49342455\n",
      " 0.49532526 0.49558212 0.49558209 0.50467478 0.50333914 0.50354455\n",
      " 0.52399036 0.52506925 0.5240418         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55815278 0.55984785 0.56370072 0.48448574 0.48767095 0.48607862\n",
      " 0.48957174 0.49285953 0.49409252 0.50323649 0.50148982 0.5028254\n",
      " 0.52013784 0.52003492 0.5218843  0.55681691 0.56082367 0.56149179\n",
      " 0.49224297 0.48880115 0.49321905 0.49491441 0.49645526 0.49594168\n",
      " 0.50508575 0.50431511 0.5033389  0.52342533 0.5248123  0.52486368\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.5111477  0.50929836 0.50832227\n",
      " 0.48428041 0.48756803 0.48052998 0.49409223 0.49239722 0.49065065\n",
      " 0.5015411  0.50200356 0.5017466  0.51119906 0.51155862 0.50827094\n",
      " 0.51068518 0.51207226 0.51217492 0.4913697  0.48818484 0.49178066\n",
      " 0.49527405 0.49378397 0.49522253 0.50287664 0.5019006  0.50282534\n",
      " 0.51232914 0.51130168 0.51191802        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55481325 0.55804977 0.55620051 0.4846913  0.48797911 0.48756837\n",
      " 0.49219174 0.49234582 0.49249984 0.5015924  0.50169539 0.5031336\n",
      " 0.51957264 0.52142194 0.5217302  0.55959088 0.55948808 0.56000189\n",
      " 0.49167788 0.49368137 0.49178047 0.49707187 0.49311645 0.49491426\n",
      " 0.50323635 0.50205491 0.50441782 0.52486381 0.52470966 0.52486373\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 1.33704638,  2.6659387 ,  4.00279705,  0.43998694,  0.89489277,\n",
      "        1.47179222,  0.47223552,  0.96257401,  1.44314361,  0.54006243,\n",
      "        1.07358932,  1.68793901,  0.65869459,  1.3292129 ,  2.03879913,\n",
      "        1.94197265,  4.02075648,  6.20082974,  0.71378072,  1.33478729,\n",
      "        2.10786406,  0.73247139,  1.38372207,  1.99485485,  0.74340097,\n",
      "        1.55518961,  2.32538891,  0.97843345,  1.8780822 ,  2.76123842,\n",
      "        0.01937286,  0.03626307,  0.04933318,  0.01733303,  0.02933288,\n",
      "        0.04399991,  0.01599987,  0.02933304,  0.04399999,  0.01599987,\n",
      "        0.03066659,  0.04133296,  0.01599987,  0.03066675,  0.04764573,\n",
      "        0.58463367,  1.26646296,  1.73015014,  0.50050497,  0.94679109,\n",
      "        1.41793458,  0.52069696,  1.08583585,  1.5051868 ,  0.53791634,\n",
      "        1.13430127,  1.62747471,  0.55151868,  1.19406422,  1.74472149,\n",
      "        0.77236597,  1.63154984,  2.33070143,  0.66155664,  1.29214621,\n",
      "        2.05101156,  0.71589065,  1.49851179,  2.49040739,  0.81352345,\n",
      "        1.701998  ,  2.42344205,  0.83792377,  1.67190639,  2.2762866 ,\n",
      "        0.01601243,  0.02933343,  0.04266596,  0.01685095,  0.03267344,\n",
      "        0.05191724,  0.01796269,  0.0333333 ,  0.04633919,  0.01732143,\n",
      "        0.03704127,  0.05339694,  0.01999728,  0.03200277,  0.04616857,\n",
      "        0.92440375,  1.86236652,  3.27012157,  0.44887002,  0.96279915,\n",
      "        1.5057528 ,  0.49152621,  0.98810712,  1.48345725,  0.67587837,\n",
      "        1.13246584,  1.93542933,  0.78934121,  1.56696884,  2.1667219 ,\n",
      "        1.3225828 ,  2.60496688,  4.19497148,  0.61579132,  1.34614857,\n",
      "        2.00678166,  0.66341575,  1.58481065,  2.17883738,  0.77679396,\n",
      "        1.50976912,  2.40133063,  0.95502631,  1.89300593,  2.93684785,\n",
      "        0.01599987,  0.0279998 ,  0.04266675,  0.01600003,  0.02934392,\n",
      "        0.04399999,  0.01600003,  0.02933375,  0.04399975,  0.01599964,\n",
      "        0.03034266,  0.04133344,  0.01733335,  0.02800067,  0.04133336,\n",
      "        3.21319493,  7.19682185, 11.12918242,  1.55564014,  3.21976352,\n",
      "        4.13433536,  1.47769364,  2.93763073,  4.45286743,  1.66829975,\n",
      "        3.31713589,  5.06951817,  1.98530539,  4.04170815,  6.07009371,\n",
      "        5.2402343 , 10.55100433, 15.69626911,  1.94710771,  4.04630621,\n",
      "        5.98355881,  2.14909776,  4.30557362,  6.41182121,  2.39754025,\n",
      "        4.88157892,  7.279145  ,  2.85597253,  5.77173734,  8.70201198,\n",
      "        0.0172871 ,  0.03358889,  0.04679092,  0.0192732 ,  0.03192767,\n",
      "        0.04853638,  0.0188125 ,  0.03277381,  0.04720887,  0.01861986,\n",
      "        0.03290033,  0.05052129,  0.01961374,  0.03422983,  0.04932046,\n",
      "        1.61634453,  3.25019479,  4.82773177,  1.33111978,  2.67995286,\n",
      "        4.00350134,  1.41053526,  2.81346027,  4.31860415,  1.54243207,\n",
      "        3.07666675,  4.60034116,  1.62412524,  3.17906602,  4.82622862,\n",
      "        2.35268442,  4.66026934,  6.98994525,  1.92630426,  3.86155383,\n",
      "        5.8810122 ,  2.0344553 ,  4.14281654,  6.20970352,  2.22613446,\n",
      "        5.26567618,  6.79201833,  2.38423387,  4.66367952,  7.03992128,\n",
      "        0.01795141,  0.03259261,  0.04654233,  0.0172747 ,  0.03458691,\n",
      "        0.04672567,  0.01793949,  0.0336136 ,  0.04652913,  0.01964116,\n",
      "        0.03259142,  0.04763095,  0.01781305,  0.03257942,  0.05118521,\n",
      "        2.84593972,  5.56058741,  8.33070389,  1.336893  ,  2.7054441 ,\n",
      "        4.20617096,  1.45769294,  2.90868115,  4.40898355,  1.65844361,\n",
      "        3.33834839,  5.0419236 ,  2.00133101,  3.97733998,  6.0852801 ,\n",
      "        4.33225648,  8.57771985, 12.36816557,  1.99903997,  4.05956833,\n",
      "        5.40231657,  1.90303206,  3.97558045,  5.68172542,  2.46800224,\n",
      "        4.96467574,  7.358181  ,  2.88007323,  5.86768389,  8.68694981,\n",
      "        0.02163315,  0.03888051,  0.05119054,  0.01861684,  0.03407876,\n",
      "        0.04837473,  0.01895006,  0.03324596,  0.04886913,  0.01795181,\n",
      "        0.03224651,  0.04787199,  0.01761953,  0.03124881,  0.04408518,\n",
      "        3.77305555,  7.65034421, 11.993975  ,  1.22839427,  2.6068476 ,\n",
      "        3.91241566,  1.42736204,  2.79066149,  4.15443571,  1.60602077,\n",
      "        3.25974917,  5.02084732,  1.86967842,  5.17886225,  6.20609101,\n",
      "        5.14188544, 10.70403536, 15.88908378,  1.85480746,  3.75269055,\n",
      "        6.19311039,  2.06959263,  4.06101394,  6.0617195 ,  2.35343862,\n",
      "        4.67493741,  7.02645501,  2.7802465 ,  6.48763919,  8.46160682,\n",
      "        0.01696316,  0.0305659 ,  0.04753923,  0.01728725,  0.03224746,\n",
      "        0.04737838,  0.0189484 ,  0.03224778,  0.04624557,  0.01695569,\n",
      "        0.03143207,  0.04688025,  0.01695458,  0.03241809,  0.04787175,\n",
      "        1.5458467 ,  3.12480776,  4.6650672 ,  1.300548  ,  2.59319599,\n",
      "        3.86666505,  1.5662276 ,  2.6549445 ,  4.13366167,  1.48698394,\n",
      "        2.99760596,  4.46944666,  1.5584391 ,  3.10755499,  4.73437444,\n",
      "        2.29642399,  4.52033726,  6.73313371,  1.88963787,  3.69835623,\n",
      "        5.65513039,  1.97343763,  3.97077727,  5.880771  ,  2.128534  ,\n",
      "        4.30221804,  6.42111071,  2.21474576,  4.60028044,  6.9198672 ,\n",
      "        0.01684539,  0.03310053,  0.04655449,  0.01764496,  0.03322824,\n",
      "        0.04853654,  0.02059984,  0.04321933,  0.06929119,  0.02633564,\n",
      "        0.04920212,  0.0706981 ,  0.01987187,  0.03425511,  0.04621077,\n",
      "        2.93595457,  5.43188063,  8.10072207,  1.31119196,  2.61239688,\n",
      "        3.89928937,  1.37589796,  2.79095205,  4.19381483,  1.61761522,\n",
      "        3.4103183 ,  4.80461129,  1.87623946,  3.82022961,  5.76647655,\n",
      "        3.89959574,  8.32148838, 12.44831785,  1.98892268,  3.90816824,\n",
      "        5.76949255,  2.09751717,  4.20324771,  6.15537429,  2.31982891,\n",
      "        4.65289632,  6.97496152,  2.85480364,  5.61648329,  8.79067405,\n",
      "        0.01728861,  0.03124968,  0.04621037,  0.01761953,  0.03158299,\n",
      "        0.04970487,  0.01826644,  0.03175187,  0.04538274,  0.01800442,\n",
      "        0.03091757,  0.04654217,  0.01795133,  0.03190136,  0.0461998 ]), 'std_fit_time': array([4.22735723e-03, 1.42995473e-02, 1.14481011e-02, 3.28133475e-03,\n",
      "       3.30577158e-02, 3.36563354e-02, 1.48322957e-02, 1.24941261e-02,\n",
      "       1.20170754e-02, 3.24414153e-03, 1.35024525e-02, 6.42110336e-02,\n",
      "       2.53236309e-02, 5.11247171e-02, 1.15721232e-01, 5.37392411e-02,\n",
      "       1.60163534e-01, 2.72548686e-01, 5.05242334e-02, 4.98955554e-02,\n",
      "       3.04343206e-01, 1.02394078e-01, 7.46860647e-02, 2.89556445e-02,\n",
      "       5.59784065e-03, 4.77005823e-02, 1.24398433e-01, 5.64405919e-02,\n",
      "       8.50993004e-02, 1.00298362e-01, 4.19666743e-04, 8.78513474e-04,\n",
      "       1.88508805e-03, 1.88581860e-03, 1.88581860e-03, 1.94667955e-07,\n",
      "       4.05233662e-07, 1.88604337e-03, 2.97360213e-07, 1.12391596e-07,\n",
      "       1.88581860e-03, 1.88598718e-03, 1.12391596e-07, 1.88593099e-03,\n",
      "       5.31479038e-04, 2.35094349e-02, 2.80948176e-02, 6.27519346e-02,\n",
      "       1.46317111e-02, 3.21124183e-02, 9.41440402e-03, 6.33458091e-02,\n",
      "       7.68822881e-02, 8.73733887e-05, 1.26343866e-02, 9.07718896e-02,\n",
      "       4.41966257e-02, 5.46615713e-03, 6.10947599e-02, 1.03563647e-01,\n",
      "       1.49178950e-02, 7.51357609e-02, 4.79385020e-04, 2.85438683e-03,\n",
      "       2.38332075e-02, 7.71459051e-02, 8.24531245e-02, 1.65630889e-01,\n",
      "       8.41447077e-02, 6.10430805e-02, 2.35093536e-01, 1.67616101e-01,\n",
      "       4.91219087e-03, 2.12943372e-01, 8.63039483e-02, 1.90565909e-05,\n",
      "       1.88660634e-03, 1.87907997e-03, 1.20388262e-03, 3.36792953e-03,\n",
      "       2.42057282e-03, 3.34985026e-03, 1.88598720e-03, 1.70206223e-03,\n",
      "       1.87497764e-03, 2.79633229e-03, 2.59512855e-03, 3.84109687e-06,\n",
      "       1.98717114e-05, 1.64517568e-03, 8.57516474e-03, 7.71244309e-02,\n",
      "       1.58580135e-01, 1.05708045e-03, 2.84754888e-02, 7.82438625e-02,\n",
      "       5.49696849e-03, 2.10060369e-02, 5.67158682e-02, 8.79799820e-02,\n",
      "       4.00658385e-02, 1.51281360e-01, 1.02604395e-01, 7.29334769e-02,\n",
      "       9.07486100e-02, 4.63159332e-02, 2.81255186e-02, 1.94499742e-01,\n",
      "       1.02930914e-03, 1.21415951e-01, 1.23266888e-01, 4.89993567e-03,\n",
      "       2.24865196e-01, 1.64804562e-01, 1.78575794e-02, 2.71645766e-02,\n",
      "       1.09984637e-01, 8.92493294e-02, 1.34828765e-01, 2.41494208e-01,\n",
      "       4.05233662e-07, 2.41837884e-06, 1.88452615e-03, 2.05095417e-06,\n",
      "       2.17029547e-03, 2.97360213e-07, 4.28269500e-06, 1.87930185e-03,\n",
      "       1.07214749e-06, 1.12391596e-07, 1.25141913e-03, 1.88548143e-03,\n",
      "       1.88593102e-03, 1.38109105e-06, 1.88536903e-03, 1.76190053e-02,\n",
      "       1.52251819e-01, 5.11034183e-01, 2.13153281e-01, 3.43469713e-01,\n",
      "       1.42575762e-02, 2.37189278e-02, 4.27852083e-02, 1.27455228e-01,\n",
      "       1.57277780e-02, 7.13042082e-03, 7.78689296e-02, 1.25886515e-02,\n",
      "       1.59403320e-02, 2.25437595e-02, 3.45719963e-02, 5.86956553e-03,\n",
      "       7.10396146e-02, 3.64789452e-03, 1.79798197e-01, 1.66439821e-01,\n",
      "       3.21109098e-02, 1.89131153e-01, 1.15072270e-01, 2.34186866e-02,\n",
      "       5.16236903e-02, 2.93606631e-02, 1.10570860e-02, 1.06617766e-01,\n",
      "       4.71973554e-02, 4.70302644e-04, 1.86407139e-03, 8.33546549e-04,\n",
      "       1.88691294e-03, 1.88258440e-05, 2.35107878e-03, 6.49197996e-04,\n",
      "       6.42005864e-04, 9.66208705e-04, 4.72288905e-04, 8.15148275e-04,\n",
      "       3.09366072e-03, 1.72248160e-03, 4.52432632e-04, 1.74920074e-03,\n",
      "       2.27110356e-02, 1.68584311e-02, 1.61240840e-02, 9.93738046e-03,\n",
      "       4.91942057e-02, 3.73863713e-02, 2.65791373e-02, 3.90246533e-02,\n",
      "       1.15838023e-02, 8.98836145e-03, 1.35694403e-02, 1.35932404e-02,\n",
      "       2.71489264e-02, 1.87446115e-02, 4.77432154e-02, 2.48007562e-02,\n",
      "       6.52477006e-02, 1.73493201e-02, 1.85930881e-02, 2.96490575e-02,\n",
      "       5.48846366e-02, 4.99500688e-03, 2.98259999e-02, 1.12109683e-02,\n",
      "       1.96266121e-02, 2.59676166e-01, 5.46017478e-02, 7.27431682e-02,\n",
      "       5.14534708e-02, 2.89687163e-02, 4.49566384e-07, 4.52234287e-04,\n",
      "       4.71190249e-04, 4.79129065e-04, 1.24811646e-03, 1.50187235e-03,\n",
      "       1.97031796e-05, 4.96328822e-04, 9.49711839e-04, 1.23699014e-03,\n",
      "       9.32174820e-04, 8.82787008e-04, 1.97649274e-04, 9.40717679e-04,\n",
      "       4.78216868e-03, 8.70756069e-02, 4.06297243e-02, 3.59275952e-02,\n",
      "       6.98068921e-03, 8.01833804e-03, 1.94986682e-01, 2.08304102e-02,\n",
      "       2.06791968e-02, 3.89848824e-02, 8.95832742e-03, 3.29778947e-02,\n",
      "       2.76656524e-02, 1.94510178e-02, 3.28129769e-02, 7.05413268e-02,\n",
      "       4.91415171e-02, 2.70009482e-01, 8.60867906e-02, 1.32490114e-01,\n",
      "       2.19659540e-01, 7.30238766e-02, 1.27509322e-02, 2.38919139e-01,\n",
      "       1.21324565e-01, 2.88205889e-01, 6.03461480e-02, 9.69760678e-02,\n",
      "       1.38876965e-01, 3.18677561e-01, 3.97387911e-01, 1.23023623e-03,\n",
      "       8.31217813e-04, 2.44198616e-03, 4.70302644e-04, 6.18936356e-04,\n",
      "       4.06988375e-04, 8.14004054e-04, 4.72606661e-04, 1.08386530e-06,\n",
      "       5.94720425e-07, 4.70246478e-04, 8.14296062e-04, 4.70134086e-04,\n",
      "       4.70697011e-04, 2.40866597e-04, 6.66053643e-02, 5.79958453e-02,\n",
      "       8.06176833e-01, 3.71548576e-02, 9.32875390e-02, 7.81473535e-02,\n",
      "       1.04209530e-02, 1.50117987e-01, 7.24808287e-02, 3.11057264e-02,\n",
      "       2.75587085e-02, 2.66163547e-01, 3.27549486e-02, 6.96289013e-01,\n",
      "       2.71176596e-01, 3.02365323e-02, 3.99400302e-01, 6.69077926e-01,\n",
      "       3.89529673e-03, 2.76293370e-02, 6.00716282e-01, 3.50342554e-02,\n",
      "       1.52244202e-02, 6.31584891e-03, 2.27849219e-02, 2.11375678e-02,\n",
      "       1.02593193e-02, 3.12738212e-03, 7.15339874e-01, 8.73671763e-02,\n",
      "       1.23630756e-05, 4.81766036e-04, 4.71202259e-04, 4.70021655e-04,\n",
      "       4.68560726e-04, 7.01382193e-04, 2.15512387e-03, 4.71201776e-04,\n",
      "       1.23292142e-03, 3.16497608e-06, 6.57796941e-04, 1.77550452e-03,\n",
      "       1.12391596e-07, 4.08560055e-04, 8.14490753e-04, 1.15362106e-02,\n",
      "       2.59238598e-02, 9.65726659e-03, 2.11454525e-02, 9.41550587e-03,\n",
      "       7.04352613e-02, 6.98407021e-02, 7.09667208e-02, 2.00694406e-02,\n",
      "       1.92258249e-02, 4.08622017e-02, 1.70023276e-02, 1.74363562e-02,\n",
      "       1.65474598e-02, 1.53161231e-01, 1.91001387e-02, 2.44780284e-02,\n",
      "       2.43665399e-02, 5.71031482e-02, 2.11076299e-02, 1.06795089e-01,\n",
      "       2.89217531e-02, 1.72788628e-02, 1.91922302e-02, 2.23875129e-02,\n",
      "       1.70766697e-02, 2.90746781e-02, 2.00326534e-02, 8.84091409e-02,\n",
      "       1.91677530e-01, 2.01263162e-04, 1.65076113e-03, 4.79129065e-04,\n",
      "       4.28449545e-04, 4.80373002e-04, 2.35249719e-03, 4.86210760e-04,\n",
      "       2.48890583e-03, 2.79864669e-03, 1.16815270e-03, 1.24472861e-03,\n",
      "       5.42633521e-03, 6.92161406e-04, 4.88005708e-04, 1.69613829e-03,\n",
      "       8.63110749e-02, 5.00546785e-02, 1.78605960e-02, 3.19247034e-02,\n",
      "       2.27130081e-02, 8.05079724e-03, 8.83950546e-03, 3.86915652e-02,\n",
      "       3.62181442e-02, 3.20031576e-02, 2.37554520e-01, 1.72011940e-02,\n",
      "       4.40562474e-03, 3.86098687e-02, 3.45010866e-02, 1.85675807e-02,\n",
      "       6.76811079e-01, 4.17849037e-01, 1.45274303e-01, 1.89188586e-01,\n",
      "       8.23370232e-02, 8.40571206e-02, 2.42284930e-01, 6.19839736e-02,\n",
      "       3.29322969e-02, 4.26704240e-02, 2.60811650e-02, 6.36801495e-02,\n",
      "       6.90215198e-02, 4.55841891e-01, 4.72799104e-04, 4.70077941e-04,\n",
      "       4.70976993e-04, 4.70134086e-04, 4.72678100e-04, 2.23918485e-03,\n",
      "       4.82989477e-04, 6.26312886e-04, 1.06898821e-03, 7.43476142e-05,\n",
      "       8.13712058e-04, 4.45291362e-04, 4.05233662e-07, 8.31282017e-04,\n",
      "       4.77639517e-04]), 'mean_score_time': array([0.0690399 , 0.13199274, 0.19864122, 0.02266637, 0.04641509,\n",
      "       0.08053207, 0.02401058, 0.05182926, 0.07340638, 0.02665377,\n",
      "       0.05333447, 0.08052985, 0.03567855, 0.06275654, 0.09789228,\n",
      "       0.07254179, 0.13612843, 0.22430642, 0.02903612, 0.05079452,\n",
      "       0.08183217, 0.02529526, 0.05238875, 0.0734117 , 0.0288864 ,\n",
      "       0.05270012, 0.07932671, 0.03428467, 0.06196888, 0.09182008,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03367146, 0.07560054, 0.09260496, 0.03166993, 0.05094179,\n",
      "       0.07344381, 0.02581263, 0.05213149, 0.07654961, 0.0268902 ,\n",
      "       0.06277688, 0.0831244 , 0.02933192, 0.06550296, 0.08709598,\n",
      "       0.03062256, 0.0622464 , 0.08915329, 0.02711248, 0.04866107,\n",
      "       0.08021148, 0.02533253, 0.05631065, 0.09793067, 0.02973008,\n",
      "       0.06811039, 0.09150394, 0.03396869, 0.05946692, 0.08627446,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.05092263, 0.09129985, 0.15817984, 0.02499628, 0.04667036,\n",
      "       0.0779202 , 0.0251116 , 0.05099026, 0.07556987, 0.03247754,\n",
      "       0.06574639, 0.08812253, 0.03784784, 0.07590667, 0.09585611,\n",
      "       0.04507216, 0.09206414, 0.14032396, 0.02399961, 0.07198636,\n",
      "       0.07304478, 0.02400009, 0.06838044, 0.07829722, 0.02612201,\n",
      "       0.05200013, 0.08194296, 0.03552294, 0.05951722, 0.08852299,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.06399949, 0.13949553, 0.29201214, 0.03835615, 0.05696479,\n",
      "       0.08347456, 0.02924466, 0.05495747, 0.08164382, 0.03041784,\n",
      "       0.05851269, 0.08859253, 0.03292537, 0.07510893, 0.10094953,\n",
      "       0.07449134, 0.14288433, 0.22325857, 0.03094331, 0.06085205,\n",
      "       0.08075253, 0.0283107 , 0.05618389, 0.08265599, 0.03093505,\n",
      "       0.06050309, 0.09144926, 0.03392283, 0.07216628, 0.1007545 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03224985, 0.06382386, 0.09509254, 0.02659551, 0.05533012,\n",
      "       0.08426277, 0.02911035, 0.05569077, 0.08196195, 0.03043588,\n",
      "       0.05916071, 0.08824666, 0.03227329, 0.06411576, 0.09394193,\n",
      "       0.0322477 , 0.06383038, 0.09803398, 0.02790467, 0.05454699,\n",
      "       0.08161918, 0.02791127, 0.05890648, 0.0832034 , 0.03059856,\n",
      "       0.0755415 , 0.08906039, 0.03291154, 0.06418649, 0.09342861,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.05255119, 0.10193475, 0.15619349, 0.02726102, 0.05387966,\n",
      "       0.0791231 , 0.02824402, 0.0561951 , 0.08554085, 0.03057456,\n",
      "       0.06083703, 0.0895532 , 0.03290057, 0.06751172, 0.10259247,\n",
      "       0.05817016, 0.12517214, 0.15361778, 0.03718106, 0.06037641,\n",
      "       0.07631079, 0.02744261, 0.05005797, 0.07339183, 0.03711375,\n",
      "       0.06015126, 0.0929172 , 0.03474641, 0.07115785, 0.10062536,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.07365171, 0.15823468, 0.23736374, 0.02558517, 0.0568095 ,\n",
      "       0.07367365, 0.02768532, 0.05374948, 0.07597709, 0.02912188,\n",
      "       0.05796059, 0.08350388, 0.03291106, 0.08841507, 0.1146938 ,\n",
      "       0.0739851 , 0.15692568, 0.21941336, 0.02592564, 0.0522027 ,\n",
      "       0.07928149, 0.02757915, 0.05384533, 0.08118176, 0.02959879,\n",
      "       0.05819432, 0.08798226, 0.03555902, 0.06982565, 0.09740543,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.03190899, 0.06351161, 0.09108194, 0.02659702, 0.05318069,\n",
      "       0.08678484, 0.03092623, 0.05486814, 0.0807941 , 0.02890031,\n",
      "       0.05716658, 0.08528733, 0.03125072, 0.06117201, 0.10064928,\n",
      "       0.03143191, 0.06182281, 0.09240977, 0.02742926, 0.0541904 ,\n",
      "       0.0788192 , 0.02724767, 0.05357075, 0.0804623 , 0.02927279,\n",
      "       0.05716602, 0.08510598, 0.03159348, 0.06249913, 0.09407663,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.05935462, 0.10953514, 0.14861592, 0.02725967, 0.05201983,\n",
      "       0.07713977, 0.02710859, 0.05320438, 0.07795167, 0.02858726,\n",
      "       0.05783383, 0.09014463, 0.03190525, 0.06433972, 0.0954121 ,\n",
      "       0.05019887, 0.11602449, 0.14870699, 0.03322117, 0.06117082,\n",
      "       0.09442504, 0.02760792, 0.06271346, 0.0779887 , 0.02857749,\n",
      "       0.05752675, 0.08589212, 0.03354836, 0.06849591, 0.09638119,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ]), 'std_score_time': array([1.46968871e-03, 1.19706283e-05, 1.89139816e-03, 1.88542534e-03,\n",
      "       1.73718881e-03, 6.85004623e-03, 1.67474792e-05, 4.91329112e-03,\n",
      "       1.83420713e-03, 1.87947204e-03, 1.88531295e-03, 3.92766547e-03,\n",
      "       5.22425840e-03, 3.86956442e-03, 1.61174258e-02, 9.39384472e-03,\n",
      "       3.42536264e-03, 1.43331004e-02, 7.93941967e-04, 1.94061058e-03,\n",
      "       8.92910903e-03, 1.80512991e-03, 1.34946320e-03, 2.26345203e-03,\n",
      "       1.26081555e-03, 9.93384876e-04, 2.52374108e-03, 2.38200120e-03,\n",
      "       1.64914241e-03, 4.22090489e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 5.44270619e-03, 1.16907007e-02, 8.05209918e-03,\n",
      "       5.91225891e-03, 8.74713726e-04, 1.30301432e-03, 2.56455150e-03,\n",
      "       2.35892450e-04, 3.95795859e-03, 1.51437201e-03, 1.09459872e-02,\n",
      "       1.21297518e-03, 1.88497578e-03, 9.00463822e-03, 2.25299406e-03,\n",
      "       9.83485402e-04, 3.30553240e-03, 2.75612185e-03, 6.66209260e-04,\n",
      "       1.05524988e-03, 8.45020250e-03, 1.88643747e-03, 5.94372225e-03,\n",
      "       3.36700474e-03, 2.13980541e-03, 1.46149958e-02, 1.23497325e-02,\n",
      "       8.44066506e-03, 4.59787620e-03, 1.54424925e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 8.43101924e-03, 1.03223814e-02,\n",
      "       2.20981592e-02, 2.16355029e-03, 1.88998610e-03, 8.39498925e-03,\n",
      "       2.06046629e-03, 3.47005917e-03, 2.98139166e-03, 6.20699171e-03,\n",
      "       1.94397562e-02, 1.74547627e-02, 8.11384435e-03, 1.41063776e-02,\n",
      "       7.57736736e-03, 1.51503891e-03, 2.31401627e-03, 9.91003936e-03,\n",
      "       6.83651389e-07, 3.39183226e-02, 1.42055225e-03, 1.12391596e-07,\n",
      "       1.39201315e-02, 4.98219978e-03, 1.61904532e-03, 2.24783192e-07,\n",
      "       4.89650434e-03, 1.01451045e-02, 2.69503476e-03, 7.36334629e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.23630756e-06,\n",
      "       6.73331051e-03, 5.99945455e-02, 1.08884842e-02, 7.34172856e-03,\n",
      "       2.86725899e-03, 9.31434311e-04, 1.75502806e-03, 1.43712533e-03,\n",
      "       4.23484479e-04, 9.43246475e-04, 4.30312389e-03, 1.82116007e-05,\n",
      "       1.17701811e-02, 1.65883116e-03, 2.47168447e-03, 4.05196443e-03,\n",
      "       1.20939761e-02, 4.30957330e-03, 8.46124617e-03, 1.68185020e-03,\n",
      "       8.67074547e-04, 4.69369522e-04, 3.69975670e-03, 1.62588907e-03,\n",
      "       3.87648648e-03, 4.46300094e-03, 8.14052353e-04, 6.09680914e-03,\n",
      "       2.14896558e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.02890442e-03, 8.27766607e-04, 1.89846285e-03, 4.95449118e-04,\n",
      "       1.07169165e-03, 4.92066927e-03, 2.43704205e-03, 1.30465866e-03,\n",
      "       1.66676741e-03, 1.48925528e-03, 2.60285982e-03, 6.76320807e-04,\n",
      "       9.54374354e-04, 4.78662019e-04, 1.06173675e-03, 4.70752210e-04,\n",
      "       7.01885292e-07, 3.31975155e-03, 2.04636055e-05, 4.64040891e-04,\n",
      "       8.35299446e-04, 4.33442675e-05, 2.92030057e-03, 2.51066352e-03,\n",
      "       4.79847045e-04, 2.28024616e-03, 4.70064962e-04, 7.95029432e-04,\n",
      "       4.79532900e-04, 2.86461954e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 2.33330619e-03, 2.00331473e-03, 7.01448557e-04,\n",
      "       4.69517597e-04, 3.99293982e-05, 1.21494773e-03, 4.51585475e-04,\n",
      "       2.06068158e-03, 3.28491485e-03, 9.25207639e-04, 3.54533411e-03,\n",
      "       1.63447940e-03, 7.99351068e-04, 3.29249107e-03, 5.14266940e-03,\n",
      "       4.88666611e-03, 3.33486938e-02, 1.83379301e-03, 7.61277492e-03,\n",
      "       1.36723085e-02, 1.22161254e-03, 3.57095779e-03, 1.13667361e-03,\n",
      "       4.23157374e-04, 1.24784335e-02, 9.50522466e-04, 4.81473338e-03,\n",
      "       3.32507158e-03, 1.22821120e-02, 7.52601096e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.07372709e-03, 2.11491756e-02,\n",
      "       3.54286675e-02, 9.49958795e-04, 4.52540916e-03, 1.69559135e-03,\n",
      "       9.63606028e-04, 2.19445855e-03, 3.00596571e-05, 2.01364005e-03,\n",
      "       5.39241971e-03, 3.79223362e-03, 1.62937082e-03, 1.20425560e-02,\n",
      "       1.33429060e-02, 1.66564356e-03, 2.84606081e-02, 1.06126701e-02,\n",
      "       4.80068701e-05, 4.89079091e-04, 2.03625421e-03, 4.60929912e-04,\n",
      "       8.14949076e-04, 1.75308947e-03, 4.79555027e-04, 4.88294612e-04,\n",
      "       2.72923369e-03, 4.49442220e-03, 9.89897392e-03, 4.48564730e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.11289649e-04,\n",
      "       1.25903849e-03, 4.57827673e-04, 4.71887208e-04, 4.79550075e-04,\n",
      "       1.20016218e-02, 8.24139357e-04, 6.45763540e-03, 5.05013700e-04,\n",
      "       3.70606955e-04, 4.78056422e-04, 1.07114913e-03, 4.69853319e-04,\n",
      "       4.70873052e-04, 9.85429618e-03, 4.07658542e-04, 7.99933863e-04,\n",
      "       1.24322921e-03, 4.23668063e-04, 1.24617413e-03, 1.44085654e-03,\n",
      "       4.53669523e-04, 4.51962314e-04, 1.71107377e-03, 4.59194555e-04,\n",
      "       4.80093026e-04, 4.70134086e-04, 4.79962689e-04, 4.69748027e-04,\n",
      "       2.62642100e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.37621580e-02, 1.28165753e-02, 1.61479210e-03, 9.39594065e-04,\n",
      "       1.31377070e-03, 9.50401758e-04, 2.31254169e-04, 1.26936422e-03,\n",
      "       1.04447701e-03, 4.70639899e-04, 3.24308103e-03, 8.25590064e-03,\n",
      "       1.72984505e-05, 1.12065633e-03, 9.39650186e-04, 1.24443125e-03,\n",
      "       2.58572602e-02, 7.98357750e-03, 1.03908188e-02, 1.10823652e-02,\n",
      "       2.14198445e-02, 4.80263598e-04, 1.13857117e-02, 1.57045815e-03,\n",
      "       4.86322332e-04, 4.72412415e-04, 1.47570176e-03, 1.24745287e-03,\n",
      "       4.64673533e-03, 8.32129981e-04, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=['sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_leaf_nodes': masked_array(data=[None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32, None, None, None, 8, 8, 8, 10,\n",
      "                   10, 10, 16, 16, 16, 32, 32, 32, None, None, None, 8, 8,\n",
      "                   8, 10, 10, 10, 16, 16, 16, 32, 32, 32, None, None,\n",
      "                   None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32, 32, 32,\n",
      "                   None, None, None, 8, 8, 8, 10, 10, 10, 16, 16, 16, 32,\n",
      "                   32, 32, None, None, None, 8, 8, 8, 10, 10, 10, 16, 16,\n",
      "                   16, 32, 32, 32, None, None, None, 8, 8, 8, 10, 10, 10,\n",
      "                   16, 16, 16, 32, 32, 32],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150, 50, 100, 150,\n",
      "                   50, 100, 150, 50, 100, 150, 50, 100, 150],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'gini', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': None, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 32, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': None, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 8, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 10, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 16, 'n_estimators': 150}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 50}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'None', 'max_leaf_nodes': 32, 'n_estimators': 150}], 'split0_test_score': array([0.55617198, 0.55832948, 0.55971644, 0.48127601, 0.48420404,\n",
      "       0.48096779, 0.48651564, 0.49175528, 0.49113885, 0.50161812,\n",
      "       0.49776545, 0.49745724, 0.51764525, 0.52057328, 0.52118971,\n",
      "       0.55524734, 0.55956234, 0.55987055, 0.48358761, 0.48744028,\n",
      "       0.48851903, 0.49036832, 0.49098474, 0.49144706, 0.49869009,\n",
      "       0.50300509, 0.50023116, 0.52118971, 0.52088149, 0.52196024,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.50254276, 0.50392973, 0.50377562, 0.48435814, 0.48281708,\n",
      "       0.48451225, 0.49144706, 0.48944367, 0.48728618, 0.49529974,\n",
      "       0.4966867 , 0.49591617, 0.50192634, 0.50408383, 0.50192634,\n",
      "       0.50654955, 0.50747419, 0.50716597, 0.48235475, 0.48543689,\n",
      "       0.48836493, 0.48574511, 0.49314224, 0.49190939, 0.49591617,\n",
      "       0.50300509, 0.50254276, 0.5099399 , 0.5077824 , 0.5077824 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.54908306, 0.54862074, 0.55139467, 0.48235475, 0.48836493,\n",
      "       0.4811219 , 0.48975189, 0.4900601 , 0.48898135, 0.49838188,\n",
      "       0.49622438, 0.50069348, 0.51810757, 0.51964864, 0.51795346,\n",
      "       0.55478502, 0.55555556, 0.5543227 , 0.48281708, 0.48913546,\n",
      "       0.48744028, 0.49422099, 0.49021421, 0.4943751 , 0.50084759,\n",
      "       0.50053937, 0.50161812, 0.51964864, 0.51949453, 0.51995685,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55524734, 0.56017876, 0.56295269, 0.48312529, 0.48666975,\n",
      "       0.49067653, 0.48944367, 0.48959778, 0.48959778, 0.50130991,\n",
      "       0.49869009, 0.4988442 , 0.52257667, 0.51733703, 0.51918632,\n",
      "       0.55786716, 0.55570966, 0.56079519, 0.48913546, 0.4900601 ,\n",
      "       0.49021421, 0.49375867, 0.49406688, 0.4966867 , 0.50439205,\n",
      "       0.5033133 , 0.50577901, 0.52226845, 0.52226845, 0.52535059,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.50577901, 0.50315919, 0.50269687, 0.48512868, 0.48358761,\n",
      "       0.48482047, 0.49083064, 0.49360456, 0.49345045, 0.49822777,\n",
      "       0.49776545, 0.49730313, 0.50454616, 0.50485437, 0.50269687,\n",
      "       0.51194329, 0.51410079, 0.50870704, 0.48882725, 0.49468331,\n",
      "       0.49514563, 0.48713207, 0.4988442 , 0.49483742, 0.49699491,\n",
      "       0.5011558 , 0.5054708 , 0.5122515 , 0.51317614, 0.51178918,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55632609, 0.5564802 , 0.55324395, 0.48666975, 0.48975189,\n",
      "       0.48451225, 0.48928957, 0.48697796, 0.49298813, 0.50423794,\n",
      "       0.50053937, 0.50130991, 0.51641239, 0.51918632, 0.52242256,\n",
      "       0.55740484, 0.55709663, 0.55817537, 0.49129296, 0.48928957,\n",
      "       0.49175528, 0.49375867, 0.4943751 , 0.49514563, 0.50238866,\n",
      "       0.50346741, 0.5033133 , 0.52396363, 0.52473417, 0.52273078,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55524734, 0.55894591, 0.56156573, 0.48420404, 0.49391278,\n",
      "       0.48759439, 0.48805671, 0.48913546, 0.49067653, 0.50208044,\n",
      "       0.49869009, 0.49976884, 0.51749114, 0.51949453, 0.52057328,\n",
      "       0.55478502, 0.56341501, 0.56249037, 0.49360456, 0.49329635,\n",
      "       0.49406688, 0.4922176 , 0.49791956, 0.49375867, 0.50439205,\n",
      "       0.50408383, 0.50408383, 0.5231931 , 0.52257667, 0.5233472 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.50654955, 0.50516258, 0.50285098, 0.48512868, 0.48851903,\n",
      "       0.48497457, 0.49036832, 0.49190939, 0.49160117, 0.4988442 ,\n",
      "       0.49714902, 0.50146402, 0.50685776, 0.50886115, 0.5033133 ,\n",
      "       0.51333025, 0.51040222, 0.5120974 , 0.48744028, 0.49098474,\n",
      "       0.49083064, 0.4943751 , 0.49576206, 0.49529974, 0.50208044,\n",
      "       0.49838188, 0.50377562, 0.50978579, 0.50809061, 0.51163507,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55709663, 0.55894591, 0.55509323, 0.48466636, 0.48913546,\n",
      "       0.48913546, 0.48805671, 0.4900601 , 0.49098474, 0.50392973,\n",
      "       0.4966867 , 0.5033133 , 0.51980274, 0.5210356 , 0.52134381,\n",
      "       0.55771305, 0.5587918 , 0.55725073, 0.49083064, 0.4943751 ,\n",
      "       0.49468331, 0.49560795, 0.49252581, 0.49637849, 0.50161812,\n",
      "       0.5011558 , 0.50516258, 0.52288488, 0.5231931 , 0.52442595,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split1_test_score': array([0.5609493 , 0.56125751, 0.56079519, 0.49314224, 0.49483742,\n",
      "       0.49113885, 0.49576206, 0.49514563, 0.4945292 , 0.50839883,\n",
      "       0.50531669, 0.50593312, 0.5255047 , 0.5255047 , 0.5231931 ,\n",
      "       0.55555556, 0.55786716, 0.55894591, 0.48374172, 0.49252581,\n",
      "       0.49298813, 0.49838188, 0.49637849, 0.49422099, 0.50608722,\n",
      "       0.50254276, 0.50423794, 0.52411774, 0.52750809, 0.52473417,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.51333025, 0.51148097, 0.51178918, 0.49791956, 0.49298813,\n",
      "       0.48851903, 0.49776545, 0.50038527, 0.49961473, 0.5054708 ,\n",
      "       0.50423794, 0.50470026, 0.51040222, 0.51194329, 0.51117275,\n",
      "       0.51255972, 0.51487132, 0.51379257, 0.4945292 , 0.48158422,\n",
      "       0.49329635, 0.49375867, 0.49514563, 0.49838188, 0.51178918,\n",
      "       0.50485437, 0.50793651, 0.51502543, 0.51363847, 0.51286793,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55694252, 0.55709663, 0.55940823, 0.49360456, 0.4945292 ,\n",
      "       0.49252581, 0.49961473, 0.49745724, 0.49853598, 0.50654955,\n",
      "       0.5077824 , 0.50470026, 0.52257667, 0.52396363, 0.5231931 ,\n",
      "       0.56202805, 0.56356912, 0.56356912, 0.48543689, 0.49329635,\n",
      "       0.49267992, 0.49946063, 0.49653259, 0.49714902, 0.50516258,\n",
      "       0.50639544, 0.50839883, 0.52581291, 0.52458006, 0.52642934,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.56110341, 0.56279858, 0.56711358, 0.48220065, 0.47742333,\n",
      "       0.48204654, 0.49560795, 0.48620743, 0.49391278, 0.50701187,\n",
      "       0.50285098, 0.50516258, 0.52874095, 0.52904916, 0.52242256,\n",
      "       0.55678841, 0.55802127, 0.56156573, 0.48127601, 0.48990599,\n",
      "       0.48805671, 0.4943751 , 0.49098474, 0.49607027, 0.50624133,\n",
      "       0.50423794, 0.50500848, 0.52981969, 0.52673756, 0.53166898,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.51009401, 0.51255972, 0.51117275, 0.47495762, 0.47757744,\n",
      "       0.48297118, 0.48682386, 0.49144706, 0.48620743, 0.49961473,\n",
      "       0.49961473, 0.50685776, 0.51379257, 0.51271382, 0.51132686,\n",
      "       0.51456311, 0.51363847, 0.51641239, 0.49345045, 0.49190939,\n",
      "       0.48374172, 0.49684081, 0.49483742, 0.49360456, 0.50285098,\n",
      "       0.50470026, 0.50624133, 0.51348436, 0.51579596, 0.51548775,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.56110341, 0.55910002, 0.56033287, 0.48019726, 0.47156727,\n",
      "       0.47911851, 0.49314224, 0.49021421, 0.4988442 , 0.50732008,\n",
      "       0.50315919, 0.50947758, 0.52535059, 0.52288488, 0.5255047 ,\n",
      "       0.56418554, 0.56418554, 0.56603483, 0.4766528 , 0.48281708,\n",
      "       0.49283403, 0.49529974, 0.49529974, 0.49499152, 0.5077824 ,\n",
      "       0.50346741, 0.5054708 , 0.5276622 , 0.52735398, 0.5276622 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55894591, 0.56249037, 0.5675759 , 0.48528279, 0.47881029,\n",
      "       0.47819387, 0.48759439, 0.49298813, 0.49252581, 0.50285098,\n",
      "       0.50346741, 0.50670365, 0.51949453, 0.52088149, 0.52350131,\n",
      "       0.5609493 , 0.56464787, 0.56125751, 0.48913546, 0.4811219 ,\n",
      "       0.49036832, 0.49375867, 0.49684081, 0.49730313, 0.50654955,\n",
      "       0.50654955, 0.50747419, 0.52627524, 0.53089844, 0.5299738 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.51456311, 0.51148097, 0.51255972, 0.48096779, 0.48744028,\n",
      "       0.47958083, 0.49853598, 0.48867314, 0.48420404, 0.50516258,\n",
      "       0.5056249 , 0.50269687, 0.51456311, 0.51410079, 0.51117275,\n",
      "       0.51024811, 0.51517953, 0.51517953, 0.49267992, 0.47927262,\n",
      "       0.49036832, 0.49144706, 0.49314224, 0.49345045, 0.50701187,\n",
      "       0.50839883, 0.50377562, 0.51579596, 0.51595007, 0.51595007,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55786716, 0.56033287, 0.55817537, 0.48389582, 0.48543689,\n",
      "       0.48019726, 0.49190939, 0.49098474, 0.4922176 , 0.50161812,\n",
      "       0.50423794, 0.50423794, 0.51826167, 0.52226845, 0.52196024,\n",
      "       0.5654184 , 0.56526429, 0.56588072, 0.49098474, 0.49144706,\n",
      "       0.49021421, 0.49761134, 0.48898135, 0.49252581, 0.50608722,\n",
      "       0.50208044, 0.50639544, 0.52797041, 0.52797041, 0.52797041,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'split2_test_score': array([0.55363748, 0.55903206, 0.55995684, 0.48797781, 0.49491369,\n",
      "       0.49352651, 0.49337238, 0.49753391, 0.49845869, 0.50231196,\n",
      "       0.5060111 , 0.5020037 , 0.52496917, 0.52389026, 0.52450678,\n",
      "       0.55841554, 0.56350185, 0.56196054, 0.48766954, 0.49275586,\n",
      "       0.49260173, 0.49475956, 0.49553021, 0.49491369, 0.50477805,\n",
      "       0.50107891, 0.50339088, 0.52311961, 0.52296547, 0.52389026,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.5115598 , 0.51140567, 0.5095561 , 0.49121455, 0.49352651,\n",
      "       0.49152281, 0.49522195, 0.49753391, 0.49614673, 0.50354501,\n",
      "       0.5040074 , 0.50184957, 0.5135635 , 0.50786067, 0.51186806,\n",
      "       0.51063502, 0.51233046, 0.5115598 , 0.49460543, 0.49522195,\n",
      "       0.49614673, 0.49660912, 0.49537608, 0.49614673, 0.50215783,\n",
      "       0.5040074 , 0.50154131, 0.5115598 , 0.51541307, 0.51233046,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55178792, 0.55456227, 0.55348335, 0.49275586, 0.49306412,\n",
      "       0.49491369, 0.49722565, 0.49645499, 0.49737978, 0.50154131,\n",
      "       0.50308261, 0.50169544, 0.52373613, 0.52296547, 0.52250308,\n",
      "       0.55379162, 0.55856967, 0.55718249, 0.4919852 , 0.4939889 ,\n",
      "       0.49352651, 0.49630086, 0.4959926 , 0.49537608, 0.50138718,\n",
      "       0.50107891, 0.50369914, 0.52219482, 0.52404439, 0.52080764,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55856967, 0.55841554, 0.5647349 , 0.47950062, 0.48397041,\n",
      "       0.48381628, 0.49553021, 0.49660912, 0.49784217, 0.50308261,\n",
      "       0.50323674, 0.50184957, 0.52450678, 0.52234895, 0.52127004,\n",
      "       0.5547164 , 0.56334772, 0.56211467, 0.49460543, 0.49260173,\n",
      "       0.49352651, 0.49537608, 0.49676326, 0.49568434, 0.49969174,\n",
      "       0.50092478, 0.50123305, 0.52404439, 0.51972873, 0.52296547,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.51125154, 0.51495068, 0.50986436, 0.48566584, 0.4899815 ,\n",
      "       0.48104192, 0.49830456, 0.49630086, 0.49614673, 0.50123305,\n",
      "       0.49922935, 0.50154131, 0.51063502, 0.51032676, 0.51078915,\n",
      "       0.5095561 , 0.51094328, 0.51171393, 0.49475956, 0.49352651,\n",
      "       0.49676326, 0.49368064, 0.49676326, 0.49722565, 0.49645499,\n",
      "       0.50077065, 0.50369914, 0.51202219, 0.50893958, 0.51202219,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55163379, 0.55363748, 0.55656597, 0.49059803, 0.48551171,\n",
      "       0.49414303, 0.49553021, 0.49090629, 0.49445129, 0.50215783,\n",
      "       0.50262022, 0.50061652, 0.52296547, 0.52188656, 0.52111591,\n",
      "       0.55147965, 0.55502466, 0.5567201 , 0.49013564, 0.49229346,\n",
      "       0.49568434, 0.49691739, 0.49707152, 0.49660912, 0.50385327,\n",
      "       0.50308261, 0.50184957, 0.52034525, 0.52311961, 0.52173243,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.5602651 , 0.55810727, 0.56196054, 0.48397041, 0.49028977,\n",
      "       0.4924476 , 0.49306412, 0.49645499, 0.49907522, 0.50477805,\n",
      "       0.50231196, 0.5020037 , 0.52342787, 0.51972873, 0.5215783 ,\n",
      "       0.5547164 , 0.55440814, 0.5607275 , 0.4939889 , 0.4919852 ,\n",
      "       0.49522195, 0.49876695, 0.49460543, 0.49676326, 0.50431566,\n",
      "       0.50231196, 0.49845869, 0.52080764, 0.52096178, 0.52127004,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.51233046, 0.51125154, 0.5095561 , 0.48674476, 0.48674476,\n",
      "       0.47703453, 0.49337238, 0.49660912, 0.49614673, 0.50061652,\n",
      "       0.50323674, 0.50107891, 0.51217633, 0.51171393, 0.51032676,\n",
      "       0.50847719, 0.51063502, 0.50924784, 0.4939889 , 0.49429716,\n",
      "       0.49414303, 0.5       , 0.4924476 , 0.49691739, 0.49953761,\n",
      "       0.49892109, 0.50092478, 0.51140567, 0.50986436, 0.50816893,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.54947596, 0.55487053, 0.55533292, 0.48551171, 0.48936498,\n",
      "       0.49337238, 0.49660912, 0.4959926 , 0.49429716, 0.49922935,\n",
      "       0.50416153, 0.50184957, 0.52065351, 0.52096178, 0.52188656,\n",
      "       0.55564118, 0.55440814, 0.55687423, 0.49321825, 0.49522195,\n",
      "       0.4904439 , 0.4979963 , 0.49784217, 0.49583847, 0.5020037 ,\n",
      "       0.50292848, 0.50169544, 0.52373613, 0.52296547, 0.52219482,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'mean_test_score': array([0.55691959, 0.55953968, 0.56015616, 0.48746535, 0.49131838,\n",
      "       0.48854438, 0.49188336, 0.49481161, 0.49470892, 0.50410964,\n",
      "       0.50303108, 0.50179802, 0.52270637, 0.52332275, 0.52296319,\n",
      "       0.55640614, 0.56031045, 0.560259  , 0.48499962, 0.49090732,\n",
      "       0.49136963, 0.49450325, 0.49429781, 0.49352725, 0.50318512,\n",
      "       0.50220892, 0.50261999, 0.52280902, 0.52378502, 0.52352822,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.50914427, 0.50893879, 0.50837364, 0.49116408, 0.48977724,\n",
      "       0.4881847 , 0.49481149, 0.49578762, 0.49434921, 0.50143851,\n",
      "       0.50164401, 0.500822  , 0.50863069, 0.5079626 , 0.50832238,\n",
      "       0.50991476, 0.51155865, 0.51083945, 0.49049646, 0.48741435,\n",
      "       0.49260267, 0.49203763, 0.49455465, 0.49547933, 0.50328773,\n",
      "       0.50395562, 0.50400686, 0.51217504, 0.51227798, 0.5109936 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.5526045 , 0.55342655, 0.55476208, 0.48957172, 0.49198608,\n",
      "       0.48952047, 0.49553076, 0.49465744, 0.49496571, 0.50215758,\n",
      "       0.50236313, 0.50236306, 0.52147345, 0.52219258, 0.52121655,\n",
      "       0.55686823, 0.55923145, 0.5583581 , 0.48674639, 0.49214024,\n",
      "       0.49121557, 0.49666083, 0.49424647, 0.4956334 , 0.50246578,\n",
      "       0.50267124, 0.50457203, 0.52255212, 0.52270633, 0.52239795,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.5583068 , 0.56046429, 0.56493372, 0.48160885, 0.48268783,\n",
      "       0.48551312, 0.49352728, 0.49080478, 0.49378424, 0.50380146,\n",
      "       0.5015926 , 0.50195212, 0.5252748 , 0.52291171, 0.52095964,\n",
      "       0.55645732, 0.55902622, 0.56149186, 0.48833896, 0.49085594,\n",
      "       0.49059914, 0.49450328, 0.49393829, 0.4961471 , 0.50344171,\n",
      "       0.50282534, 0.50400684, 0.52537751, 0.52291158, 0.52666168,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.50904152, 0.5102232 , 0.50791133, 0.48191738, 0.48371552,\n",
      "       0.48294452, 0.49198635, 0.49378416, 0.49193487, 0.49969185,\n",
      "       0.49886984, 0.50190073, 0.50965792, 0.50929832, 0.50827096,\n",
      "       0.51202083, 0.51289418, 0.51227779, 0.49234575, 0.49337307,\n",
      "       0.49188353, 0.49255117, 0.49681496, 0.49522254, 0.49876696,\n",
      "       0.50220891, 0.50513709, 0.51258602, 0.51263723, 0.51309971,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55635443, 0.5564059 , 0.55671426, 0.48582168, 0.48227696,\n",
      "       0.4859246 , 0.49265401, 0.48936615, 0.49542788, 0.50457195,\n",
      "       0.50210626, 0.50380134, 0.52157615, 0.52131925, 0.52301439,\n",
      "       0.55769001, 0.55876894, 0.5603101 , 0.48602713, 0.48813337,\n",
      "       0.49342455, 0.49532526, 0.49558212, 0.49558209, 0.50467478,\n",
      "       0.50333914, 0.50354455, 0.52399036, 0.52506925, 0.5240418 ,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55815278, 0.55984785, 0.56370072, 0.48448574, 0.48767095,\n",
      "       0.48607862, 0.48957174, 0.49285953, 0.49409252, 0.50323649,\n",
      "       0.50148982, 0.5028254 , 0.52013784, 0.52003492, 0.5218843 ,\n",
      "       0.55681691, 0.56082367, 0.56149179, 0.49224297, 0.48880115,\n",
      "       0.49321905, 0.49491441, 0.49645526, 0.49594168, 0.50508575,\n",
      "       0.50431511, 0.5033389 , 0.52342533, 0.5248123 , 0.52486368,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.5111477 , 0.50929836, 0.50832227, 0.48428041, 0.48756803,\n",
      "       0.48052998, 0.49409223, 0.49239722, 0.49065065, 0.5015411 ,\n",
      "       0.50200356, 0.5017466 , 0.51119906, 0.51155862, 0.50827094,\n",
      "       0.51068518, 0.51207226, 0.51217492, 0.4913697 , 0.48818484,\n",
      "       0.49178066, 0.49527405, 0.49378397, 0.49522253, 0.50287664,\n",
      "       0.5019006 , 0.50282534, 0.51232914, 0.51130168, 0.51191802,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.55481325, 0.55804977, 0.55620051, 0.4846913 , 0.48797911,\n",
      "       0.48756837, 0.49219174, 0.49234582, 0.49249984, 0.5015924 ,\n",
      "       0.50169539, 0.5031336 , 0.51957264, 0.52142194, 0.5217302 ,\n",
      "       0.55959088, 0.55948808, 0.56000189, 0.49167788, 0.49368137,\n",
      "       0.49178047, 0.49707187, 0.49311645, 0.49491426, 0.50323635,\n",
      "       0.50205491, 0.50441782, 0.52486381, 0.52470966, 0.52486373,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'std_test_score': array([0.00303148, 0.00124809, 0.0004624 , 0.0048579 , 0.0050307 ,\n",
      "       0.00544541, 0.00391892, 0.00237091, 0.00299101, 0.00304611,\n",
      "       0.00373414, 0.00346332, 0.00358543, 0.00205285, 0.00136391,\n",
      "       0.00142642, 0.00236039, 0.001261  , 0.00188897, 0.00245336,\n",
      "       0.00202184, 0.00327654, 0.00236815, 0.00149785, 0.00322309,\n",
      "       0.00082102, 0.00172419, 0.00121537, 0.00276667, 0.00116102,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.0047236 , 0.00354207, 0.00337668, 0.00553654, 0.00492649,\n",
      "       0.0028718 , 0.00259575, 0.00463442, 0.00519112, 0.00441139,\n",
      "       0.00350661, 0.00365896, 0.00491322, 0.00320942, 0.00453159,\n",
      "       0.00250594, 0.00306878, 0.00275283, 0.00575714, 0.00574048,\n",
      "       0.00321455, 0.00459914, 0.00100315, 0.0026842 , 0.0065292 ,\n",
      "       0.00075585, 0.0028086 , 0.00212125, 0.00326037, 0.00228123,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00326015, 0.00355223, 0.00339418, 0.00511492, 0.00262947,\n",
      "       0.00601816, 0.00420106, 0.00327646, 0.00425782, 0.00336279,\n",
      "       0.00474589, 0.00170252, 0.00242666, 0.00184442, 0.00232448,\n",
      "       0.00367101, 0.00330482, 0.00386528, 0.00385571, 0.00214343,\n",
      "       0.00269181, 0.00215416, 0.00285975, 0.00114697, 0.00191961,\n",
      "       0.0026426 , 0.00283619, 0.00252921, 0.00228159, 0.00287171,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00239794, 0.00180073, 0.00170448, 0.0015378 , 0.00388225,\n",
      "       0.00372188, 0.00288772, 0.00433139, 0.00336698, 0.00238266,\n",
      "       0.00205842, 0.00258049, 0.00257449, 0.00479799, 0.0013393 ,\n",
      "       0.00130742, 0.00319817, 0.0005412 , 0.00547078, 0.00123606,\n",
      "       0.00224956, 0.0006665 , 0.00236082, 0.0004128 , 0.00275701,\n",
      "       0.00139591, 0.00198644, 0.00322369, 0.00289725, 0.00367214,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00235485, 0.00508948, 0.00372567, 0.00492618, 0.00506475,\n",
      "       0.0015427 , 0.00475769, 0.00198562, 0.00419684, 0.00122811,\n",
      "       0.00079662, 0.00390893, 0.00383754, 0.00328999, 0.00394758,\n",
      "       0.00204484, 0.00139234, 0.00317086, 0.00254471, 0.00113764,\n",
      "       0.00579489, 0.00404324, 0.00163617, 0.00150318, 0.00289624,\n",
      "       0.00176866, 0.00106433, 0.00064208, 0.00282493, 0.00169128,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00386601, 0.00223069, 0.00289594, 0.00428823, 0.00776822,\n",
      "       0.00621451, 0.00257102, 0.00171218, 0.00248846, 0.00212067,\n",
      "       0.00112959, 0.00402368, 0.00377894, 0.00156231, 0.00183994,\n",
      "       0.00519108, 0.00392241, 0.00409136, 0.00664547, 0.00395416,\n",
      "       0.00165749, 0.00128967, 0.00111877, 0.00072894, 0.00227732,\n",
      "       0.00018139, 0.00148738, 0.00298719, 0.00174484, 0.00259225,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00212388, 0.00189965, 0.0027449 , 0.00057161, 0.00643764,\n",
      "       0.00591695, 0.00247669, 0.00298957, 0.00360328, 0.00113453,\n",
      "       0.00203513, 0.00289013, 0.00246598, 0.00060621, 0.00121479,\n",
      "       0.00292218, 0.0045643 , 0.00073851, 0.00220294, 0.00545637,\n",
      "       0.00207019, 0.00279587, 0.00138018, 0.00155928, 0.00103553,\n",
      "       0.0017377 , 0.00371806, 0.00223817, 0.00435376, 0.00371157,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00337673, 0.00292594, 0.00405846, 0.00243352, 0.00072995,\n",
      "       0.00331026, 0.00337306, 0.00325816, 0.00492169, 0.00266103,\n",
      "       0.00356845, 0.00069009, 0.0032207 , 0.00214189, 0.00352255,\n",
      "       0.00200521, 0.00219923, 0.00242222, 0.00282944, 0.00644535,\n",
      "       0.00168108, 0.00354911, 0.00142718, 0.00141642, 0.00310286,\n",
      "       0.00460021, 0.0013439 , 0.00253905, 0.00336573, 0.00318293,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.00378712, 0.00231827, 0.00139986, 0.00065992, 0.00180006,\n",
      "       0.00549168, 0.00349721, 0.00260615, 0.00136694, 0.00191901,\n",
      "       0.00354182, 0.00098329, 0.00098993, 0.00059933, 0.00027487,\n",
      "       0.0042066 , 0.00445927, 0.0041598 , 0.00109102, 0.00161728,\n",
      "       0.00205476, 0.00104701, 0.00364144, 0.00170321, 0.00202201,\n",
      "       0.00072392, 0.00198972, 0.00222402, 0.00230757, 0.00237811,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan]), 'rank_test_score': array([ 24,  14,  10, 252, 228, 243, 222, 183, 185, 116, 131, 150,  57,\n",
      "        51,  53,  29,   7,   9, 260, 231, 227, 189, 191, 201, 129, 141,\n",
      "       137,  56,  48,  49, 289, 288, 287, 286, 284, 283, 282, 294, 291,\n",
      "       271, 295, 296, 303, 311, 273,  98, 100, 102, 230, 237, 246, 184,\n",
      "       169, 190, 158, 153, 159, 101, 107, 103,  94,  85,  91, 236, 253,\n",
      "       208, 217, 187, 174, 126, 119, 117,  80,  78,  90, 368, 367, 366,\n",
      "       365, 364, 363, 362, 315, 381, 383, 404, 384, 403, 402, 401,  36,\n",
      "        35,  34, 239, 219, 240, 173, 186, 180, 143, 139, 140,  65,  61,\n",
      "        68,  25,  16,  19, 254, 216, 229, 165, 192, 170, 138, 136, 112,\n",
      "        59,  58,  60, 385, 361, 360, 359, 358, 334, 333, 317, 325, 336,\n",
      "       337, 338, 357, 355, 354,  20,   6,   1, 269, 266, 259, 200, 233,\n",
      "       196, 120, 154, 147,  39,  54,  69,  28,  17,   3, 244, 232, 235,\n",
      "       188, 195, 167, 123, 134, 118,  38,  55,  37, 339, 340, 341, 342,\n",
      "       343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,  99,  93,\n",
      "       108, 268, 264, 265, 218, 197, 220, 160, 161, 148,  95,  97, 105,\n",
      "        83,  74,  79, 213, 203, 221, 209, 164, 178, 162, 142, 109,  76,\n",
      "        75,  73, 318, 319, 320, 321, 322, 323, 324, 326, 335, 327, 328,\n",
      "       329, 330, 331, 332,  31,  30,  27, 258, 267, 257, 207, 241, 175,\n",
      "       113, 144, 121,  64,  67,  52,  23,  18,   8, 256, 247, 202, 176,\n",
      "       171, 172, 111, 124, 122,  47,  40,  46, 386, 387, 388, 389, 390,\n",
      "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400,  21,  12,   2,\n",
      "       262, 249, 255, 238, 206, 193, 127, 157, 133,  70,  71,  62,  26,\n",
      "         5,   4, 214, 242, 204, 181, 166, 168, 110, 115, 125,  50,  44,\n",
      "        43, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "       316, 382, 314,  89,  96, 104, 263, 251, 270, 194, 211, 234, 156,\n",
      "       146, 151,  88,  86, 106,  92,  82,  81, 226, 245, 223, 177, 198,\n",
      "       179, 132, 149, 134,  77,  87,  84, 297, 298, 299, 300, 301, 305,\n",
      "       307, 309, 310, 312, 293, 313, 274, 275, 276,  33,  22,  32, 261,\n",
      "       248, 250, 215, 212, 210, 155, 152, 130,  72,  66,  63,  13,  15,\n",
      "        11, 225, 199, 224, 163, 205, 182, 128, 145, 114,  41,  45,  42,\n",
      "       302, 304, 306, 308, 292, 290, 272, 277, 278, 279, 280, 281, 285,\n",
      "       356, 405])}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'criterion': [\"gini\", \"log_loss\", \"entropy\"],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'max_features': [\"sqrt\", \"log2\", \"None\"],\n",
    "    'max_leaf_nodes': [None, 8, 10, 16, 32],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(rf, params, scoring=\"accuracy\", cv=StratifiedKFold(3))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a17eb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='log_loss', n_estimators=150)\n",
      "0.5726353112941912\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff2ff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int64),\n",
       " array([ 101, 3692, 2137, 2479,  806,  284,   48,   41,    1], dtype=int64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(grid.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b6f81",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59b0849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.337365731567421"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f6c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(svm, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab5ee89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d05423c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([14.57354021, 13.36744229, 19.72793516, 15.8088309 , 24.59926573,\n",
      "       16.61237113, 15.4977959 , 22.48543779]), 'std_fit_time': array([0.6403231 , 0.36829745, 0.50216204, 0.3708878 , 0.92769817,\n",
      "       0.82695045, 0.10233664, 1.2725358 ]), 'mean_score_time': array([ 8.69328372,  8.54722722,  9.04597624,  3.08654722,  4.09583473,\n",
      "        9.28272867,  9.52869797, 10.19569747]), 'std_score_time': array([0.86324477, 0.0421147 , 0.2468126 , 0.15887575, 0.31150852,\n",
      "       0.23434366, 0.4807333 , 0.55874122]), 'param_SVM__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'sigmoid', 'sigmoid', 'rbf',\n",
      "                   'rbf', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__gamma': masked_array(data=['auto', 'scale', 'auto', 'auto', 'scale', 'auto',\n",
      "                   'scale', 'scale'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__C': masked_array(data=[2, 5, 0.1, 5, 0.1, 5, 1, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'SVM__kernel': 'rbf', 'SVM__gamma': 'auto', 'SVM__class_weight': 'balanced', 'SVM__C': 2}, {'SVM__kernel': 'rbf', 'SVM__gamma': 'scale', 'SVM__class_weight': 'balanced', 'SVM__C': 5}, {'SVM__kernel': 'rbf', 'SVM__gamma': 'auto', 'SVM__class_weight': 'balanced', 'SVM__C': 0.1}, {'SVM__kernel': 'sigmoid', 'SVM__gamma': 'auto', 'SVM__class_weight': 'balanced', 'SVM__C': 5}, {'SVM__kernel': 'sigmoid', 'SVM__gamma': 'scale', 'SVM__class_weight': 'balanced', 'SVM__C': 0.1}, {'SVM__kernel': 'rbf', 'SVM__gamma': 'auto', 'SVM__class_weight': 'balanced', 'SVM__C': 5}, {'SVM__kernel': 'rbf', 'SVM__gamma': 'scale', 'SVM__class_weight': 'balanced', 'SVM__C': 1}, {'SVM__kernel': 'rbf', 'SVM__gamma': 'scale', 'SVM__class_weight': 'balanced', 'SVM__C': 0.01}], 'split0_test_score': array([0.28340268, 0.38079827, 0.16289105, 0.25751271, 0.10833719,\n",
      "       0.32747727, 0.34766528, 0.13268608]), 'split1_test_score': array([0.32069656, 0.38095238, 0.18662352, 0.27770072, 0.15210356,\n",
      "       0.33811065, 0.33734011, 0.33287101]), 'split2_test_score': array([0.35403822, 0.38918002, 0.29454377, 0.32521578, 0.09972256,\n",
      "       0.36451911, 0.37993218, 0.1345561 ]), 'mean_test_score': array([0.31937916, 0.38364356, 0.21468611, 0.28680974, 0.12005444,\n",
      "       0.34336901, 0.35497919, 0.20003773]), 'std_test_score': array([0.02885188, 0.00391538, 0.05729306, 0.02838024, 0.02293342,\n",
      "       0.01557267, 0.01814095, 0.09393041]), 'rank_test_score': array([4, 1, 6, 5, 8, 3, 2, 7])}\n"
     ]
    }
   ],
   "source": [
    "# Non-linear\n",
    "svm = SVC()\n",
    "\n",
    "params = {\n",
    "    'SVM__C': [0.01, 0.1, 1, 2, 5],\n",
    "    'SVM__kernel': [\"rbf\", \"sigmoid\"],\n",
    "    'SVM__gamma': [\"scale\", \"auto\"],\n",
    "    'SVM__class_weight': [\"balanced\"],\n",
    "}\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"SVM\", svm)])\n",
    "\n",
    "rscv = RandomizedSearchCV(pipe, params, scoring=\"accuracy\", cv=StratifiedKFold(3), n_iter=8)\n",
    "rscv.fit(X_train, y_train)\n",
    "\n",
    "print(rscv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02852ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(feature_range=(-1, 1))),\n",
      "                ('SVM', SVC(C=5, class_weight='balanced'))])\n",
      "0.38773594743977474\n"
     ]
    }
   ],
   "source": [
    "print(rscv.best_estimator_)\n",
    "print(rscv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f6188f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int64),\n",
       " array([ 189, 1907, 1601, 1941,  262, 1188,  332, 1194,  975], dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rscv.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fbaf411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(rscv.best_estimator_[1], X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da4fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.04409695, 0.05485376, 0.12265118, 0.21149898, 0.40543787]), 'std_fit_time': array([0.00481769, 0.0112835 , 0.01144422, 0.01508004, 0.01632739]), 'mean_score_time': array([0.0031565 , 0.00166265, 0.00098499, 0.00199596, 0.00162911]), 'std_score_time': array([1.61877980e-03, 4.71936327e-04, 2.13162151e-05, 1.25153985e-06,\n",
      "       4.71889859e-04]), 'param_SVM__C': masked_array(data=[0.01, 0.1, 1, 2, 5],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced'],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__loss': masked_array(data=['hinge', 'hinge', 'hinge', 'hinge', 'hinge'],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__max_iter': masked_array(data=[300000, 300000, 300000, 300000, 300000],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2'],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__tol': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'SVM__C': 0.01, 'SVM__class_weight': 'balanced', 'SVM__loss': 'hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 0.1, 'SVM__class_weight': 'balanced', 'SVM__loss': 'hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__loss': 'hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 2, 'SVM__class_weight': 'balanced', 'SVM__loss': 'hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 5, 'SVM__class_weight': 'balanced', 'SVM__loss': 'hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}], 'split0_test_score': array([0.09292649, 0.32901834, 0.20141778, 0.27353984, 0.31206657]), 'split1_test_score': array([0.07458776, 0.27754662, 0.2505779 , 0.12390199, 0.07566651]), 'split2_test_score': array([0.26263872, 0.27928483, 0.32660296, 0.11174476, 0.28175092]), 'mean_test_score': array([0.14338432, 0.29528326, 0.25953288, 0.16972886, 0.22316134]), 'std_test_score': array([0.08465729, 0.02386485, 0.05149742, 0.07357304, 0.10502635]), 'rank_test_score': array([5, 1, 2, 4, 3])}\n"
     ]
    }
   ],
   "source": [
    "# Linear L2, Hinge loss\n",
    "svm_h = LinearSVC()\n",
    "\n",
    "params = {\n",
    "    'SVM__C': [0.01, 0.1, 1, 2, 5],\n",
    "    'SVM__penalty': [\"l2\"],\n",
    "    'SVM__loss': [\"hinge\"],\n",
    "    'SVM__class_weight': [\"balanced\"],\n",
    "    'SVM__max_iter': [300000],\n",
    "    'SVM__tol': [1e-4],\n",
    "}\n",
    "\n",
    "pipe_h = Pipeline(steps=[(\"scaler\", scaler), (\"SVM\", svm_h)])\n",
    "\n",
    "grid_h = GridSearchCV(pipe_h, params, scoring=\"accuracy\", cv=StratifiedKFold(3), error_score=\"raise\")\n",
    "grid_h.fit(X_train, y_train)\n",
    "\n",
    "print(grid_h.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c71386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.1, class_weight='balanced', loss='hinge', max_iter=300000)\n",
      "0.21576806757743247\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int64), array([1015,  593,  665, 3188,  917,    1,  400,  509, 2301], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(grid_h.best_estimator_[1])\n",
    "print(grid_h.score(X_test, y_test))\n",
    "print(np.unique(grid_h.predict(X_test), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ee45116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 0.76792741,  0.10354416,  7.68747131,  0.12187958, 30.17026552,\n",
      "        0.12201929, 36.39457726,  0.15759913, 52.48580082,  0.1169068 ]), 'std_fit_time': array([1.75139162e-01, 6.42500111e-03, 5.15805340e+00, 3.75949794e-03,\n",
      "       1.43181333e+01, 9.27832967e-03, 8.23775972e+00, 3.18524064e-02,\n",
      "       1.34238709e+01, 3.15884399e-03]), 'mean_score_time': array([0.00131647, 0.00131671, 0.00156641, 0.00198142, 0.00146675,\n",
      "       0.00199374, 0.0019838 , 0.00198809, 0.00200669, 0.0019722 ]), 'std_score_time': array([4.79859364e-04, 4.78692987e-04, 4.19783740e-04, 1.61636934e-05,\n",
      "       4.10106616e-04, 2.95897426e-05, 8.31072640e-04, 8.71089251e-06,\n",
      "       3.65355675e-05, 1.69293980e-05]), 'param_SVM__C': masked_array(data=[0.01, 0.01, 0.1, 0.1, 1, 1, 2, 2, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__dual': masked_array(data=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__loss': masked_array(data=['squared_hinge', 'squared_hinge', 'squared_hinge',\n",
      "                   'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
      "                   'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
      "                   'squared_hinge'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__max_iter': masked_array(data=[300000, 300000, 300000, 300000, 300000, 300000, 300000,\n",
      "                   300000, 300000, 300000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVM__tol': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "                   0.0001, 0.0001, 0.0001],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'SVM__C': 0.01, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l1', 'SVM__tol': 0.0001}, {'SVM__C': 0.01, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 0.1, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l1', 'SVM__tol': 0.0001}, {'SVM__C': 0.1, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l1', 'SVM__tol': 0.0001}, {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 2, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l1', 'SVM__tol': 0.0001}, {'SVM__C': 2, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}, {'SVM__C': 5, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l1', 'SVM__tol': 0.0001}, {'SVM__C': 5, 'SVM__class_weight': 'balanced', 'SVM__dual': False, 'SVM__loss': 'squared_hinge', 'SVM__max_iter': 300000, 'SVM__penalty': 'l2', 'SVM__tol': 0.0001}], 'split0_test_score': array([0.39944521, 0.42548929, 0.44012945, 0.44136231, 0.44506087,\n",
      "       0.44521498, 0.44536909, 0.44521498, 0.44521498, 0.44506087]), 'split1_test_score': array([0.4123902 , 0.43781785, 0.44891355, 0.44737248, 0.44968408,\n",
      "       0.44968408, 0.44983819, 0.45030051, 0.4501464 , 0.4501464 ]), 'split2_test_score': array([0.39827374, 0.42247226, 0.43603576, 0.43418619, 0.43819359,\n",
      "       0.43834772, 0.43881011, 0.43896424, 0.43911837, 0.43881011]), 'mean_test_score': array([0.40336972, 0.42859313, 0.44169292, 0.44097366, 0.44431285,\n",
      "       0.44441559, 0.44467246, 0.44482658, 0.44482658, 0.44467246]), 'std_test_score': array([0.00639635, 0.00663813, 0.00537232, 0.00539029, 0.0047207 ,\n",
      "       0.00466244, 0.00452906, 0.00463615, 0.00451054, 0.00463616]), 'rank_test_score': array([10,  9,  7,  8,  6,  5,  3,  2,  1,  3])}\n"
     ]
    }
   ],
   "source": [
    "# Linear Squared_hinge\n",
    "svm_sh = LinearSVC()\n",
    "\n",
    "params = {\n",
    "    'SVM__C': [0.01, 0.1, 1, 2, 5],\n",
    "    'SVM__penalty': [\"l1\", \"l2\"],\n",
    "    'SVM__dual': [False],\n",
    "    'SVM__loss': [\"squared_hinge\"],\n",
    "    'SVM__class_weight': [\"balanced\"],\n",
    "    'SVM__max_iter': [300000],\n",
    "    'SVM__tol': [1e-4],\n",
    "}\n",
    "\n",
    "pipe_sh = Pipeline(steps=[(\"scaler\", scaler), (\"SVM\", svm_sh)])\n",
    "\n",
    "grid_sh = GridSearchCV(pipe_sh, params, scoring=\"accuracy\", cv=StratifiedKFold(3), error_score=\"raise\")\n",
    "grid_sh.fit(X_train, y_train)\n",
    "\n",
    "print(grid_sh.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cb2e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=5, class_weight='balanced', dual=False, max_iter=300000,\n",
      "          penalty='l1')\n",
      "0.44926478256335384\n",
      "(array([0, 1, 2, 3, 4, 5, 7], dtype=int64), array([ 612, 3496, 2134, 2169,  490,  652,   36], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(grid_sh.best_estimator_[1])\n",
    "print(grid_sh.score(X_test, y_test))\n",
    "print(np.unique(grid_sh.predict(X_test), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70c4eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(grid_sh.best_estimator_[1], \n",
    "                                                             X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da1596",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8063069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(8, )))\n",
    "#     for i in range(hp.Int(\"n_layers\", 1, 3)):\n",
    "    model.add(Dense(hp.Int(\"n_neurons\", 64, 208, 16), activation=\"softmax\"))\n",
    "    model.add(Dense(8, activation=\"softmax\"))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-3, 1e-4, 1e-5])\n",
    "    hp_beta_1 = hp.Choice(\"beta_1\", values=[0.9, 0.85, 0.95])\n",
    "    hp_beta_2 = hp.Choice(\"beta_2\", values=[0.999, 0.99, 0.9999])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate, beta_1=hp_beta_1, beta_2=hp_beta_2), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "853f672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10)\n",
    "tuner = RandomSearch(build_model, objective=\"val_accuracy\", max_trials=100, overwrite=False)\n",
    "tuner.search(x=X_train, y=y_train, epochs=120, batch_size=10, validation_data=(X_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e43bf94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 128\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.99\n",
      "Score: 0.5083950161933899\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 96\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.95\n",
      "beta_2: 0.9999\n",
      "Score: 0.5020335912704468\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 96\n",
      "learning_rate: 0.0001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "Score: 0.490353524684906\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 160\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "Score: 0.3541558086872101\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 176\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.9999\n",
      "Score: 0.35405153036117554\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 112\n",
      "learning_rate: 1e-05\n",
      "beta_1: 0.85\n",
      "beta_2: 0.999\n",
      "Score: 0.3539472222328186\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 160\n",
      "learning_rate: 1e-05\n",
      "beta_1: 0.95\n",
      "beta_2: 0.99\n",
      "Score: 0.35384294390678406\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 2\n",
      "n_neurons: 176\n",
      "learning_rate: 0.001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.99\n",
      "Score: 0.3537386655807495\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 3\n",
      "n_neurons: 64\n",
      "learning_rate: 0.0001\n",
      "beta_1: 0.9\n",
      "beta_2: 0.999\n",
      "Score: 0.3537386655807495\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 2\n",
      "n_neurons: 192\n",
      "learning_rate: 1e-05\n",
      "beta_1: 0.95\n",
      "beta_2: 0.999\n",
      "Score: 0.3537386655807495\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a7ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_a(act=\"softmax\", opt=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.95, beta_2=0.99)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(128, activation=act, input_shape=(8, )))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27666ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_b(act=\"softmax\", opt=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.95, beta_2=0.9999)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(96, activation=act, input_shape=(8, )))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4237778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_c(act=\"softmax\", opt=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.99)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(96, activation=act, input_shape=(8, )))\n",
    "    model.add(Dense(8, activation=act))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "140491e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59653f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6699 - accuracy: 0.3620 - val_loss: 1.6581 - val_accuracy: 0.3649\n",
      "Epoch 2/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6636 - accuracy: 0.3667 - val_loss: 1.6520 - val_accuracy: 0.3726\n",
      "Epoch 3/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6588 - accuracy: 0.3699 - val_loss: 1.6500 - val_accuracy: 0.3742\n",
      "Epoch 4/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6545 - accuracy: 0.3700 - val_loss: 1.6397 - val_accuracy: 0.3711\n",
      "Epoch 5/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6445 - accuracy: 0.3718 - val_loss: 1.6368 - val_accuracy: 0.3657\n",
      "Epoch 6/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6369 - accuracy: 0.3734 - val_loss: 1.6227 - val_accuracy: 0.3695\n",
      "Epoch 7/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6252 - accuracy: 0.3795 - val_loss: 1.6116 - val_accuracy: 0.3734\n",
      "Epoch 8/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6108 - accuracy: 0.3890 - val_loss: 1.6107 - val_accuracy: 0.3819\n",
      "Epoch 9/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6000 - accuracy: 0.3940 - val_loss: 1.5830 - val_accuracy: 0.3980\n",
      "Epoch 10/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5823 - accuracy: 0.4065 - val_loss: 1.5702 - val_accuracy: 0.4199\n",
      "Epoch 11/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5696 - accuracy: 0.4118 - val_loss: 1.5562 - val_accuracy: 0.4171\n",
      "Epoch 12/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5544 - accuracy: 0.4227 - val_loss: 1.5420 - val_accuracy: 0.4335\n",
      "Epoch 13/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5423 - accuracy: 0.4277 - val_loss: 1.5334 - val_accuracy: 0.4366\n",
      "Epoch 14/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5314 - accuracy: 0.4402 - val_loss: 1.5226 - val_accuracy: 0.4345\n",
      "Epoch 15/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5221 - accuracy: 0.4443 - val_loss: 1.5137 - val_accuracy: 0.4314\n",
      "Epoch 16/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5130 - accuracy: 0.4502 - val_loss: 1.5204 - val_accuracy: 0.4497\n",
      "Epoch 17/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5059 - accuracy: 0.4538 - val_loss: 1.5118 - val_accuracy: 0.4330\n",
      "Epoch 18/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5009 - accuracy: 0.4550 - val_loss: 1.5246 - val_accuracy: 0.4530\n",
      "Epoch 19/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4947 - accuracy: 0.4587 - val_loss: 1.4895 - val_accuracy: 0.4640\n",
      "Epoch 20/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4893 - accuracy: 0.4601 - val_loss: 1.5081 - val_accuracy: 0.4515\n",
      "Epoch 21/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4805 - accuracy: 0.4635 - val_loss: 1.4854 - val_accuracy: 0.4489\n",
      "Epoch 22/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4762 - accuracy: 0.4635 - val_loss: 1.4826 - val_accuracy: 0.4748\n",
      "Epoch 23/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4734 - accuracy: 0.4695 - val_loss: 1.4720 - val_accuracy: 0.4779\n",
      "Epoch 24/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4692 - accuracy: 0.4672 - val_loss: 1.4653 - val_accuracy: 0.4684\n",
      "Epoch 25/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4655 - accuracy: 0.4735 - val_loss: 1.4769 - val_accuracy: 0.4774\n",
      "Epoch 26/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4632 - accuracy: 0.4750 - val_loss: 1.4591 - val_accuracy: 0.4687\n",
      "Epoch 27/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4633 - accuracy: 0.4688 - val_loss: 1.4495 - val_accuracy: 0.4687\n",
      "Epoch 28/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4501 - accuracy: 0.4739 - val_loss: 1.4442 - val_accuracy: 0.4710\n",
      "Epoch 29/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4447 - accuracy: 0.4755 - val_loss: 1.4571 - val_accuracy: 0.4579\n",
      "Epoch 30/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4393 - accuracy: 0.4770 - val_loss: 1.4321 - val_accuracy: 0.4797\n",
      "Epoch 31/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4410 - accuracy: 0.4769 - val_loss: 1.4676 - val_accuracy: 0.4548\n",
      "Epoch 32/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4323 - accuracy: 0.4788 - val_loss: 1.4483 - val_accuracy: 0.4648\n",
      "Epoch 33/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4304 - accuracy: 0.4765 - val_loss: 1.4355 - val_accuracy: 0.4810\n",
      "Epoch 34/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4272 - accuracy: 0.4772 - val_loss: 1.4343 - val_accuracy: 0.4759\n",
      "Epoch 35/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4190 - accuracy: 0.4835 - val_loss: 1.4364 - val_accuracy: 0.4751\n",
      "Epoch 36/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4166 - accuracy: 0.4817 - val_loss: 1.4297 - val_accuracy: 0.4715\n",
      "Epoch 37/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4149 - accuracy: 0.4841 - val_loss: 1.4244 - val_accuracy: 0.4795\n",
      "Epoch 38/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4178 - accuracy: 0.4833 - val_loss: 1.4122 - val_accuracy: 0.4879\n",
      "Epoch 39/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4127 - accuracy: 0.4833 - val_loss: 1.4114 - val_accuracy: 0.4892\n",
      "Epoch 40/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4069 - accuracy: 0.4846 - val_loss: 1.4198 - val_accuracy: 0.4748\n",
      "Epoch 41/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4077 - accuracy: 0.4835 - val_loss: 1.4193 - val_accuracy: 0.4933\n",
      "Epoch 42/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4035 - accuracy: 0.4881 - val_loss: 1.4301 - val_accuracy: 0.4725\n",
      "Epoch 43/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4002 - accuracy: 0.4857 - val_loss: 1.4032 - val_accuracy: 0.4908\n",
      "Epoch 44/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4025 - accuracy: 0.4891 - val_loss: 1.4239 - val_accuracy: 0.4777\n",
      "Epoch 45/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4024 - accuracy: 0.4857 - val_loss: 1.3991 - val_accuracy: 0.4956\n",
      "Epoch 46/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3969 - accuracy: 0.4904 - val_loss: 1.4022 - val_accuracy: 0.4941\n",
      "Epoch 47/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3928 - accuracy: 0.4918 - val_loss: 1.4069 - val_accuracy: 0.4964\n",
      "Epoch 48/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3949 - accuracy: 0.4923 - val_loss: 1.3906 - val_accuracy: 0.5018\n",
      "Epoch 49/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3876 - accuracy: 0.4955 - val_loss: 1.3993 - val_accuracy: 0.4900\n",
      "Epoch 50/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3884 - accuracy: 0.4938 - val_loss: 1.3967 - val_accuracy: 0.4908\n",
      "Epoch 51/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3869 - accuracy: 0.4953 - val_loss: 1.3968 - val_accuracy: 0.4972\n",
      "Epoch 52/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3885 - accuracy: 0.4939 - val_loss: 1.3895 - val_accuracy: 0.5031\n",
      "Epoch 53/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3867 - accuracy: 0.4939 - val_loss: 1.3815 - val_accuracy: 0.4992\n",
      "Epoch 54/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3841 - accuracy: 0.4959 - val_loss: 1.3942 - val_accuracy: 0.4982\n",
      "Epoch 55/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3841 - accuracy: 0.4977 - val_loss: 1.4049 - val_accuracy: 0.4923\n",
      "Epoch 56/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3796 - accuracy: 0.4957 - val_loss: 1.3965 - val_accuracy: 0.4856\n",
      "Epoch 57/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3796 - accuracy: 0.4958 - val_loss: 1.3875 - val_accuracy: 0.4918\n",
      "Epoch 58/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3780 - accuracy: 0.5010 - val_loss: 1.3780 - val_accuracy: 0.4956\n",
      "Epoch 59/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3743 - accuracy: 0.4956 - val_loss: 1.3724 - val_accuracy: 0.5033\n",
      "Epoch 60/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3743 - accuracy: 0.4990 - val_loss: 1.3792 - val_accuracy: 0.4918\n",
      "Epoch 61/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3727 - accuracy: 0.4993 - val_loss: 1.3742 - val_accuracy: 0.4977\n",
      "Epoch 62/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3730 - accuracy: 0.5006 - val_loss: 1.3804 - val_accuracy: 0.5046\n",
      "Epoch 63/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3708 - accuracy: 0.4995 - val_loss: 1.3880 - val_accuracy: 0.4974\n",
      "Epoch 64/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3703 - accuracy: 0.5011 - val_loss: 1.3828 - val_accuracy: 0.4959\n",
      "Epoch 65/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3780 - accuracy: 0.4939 - val_loss: 1.3653 - val_accuracy: 0.5039\n",
      "Epoch 66/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3665 - accuracy: 0.5044 - val_loss: 1.3674 - val_accuracy: 0.4944\n",
      "Epoch 67/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3639 - accuracy: 0.5005 - val_loss: 1.3715 - val_accuracy: 0.5033\n",
      "Epoch 68/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3640 - accuracy: 0.4983 - val_loss: 1.3655 - val_accuracy: 0.5000\n",
      "Epoch 69/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3639 - accuracy: 0.5021 - val_loss: 1.3691 - val_accuracy: 0.4946\n",
      "Epoch 70/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3643 - accuracy: 0.4987 - val_loss: 1.3799 - val_accuracy: 0.4926\n",
      "Epoch 71/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3646 - accuracy: 0.4988 - val_loss: 1.3650 - val_accuracy: 0.5046\n",
      "Epoch 72/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3663 - accuracy: 0.5005 - val_loss: 1.3647 - val_accuracy: 0.5026\n",
      "Epoch 73/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3602 - accuracy: 0.5000 - val_loss: 1.3768 - val_accuracy: 0.4887\n",
      "Epoch 74/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3636 - accuracy: 0.4984 - val_loss: 1.3846 - val_accuracy: 0.4805\n",
      "Epoch 75/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3624 - accuracy: 0.5028 - val_loss: 1.3878 - val_accuracy: 0.4956\n",
      "Epoch 76/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3582 - accuracy: 0.5008 - val_loss: 1.3523 - val_accuracy: 0.5090\n",
      "Epoch 77/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3588 - accuracy: 0.4995 - val_loss: 1.3686 - val_accuracy: 0.4941\n",
      "Epoch 78/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3593 - accuracy: 0.5005 - val_loss: 1.3660 - val_accuracy: 0.4972\n",
      "Epoch 79/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3532 - accuracy: 0.5054 - val_loss: 1.3729 - val_accuracy: 0.4977\n",
      "Epoch 80/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3512 - accuracy: 0.5025 - val_loss: 1.3785 - val_accuracy: 0.4967\n",
      "Epoch 81/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3531 - accuracy: 0.5040 - val_loss: 1.3522 - val_accuracy: 0.5021\n",
      "Epoch 82/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3521 - accuracy: 0.5012 - val_loss: 1.3699 - val_accuracy: 0.4933\n",
      "Epoch 83/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3507 - accuracy: 0.5058 - val_loss: 1.3795 - val_accuracy: 0.4951\n",
      "Epoch 84/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3520 - accuracy: 0.5039 - val_loss: 1.3498 - val_accuracy: 0.5046\n",
      "Epoch 85/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3445 - accuracy: 0.5058 - val_loss: 1.4079 - val_accuracy: 0.4777\n",
      "Epoch 86/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3527 - accuracy: 0.5029 - val_loss: 1.3537 - val_accuracy: 0.5041\n",
      "Epoch 87/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3516 - accuracy: 0.5021 - val_loss: 1.4046 - val_accuracy: 0.4774\n",
      "Epoch 88/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3458 - accuracy: 0.5053 - val_loss: 1.3455 - val_accuracy: 0.5108\n",
      "Epoch 89/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3459 - accuracy: 0.5061 - val_loss: 1.3574 - val_accuracy: 0.4977\n",
      "Epoch 90/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3414 - accuracy: 0.5070 - val_loss: 1.3661 - val_accuracy: 0.4884\n",
      "Epoch 91/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3457 - accuracy: 0.5077 - val_loss: 1.3622 - val_accuracy: 0.5008\n",
      "Epoch 92/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3479 - accuracy: 0.5048 - val_loss: 1.3411 - val_accuracy: 0.5046\n",
      "Epoch 93/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3403 - accuracy: 0.5065 - val_loss: 1.3426 - val_accuracy: 0.5051\n",
      "Epoch 94/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3402 - accuracy: 0.5087 - val_loss: 1.3435 - val_accuracy: 0.5082\n",
      "Epoch 95/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3422 - accuracy: 0.5038 - val_loss: 1.3944 - val_accuracy: 0.4915\n",
      "Epoch 96/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3410 - accuracy: 0.5071 - val_loss: 1.3381 - val_accuracy: 0.5123\n",
      "Epoch 97/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3411 - accuracy: 0.5050 - val_loss: 1.3572 - val_accuracy: 0.5064\n",
      "Epoch 98/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3400 - accuracy: 0.5057 - val_loss: 1.3358 - val_accuracy: 0.5098\n",
      "Epoch 99/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3393 - accuracy: 0.5060 - val_loss: 1.3477 - val_accuracy: 0.5080\n",
      "Epoch 100/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3420 - accuracy: 0.5068 - val_loss: 1.3770 - val_accuracy: 0.4936\n",
      "Epoch 101/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3417 - accuracy: 0.5042 - val_loss: 1.3429 - val_accuracy: 0.5005\n",
      "Epoch 102/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3375 - accuracy: 0.5085 - val_loss: 1.3327 - val_accuracy: 0.5072\n",
      "Epoch 103/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3371 - accuracy: 0.5077 - val_loss: 1.3489 - val_accuracy: 0.5018\n",
      "Epoch 104/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3350 - accuracy: 0.5108 - val_loss: 1.3594 - val_accuracy: 0.5067\n",
      "Epoch 105/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3452 - accuracy: 0.5056 - val_loss: 1.3725 - val_accuracy: 0.4992\n",
      "Epoch 106/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3387 - accuracy: 0.5096 - val_loss: 1.3324 - val_accuracy: 0.5164\n",
      "Epoch 107/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3321 - accuracy: 0.5114 - val_loss: 1.3304 - val_accuracy: 0.5092\n",
      "Epoch 108/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3363 - accuracy: 0.5070 - val_loss: 1.3835 - val_accuracy: 0.4961\n",
      "Epoch 109/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3332 - accuracy: 0.5080 - val_loss: 1.3489 - val_accuracy: 0.4982\n",
      "Epoch 110/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3380 - accuracy: 0.5080 - val_loss: 1.3327 - val_accuracy: 0.5154\n",
      "Epoch 111/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3354 - accuracy: 0.5088 - val_loss: 1.3373 - val_accuracy: 0.5059\n",
      "Epoch 112/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3306 - accuracy: 0.5110 - val_loss: 1.3361 - val_accuracy: 0.5100\n",
      "Epoch 113/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3294 - accuracy: 0.5139 - val_loss: 1.3579 - val_accuracy: 0.5044\n",
      "Epoch 114/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3326 - accuracy: 0.5100 - val_loss: 1.3345 - val_accuracy: 0.5152\n",
      "Epoch 115/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3354 - accuracy: 0.5085 - val_loss: 1.3431 - val_accuracy: 0.5008\n",
      "Epoch 116/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3277 - accuracy: 0.5097 - val_loss: 1.3253 - val_accuracy: 0.5113\n",
      "Epoch 117/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3330 - accuracy: 0.5110 - val_loss: 1.3634 - val_accuracy: 0.5051\n",
      "Epoch 118/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3275 - accuracy: 0.5146 - val_loss: 1.3466 - val_accuracy: 0.5018\n",
      "Epoch 119/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3316 - accuracy: 0.5122 - val_loss: 1.3290 - val_accuracy: 0.5095\n",
      "Epoch 120/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3301 - accuracy: 0.5107 - val_loss: 1.3299 - val_accuracy: 0.5139\n",
      "Epoch 121/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3250 - accuracy: 0.5140 - val_loss: 1.3402 - val_accuracy: 0.5041\n",
      "Epoch 122/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3322 - accuracy: 0.5083 - val_loss: 1.3422 - val_accuracy: 0.5033\n",
      "Epoch 123/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3249 - accuracy: 0.5124 - val_loss: 1.3240 - val_accuracy: 0.5167\n",
      "Epoch 124/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3211 - accuracy: 0.5131 - val_loss: 1.3488 - val_accuracy: 0.5118\n",
      "Epoch 125/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3245 - accuracy: 0.5104 - val_loss: 1.3551 - val_accuracy: 0.4946\n",
      "Epoch 126/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5156 - val_loss: 1.3294 - val_accuracy: 0.5095\n",
      "Epoch 127/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3249 - accuracy: 0.5139 - val_loss: 1.3443 - val_accuracy: 0.5144\n",
      "Epoch 128/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3282 - accuracy: 0.5117 - val_loss: 1.3222 - val_accuracy: 0.5105\n",
      "Epoch 129/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3278 - accuracy: 0.5130 - val_loss: 1.3171 - val_accuracy: 0.5172\n",
      "Epoch 130/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3264 - accuracy: 0.5153 - val_loss: 1.3231 - val_accuracy: 0.5136\n",
      "Epoch 131/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3263 - accuracy: 0.5108 - val_loss: 1.3274 - val_accuracy: 0.5141\n",
      "Epoch 132/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3212 - accuracy: 0.5167 - val_loss: 1.3274 - val_accuracy: 0.5100\n",
      "Epoch 133/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3243 - accuracy: 0.5134 - val_loss: 1.3264 - val_accuracy: 0.5064\n",
      "Epoch 134/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3180 - accuracy: 0.5134 - val_loss: 1.3172 - val_accuracy: 0.5182\n",
      "Epoch 135/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3185 - accuracy: 0.5144 - val_loss: 1.3323 - val_accuracy: 0.5190\n",
      "Epoch 136/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3184 - accuracy: 0.5167 - val_loss: 1.3270 - val_accuracy: 0.5144\n",
      "Epoch 137/750\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.3218 - accuracy: 0.5160 - val_loss: 1.3224 - val_accuracy: 0.5159\n",
      "Epoch 138/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3190 - accuracy: 0.5159 - val_loss: 1.3205 - val_accuracy: 0.5098\n",
      "Epoch 139/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3186 - accuracy: 0.5154 - val_loss: 1.3137 - val_accuracy: 0.5177\n",
      "Epoch 140/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3171 - accuracy: 0.5168 - val_loss: 1.3204 - val_accuracy: 0.5244\n",
      "Epoch 141/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3160 - accuracy: 0.5173 - val_loss: 1.3173 - val_accuracy: 0.5167\n",
      "Epoch 142/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3184 - accuracy: 0.5169 - val_loss: 1.3336 - val_accuracy: 0.5211\n",
      "Epoch 143/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3161 - accuracy: 0.5179 - val_loss: 1.3270 - val_accuracy: 0.5134\n",
      "Epoch 144/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3153 - accuracy: 0.5180 - val_loss: 1.3158 - val_accuracy: 0.5113\n",
      "Epoch 145/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3148 - accuracy: 0.5173 - val_loss: 1.3236 - val_accuracy: 0.5090\n",
      "Epoch 146/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3135 - accuracy: 0.5171 - val_loss: 1.3788 - val_accuracy: 0.4977\n",
      "Epoch 147/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3165 - accuracy: 0.5179 - val_loss: 1.3251 - val_accuracy: 0.5108\n",
      "Epoch 148/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3123 - accuracy: 0.5189 - val_loss: 1.3577 - val_accuracy: 0.5095\n",
      "Epoch 149/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3157 - accuracy: 0.5174 - val_loss: 1.3119 - val_accuracy: 0.5190\n",
      "Epoch 150/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3176 - accuracy: 0.5170 - val_loss: 1.3270 - val_accuracy: 0.5205\n",
      "Epoch 151/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3104 - accuracy: 0.5196 - val_loss: 1.3155 - val_accuracy: 0.5198\n",
      "Epoch 152/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3100 - accuracy: 0.5223 - val_loss: 1.3338 - val_accuracy: 0.5157\n",
      "Epoch 153/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3121 - accuracy: 0.5202 - val_loss: 1.3156 - val_accuracy: 0.5154\n",
      "Epoch 154/750\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.3145 - accuracy: 0.5164 - val_loss: 1.3335 - val_accuracy: 0.5185\n",
      "Epoch 155/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3165 - accuracy: 0.5136 - val_loss: 1.3152 - val_accuracy: 0.5159\n",
      "Epoch 156/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3101 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5177\n",
      "Epoch 157/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3128 - accuracy: 0.5193 - val_loss: 1.3233 - val_accuracy: 0.5195\n",
      "Epoch 158/750\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.3117 - accuracy: 0.5169 - val_loss: 1.3468 - val_accuracy: 0.5010\n",
      "Epoch 159/750\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.3123 - accuracy: 0.5192 - val_loss: 1.3424 - val_accuracy: 0.5141\n",
      "Epoch 160/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3090 - accuracy: 0.5202 - val_loss: 1.3148 - val_accuracy: 0.5169\n",
      "Epoch 161/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3101 - accuracy: 0.5202 - val_loss: 1.3170 - val_accuracy: 0.5193\n",
      "Epoch 162/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3113 - accuracy: 0.5192 - val_loss: 1.3115 - val_accuracy: 0.5262\n",
      "Epoch 163/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3096 - accuracy: 0.5177 - val_loss: 1.3178 - val_accuracy: 0.5103\n",
      "Epoch 164/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3088 - accuracy: 0.5189 - val_loss: 1.3303 - val_accuracy: 0.5056\n",
      "Epoch 165/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3053 - accuracy: 0.5221 - val_loss: 1.3285 - val_accuracy: 0.5139\n",
      "Epoch 166/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3052 - accuracy: 0.5247 - val_loss: 1.3331 - val_accuracy: 0.5211\n",
      "Epoch 167/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3091 - accuracy: 0.5250 - val_loss: 1.3185 - val_accuracy: 0.5218\n",
      "Epoch 168/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3093 - accuracy: 0.5217 - val_loss: 1.3162 - val_accuracy: 0.5162\n",
      "Epoch 169/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3055 - accuracy: 0.5208 - val_loss: 1.3057 - val_accuracy: 0.5208\n",
      "Epoch 170/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3136 - accuracy: 0.5187 - val_loss: 1.3374 - val_accuracy: 0.5067\n",
      "Epoch 171/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3081 - accuracy: 0.5215 - val_loss: 1.3122 - val_accuracy: 0.5316\n",
      "Epoch 172/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3036 - accuracy: 0.5242 - val_loss: 1.3124 - val_accuracy: 0.5241\n",
      "Epoch 173/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3034 - accuracy: 0.5192 - val_loss: 1.3262 - val_accuracy: 0.5159\n",
      "Epoch 174/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3048 - accuracy: 0.5221 - val_loss: 1.3094 - val_accuracy: 0.5249\n",
      "Epoch 175/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3042 - accuracy: 0.5190 - val_loss: 1.3138 - val_accuracy: 0.5149\n",
      "Epoch 176/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3049 - accuracy: 0.5224 - val_loss: 1.3309 - val_accuracy: 0.5044\n",
      "Epoch 177/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3032 - accuracy: 0.5209 - val_loss: 1.3408 - val_accuracy: 0.5146\n",
      "Epoch 178/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3041 - accuracy: 0.5209 - val_loss: 1.3172 - val_accuracy: 0.5195\n",
      "Epoch 179/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3044 - accuracy: 0.5194 - val_loss: 1.3103 - val_accuracy: 0.5216\n",
      "Epoch 180/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3063 - accuracy: 0.5194 - val_loss: 1.3071 - val_accuracy: 0.5218\n",
      "Epoch 181/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3021 - accuracy: 0.5229 - val_loss: 1.3230 - val_accuracy: 0.5167\n",
      "Epoch 182/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2995 - accuracy: 0.5231 - val_loss: 1.3108 - val_accuracy: 0.5306\n",
      "Epoch 183/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3070 - accuracy: 0.5149 - val_loss: 1.3072 - val_accuracy: 0.5270\n",
      "Epoch 184/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3040 - accuracy: 0.5205 - val_loss: 1.3038 - val_accuracy: 0.5244\n",
      "Epoch 185/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2992 - accuracy: 0.5231 - val_loss: 1.3025 - val_accuracy: 0.5290\n",
      "Epoch 186/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3023 - accuracy: 0.5237 - val_loss: 1.3049 - val_accuracy: 0.5213\n",
      "Epoch 187/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3008 - accuracy: 0.5209 - val_loss: 1.3146 - val_accuracy: 0.5290\n",
      "Epoch 188/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2988 - accuracy: 0.5228 - val_loss: 1.3073 - val_accuracy: 0.5275\n",
      "Epoch 189/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3059 - accuracy: 0.5215 - val_loss: 1.3169 - val_accuracy: 0.5205\n",
      "Epoch 190/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3017 - accuracy: 0.5231 - val_loss: 1.3114 - val_accuracy: 0.5180\n",
      "Epoch 191/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3010 - accuracy: 0.5208 - val_loss: 1.3434 - val_accuracy: 0.5064\n",
      "Epoch 192/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3020 - accuracy: 0.5222 - val_loss: 1.3025 - val_accuracy: 0.5239\n",
      "Epoch 193/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3004 - accuracy: 0.5200 - val_loss: 1.3119 - val_accuracy: 0.5223\n",
      "Epoch 194/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2939 - accuracy: 0.5256 - val_loss: 1.3152 - val_accuracy: 0.5231\n",
      "Epoch 195/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2963 - accuracy: 0.5233 - val_loss: 1.3094 - val_accuracy: 0.5244\n",
      "Epoch 196/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2920 - accuracy: 0.5245 - val_loss: 1.3004 - val_accuracy: 0.5252\n",
      "Epoch 197/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2978 - accuracy: 0.5232 - val_loss: 1.3321 - val_accuracy: 0.5167\n",
      "Epoch 198/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2990 - accuracy: 0.5217 - val_loss: 1.3237 - val_accuracy: 0.5146\n",
      "Epoch 199/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3005 - accuracy: 0.5205 - val_loss: 1.3084 - val_accuracy: 0.5190\n",
      "Epoch 200/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2947 - accuracy: 0.5268 - val_loss: 1.3264 - val_accuracy: 0.5162\n",
      "Epoch 201/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2979 - accuracy: 0.5211 - val_loss: 1.3010 - val_accuracy: 0.5241\n",
      "Epoch 202/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2953 - accuracy: 0.5258 - val_loss: 1.3013 - val_accuracy: 0.5231\n",
      "Epoch 203/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3034 - accuracy: 0.5210 - val_loss: 1.3182 - val_accuracy: 0.5098\n",
      "Epoch 204/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2981 - accuracy: 0.5246 - val_loss: 1.3021 - val_accuracy: 0.5329\n",
      "Epoch 205/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2970 - accuracy: 0.5241 - val_loss: 1.3316 - val_accuracy: 0.5136\n",
      "Epoch 206/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2982 - accuracy: 0.5238 - val_loss: 1.3373 - val_accuracy: 0.5121\n",
      "Epoch 207/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3007 - accuracy: 0.5212 - val_loss: 1.3221 - val_accuracy: 0.5195\n",
      "Epoch 208/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2950 - accuracy: 0.5234 - val_loss: 1.3209 - val_accuracy: 0.5234\n",
      "Epoch 209/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3010 - accuracy: 0.5202 - val_loss: 1.3070 - val_accuracy: 0.5216\n",
      "Epoch 210/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2941 - accuracy: 0.5232 - val_loss: 1.3050 - val_accuracy: 0.5316\n",
      "Epoch 211/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2929 - accuracy: 0.5252 - val_loss: 1.3037 - val_accuracy: 0.5352\n",
      "Epoch 212/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2976 - accuracy: 0.5238 - val_loss: 1.2993 - val_accuracy: 0.5254\n",
      "Epoch 213/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2913 - accuracy: 0.5227 - val_loss: 1.2982 - val_accuracy: 0.5216\n",
      "Epoch 214/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2893 - accuracy: 0.5238 - val_loss: 1.3004 - val_accuracy: 0.5318\n",
      "Epoch 215/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2921 - accuracy: 0.5255 - val_loss: 1.3073 - val_accuracy: 0.5218\n",
      "Epoch 216/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2888 - accuracy: 0.5257 - val_loss: 1.3026 - val_accuracy: 0.5190\n",
      "Epoch 217/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2919 - accuracy: 0.5244 - val_loss: 1.3143 - val_accuracy: 0.5193\n",
      "Epoch 218/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2956 - accuracy: 0.5205 - val_loss: 1.3008 - val_accuracy: 0.5275\n",
      "Epoch 219/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2979 - accuracy: 0.5228 - val_loss: 1.3173 - val_accuracy: 0.5134\n",
      "Epoch 220/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2894 - accuracy: 0.5268 - val_loss: 1.3011 - val_accuracy: 0.5249\n",
      "Epoch 221/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2971 - accuracy: 0.5264 - val_loss: 1.3163 - val_accuracy: 0.5259\n",
      "Epoch 222/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2925 - accuracy: 0.5230 - val_loss: 1.2968 - val_accuracy: 0.5234\n",
      "Epoch 223/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2877 - accuracy: 0.5278 - val_loss: 1.3026 - val_accuracy: 0.5280\n",
      "Epoch 224/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2869 - accuracy: 0.5263 - val_loss: 1.3074 - val_accuracy: 0.5311\n",
      "Epoch 225/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2914 - accuracy: 0.5248 - val_loss: 1.3014 - val_accuracy: 0.5280\n",
      "Epoch 226/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2881 - accuracy: 0.5242 - val_loss: 1.2967 - val_accuracy: 0.5259\n",
      "Epoch 227/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2912 - accuracy: 0.5270 - val_loss: 1.3004 - val_accuracy: 0.5198\n",
      "Epoch 228/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2886 - accuracy: 0.5251 - val_loss: 1.3195 - val_accuracy: 0.5100\n",
      "Epoch 229/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2927 - accuracy: 0.5246 - val_loss: 1.3032 - val_accuracy: 0.5190\n",
      "Epoch 230/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2887 - accuracy: 0.5281 - val_loss: 1.3288 - val_accuracy: 0.5167\n",
      "Epoch 231/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2962 - accuracy: 0.5199 - val_loss: 1.3007 - val_accuracy: 0.5300\n",
      "Epoch 232/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2866 - accuracy: 0.5285 - val_loss: 1.3032 - val_accuracy: 0.5324\n",
      "Epoch 233/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2886 - accuracy: 0.5284 - val_loss: 1.3115 - val_accuracy: 0.5123\n",
      "Epoch 234/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5268 - val_loss: 1.2969 - val_accuracy: 0.5270\n",
      "Epoch 235/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2909 - accuracy: 0.5251 - val_loss: 1.2998 - val_accuracy: 0.5277\n",
      "Epoch 236/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2899 - accuracy: 0.5270 - val_loss: 1.2931 - val_accuracy: 0.5303\n",
      "Epoch 237/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2866 - accuracy: 0.5297 - val_loss: 1.3156 - val_accuracy: 0.5180\n",
      "Epoch 238/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2860 - accuracy: 0.5281 - val_loss: 1.3030 - val_accuracy: 0.5308\n",
      "Epoch 239/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2862 - accuracy: 0.5284 - val_loss: 1.2939 - val_accuracy: 0.5249\n",
      "Epoch 240/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2824 - accuracy: 0.5299 - val_loss: 1.3144 - val_accuracy: 0.5208\n",
      "Epoch 241/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2878 - accuracy: 0.5258 - val_loss: 1.2999 - val_accuracy: 0.5203\n",
      "Epoch 242/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2906 - accuracy: 0.5245 - val_loss: 1.3214 - val_accuracy: 0.5198\n",
      "Epoch 243/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2845 - accuracy: 0.5264 - val_loss: 1.2963 - val_accuracy: 0.5331\n",
      "Epoch 244/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2889 - accuracy: 0.5269 - val_loss: 1.3201 - val_accuracy: 0.5334\n",
      "Epoch 245/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2908 - accuracy: 0.5258 - val_loss: 1.2897 - val_accuracy: 0.5280\n",
      "Epoch 246/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2921 - accuracy: 0.5246 - val_loss: 1.2999 - val_accuracy: 0.5313\n",
      "Epoch 247/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2847 - accuracy: 0.5281 - val_loss: 1.2930 - val_accuracy: 0.5247\n",
      "Epoch 248/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2848 - accuracy: 0.5265 - val_loss: 1.3005 - val_accuracy: 0.5223\n",
      "Epoch 249/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2831 - accuracy: 0.5275 - val_loss: 1.3137 - val_accuracy: 0.5236\n",
      "Epoch 250/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2871 - accuracy: 0.5290 - val_loss: 1.3010 - val_accuracy: 0.5190\n",
      "Epoch 251/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2843 - accuracy: 0.5258 - val_loss: 1.3078 - val_accuracy: 0.5295\n",
      "Epoch 252/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2826 - accuracy: 0.5268 - val_loss: 1.2996 - val_accuracy: 0.5324\n",
      "Epoch 253/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2887 - accuracy: 0.5250 - val_loss: 1.3255 - val_accuracy: 0.5213\n",
      "Epoch 254/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2887 - accuracy: 0.5246 - val_loss: 1.3204 - val_accuracy: 0.5205\n",
      "Epoch 255/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2863 - accuracy: 0.5256 - val_loss: 1.3100 - val_accuracy: 0.5247\n",
      "Epoch 256/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2844 - accuracy: 0.5303 - val_loss: 1.3024 - val_accuracy: 0.5164\n",
      "Epoch 257/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2856 - accuracy: 0.5314 - val_loss: 1.3525 - val_accuracy: 0.5131\n",
      "Epoch 258/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2875 - accuracy: 0.5242 - val_loss: 1.3077 - val_accuracy: 0.5229\n",
      "Epoch 259/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2860 - accuracy: 0.5286 - val_loss: 1.3004 - val_accuracy: 0.5218\n",
      "Epoch 260/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2823 - accuracy: 0.5292 - val_loss: 1.2906 - val_accuracy: 0.5329\n",
      "Epoch 261/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2858 - accuracy: 0.5278 - val_loss: 1.2938 - val_accuracy: 0.5336\n",
      "Epoch 262/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2840 - accuracy: 0.5281 - val_loss: 1.2992 - val_accuracy: 0.5244\n",
      "Epoch 263/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2837 - accuracy: 0.5298 - val_loss: 1.3036 - val_accuracy: 0.5169\n",
      "Epoch 264/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2812 - accuracy: 0.5274 - val_loss: 1.3134 - val_accuracy: 0.5182\n",
      "Epoch 265/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2879 - accuracy: 0.5252 - val_loss: 1.3006 - val_accuracy: 0.5213\n",
      "Epoch 266/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2851 - accuracy: 0.5294 - val_loss: 1.3270 - val_accuracy: 0.5205\n",
      "Epoch 267/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2827 - accuracy: 0.5273 - val_loss: 1.3238 - val_accuracy: 0.5282\n",
      "Epoch 268/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2806 - accuracy: 0.5291 - val_loss: 1.3035 - val_accuracy: 0.5360\n",
      "Epoch 269/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2851 - accuracy: 0.5261 - val_loss: 1.2938 - val_accuracy: 0.5293\n",
      "Epoch 270/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2833 - accuracy: 0.5254 - val_loss: 1.3343 - val_accuracy: 0.5077\n",
      "Epoch 271/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2822 - accuracy: 0.5286 - val_loss: 1.3231 - val_accuracy: 0.5241\n",
      "Epoch 272/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2812 - accuracy: 0.5298 - val_loss: 1.3042 - val_accuracy: 0.5203\n",
      "Epoch 273/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5268 - val_loss: 1.2900 - val_accuracy: 0.5316\n",
      "Epoch 274/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2812 - accuracy: 0.5268 - val_loss: 1.2927 - val_accuracy: 0.5198\n",
      "Epoch 275/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2882 - accuracy: 0.5271 - val_loss: 1.3186 - val_accuracy: 0.5218\n",
      "Epoch 276/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2803 - accuracy: 0.5265 - val_loss: 1.3087 - val_accuracy: 0.5200\n",
      "Epoch 277/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2831 - accuracy: 0.5290 - val_loss: 1.2928 - val_accuracy: 0.5349\n",
      "Epoch 278/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2814 - accuracy: 0.5283 - val_loss: 1.2987 - val_accuracy: 0.5244\n",
      "Epoch 279/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2817 - accuracy: 0.5307 - val_loss: 1.2869 - val_accuracy: 0.5321\n",
      "Epoch 280/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5274 - val_loss: 1.3026 - val_accuracy: 0.5282\n",
      "Epoch 281/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2809 - accuracy: 0.5298 - val_loss: 1.3203 - val_accuracy: 0.5187\n",
      "Epoch 282/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2815 - accuracy: 0.5289 - val_loss: 1.2995 - val_accuracy: 0.5221\n",
      "Epoch 283/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2834 - accuracy: 0.5268 - val_loss: 1.3117 - val_accuracy: 0.5169\n",
      "Epoch 284/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2813 - accuracy: 0.5279 - val_loss: 1.3173 - val_accuracy: 0.5236\n",
      "Epoch 285/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2775 - accuracy: 0.5293 - val_loss: 1.2956 - val_accuracy: 0.5234\n",
      "Epoch 286/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2777 - accuracy: 0.5316 - val_loss: 1.2898 - val_accuracy: 0.5200\n",
      "Epoch 287/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2879 - accuracy: 0.5244 - val_loss: 1.2888 - val_accuracy: 0.5334\n",
      "Epoch 288/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2765 - accuracy: 0.5307 - val_loss: 1.2889 - val_accuracy: 0.5262\n",
      "Epoch 289/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2784 - accuracy: 0.5307 - val_loss: 1.2991 - val_accuracy: 0.5316\n",
      "Epoch 290/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2805 - accuracy: 0.5270 - val_loss: 1.2874 - val_accuracy: 0.5290\n",
      "Epoch 291/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2748 - accuracy: 0.5305 - val_loss: 1.3014 - val_accuracy: 0.5200\n",
      "Epoch 292/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2829 - accuracy: 0.5277 - val_loss: 1.2903 - val_accuracy: 0.5339\n",
      "Epoch 293/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2792 - accuracy: 0.5283 - val_loss: 1.2984 - val_accuracy: 0.5285\n",
      "Epoch 294/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2782 - accuracy: 0.5311 - val_loss: 1.3089 - val_accuracy: 0.5231\n",
      "Epoch 295/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2754 - accuracy: 0.5311 - val_loss: 1.3077 - val_accuracy: 0.5334\n",
      "Epoch 296/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2772 - accuracy: 0.5294 - val_loss: 1.3119 - val_accuracy: 0.5244\n",
      "Epoch 297/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2791 - accuracy: 0.5291 - val_loss: 1.2909 - val_accuracy: 0.5316\n",
      "Epoch 298/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2764 - accuracy: 0.5274 - val_loss: 1.2953 - val_accuracy: 0.5349\n",
      "Epoch 299/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2754 - accuracy: 0.5314 - val_loss: 1.3085 - val_accuracy: 0.5167\n",
      "Epoch 300/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2820 - accuracy: 0.5261 - val_loss: 1.3141 - val_accuracy: 0.5141\n",
      "Epoch 301/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2782 - accuracy: 0.5289 - val_loss: 1.2972 - val_accuracy: 0.5365\n",
      "Epoch 302/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2751 - accuracy: 0.5312 - val_loss: 1.3112 - val_accuracy: 0.5167\n",
      "Epoch 303/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2771 - accuracy: 0.5261 - val_loss: 1.2884 - val_accuracy: 0.5259\n",
      "Epoch 304/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5294 - val_loss: 1.2943 - val_accuracy: 0.5262\n",
      "Epoch 305/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2741 - accuracy: 0.5284 - val_loss: 1.3008 - val_accuracy: 0.5157\n",
      "Epoch 306/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2753 - accuracy: 0.5298 - val_loss: 1.2954 - val_accuracy: 0.5298\n",
      "Epoch 307/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2785 - accuracy: 0.5305 - val_loss: 1.3274 - val_accuracy: 0.5162\n",
      "Epoch 308/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2789 - accuracy: 0.5297 - val_loss: 1.3150 - val_accuracy: 0.5221\n",
      "Epoch 309/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2799 - accuracy: 0.5296 - val_loss: 1.2883 - val_accuracy: 0.5370\n",
      "Epoch 310/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2778 - accuracy: 0.5314 - val_loss: 1.2875 - val_accuracy: 0.5288\n",
      "Epoch 311/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2780 - accuracy: 0.5303 - val_loss: 1.3174 - val_accuracy: 0.5272\n",
      "Epoch 312/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2765 - accuracy: 0.5331 - val_loss: 1.2965 - val_accuracy: 0.5241\n",
      "Epoch 313/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2751 - accuracy: 0.5304 - val_loss: 1.2882 - val_accuracy: 0.5339\n",
      "Epoch 314/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2792 - accuracy: 0.5285 - val_loss: 1.3010 - val_accuracy: 0.5329\n",
      "Epoch 315/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2778 - accuracy: 0.5255 - val_loss: 1.2902 - val_accuracy: 0.5298\n",
      "Epoch 316/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2718 - accuracy: 0.5334 - val_loss: 1.2999 - val_accuracy: 0.5241\n",
      "Epoch 317/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2746 - accuracy: 0.5293 - val_loss: 1.3010 - val_accuracy: 0.5200\n",
      "Epoch 318/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2718 - accuracy: 0.5294 - val_loss: 1.2902 - val_accuracy: 0.5193\n",
      "Epoch 319/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2795 - accuracy: 0.5298 - val_loss: 1.2913 - val_accuracy: 0.5300\n",
      "Epoch 320/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2773 - accuracy: 0.5299 - val_loss: 1.2845 - val_accuracy: 0.5311\n",
      "Epoch 321/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2737 - accuracy: 0.5297 - val_loss: 1.2848 - val_accuracy: 0.5254\n",
      "Epoch 322/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2800 - accuracy: 0.5291 - val_loss: 1.2976 - val_accuracy: 0.5288\n",
      "Epoch 323/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2773 - accuracy: 0.5310 - val_loss: 1.3136 - val_accuracy: 0.5182\n",
      "Epoch 324/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2796 - accuracy: 0.5298 - val_loss: 1.2876 - val_accuracy: 0.5334\n",
      "Epoch 325/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2734 - accuracy: 0.5288 - val_loss: 1.2973 - val_accuracy: 0.5336\n",
      "Epoch 326/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2766 - accuracy: 0.5284 - val_loss: 1.2880 - val_accuracy: 0.5280\n",
      "Epoch 327/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2720 - accuracy: 0.5335 - val_loss: 1.2857 - val_accuracy: 0.5290\n",
      "Epoch 328/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2719 - accuracy: 0.5315 - val_loss: 1.2820 - val_accuracy: 0.5298\n",
      "Epoch 329/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2744 - accuracy: 0.5270 - val_loss: 1.3214 - val_accuracy: 0.5105\n",
      "Epoch 330/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2780 - accuracy: 0.5280 - val_loss: 1.2921 - val_accuracy: 0.5254\n",
      "Epoch 331/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2719 - accuracy: 0.5309 - val_loss: 1.2980 - val_accuracy: 0.5221\n",
      "Epoch 332/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2703 - accuracy: 0.5300 - val_loss: 1.3183 - val_accuracy: 0.5218\n",
      "Epoch 333/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2723 - accuracy: 0.5302 - val_loss: 1.2868 - val_accuracy: 0.5360\n",
      "Epoch 334/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2740 - accuracy: 0.5308 - val_loss: 1.2954 - val_accuracy: 0.5244\n",
      "Epoch 335/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2744 - accuracy: 0.5267 - val_loss: 1.3034 - val_accuracy: 0.5221\n",
      "Epoch 336/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2788 - accuracy: 0.5303 - val_loss: 1.2869 - val_accuracy: 0.5380\n",
      "Epoch 337/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2710 - accuracy: 0.5320 - val_loss: 1.2960 - val_accuracy: 0.5300\n",
      "Epoch 338/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2681 - accuracy: 0.5322 - val_loss: 1.2873 - val_accuracy: 0.5318\n",
      "Epoch 339/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2730 - accuracy: 0.5317 - val_loss: 1.2971 - val_accuracy: 0.5378\n",
      "Epoch 340/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5284 - val_loss: 1.2912 - val_accuracy: 0.5267\n",
      "Epoch 341/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2706 - accuracy: 0.5295 - val_loss: 1.3415 - val_accuracy: 0.5121\n",
      "Epoch 342/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2736 - accuracy: 0.5294 - val_loss: 1.2970 - val_accuracy: 0.5321\n",
      "Epoch 343/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2699 - accuracy: 0.5327 - val_loss: 1.3131 - val_accuracy: 0.5218\n",
      "Epoch 344/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5320 - val_loss: 1.3061 - val_accuracy: 0.5334\n",
      "Epoch 345/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2706 - accuracy: 0.5311 - val_loss: 1.3056 - val_accuracy: 0.5262\n",
      "Epoch 346/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2715 - accuracy: 0.5311 - val_loss: 1.2928 - val_accuracy: 0.5298\n",
      "Epoch 347/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2742 - accuracy: 0.5294 - val_loss: 1.2978 - val_accuracy: 0.5257\n",
      "Epoch 348/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2681 - accuracy: 0.5347 - val_loss: 1.3151 - val_accuracy: 0.5203\n",
      "Epoch 349/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2716 - accuracy: 0.5294 - val_loss: 1.2924 - val_accuracy: 0.5349\n",
      "Epoch 350/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2649 - accuracy: 0.5359 - val_loss: 1.3294 - val_accuracy: 0.5182\n",
      "Epoch 351/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2733 - accuracy: 0.5307 - val_loss: 1.2959 - val_accuracy: 0.5339\n",
      "Epoch 352/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2771 - accuracy: 0.5304 - val_loss: 1.3022 - val_accuracy: 0.5254\n",
      "Epoch 353/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2725 - accuracy: 0.5331 - val_loss: 1.2934 - val_accuracy: 0.5362\n",
      "Epoch 354/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5343 - val_loss: 1.2944 - val_accuracy: 0.5265\n",
      "Epoch 355/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2717 - accuracy: 0.5316 - val_loss: 1.2952 - val_accuracy: 0.5262\n",
      "Epoch 356/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2668 - accuracy: 0.5330 - val_loss: 1.3003 - val_accuracy: 0.5244\n",
      "Epoch 357/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2724 - accuracy: 0.5304 - val_loss: 1.3073 - val_accuracy: 0.5306\n",
      "Epoch 358/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2702 - accuracy: 0.5345 - val_loss: 1.2898 - val_accuracy: 0.5313\n",
      "Epoch 359/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2686 - accuracy: 0.5315 - val_loss: 1.2983 - val_accuracy: 0.5236\n",
      "Epoch 360/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5318 - val_loss: 1.2932 - val_accuracy: 0.5277\n",
      "Epoch 361/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2654 - accuracy: 0.5334 - val_loss: 1.2935 - val_accuracy: 0.5360\n",
      "Epoch 362/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2696 - accuracy: 0.5294 - val_loss: 1.2980 - val_accuracy: 0.5265\n",
      "Epoch 363/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2735 - accuracy: 0.5285 - val_loss: 1.2931 - val_accuracy: 0.5311\n",
      "Epoch 364/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2733 - accuracy: 0.5317 - val_loss: 1.2987 - val_accuracy: 0.5270\n",
      "Epoch 365/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2673 - accuracy: 0.5334 - val_loss: 1.3042 - val_accuracy: 0.5231\n",
      "Epoch 366/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2690 - accuracy: 0.5316 - val_loss: 1.2989 - val_accuracy: 0.5275\n",
      "Epoch 367/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2665 - accuracy: 0.5307 - val_loss: 1.2936 - val_accuracy: 0.5318\n",
      "Epoch 368/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2665 - accuracy: 0.5337 - val_loss: 1.3656 - val_accuracy: 0.5056\n",
      "Epoch 369/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2740 - accuracy: 0.5306 - val_loss: 1.2959 - val_accuracy: 0.5270\n",
      "Epoch 370/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2643 - accuracy: 0.5336 - val_loss: 1.2962 - val_accuracy: 0.5216\n",
      "Epoch 371/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2701 - accuracy: 0.5324 - val_loss: 1.2907 - val_accuracy: 0.5357\n",
      "Epoch 372/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2656 - accuracy: 0.5337 - val_loss: 1.2859 - val_accuracy: 0.5257\n",
      "Epoch 373/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2703 - accuracy: 0.5287 - val_loss: 1.3025 - val_accuracy: 0.5211\n",
      "Epoch 374/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2715 - accuracy: 0.5293 - val_loss: 1.3045 - val_accuracy: 0.5254\n",
      "Epoch 375/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2651 - accuracy: 0.5304 - val_loss: 1.3009 - val_accuracy: 0.5285\n",
      "Epoch 376/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2693 - accuracy: 0.5331 - val_loss: 1.3032 - val_accuracy: 0.5231\n",
      "Epoch 377/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2691 - accuracy: 0.5327 - val_loss: 1.3076 - val_accuracy: 0.5257\n",
      "Epoch 378/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2677 - accuracy: 0.5334 - val_loss: 1.2850 - val_accuracy: 0.5277\n",
      "Epoch 379/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2687 - accuracy: 0.5343 - val_loss: 1.2874 - val_accuracy: 0.5339\n",
      "Epoch 380/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2692 - accuracy: 0.5315 - val_loss: 1.2889 - val_accuracy: 0.5308\n",
      "Epoch 381/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2666 - accuracy: 0.5316 - val_loss: 1.2951 - val_accuracy: 0.5211\n",
      "Epoch 382/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2667 - accuracy: 0.5314 - val_loss: 1.3429 - val_accuracy: 0.5175\n",
      "Epoch 383/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2693 - accuracy: 0.5317 - val_loss: 1.2846 - val_accuracy: 0.5313\n",
      "Epoch 384/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2645 - accuracy: 0.5324 - val_loss: 1.2843 - val_accuracy: 0.5298\n",
      "Epoch 385/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2667 - accuracy: 0.5340 - val_loss: 1.3201 - val_accuracy: 0.5205\n",
      "Epoch 386/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2660 - accuracy: 0.5328 - val_loss: 1.2945 - val_accuracy: 0.5262\n",
      "Epoch 387/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2668 - accuracy: 0.5345 - val_loss: 1.3111 - val_accuracy: 0.5198\n",
      "Epoch 388/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2678 - accuracy: 0.5346 - val_loss: 1.2837 - val_accuracy: 0.5321\n",
      "Epoch 389/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2722 - accuracy: 0.5302 - val_loss: 1.3050 - val_accuracy: 0.5231\n",
      "Epoch 390/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2650 - accuracy: 0.5350 - val_loss: 1.3033 - val_accuracy: 0.5272\n",
      "Epoch 391/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2653 - accuracy: 0.5329 - val_loss: 1.2851 - val_accuracy: 0.5290\n",
      "Epoch 392/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2612 - accuracy: 0.5332 - val_loss: 1.2826 - val_accuracy: 0.5290\n",
      "Epoch 393/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2690 - accuracy: 0.5291 - val_loss: 1.2900 - val_accuracy: 0.5372\n",
      "Epoch 394/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2685 - accuracy: 0.5338 - val_loss: 1.3046 - val_accuracy: 0.5334\n",
      "Epoch 395/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2680 - accuracy: 0.5367 - val_loss: 1.2871 - val_accuracy: 0.5329\n",
      "Epoch 396/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2661 - accuracy: 0.5343 - val_loss: 1.2849 - val_accuracy: 0.5318\n",
      "Epoch 397/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2633 - accuracy: 0.5337 - val_loss: 1.3059 - val_accuracy: 0.5226\n",
      "Epoch 398/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2609 - accuracy: 0.5359 - val_loss: 1.3028 - val_accuracy: 0.5331\n",
      "Epoch 399/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2706 - accuracy: 0.5291 - val_loss: 1.2950 - val_accuracy: 0.5326\n",
      "Epoch 400/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2693 - accuracy: 0.5311 - val_loss: 1.2907 - val_accuracy: 0.5334\n",
      "Epoch 401/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2633 - accuracy: 0.5330 - val_loss: 1.2826 - val_accuracy: 0.5365\n",
      "Epoch 402/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2654 - accuracy: 0.5321 - val_loss: 1.3086 - val_accuracy: 0.5262\n",
      "Epoch 403/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2640 - accuracy: 0.5330 - val_loss: 1.2932 - val_accuracy: 0.5270\n",
      "Epoch 404/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2634 - accuracy: 0.5322 - val_loss: 1.2890 - val_accuracy: 0.5262\n",
      "Epoch 405/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2632 - accuracy: 0.5339 - val_loss: 1.3023 - val_accuracy: 0.5252\n",
      "Epoch 406/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2630 - accuracy: 0.5345 - val_loss: 1.2873 - val_accuracy: 0.5288\n",
      "Epoch 407/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2624 - accuracy: 0.5357 - val_loss: 1.2982 - val_accuracy: 0.5257\n",
      "Epoch 408/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2647 - accuracy: 0.5363 - val_loss: 1.3046 - val_accuracy: 0.5249\n",
      "Epoch 409/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2647 - accuracy: 0.5334 - val_loss: 1.2902 - val_accuracy: 0.5324\n",
      "Epoch 410/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2613 - accuracy: 0.5355 - val_loss: 1.2904 - val_accuracy: 0.5342\n",
      "Epoch 411/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2620 - accuracy: 0.5336 - val_loss: 1.2929 - val_accuracy: 0.5280\n",
      "Epoch 412/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2648 - accuracy: 0.5326 - val_loss: 1.2935 - val_accuracy: 0.5249\n",
      "Epoch 413/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2643 - accuracy: 0.5339 - val_loss: 1.3257 - val_accuracy: 0.5193\n",
      "Epoch 414/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2649 - accuracy: 0.5302 - val_loss: 1.2866 - val_accuracy: 0.5298\n",
      "Epoch 415/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2675 - accuracy: 0.5321 - val_loss: 1.2795 - val_accuracy: 0.5306\n",
      "Epoch 416/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2624 - accuracy: 0.5312 - val_loss: 1.2938 - val_accuracy: 0.5290\n",
      "Epoch 417/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2588 - accuracy: 0.5358 - val_loss: 1.2900 - val_accuracy: 0.5295\n",
      "Epoch 418/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2659 - accuracy: 0.5353 - val_loss: 1.3009 - val_accuracy: 0.5290\n",
      "Epoch 419/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2629 - accuracy: 0.5379 - val_loss: 1.2995 - val_accuracy: 0.5267\n",
      "Epoch 420/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2663 - accuracy: 0.5361 - val_loss: 1.3218 - val_accuracy: 0.5277\n",
      "Epoch 421/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2687 - accuracy: 0.5312 - val_loss: 1.2939 - val_accuracy: 0.5324\n",
      "Epoch 422/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2612 - accuracy: 0.5308 - val_loss: 1.2799 - val_accuracy: 0.5331\n",
      "Epoch 423/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2598 - accuracy: 0.5357 - val_loss: 1.2970 - val_accuracy: 0.5298\n",
      "Epoch 424/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2634 - accuracy: 0.5376 - val_loss: 1.3053 - val_accuracy: 0.5236\n",
      "Epoch 425/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2627 - accuracy: 0.5327 - val_loss: 1.2869 - val_accuracy: 0.5303\n",
      "Epoch 426/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2652 - accuracy: 0.5360 - val_loss: 1.2872 - val_accuracy: 0.5331\n",
      "Epoch 427/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2589 - accuracy: 0.5330 - val_loss: 1.2952 - val_accuracy: 0.5275\n",
      "Epoch 428/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2620 - accuracy: 0.5314 - val_loss: 1.2946 - val_accuracy: 0.5383\n",
      "Epoch 429/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2610 - accuracy: 0.5353 - val_loss: 1.2971 - val_accuracy: 0.5236\n",
      "Epoch 430/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2563 - accuracy: 0.5324 - val_loss: 1.2972 - val_accuracy: 0.5272\n",
      "Epoch 431/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2593 - accuracy: 0.5354 - val_loss: 1.2813 - val_accuracy: 0.5321\n",
      "Epoch 432/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2588 - accuracy: 0.5343 - val_loss: 1.2846 - val_accuracy: 0.5285\n",
      "Epoch 433/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2595 - accuracy: 0.5350 - val_loss: 1.3183 - val_accuracy: 0.5182\n",
      "Epoch 434/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2627 - accuracy: 0.5341 - val_loss: 1.3140 - val_accuracy: 0.5270\n",
      "Epoch 435/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2649 - accuracy: 0.5326 - val_loss: 1.2929 - val_accuracy: 0.5295\n",
      "Epoch 436/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2626 - accuracy: 0.5347 - val_loss: 1.3054 - val_accuracy: 0.5280\n",
      "Epoch 437/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2610 - accuracy: 0.5347 - val_loss: 1.2884 - val_accuracy: 0.5306\n",
      "Epoch 438/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2608 - accuracy: 0.5352 - val_loss: 1.2987 - val_accuracy: 0.5270\n",
      "Epoch 439/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2637 - accuracy: 0.5343 - val_loss: 1.2900 - val_accuracy: 0.5282\n",
      "Epoch 440/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2618 - accuracy: 0.5331 - val_loss: 1.2836 - val_accuracy: 0.5300\n",
      "Epoch 441/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2592 - accuracy: 0.5368 - val_loss: 1.2839 - val_accuracy: 0.5331\n",
      "Epoch 442/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2603 - accuracy: 0.5347 - val_loss: 1.2967 - val_accuracy: 0.5236\n",
      "Epoch 443/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2594 - accuracy: 0.5334 - val_loss: 1.3528 - val_accuracy: 0.5149\n",
      "Epoch 444/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2639 - accuracy: 0.5327 - val_loss: 1.2848 - val_accuracy: 0.5344\n",
      "Epoch 445/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2568 - accuracy: 0.5365 - val_loss: 1.2936 - val_accuracy: 0.5262\n",
      "Epoch 446/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2576 - accuracy: 0.5345 - val_loss: 1.2771 - val_accuracy: 0.5288\n",
      "Epoch 447/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2567 - accuracy: 0.5342 - val_loss: 1.2826 - val_accuracy: 0.5300\n",
      "Epoch 448/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2594 - accuracy: 0.5358 - val_loss: 1.2856 - val_accuracy: 0.5352\n",
      "Epoch 449/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2616 - accuracy: 0.5324 - val_loss: 1.2993 - val_accuracy: 0.5211\n",
      "Epoch 450/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2607 - accuracy: 0.5360 - val_loss: 1.2893 - val_accuracy: 0.5252\n",
      "Epoch 451/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2613 - accuracy: 0.5350 - val_loss: 1.2868 - val_accuracy: 0.5375\n",
      "Epoch 452/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2573 - accuracy: 0.5313 - val_loss: 1.2990 - val_accuracy: 0.5231\n",
      "Epoch 453/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2585 - accuracy: 0.5366 - val_loss: 1.2916 - val_accuracy: 0.5354\n",
      "Epoch 454/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2586 - accuracy: 0.5367 - val_loss: 1.2944 - val_accuracy: 0.5265\n",
      "Epoch 455/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2616 - accuracy: 0.5345 - val_loss: 1.2849 - val_accuracy: 0.5331\n",
      "Epoch 456/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2567 - accuracy: 0.5343 - val_loss: 1.2946 - val_accuracy: 0.5270\n",
      "Epoch 457/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2608 - accuracy: 0.5369 - val_loss: 1.2856 - val_accuracy: 0.5342\n",
      "Epoch 458/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2595 - accuracy: 0.5297 - val_loss: 1.2909 - val_accuracy: 0.5318\n",
      "Epoch 459/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2678 - accuracy: 0.5330 - val_loss: 1.3075 - val_accuracy: 0.5211\n",
      "Epoch 460/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2574 - accuracy: 0.5353 - val_loss: 1.2881 - val_accuracy: 0.5244\n",
      "Epoch 461/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2622 - accuracy: 0.5344 - val_loss: 1.2983 - val_accuracy: 0.5270\n",
      "Epoch 462/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2603 - accuracy: 0.5359 - val_loss: 1.2846 - val_accuracy: 0.5347\n",
      "Epoch 463/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2606 - accuracy: 0.5357 - val_loss: 1.2967 - val_accuracy: 0.5229\n",
      "Epoch 464/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2624 - accuracy: 0.5339 - val_loss: 1.2874 - val_accuracy: 0.5331\n",
      "Epoch 465/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2594 - accuracy: 0.5354 - val_loss: 1.2949 - val_accuracy: 0.5295\n",
      "Epoch 466/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2617 - accuracy: 0.5338 - val_loss: 1.2866 - val_accuracy: 0.5298\n",
      "Epoch 467/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2565 - accuracy: 0.5350 - val_loss: 1.2817 - val_accuracy: 0.5336\n",
      "Epoch 468/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2610 - accuracy: 0.5331 - val_loss: 1.2762 - val_accuracy: 0.5393\n",
      "Epoch 469/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2589 - accuracy: 0.5324 - val_loss: 1.2848 - val_accuracy: 0.5303\n",
      "Epoch 470/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2564 - accuracy: 0.5351 - val_loss: 1.2876 - val_accuracy: 0.5318\n",
      "Epoch 471/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2581 - accuracy: 0.5321 - val_loss: 1.2894 - val_accuracy: 0.5347\n",
      "Epoch 472/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2562 - accuracy: 0.5373 - val_loss: 1.2881 - val_accuracy: 0.5334\n",
      "Epoch 473/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2590 - accuracy: 0.5344 - val_loss: 1.2885 - val_accuracy: 0.5288\n",
      "Epoch 474/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2540 - accuracy: 0.5366 - val_loss: 1.2989 - val_accuracy: 0.5272\n",
      "Epoch 475/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2579 - accuracy: 0.5340 - val_loss: 1.2942 - val_accuracy: 0.5331\n",
      "Epoch 476/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2623 - accuracy: 0.5339 - val_loss: 1.3115 - val_accuracy: 0.5218\n",
      "Epoch 477/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2570 - accuracy: 0.5333 - val_loss: 1.2928 - val_accuracy: 0.5298\n",
      "Epoch 478/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2577 - accuracy: 0.5352 - val_loss: 1.2885 - val_accuracy: 0.5265\n",
      "Epoch 479/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2566 - accuracy: 0.5371 - val_loss: 1.2935 - val_accuracy: 0.5308\n",
      "Epoch 480/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2609 - accuracy: 0.5344 - val_loss: 1.2899 - val_accuracy: 0.5277\n",
      "Epoch 481/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2557 - accuracy: 0.5355 - val_loss: 1.2870 - val_accuracy: 0.5344\n",
      "Epoch 482/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2571 - accuracy: 0.5359 - val_loss: 1.2823 - val_accuracy: 0.5262\n",
      "Epoch 483/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2559 - accuracy: 0.5356 - val_loss: 1.2970 - val_accuracy: 0.5265\n",
      "Epoch 484/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2601 - accuracy: 0.5340 - val_loss: 1.3112 - val_accuracy: 0.5223\n",
      "Epoch 485/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2559 - accuracy: 0.5355 - val_loss: 1.2919 - val_accuracy: 0.5339\n",
      "Epoch 486/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2612 - accuracy: 0.5342 - val_loss: 1.2850 - val_accuracy: 0.5367\n",
      "Epoch 487/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2590 - accuracy: 0.5354 - val_loss: 1.2842 - val_accuracy: 0.5303\n",
      "Epoch 488/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2576 - accuracy: 0.5364 - val_loss: 1.2922 - val_accuracy: 0.5303\n",
      "Epoch 489/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2598 - accuracy: 0.5353 - val_loss: 1.2839 - val_accuracy: 0.5293\n",
      "Epoch 490/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2573 - accuracy: 0.5336 - val_loss: 1.2880 - val_accuracy: 0.5280\n",
      "Epoch 491/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2535 - accuracy: 0.5332 - val_loss: 1.2877 - val_accuracy: 0.5370\n",
      "Epoch 492/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2551 - accuracy: 0.5367 - val_loss: 1.2929 - val_accuracy: 0.5282\n",
      "Epoch 493/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2617 - accuracy: 0.5306 - val_loss: 1.2935 - val_accuracy: 0.5357\n",
      "Epoch 494/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2581 - accuracy: 0.5320 - val_loss: 1.2925 - val_accuracy: 0.5226\n",
      "Epoch 495/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2576 - accuracy: 0.5362 - val_loss: 1.2853 - val_accuracy: 0.5308\n",
      "Epoch 496/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2504 - accuracy: 0.5358 - val_loss: 1.2977 - val_accuracy: 0.5326\n",
      "Epoch 497/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2589 - accuracy: 0.5333 - val_loss: 1.2828 - val_accuracy: 0.5306\n",
      "Epoch 498/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2549 - accuracy: 0.5350 - val_loss: 1.2911 - val_accuracy: 0.5336\n",
      "Epoch 499/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2598 - accuracy: 0.5353 - val_loss: 1.2805 - val_accuracy: 0.5378\n",
      "Epoch 500/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2529 - accuracy: 0.5353 - val_loss: 1.2804 - val_accuracy: 0.5308\n",
      "Epoch 501/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2541 - accuracy: 0.5363 - val_loss: 1.2841 - val_accuracy: 0.5300\n",
      "Epoch 502/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2554 - accuracy: 0.5353 - val_loss: 1.2805 - val_accuracy: 0.5334\n",
      "Epoch 503/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2540 - accuracy: 0.5369 - val_loss: 1.2788 - val_accuracy: 0.5380\n",
      "Epoch 504/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2544 - accuracy: 0.5344 - val_loss: 1.2853 - val_accuracy: 0.5280\n",
      "Epoch 505/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2563 - accuracy: 0.5343 - val_loss: 1.2830 - val_accuracy: 0.5390\n",
      "Epoch 506/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2565 - accuracy: 0.5359 - val_loss: 1.2886 - val_accuracy: 0.5288\n",
      "Epoch 507/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2548 - accuracy: 0.5367 - val_loss: 1.2857 - val_accuracy: 0.5383\n",
      "Epoch 508/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2585 - accuracy: 0.5329 - val_loss: 1.2917 - val_accuracy: 0.5254\n",
      "Epoch 509/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2599 - accuracy: 0.5316 - val_loss: 1.3315 - val_accuracy: 0.5159\n",
      "Epoch 510/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2563 - accuracy: 0.5340 - val_loss: 1.2749 - val_accuracy: 0.5352\n",
      "Epoch 511/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2562 - accuracy: 0.5363 - val_loss: 1.2813 - val_accuracy: 0.5329\n",
      "Epoch 512/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2553 - accuracy: 0.5378 - val_loss: 1.3191 - val_accuracy: 0.5187\n",
      "Epoch 513/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2557 - accuracy: 0.5362 - val_loss: 1.2801 - val_accuracy: 0.5334\n",
      "Epoch 514/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2513 - accuracy: 0.5362 - val_loss: 1.3017 - val_accuracy: 0.5241\n",
      "Epoch 515/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2579 - accuracy: 0.5338 - val_loss: 1.2765 - val_accuracy: 0.5318\n",
      "Epoch 516/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2512 - accuracy: 0.5340 - val_loss: 1.2797 - val_accuracy: 0.5329\n",
      "Epoch 517/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2600 - accuracy: 0.5333 - val_loss: 1.2740 - val_accuracy: 0.5375\n",
      "Epoch 518/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2580 - accuracy: 0.5360 - val_loss: 1.2818 - val_accuracy: 0.5290\n",
      "Epoch 519/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2556 - accuracy: 0.5346 - val_loss: 1.3092 - val_accuracy: 0.5326\n",
      "Epoch 520/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2534 - accuracy: 0.5352 - val_loss: 1.2842 - val_accuracy: 0.5326\n",
      "Epoch 521/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2552 - accuracy: 0.5357 - val_loss: 1.2901 - val_accuracy: 0.5285\n",
      "Epoch 522/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2558 - accuracy: 0.5368 - val_loss: 1.2879 - val_accuracy: 0.5308\n",
      "Epoch 523/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2523 - accuracy: 0.5373 - val_loss: 1.3111 - val_accuracy: 0.5254\n",
      "Epoch 524/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2564 - accuracy: 0.5330 - val_loss: 1.3092 - val_accuracy: 0.5306\n",
      "Epoch 525/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2557 - accuracy: 0.5350 - val_loss: 1.2855 - val_accuracy: 0.5285\n",
      "Epoch 526/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2570 - accuracy: 0.5340 - val_loss: 1.3286 - val_accuracy: 0.5213\n",
      "Epoch 527/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2533 - accuracy: 0.5360 - val_loss: 1.3061 - val_accuracy: 0.5218\n",
      "Epoch 528/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2542 - accuracy: 0.5373 - val_loss: 1.2800 - val_accuracy: 0.5285\n",
      "Epoch 529/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2492 - accuracy: 0.5382 - val_loss: 1.2881 - val_accuracy: 0.5326\n",
      "Epoch 530/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2518 - accuracy: 0.5362 - val_loss: 1.3020 - val_accuracy: 0.5282\n",
      "Epoch 531/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2620 - accuracy: 0.5336 - val_loss: 1.2858 - val_accuracy: 0.5349\n",
      "Epoch 532/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2526 - accuracy: 0.5357 - val_loss: 1.2838 - val_accuracy: 0.5300\n",
      "Epoch 533/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2574 - accuracy: 0.5351 - val_loss: 1.2865 - val_accuracy: 0.5360\n",
      "Epoch 534/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2547 - accuracy: 0.5376 - val_loss: 1.2980 - val_accuracy: 0.5298\n",
      "Epoch 535/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2577 - accuracy: 0.5367 - val_loss: 1.2859 - val_accuracy: 0.5282\n",
      "Epoch 536/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2550 - accuracy: 0.5359 - val_loss: 1.2908 - val_accuracy: 0.5306\n",
      "Epoch 537/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2562 - accuracy: 0.5327 - val_loss: 1.2767 - val_accuracy: 0.5331\n",
      "Epoch 538/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2555 - accuracy: 0.5353 - val_loss: 1.2934 - val_accuracy: 0.5303\n",
      "Epoch 539/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2545 - accuracy: 0.5350 - val_loss: 1.2823 - val_accuracy: 0.5321\n",
      "Epoch 540/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2541 - accuracy: 0.5376 - val_loss: 1.2914 - val_accuracy: 0.5290\n",
      "Epoch 541/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2504 - accuracy: 0.5388 - val_loss: 1.2770 - val_accuracy: 0.5352\n",
      "Epoch 542/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2555 - accuracy: 0.5380 - val_loss: 1.2884 - val_accuracy: 0.5324\n",
      "Epoch 543/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2531 - accuracy: 0.5362 - val_loss: 1.2821 - val_accuracy: 0.5326\n",
      "Epoch 544/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2532 - accuracy: 0.5366 - val_loss: 1.3004 - val_accuracy: 0.5306\n",
      "Epoch 545/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2561 - accuracy: 0.5371 - val_loss: 1.3052 - val_accuracy: 0.5275\n",
      "Epoch 546/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2530 - accuracy: 0.5347 - val_loss: 1.2750 - val_accuracy: 0.5393\n",
      "Epoch 547/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2555 - accuracy: 0.5391 - val_loss: 1.2837 - val_accuracy: 0.5349\n",
      "Epoch 548/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2509 - accuracy: 0.5369 - val_loss: 1.2949 - val_accuracy: 0.5288\n",
      "Epoch 549/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2556 - accuracy: 0.5371 - val_loss: 1.2799 - val_accuracy: 0.5311\n",
      "Epoch 550/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2531 - accuracy: 0.5376 - val_loss: 1.2809 - val_accuracy: 0.5316\n",
      "Epoch 551/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2527 - accuracy: 0.5369 - val_loss: 1.3016 - val_accuracy: 0.5241\n",
      "Epoch 552/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2541 - accuracy: 0.5350 - val_loss: 1.3014 - val_accuracy: 0.5298\n",
      "Epoch 553/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2538 - accuracy: 0.5369 - val_loss: 1.2796 - val_accuracy: 0.5318\n",
      "Epoch 554/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2550 - accuracy: 0.5353 - val_loss: 1.2871 - val_accuracy: 0.5344\n",
      "Epoch 555/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2544 - accuracy: 0.5347 - val_loss: 1.2792 - val_accuracy: 0.5406\n",
      "Epoch 556/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2513 - accuracy: 0.5367 - val_loss: 1.2926 - val_accuracy: 0.5308\n",
      "Epoch 557/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2496 - accuracy: 0.5356 - val_loss: 1.2896 - val_accuracy: 0.5290\n",
      "Epoch 558/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2549 - accuracy: 0.5353 - val_loss: 1.2943 - val_accuracy: 0.5316\n",
      "Epoch 559/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2536 - accuracy: 0.5331 - val_loss: 1.2846 - val_accuracy: 0.5367\n",
      "Epoch 560/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2537 - accuracy: 0.5342 - val_loss: 1.2976 - val_accuracy: 0.5205\n",
      "Epoch 561/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2514 - accuracy: 0.5372 - val_loss: 1.2868 - val_accuracy: 0.5324\n",
      "Epoch 562/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2532 - accuracy: 0.5366 - val_loss: 1.2994 - val_accuracy: 0.5318\n",
      "Epoch 563/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2547 - accuracy: 0.5358 - val_loss: 1.3001 - val_accuracy: 0.5270\n",
      "Epoch 564/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2484 - accuracy: 0.5391 - val_loss: 1.2917 - val_accuracy: 0.5388\n",
      "Epoch 565/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2531 - accuracy: 0.5358 - val_loss: 1.3042 - val_accuracy: 0.5254\n",
      "Epoch 566/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2531 - accuracy: 0.5365 - val_loss: 1.2770 - val_accuracy: 0.5336\n",
      "Epoch 567/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2521 - accuracy: 0.5370 - val_loss: 1.2893 - val_accuracy: 0.5347\n",
      "Epoch 568/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2545 - accuracy: 0.5365 - val_loss: 1.2764 - val_accuracy: 0.5362\n",
      "Epoch 569/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2506 - accuracy: 0.5376 - val_loss: 1.2793 - val_accuracy: 0.5378\n",
      "Epoch 570/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2512 - accuracy: 0.5380 - val_loss: 1.2905 - val_accuracy: 0.5324\n",
      "Epoch 571/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2515 - accuracy: 0.5364 - val_loss: 1.2829 - val_accuracy: 0.5352\n",
      "Epoch 572/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2519 - accuracy: 0.5363 - val_loss: 1.2919 - val_accuracy: 0.5265\n",
      "Epoch 573/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2536 - accuracy: 0.5350 - val_loss: 1.3030 - val_accuracy: 0.5239\n",
      "Epoch 574/750\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.2495 - accuracy: 0.5353 - val_loss: 1.2775 - val_accuracy: 0.5360\n",
      "Epoch 575/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2485 - accuracy: 0.5373 - val_loss: 1.2791 - val_accuracy: 0.5354\n",
      "Epoch 576/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.2561 - accuracy: 0.5377 - val_loss: 1.3073 - val_accuracy: 0.5218\n",
      "Epoch 577/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2521 - accuracy: 0.5346 - val_loss: 1.2824 - val_accuracy: 0.5365\n",
      "Epoch 578/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2513 - accuracy: 0.5362 - val_loss: 1.2846 - val_accuracy: 0.5344\n",
      "Epoch 579/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2509 - accuracy: 0.5360 - val_loss: 1.2934 - val_accuracy: 0.5244\n",
      "Epoch 580/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2517 - accuracy: 0.5372 - val_loss: 1.2861 - val_accuracy: 0.5295\n",
      "Epoch 581/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2504 - accuracy: 0.5388 - val_loss: 1.2911 - val_accuracy: 0.5295\n",
      "Epoch 582/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2496 - accuracy: 0.5360 - val_loss: 1.2779 - val_accuracy: 0.5352\n",
      "Epoch 583/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2480 - accuracy: 0.5384 - val_loss: 1.3403 - val_accuracy: 0.5254\n",
      "Epoch 584/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2563 - accuracy: 0.5337 - val_loss: 1.2946 - val_accuracy: 0.5313\n",
      "Epoch 585/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2512 - accuracy: 0.5390 - val_loss: 1.2868 - val_accuracy: 0.5362\n",
      "Epoch 586/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2483 - accuracy: 0.5370 - val_loss: 1.2961 - val_accuracy: 0.5380\n",
      "Epoch 587/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2500 - accuracy: 0.5377 - val_loss: 1.2785 - val_accuracy: 0.5365\n",
      "Epoch 588/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2533 - accuracy: 0.5349 - val_loss: 1.2777 - val_accuracy: 0.5360\n",
      "Epoch 589/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2514 - accuracy: 0.5340 - val_loss: 1.2793 - val_accuracy: 0.5329\n",
      "Epoch 590/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2520 - accuracy: 0.5348 - val_loss: 1.2764 - val_accuracy: 0.5349\n",
      "Epoch 591/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2508 - accuracy: 0.5380 - val_loss: 1.3114 - val_accuracy: 0.5216\n",
      "Epoch 592/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2473 - accuracy: 0.5360 - val_loss: 1.2745 - val_accuracy: 0.5344\n",
      "Epoch 593/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2532 - accuracy: 0.5337 - val_loss: 1.3165 - val_accuracy: 0.5221\n",
      "Epoch 594/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2505 - accuracy: 0.5357 - val_loss: 1.2960 - val_accuracy: 0.5257\n",
      "Epoch 595/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2464 - accuracy: 0.5397 - val_loss: 1.2883 - val_accuracy: 0.5267\n",
      "Epoch 596/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2502 - accuracy: 0.5343 - val_loss: 1.3119 - val_accuracy: 0.5198\n",
      "Epoch 597/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2502 - accuracy: 0.5363 - val_loss: 1.2780 - val_accuracy: 0.5352\n",
      "Epoch 598/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2527 - accuracy: 0.5344 - val_loss: 1.2837 - val_accuracy: 0.5270\n",
      "Epoch 599/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2503 - accuracy: 0.5373 - val_loss: 1.2837 - val_accuracy: 0.5311\n",
      "Epoch 600/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2447 - accuracy: 0.5379 - val_loss: 1.2772 - val_accuracy: 0.5342\n",
      "Epoch 601/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2464 - accuracy: 0.5374 - val_loss: 1.2818 - val_accuracy: 0.5357\n",
      "Epoch 602/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2480 - accuracy: 0.5370 - val_loss: 1.2788 - val_accuracy: 0.5347\n",
      "Epoch 603/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2524 - accuracy: 0.5372 - val_loss: 1.2811 - val_accuracy: 0.5367\n",
      "Epoch 604/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2504 - accuracy: 0.5336 - val_loss: 1.2768 - val_accuracy: 0.5331\n",
      "Epoch 605/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2467 - accuracy: 0.5381 - val_loss: 1.2756 - val_accuracy: 0.5375\n",
      "Epoch 606/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2490 - accuracy: 0.5399 - val_loss: 1.2832 - val_accuracy: 0.5370\n",
      "Epoch 607/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2446 - accuracy: 0.5370 - val_loss: 1.2838 - val_accuracy: 0.5390\n",
      "Epoch 608/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2470 - accuracy: 0.5385 - val_loss: 1.2987 - val_accuracy: 0.5311\n",
      "Epoch 609/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2490 - accuracy: 0.5390 - val_loss: 1.3108 - val_accuracy: 0.5277\n",
      "Epoch 610/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2505 - accuracy: 0.5360 - val_loss: 1.3187 - val_accuracy: 0.5190\n",
      "Epoch 611/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2477 - accuracy: 0.5388 - val_loss: 1.2781 - val_accuracy: 0.5362\n",
      "Epoch 612/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2493 - accuracy: 0.5368 - val_loss: 1.3064 - val_accuracy: 0.5203\n",
      "Epoch 613/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2492 - accuracy: 0.5369 - val_loss: 1.2871 - val_accuracy: 0.5295\n",
      "Epoch 614/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2499 - accuracy: 0.5388 - val_loss: 1.3044 - val_accuracy: 0.5295\n",
      "Epoch 615/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2462 - accuracy: 0.5385 - val_loss: 1.2902 - val_accuracy: 0.5339\n",
      "Epoch 616/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2484 - accuracy: 0.5393 - val_loss: 1.3150 - val_accuracy: 0.5218\n",
      "Epoch 617/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2481 - accuracy: 0.5386 - val_loss: 1.2975 - val_accuracy: 0.5208\n",
      "Epoch 618/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2493 - accuracy: 0.5357 - val_loss: 1.2860 - val_accuracy: 0.5293\n",
      "Epoch 619/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2443 - accuracy: 0.5378 - val_loss: 1.2806 - val_accuracy: 0.5342\n",
      "Epoch 620/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2504 - accuracy: 0.5340 - val_loss: 1.2857 - val_accuracy: 0.5370\n",
      "Epoch 621/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2459 - accuracy: 0.5387 - val_loss: 1.3910 - val_accuracy: 0.4951\n",
      "Epoch 622/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2521 - accuracy: 0.5363 - val_loss: 1.2976 - val_accuracy: 0.5306\n",
      "Epoch 623/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2470 - accuracy: 0.5373 - val_loss: 1.2899 - val_accuracy: 0.5252\n",
      "Epoch 624/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2487 - accuracy: 0.5385 - val_loss: 1.2852 - val_accuracy: 0.5318\n",
      "Epoch 625/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2442 - accuracy: 0.5386 - val_loss: 1.2921 - val_accuracy: 0.5321\n",
      "Epoch 626/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2444 - accuracy: 0.5384 - val_loss: 1.2823 - val_accuracy: 0.5311\n",
      "Epoch 627/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2511 - accuracy: 0.5382 - val_loss: 1.3014 - val_accuracy: 0.5200\n",
      "Epoch 628/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2483 - accuracy: 0.5360 - val_loss: 1.2968 - val_accuracy: 0.5285\n",
      "Epoch 629/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2463 - accuracy: 0.5384 - val_loss: 1.2890 - val_accuracy: 0.5375\n",
      "Epoch 630/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2509 - accuracy: 0.5391 - val_loss: 1.2800 - val_accuracy: 0.5318\n",
      "Epoch 631/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2500 - accuracy: 0.5364 - val_loss: 1.2862 - val_accuracy: 0.5334\n",
      "Epoch 632/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2481 - accuracy: 0.5396 - val_loss: 1.2784 - val_accuracy: 0.5365\n",
      "Epoch 633/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2463 - accuracy: 0.5374 - val_loss: 1.2888 - val_accuracy: 0.5367\n",
      "Epoch 634/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2462 - accuracy: 0.5367 - val_loss: 1.2853 - val_accuracy: 0.5385\n",
      "Epoch 635/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2515 - accuracy: 0.5367 - val_loss: 1.2753 - val_accuracy: 0.5357\n",
      "Epoch 636/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2447 - accuracy: 0.5395 - val_loss: 1.2770 - val_accuracy: 0.5380\n",
      "Epoch 637/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2445 - accuracy: 0.5370 - val_loss: 1.2772 - val_accuracy: 0.5303\n",
      "Epoch 638/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2454 - accuracy: 0.5381 - val_loss: 1.2916 - val_accuracy: 0.5318\n",
      "Epoch 639/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2473 - accuracy: 0.5358 - val_loss: 1.3025 - val_accuracy: 0.5342\n",
      "Epoch 640/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2520 - accuracy: 0.5374 - val_loss: 1.2868 - val_accuracy: 0.5316\n",
      "Epoch 641/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2512 - accuracy: 0.5374 - val_loss: 1.3154 - val_accuracy: 0.5203\n",
      "Epoch 642/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2477 - accuracy: 0.5370 - val_loss: 1.2773 - val_accuracy: 0.5393\n",
      "Epoch 643/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2474 - accuracy: 0.5359 - val_loss: 1.2913 - val_accuracy: 0.5372\n",
      "Epoch 644/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2422 - accuracy: 0.5383 - val_loss: 1.2821 - val_accuracy: 0.5318\n",
      "Epoch 645/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2471 - accuracy: 0.5363 - val_loss: 1.2853 - val_accuracy: 0.5336\n",
      "Epoch 646/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2496 - accuracy: 0.5383 - val_loss: 1.2817 - val_accuracy: 0.5331\n",
      "Epoch 647/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2486 - accuracy: 0.5383 - val_loss: 1.2831 - val_accuracy: 0.5339\n",
      "Epoch 648/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2430 - accuracy: 0.5394 - val_loss: 1.2705 - val_accuracy: 0.5390\n",
      "Epoch 649/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2492 - accuracy: 0.5385 - val_loss: 1.2844 - val_accuracy: 0.5329\n",
      "Epoch 650/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2459 - accuracy: 0.5380 - val_loss: 1.3004 - val_accuracy: 0.5247\n",
      "Epoch 651/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2471 - accuracy: 0.5371 - val_loss: 1.2870 - val_accuracy: 0.5329\n",
      "Epoch 652/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2485 - accuracy: 0.5363 - val_loss: 1.2819 - val_accuracy: 0.5365\n",
      "Epoch 653/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2456 - accuracy: 0.5372 - val_loss: 1.3135 - val_accuracy: 0.5249\n",
      "Epoch 654/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2483 - accuracy: 0.5363 - val_loss: 1.2837 - val_accuracy: 0.5344\n",
      "Epoch 655/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2499 - accuracy: 0.5332 - val_loss: 1.2919 - val_accuracy: 0.5226\n",
      "Epoch 656/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2469 - accuracy: 0.5382 - val_loss: 1.2848 - val_accuracy: 0.5375\n",
      "Epoch 657/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2462 - accuracy: 0.5391 - val_loss: 1.2949 - val_accuracy: 0.5300\n",
      "Epoch 658/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2435 - accuracy: 0.5362 - val_loss: 1.2938 - val_accuracy: 0.5290\n",
      "Epoch 659/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2433 - accuracy: 0.5376 - val_loss: 1.2889 - val_accuracy: 0.5329\n",
      "Epoch 660/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2486 - accuracy: 0.5397 - val_loss: 1.2844 - val_accuracy: 0.5288\n",
      "Epoch 661/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2478 - accuracy: 0.5363 - val_loss: 1.2858 - val_accuracy: 0.5334\n",
      "Epoch 662/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2470 - accuracy: 0.5384 - val_loss: 1.3206 - val_accuracy: 0.5239\n",
      "Epoch 663/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2505 - accuracy: 0.5398 - val_loss: 1.2884 - val_accuracy: 0.5339\n",
      "Epoch 664/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2492 - accuracy: 0.5376 - val_loss: 1.2889 - val_accuracy: 0.5324\n",
      "Epoch 665/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2414 - accuracy: 0.5370 - val_loss: 1.2975 - val_accuracy: 0.5313\n",
      "Epoch 666/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2480 - accuracy: 0.5376 - val_loss: 1.2768 - val_accuracy: 0.5339\n",
      "Epoch 667/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2462 - accuracy: 0.5383 - val_loss: 1.2892 - val_accuracy: 0.5326\n",
      "Epoch 668/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2468 - accuracy: 0.5366 - val_loss: 1.2886 - val_accuracy: 0.5375\n",
      "Epoch 669/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2474 - accuracy: 0.5368 - val_loss: 1.2862 - val_accuracy: 0.5362\n",
      "Epoch 670/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2480 - accuracy: 0.5378 - val_loss: 1.2757 - val_accuracy: 0.5375\n",
      "Epoch 671/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2419 - accuracy: 0.5393 - val_loss: 1.2768 - val_accuracy: 0.5303\n",
      "Epoch 672/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2451 - accuracy: 0.5395 - val_loss: 1.2992 - val_accuracy: 0.5277\n",
      "Epoch 673/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2437 - accuracy: 0.5386 - val_loss: 1.2964 - val_accuracy: 0.5349\n",
      "Epoch 674/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2408 - accuracy: 0.5380 - val_loss: 1.2898 - val_accuracy: 0.5298\n",
      "Epoch 675/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2449 - accuracy: 0.5392 - val_loss: 1.2907 - val_accuracy: 0.5306\n",
      "Epoch 676/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2458 - accuracy: 0.5359 - val_loss: 1.2710 - val_accuracy: 0.5395\n",
      "Epoch 677/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2447 - accuracy: 0.5396 - val_loss: 1.2847 - val_accuracy: 0.5380\n",
      "Epoch 678/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2471 - accuracy: 0.5370 - val_loss: 1.2730 - val_accuracy: 0.5372\n",
      "Epoch 679/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2415 - accuracy: 0.5379 - val_loss: 1.3075 - val_accuracy: 0.5298\n",
      "Epoch 680/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2531 - accuracy: 0.5371 - val_loss: 1.3083 - val_accuracy: 0.5311\n",
      "Epoch 681/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2449 - accuracy: 0.5380 - val_loss: 1.2967 - val_accuracy: 0.5285\n",
      "Epoch 682/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2474 - accuracy: 0.5360 - val_loss: 1.3043 - val_accuracy: 0.5316\n",
      "Epoch 683/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2458 - accuracy: 0.5397 - val_loss: 1.2870 - val_accuracy: 0.5342\n",
      "Epoch 684/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2459 - accuracy: 0.5380 - val_loss: 1.3058 - val_accuracy: 0.5259\n",
      "Epoch 685/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2459 - accuracy: 0.5403 - val_loss: 1.2863 - val_accuracy: 0.5362\n",
      "Epoch 686/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2427 - accuracy: 0.5396 - val_loss: 1.3113 - val_accuracy: 0.5223\n",
      "Epoch 687/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2449 - accuracy: 0.5396 - val_loss: 1.2830 - val_accuracy: 0.5329\n",
      "Epoch 688/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2436 - accuracy: 0.5369 - val_loss: 1.2836 - val_accuracy: 0.5388\n",
      "Epoch 689/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2415 - accuracy: 0.5393 - val_loss: 1.3085 - val_accuracy: 0.5265\n",
      "Epoch 690/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2457 - accuracy: 0.5374 - val_loss: 1.2931 - val_accuracy: 0.5293\n",
      "Epoch 691/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2447 - accuracy: 0.5363 - val_loss: 1.2932 - val_accuracy: 0.5331\n",
      "Epoch 692/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2400 - accuracy: 0.5399 - val_loss: 1.3049 - val_accuracy: 0.5221\n",
      "Epoch 693/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2407 - accuracy: 0.5390 - val_loss: 1.2951 - val_accuracy: 0.5295\n",
      "Epoch 694/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2463 - accuracy: 0.5350 - val_loss: 1.2827 - val_accuracy: 0.5324\n",
      "Epoch 695/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2461 - accuracy: 0.5379 - val_loss: 1.2806 - val_accuracy: 0.5370\n",
      "Epoch 696/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2408 - accuracy: 0.5393 - val_loss: 1.2896 - val_accuracy: 0.5293\n",
      "Epoch 697/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2414 - accuracy: 0.5387 - val_loss: 1.2845 - val_accuracy: 0.5349\n",
      "Epoch 698/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2452 - accuracy: 0.5368 - val_loss: 1.2896 - val_accuracy: 0.5318\n",
      "Epoch 699/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2465 - accuracy: 0.5403 - val_loss: 1.2944 - val_accuracy: 0.5318\n",
      "Epoch 700/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2447 - accuracy: 0.5390 - val_loss: 1.2760 - val_accuracy: 0.5383\n",
      "Epoch 701/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2445 - accuracy: 0.5413 - val_loss: 1.3041 - val_accuracy: 0.5216\n",
      "Epoch 702/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2421 - accuracy: 0.5401 - val_loss: 1.3106 - val_accuracy: 0.5272\n",
      "Epoch 703/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2433 - accuracy: 0.5380 - val_loss: 1.2898 - val_accuracy: 0.5308\n",
      "Epoch 704/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2489 - accuracy: 0.5394 - val_loss: 1.2729 - val_accuracy: 0.5380\n",
      "Epoch 705/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2420 - accuracy: 0.5379 - val_loss: 1.2972 - val_accuracy: 0.5354\n",
      "Epoch 706/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2441 - accuracy: 0.5412 - val_loss: 1.2818 - val_accuracy: 0.5380\n",
      "Epoch 707/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2429 - accuracy: 0.5406 - val_loss: 1.2785 - val_accuracy: 0.5352\n",
      "Epoch 708/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2457 - accuracy: 0.5388 - val_loss: 1.2854 - val_accuracy: 0.5316\n",
      "Epoch 709/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2440 - accuracy: 0.5380 - val_loss: 1.3168 - val_accuracy: 0.5282\n",
      "Epoch 710/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2441 - accuracy: 0.5399 - val_loss: 1.3088 - val_accuracy: 0.5270\n",
      "Epoch 711/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2450 - accuracy: 0.5371 - val_loss: 1.2866 - val_accuracy: 0.5295\n",
      "Epoch 712/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2467 - accuracy: 0.5359 - val_loss: 1.2874 - val_accuracy: 0.5349\n",
      "Epoch 713/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2454 - accuracy: 0.5379 - val_loss: 1.2820 - val_accuracy: 0.5365\n",
      "Epoch 714/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2441 - accuracy: 0.5388 - val_loss: 1.2789 - val_accuracy: 0.5349\n",
      "Epoch 715/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2443 - accuracy: 0.5387 - val_loss: 1.3028 - val_accuracy: 0.5259\n",
      "Epoch 716/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2430 - accuracy: 0.5380 - val_loss: 1.3077 - val_accuracy: 0.5252\n",
      "Epoch 717/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2449 - accuracy: 0.5399 - val_loss: 1.2884 - val_accuracy: 0.5331\n",
      "Epoch 718/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2461 - accuracy: 0.5393 - val_loss: 1.2857 - val_accuracy: 0.5372\n",
      "Epoch 719/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2423 - accuracy: 0.5410 - val_loss: 1.2787 - val_accuracy: 0.5336\n",
      "Epoch 720/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2417 - accuracy: 0.5408 - val_loss: 1.2819 - val_accuracy: 0.5378\n",
      "Epoch 721/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2393 - accuracy: 0.5421 - val_loss: 1.3010 - val_accuracy: 0.5218\n",
      "Epoch 722/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2452 - accuracy: 0.5409 - val_loss: 1.2761 - val_accuracy: 0.5347\n",
      "Epoch 723/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2440 - accuracy: 0.5387 - val_loss: 1.2963 - val_accuracy: 0.5352\n",
      "Epoch 724/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2441 - accuracy: 0.5386 - val_loss: 1.3034 - val_accuracy: 0.5326\n",
      "Epoch 725/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2407 - accuracy: 0.5369 - val_loss: 1.2974 - val_accuracy: 0.5262\n",
      "Epoch 726/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2425 - accuracy: 0.5395 - val_loss: 1.3016 - val_accuracy: 0.5244\n",
      "Epoch 727/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2418 - accuracy: 0.5414 - val_loss: 1.2714 - val_accuracy: 0.5370\n",
      "Epoch 728/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2403 - accuracy: 0.5414 - val_loss: 1.2916 - val_accuracy: 0.5365\n",
      "Epoch 729/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2422 - accuracy: 0.5393 - val_loss: 1.2974 - val_accuracy: 0.5370\n",
      "Epoch 730/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2428 - accuracy: 0.5401 - val_loss: 1.2744 - val_accuracy: 0.5388\n",
      "Epoch 731/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2433 - accuracy: 0.5406 - val_loss: 1.2947 - val_accuracy: 0.5295\n",
      "Epoch 732/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2423 - accuracy: 0.5393 - val_loss: 1.2923 - val_accuracy: 0.5308\n",
      "Epoch 733/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2462 - accuracy: 0.5393 - val_loss: 1.2873 - val_accuracy: 0.5388\n",
      "Epoch 734/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2419 - accuracy: 0.5398 - val_loss: 1.2892 - val_accuracy: 0.5329\n",
      "Epoch 735/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2416 - accuracy: 0.5396 - val_loss: 1.2928 - val_accuracy: 0.5298\n",
      "Epoch 736/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2409 - accuracy: 0.5403 - val_loss: 1.3080 - val_accuracy: 0.5272\n",
      "Epoch 737/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2402 - accuracy: 0.5400 - val_loss: 1.2948 - val_accuracy: 0.5290\n",
      "Epoch 738/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2538 - accuracy: 0.5362 - val_loss: 1.2998 - val_accuracy: 0.5331\n",
      "Epoch 739/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2429 - accuracy: 0.5396 - val_loss: 1.2860 - val_accuracy: 0.5290\n",
      "Epoch 740/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2455 - accuracy: 0.5376 - val_loss: 1.2947 - val_accuracy: 0.5347\n",
      "Epoch 741/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2473 - accuracy: 0.5402 - val_loss: 1.3036 - val_accuracy: 0.5329\n",
      "Epoch 742/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2429 - accuracy: 0.5398 - val_loss: 1.2897 - val_accuracy: 0.5303\n",
      "Epoch 743/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2435 - accuracy: 0.5381 - val_loss: 1.2791 - val_accuracy: 0.5370\n",
      "Epoch 744/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2450 - accuracy: 0.5358 - val_loss: 1.2919 - val_accuracy: 0.5375\n",
      "Epoch 745/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2412 - accuracy: 0.5393 - val_loss: 1.2867 - val_accuracy: 0.5342\n",
      "Epoch 746/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2468 - accuracy: 0.5376 - val_loss: 1.2861 - val_accuracy: 0.5311\n",
      "Epoch 747/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2412 - accuracy: 0.5382 - val_loss: 1.2787 - val_accuracy: 0.5334\n",
      "Epoch 748/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2404 - accuracy: 0.5391 - val_loss: 1.2779 - val_accuracy: 0.5390\n",
      "Epoch 749/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2435 - accuracy: 0.5403 - val_loss: 1.2881 - val_accuracy: 0.5360\n",
      "Epoch 750/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2423 - accuracy: 0.5367 - val_loss: 1.2812 - val_accuracy: 0.5378\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=750, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a53aa430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "val_acc_epoch = history.history[\"val_accuracy\"]\n",
    "best_epoch = val_acc_epoch.index(max(val_acc_epoch)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98024ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.8619 - accuracy: 0.3145 - val_loss: 1.7500 - val_accuracy: 0.3579\n",
      "Epoch 2/555\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.7142 - accuracy: 0.3595 - val_loss: 1.6912 - val_accuracy: 0.3579\n",
      "Epoch 3/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6870 - accuracy: 0.3595 - val_loss: 1.6806 - val_accuracy: 0.3579\n",
      "Epoch 4/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6815 - accuracy: 0.3595 - val_loss: 1.6779 - val_accuracy: 0.3579\n",
      "Epoch 5/555\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.6794 - accuracy: 0.3595 - val_loss: 1.6740 - val_accuracy: 0.3579\n",
      "Epoch 6/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6788 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 7/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6748 - accuracy: 0.3599 - val_loss: 1.6690 - val_accuracy: 0.3619\n",
      "Epoch 8/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6716 - accuracy: 0.3647 - val_loss: 1.6659 - val_accuracy: 0.3669\n",
      "Epoch 9/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6671 - accuracy: 0.3684 - val_loss: 1.6631 - val_accuracy: 0.3678\n",
      "Epoch 10/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6620 - accuracy: 0.3690 - val_loss: 1.6538 - val_accuracy: 0.3691\n",
      "Epoch 11/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6547 - accuracy: 0.3715 - val_loss: 1.6502 - val_accuracy: 0.3697\n",
      "Epoch 12/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6420 - accuracy: 0.3742 - val_loss: 1.6360 - val_accuracy: 0.3808\n",
      "Epoch 13/555\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.6281 - accuracy: 0.3807 - val_loss: 1.6176 - val_accuracy: 0.3766\n",
      "Epoch 14/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6127 - accuracy: 0.3898 - val_loss: 1.5987 - val_accuracy: 0.3857\n",
      "Epoch 15/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5954 - accuracy: 0.3978 - val_loss: 1.5784 - val_accuracy: 0.4077\n",
      "Epoch 16/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5744 - accuracy: 0.4052 - val_loss: 1.5640 - val_accuracy: 0.4026\n",
      "Epoch 17/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5612 - accuracy: 0.4123 - val_loss: 1.5452 - val_accuracy: 0.4276\n",
      "Epoch 18/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5414 - accuracy: 0.4213 - val_loss: 1.5346 - val_accuracy: 0.4407\n",
      "Epoch 19/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5281 - accuracy: 0.4301 - val_loss: 1.5171 - val_accuracy: 0.4496\n",
      "Epoch 20/555\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 1.5157 - accuracy: 0.4428 - val_loss: 1.5032 - val_accuracy: 0.4577\n",
      "Epoch 21/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5070 - accuracy: 0.4460 - val_loss: 1.4926 - val_accuracy: 0.4584\n",
      "Epoch 22/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4944 - accuracy: 0.4506 - val_loss: 1.4860 - val_accuracy: 0.4701\n",
      "Epoch 23/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4855 - accuracy: 0.4565 - val_loss: 1.4833 - val_accuracy: 0.4735\n",
      "Epoch 24/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4821 - accuracy: 0.4561 - val_loss: 1.4734 - val_accuracy: 0.4580\n",
      "Epoch 25/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4692 - accuracy: 0.4627 - val_loss: 1.4639 - val_accuracy: 0.4658\n",
      "Epoch 26/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4611 - accuracy: 0.4640 - val_loss: 1.4568 - val_accuracy: 0.4640\n",
      "Epoch 27/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4568 - accuracy: 0.4668 - val_loss: 1.4610 - val_accuracy: 0.4600\n",
      "Epoch 28/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4511 - accuracy: 0.4681 - val_loss: 1.4796 - val_accuracy: 0.4494\n",
      "Epoch 29/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4495 - accuracy: 0.4697 - val_loss: 1.4400 - val_accuracy: 0.4785\n",
      "Epoch 30/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4440 - accuracy: 0.4716 - val_loss: 1.4557 - val_accuracy: 0.4718\n",
      "Epoch 31/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4434 - accuracy: 0.4737 - val_loss: 1.4493 - val_accuracy: 0.4614\n",
      "Epoch 32/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4377 - accuracy: 0.4750 - val_loss: 1.4301 - val_accuracy: 0.4827\n",
      "Epoch 33/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4327 - accuracy: 0.4775 - val_loss: 1.4395 - val_accuracy: 0.4833\n",
      "Epoch 34/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4261 - accuracy: 0.4783 - val_loss: 1.4232 - val_accuracy: 0.4858\n",
      "Epoch 35/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4239 - accuracy: 0.4819 - val_loss: 1.4492 - val_accuracy: 0.4700\n",
      "Epoch 36/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4176 - accuracy: 0.4829 - val_loss: 1.4194 - val_accuracy: 0.4874\n",
      "Epoch 37/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4147 - accuracy: 0.4868 - val_loss: 1.4070 - val_accuracy: 0.4924\n",
      "Epoch 38/555\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.4096 - accuracy: 0.4855 - val_loss: 1.4110 - val_accuracy: 0.4941\n",
      "Epoch 39/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4057 - accuracy: 0.4886 - val_loss: 1.4083 - val_accuracy: 0.4874\n",
      "Epoch 40/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4020 - accuracy: 0.4883 - val_loss: 1.4083 - val_accuracy: 0.4886\n",
      "Epoch 41/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3964 - accuracy: 0.4919 - val_loss: 1.3970 - val_accuracy: 0.4905\n",
      "Epoch 42/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3938 - accuracy: 0.4923 - val_loss: 1.3906 - val_accuracy: 0.4975\n",
      "Epoch 43/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3861 - accuracy: 0.4952 - val_loss: 1.4037 - val_accuracy: 0.4930\n",
      "Epoch 44/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3842 - accuracy: 0.4952 - val_loss: 1.4046 - val_accuracy: 0.4913\n",
      "Epoch 45/555\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.3890 - accuracy: 0.4898 - val_loss: 1.3846 - val_accuracy: 0.4946\n",
      "Epoch 46/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3847 - accuracy: 0.4917 - val_loss: 1.3851 - val_accuracy: 0.4966\n",
      "Epoch 47/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3818 - accuracy: 0.4954 - val_loss: 1.3804 - val_accuracy: 0.4997\n",
      "Epoch 48/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3755 - accuracy: 0.4965 - val_loss: 1.3842 - val_accuracy: 0.4998\n",
      "Epoch 49/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3780 - accuracy: 0.4963 - val_loss: 1.3798 - val_accuracy: 0.5026\n",
      "Epoch 50/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3763 - accuracy: 0.4934 - val_loss: 1.3720 - val_accuracy: 0.5002\n",
      "Epoch 51/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3700 - accuracy: 0.5007 - val_loss: 1.3782 - val_accuracy: 0.4981\n",
      "Epoch 52/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3690 - accuracy: 0.5012 - val_loss: 1.3664 - val_accuracy: 0.5053\n",
      "Epoch 53/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3714 - accuracy: 0.5012 - val_loss: 1.3737 - val_accuracy: 0.5005\n",
      "Epoch 54/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3666 - accuracy: 0.5005 - val_loss: 1.3641 - val_accuracy: 0.5054\n",
      "Epoch 55/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3710 - accuracy: 0.4984 - val_loss: 1.3653 - val_accuracy: 0.5076\n",
      "Epoch 56/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3683 - accuracy: 0.4999 - val_loss: 1.3675 - val_accuracy: 0.5106\n",
      "Epoch 57/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3694 - accuracy: 0.4988 - val_loss: 1.3677 - val_accuracy: 0.5039\n",
      "Epoch 58/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3629 - accuracy: 0.5010 - val_loss: 1.3679 - val_accuracy: 0.5023\n",
      "Epoch 59/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3661 - accuracy: 0.4992 - val_loss: 1.3721 - val_accuracy: 0.5090\n",
      "Epoch 60/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3653 - accuracy: 0.5001 - val_loss: 1.3663 - val_accuracy: 0.5012\n",
      "Epoch 61/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3599 - accuracy: 0.5038 - val_loss: 1.3610 - val_accuracy: 0.5061\n",
      "Epoch 62/555\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.3598 - accuracy: 0.5021 - val_loss: 1.3577 - val_accuracy: 0.5037\n",
      "Epoch 63/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3578 - accuracy: 0.5031 - val_loss: 1.3778 - val_accuracy: 0.5058\n",
      "Epoch 64/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3566 - accuracy: 0.5049 - val_loss: 1.3798 - val_accuracy: 0.4919\n",
      "Epoch 65/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3607 - accuracy: 0.5025 - val_loss: 1.3721 - val_accuracy: 0.5030\n",
      "Epoch 66/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3567 - accuracy: 0.5053 - val_loss: 1.3630 - val_accuracy: 0.5030\n",
      "Epoch 67/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3523 - accuracy: 0.5058 - val_loss: 1.3596 - val_accuracy: 0.5073\n",
      "Epoch 68/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3579 - accuracy: 0.5018 - val_loss: 1.3723 - val_accuracy: 0.5016\n",
      "Epoch 69/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3552 - accuracy: 0.5058 - val_loss: 1.3707 - val_accuracy: 0.5019\n",
      "Epoch 70/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3577 - accuracy: 0.5026 - val_loss: 1.3599 - val_accuracy: 0.5073\n",
      "Epoch 71/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3543 - accuracy: 0.5035 - val_loss: 1.3759 - val_accuracy: 0.5005\n",
      "Epoch 72/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3558 - accuracy: 0.5044 - val_loss: 1.3570 - val_accuracy: 0.5042\n",
      "Epoch 73/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3526 - accuracy: 0.5057 - val_loss: 1.3716 - val_accuracy: 0.5064\n",
      "Epoch 74/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3492 - accuracy: 0.5064 - val_loss: 1.3547 - val_accuracy: 0.5187\n",
      "Epoch 75/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3505 - accuracy: 0.5070 - val_loss: 1.3836 - val_accuracy: 0.5020\n",
      "Epoch 76/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3539 - accuracy: 0.5035 - val_loss: 1.3606 - val_accuracy: 0.5067\n",
      "Epoch 77/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3522 - accuracy: 0.5077 - val_loss: 1.3506 - val_accuracy: 0.5163\n",
      "Epoch 78/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3494 - accuracy: 0.5065 - val_loss: 1.3634 - val_accuracy: 0.5006\n",
      "Epoch 79/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3512 - accuracy: 0.5031 - val_loss: 1.3554 - val_accuracy: 0.5117\n",
      "Epoch 80/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3486 - accuracy: 0.5067 - val_loss: 1.3475 - val_accuracy: 0.5065\n",
      "Epoch 81/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3515 - accuracy: 0.5047 - val_loss: 1.3887 - val_accuracy: 0.4972\n",
      "Epoch 82/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3521 - accuracy: 0.5055 - val_loss: 1.3451 - val_accuracy: 0.5159\n",
      "Epoch 83/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3484 - accuracy: 0.5055 - val_loss: 1.3519 - val_accuracy: 0.5058\n",
      "Epoch 84/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3510 - accuracy: 0.5048 - val_loss: 1.3850 - val_accuracy: 0.4919\n",
      "Epoch 85/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3458 - accuracy: 0.5073 - val_loss: 1.3521 - val_accuracy: 0.5093\n",
      "Epoch 86/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3422 - accuracy: 0.5120 - val_loss: 1.3856 - val_accuracy: 0.4981\n",
      "Epoch 87/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3444 - accuracy: 0.5089 - val_loss: 1.3885 - val_accuracy: 0.5019\n",
      "Epoch 88/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3472 - accuracy: 0.5084 - val_loss: 1.3547 - val_accuracy: 0.5137\n",
      "Epoch 89/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3402 - accuracy: 0.5102 - val_loss: 1.3572 - val_accuracy: 0.5084\n",
      "Epoch 90/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3452 - accuracy: 0.5094 - val_loss: 1.3505 - val_accuracy: 0.5114\n",
      "Epoch 91/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3418 - accuracy: 0.5094 - val_loss: 1.3518 - val_accuracy: 0.5053\n",
      "Epoch 92/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3472 - accuracy: 0.5104 - val_loss: 1.3535 - val_accuracy: 0.5135\n",
      "Epoch 93/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3392 - accuracy: 0.5118 - val_loss: 1.3473 - val_accuracy: 0.5131\n",
      "Epoch 94/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3389 - accuracy: 0.5117 - val_loss: 1.3587 - val_accuracy: 0.5040\n",
      "Epoch 95/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3408 - accuracy: 0.5123 - val_loss: 1.3446 - val_accuracy: 0.5137\n",
      "Epoch 96/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3415 - accuracy: 0.5123 - val_loss: 1.3414 - val_accuracy: 0.5145\n",
      "Epoch 97/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3402 - accuracy: 0.5110 - val_loss: 1.3376 - val_accuracy: 0.5132\n",
      "Epoch 98/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3416 - accuracy: 0.5113 - val_loss: 1.3865 - val_accuracy: 0.5014\n",
      "Epoch 99/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3436 - accuracy: 0.5116 - val_loss: 1.3429 - val_accuracy: 0.5089\n",
      "Epoch 100/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3375 - accuracy: 0.5093 - val_loss: 1.3510 - val_accuracy: 0.5139\n",
      "Epoch 101/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3460 - accuracy: 0.5061 - val_loss: 1.3355 - val_accuracy: 0.5137\n",
      "Epoch 102/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3423 - accuracy: 0.5083 - val_loss: 1.3379 - val_accuracy: 0.5114\n",
      "Epoch 103/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3427 - accuracy: 0.5088 - val_loss: 1.3392 - val_accuracy: 0.5226\n",
      "Epoch 104/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3365 - accuracy: 0.5120 - val_loss: 1.3414 - val_accuracy: 0.5219\n",
      "Epoch 105/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3391 - accuracy: 0.5084 - val_loss: 1.3469 - val_accuracy: 0.5061\n",
      "Epoch 106/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3376 - accuracy: 0.5085 - val_loss: 1.3459 - val_accuracy: 0.5195\n",
      "Epoch 107/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3394 - accuracy: 0.5103 - val_loss: 1.3387 - val_accuracy: 0.5093\n",
      "Epoch 108/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3356 - accuracy: 0.5106 - val_loss: 1.3335 - val_accuracy: 0.5123\n",
      "Epoch 109/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3398 - accuracy: 0.5086 - val_loss: 1.3429 - val_accuracy: 0.5086\n",
      "Epoch 110/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3408 - accuracy: 0.5130 - val_loss: 1.3448 - val_accuracy: 0.5126\n",
      "Epoch 111/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3406 - accuracy: 0.5113 - val_loss: 1.3403 - val_accuracy: 0.5216\n",
      "Epoch 112/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3364 - accuracy: 0.5123 - val_loss: 1.3442 - val_accuracy: 0.5156\n",
      "Epoch 113/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3378 - accuracy: 0.5097 - val_loss: 1.3556 - val_accuracy: 0.5040\n",
      "Epoch 114/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3354 - accuracy: 0.5127 - val_loss: 1.3684 - val_accuracy: 0.5118\n",
      "Epoch 115/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3357 - accuracy: 0.5106 - val_loss: 1.3602 - val_accuracy: 0.5081\n",
      "Epoch 116/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3364 - accuracy: 0.5122 - val_loss: 1.3333 - val_accuracy: 0.5254\n",
      "Epoch 117/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3358 - accuracy: 0.5130 - val_loss: 1.3389 - val_accuracy: 0.5162\n",
      "Epoch 118/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3348 - accuracy: 0.5128 - val_loss: 1.3373 - val_accuracy: 0.5187\n",
      "Epoch 119/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3298 - accuracy: 0.5150 - val_loss: 1.3436 - val_accuracy: 0.5170\n",
      "Epoch 120/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3332 - accuracy: 0.5146 - val_loss: 1.3638 - val_accuracy: 0.5137\n",
      "Epoch 121/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3347 - accuracy: 0.5141 - val_loss: 1.3314 - val_accuracy: 0.5151\n",
      "Epoch 122/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3304 - accuracy: 0.5122 - val_loss: 1.3388 - val_accuracy: 0.5131\n",
      "Epoch 123/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3352 - accuracy: 0.5126 - val_loss: 1.3496 - val_accuracy: 0.5107\n",
      "Epoch 124/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3337 - accuracy: 0.5123 - val_loss: 1.3391 - val_accuracy: 0.5081\n",
      "Epoch 125/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3318 - accuracy: 0.5131 - val_loss: 1.3304 - val_accuracy: 0.5201\n",
      "Epoch 126/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3339 - accuracy: 0.5117 - val_loss: 1.3348 - val_accuracy: 0.5160\n",
      "Epoch 127/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3344 - accuracy: 0.5117 - val_loss: 1.3356 - val_accuracy: 0.5139\n",
      "Epoch 128/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3356 - accuracy: 0.5107 - val_loss: 1.3319 - val_accuracy: 0.5117\n",
      "Epoch 129/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3356 - accuracy: 0.5100 - val_loss: 1.3392 - val_accuracy: 0.5170\n",
      "Epoch 130/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3376 - accuracy: 0.5131 - val_loss: 1.3753 - val_accuracy: 0.5095\n",
      "Epoch 131/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3365 - accuracy: 0.5104 - val_loss: 1.3400 - val_accuracy: 0.5114\n",
      "Epoch 132/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3346 - accuracy: 0.5133 - val_loss: 1.3330 - val_accuracy: 0.5159\n",
      "Epoch 133/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3317 - accuracy: 0.5114 - val_loss: 1.3361 - val_accuracy: 0.5213\n",
      "Epoch 134/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3302 - accuracy: 0.5138 - val_loss: 1.3724 - val_accuracy: 0.4989\n",
      "Epoch 135/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3369 - accuracy: 0.5109 - val_loss: 1.3411 - val_accuracy: 0.5118\n",
      "Epoch 136/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3310 - accuracy: 0.5131 - val_loss: 1.3419 - val_accuracy: 0.5173\n",
      "Epoch 137/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3278 - accuracy: 0.5162 - val_loss: 1.3322 - val_accuracy: 0.5157\n",
      "Epoch 138/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3321 - accuracy: 0.5120 - val_loss: 1.3603 - val_accuracy: 0.5002\n",
      "Epoch 139/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3264 - accuracy: 0.5154 - val_loss: 1.3348 - val_accuracy: 0.5229\n",
      "Epoch 140/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3299 - accuracy: 0.5155 - val_loss: 1.3339 - val_accuracy: 0.5145\n",
      "Epoch 141/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3280 - accuracy: 0.5123 - val_loss: 1.3362 - val_accuracy: 0.5165\n",
      "Epoch 142/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3356 - accuracy: 0.5118 - val_loss: 1.3528 - val_accuracy: 0.5132\n",
      "Epoch 143/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3297 - accuracy: 0.5154 - val_loss: 1.3433 - val_accuracy: 0.5040\n",
      "Epoch 144/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3319 - accuracy: 0.5122 - val_loss: 1.3326 - val_accuracy: 0.5109\n",
      "Epoch 145/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3326 - accuracy: 0.5108 - val_loss: 1.3367 - val_accuracy: 0.5134\n",
      "Epoch 146/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3350 - accuracy: 0.5104 - val_loss: 1.3417 - val_accuracy: 0.5139\n",
      "Epoch 147/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3328 - accuracy: 0.5126 - val_loss: 1.3348 - val_accuracy: 0.5148\n",
      "Epoch 148/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3353 - accuracy: 0.5109 - val_loss: 1.3440 - val_accuracy: 0.5162\n",
      "Epoch 149/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3308 - accuracy: 0.5103 - val_loss: 1.3443 - val_accuracy: 0.5149\n",
      "Epoch 150/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3294 - accuracy: 0.5118 - val_loss: 1.3512 - val_accuracy: 0.5233\n",
      "Epoch 151/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3354 - accuracy: 0.5087 - val_loss: 1.3345 - val_accuracy: 0.5244\n",
      "Epoch 152/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3287 - accuracy: 0.5123 - val_loss: 1.3472 - val_accuracy: 0.5163\n",
      "Epoch 153/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3258 - accuracy: 0.5164 - val_loss: 1.3305 - val_accuracy: 0.5196\n",
      "Epoch 154/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3290 - accuracy: 0.5137 - val_loss: 1.3692 - val_accuracy: 0.5054\n",
      "Epoch 155/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3322 - accuracy: 0.5126 - val_loss: 1.3412 - val_accuracy: 0.5101\n",
      "Epoch 156/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3296 - accuracy: 0.5110 - val_loss: 1.3326 - val_accuracy: 0.5160\n",
      "Epoch 157/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3312 - accuracy: 0.5137 - val_loss: 1.3313 - val_accuracy: 0.5126\n",
      "Epoch 158/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3237 - accuracy: 0.5183 - val_loss: 1.3305 - val_accuracy: 0.5265\n",
      "Epoch 159/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3275 - accuracy: 0.5156 - val_loss: 1.3320 - val_accuracy: 0.5212\n",
      "Epoch 160/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3277 - accuracy: 0.5163 - val_loss: 1.3323 - val_accuracy: 0.5167\n",
      "Epoch 161/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3259 - accuracy: 0.5160 - val_loss: 1.3275 - val_accuracy: 0.5213\n",
      "Epoch 162/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3311 - accuracy: 0.5113 - val_loss: 1.3362 - val_accuracy: 0.5244\n",
      "Epoch 163/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3299 - accuracy: 0.5122 - val_loss: 1.3353 - val_accuracy: 0.5145\n",
      "Epoch 164/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3231 - accuracy: 0.5166 - val_loss: 1.3381 - val_accuracy: 0.5201\n",
      "Epoch 165/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3297 - accuracy: 0.5129 - val_loss: 1.3399 - val_accuracy: 0.5087\n",
      "Epoch 166/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3233 - accuracy: 0.5152 - val_loss: 1.3328 - val_accuracy: 0.5174\n",
      "Epoch 167/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3276 - accuracy: 0.5135 - val_loss: 1.3351 - val_accuracy: 0.5156\n",
      "Epoch 168/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3224 - accuracy: 0.5173 - val_loss: 1.3215 - val_accuracy: 0.5260\n",
      "Epoch 169/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3231 - accuracy: 0.5159 - val_loss: 1.3456 - val_accuracy: 0.5142\n",
      "Epoch 170/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3288 - accuracy: 0.5153 - val_loss: 1.3907 - val_accuracy: 0.4991\n",
      "Epoch 171/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3274 - accuracy: 0.5163 - val_loss: 1.3285 - val_accuracy: 0.5209\n",
      "Epoch 172/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3261 - accuracy: 0.5166 - val_loss: 1.3279 - val_accuracy: 0.5257\n",
      "Epoch 173/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3226 - accuracy: 0.5169 - val_loss: 1.3326 - val_accuracy: 0.5174\n",
      "Epoch 174/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3240 - accuracy: 0.5145 - val_loss: 1.3605 - val_accuracy: 0.5030\n",
      "Epoch 175/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3222 - accuracy: 0.5179 - val_loss: 1.3368 - val_accuracy: 0.5173\n",
      "Epoch 176/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3227 - accuracy: 0.5154 - val_loss: 1.3282 - val_accuracy: 0.5202\n",
      "Epoch 177/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3257 - accuracy: 0.5135 - val_loss: 1.3234 - val_accuracy: 0.5263\n",
      "Epoch 178/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3205 - accuracy: 0.5169 - val_loss: 1.3216 - val_accuracy: 0.5299\n",
      "Epoch 179/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3212 - accuracy: 0.5146 - val_loss: 1.3538 - val_accuracy: 0.5090\n",
      "Epoch 180/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3251 - accuracy: 0.5128 - val_loss: 1.3773 - val_accuracy: 0.5106\n",
      "Epoch 181/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3282 - accuracy: 0.5105 - val_loss: 1.3325 - val_accuracy: 0.5109\n",
      "Epoch 182/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3211 - accuracy: 0.5138 - val_loss: 1.3311 - val_accuracy: 0.5333\n",
      "Epoch 183/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3173 - accuracy: 0.5153 - val_loss: 1.3430 - val_accuracy: 0.5156\n",
      "Epoch 184/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3220 - accuracy: 0.5163 - val_loss: 1.3358 - val_accuracy: 0.5179\n",
      "Epoch 185/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3210 - accuracy: 0.5187 - val_loss: 1.3407 - val_accuracy: 0.5139\n",
      "Epoch 186/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3181 - accuracy: 0.5180 - val_loss: 1.3246 - val_accuracy: 0.5227\n",
      "Epoch 187/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3201 - accuracy: 0.5154 - val_loss: 1.3321 - val_accuracy: 0.5181\n",
      "Epoch 188/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3256 - accuracy: 0.5147 - val_loss: 1.3806 - val_accuracy: 0.5026\n",
      "Epoch 189/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3228 - accuracy: 0.5169 - val_loss: 1.3457 - val_accuracy: 0.5219\n",
      "Epoch 190/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3244 - accuracy: 0.5168 - val_loss: 1.3297 - val_accuracy: 0.5263\n",
      "Epoch 191/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3199 - accuracy: 0.5173 - val_loss: 1.3400 - val_accuracy: 0.5117\n",
      "Epoch 192/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3254 - accuracy: 0.5160 - val_loss: 1.3221 - val_accuracy: 0.5265\n",
      "Epoch 193/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3198 - accuracy: 0.5157 - val_loss: 1.3462 - val_accuracy: 0.5163\n",
      "Epoch 194/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3222 - accuracy: 0.5152 - val_loss: 1.3433 - val_accuracy: 0.5201\n",
      "Epoch 195/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3165 - accuracy: 0.5212 - val_loss: 1.3219 - val_accuracy: 0.5188\n",
      "Epoch 196/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3208 - accuracy: 0.5159 - val_loss: 1.3266 - val_accuracy: 0.5167\n",
      "Epoch 197/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3214 - accuracy: 0.5141 - val_loss: 1.3248 - val_accuracy: 0.5291\n",
      "Epoch 198/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3194 - accuracy: 0.5144 - val_loss: 1.3499 - val_accuracy: 0.5128\n",
      "Epoch 199/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3227 - accuracy: 0.5179 - val_loss: 1.3500 - val_accuracy: 0.5199\n",
      "Epoch 200/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3248 - accuracy: 0.5133 - val_loss: 1.3359 - val_accuracy: 0.5277\n",
      "Epoch 201/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3199 - accuracy: 0.5139 - val_loss: 1.3218 - val_accuracy: 0.5188\n",
      "Epoch 202/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3162 - accuracy: 0.5175 - val_loss: 1.3198 - val_accuracy: 0.5226\n",
      "Epoch 203/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3230 - accuracy: 0.5152 - val_loss: 1.3629 - val_accuracy: 0.5090\n",
      "Epoch 204/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3145 - accuracy: 0.5198 - val_loss: 1.3276 - val_accuracy: 0.5260\n",
      "Epoch 205/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3186 - accuracy: 0.5151 - val_loss: 1.3270 - val_accuracy: 0.5146\n",
      "Epoch 206/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3142 - accuracy: 0.5182 - val_loss: 1.3371 - val_accuracy: 0.5241\n",
      "Epoch 207/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3138 - accuracy: 0.5190 - val_loss: 1.3231 - val_accuracy: 0.5246\n",
      "Epoch 208/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3194 - accuracy: 0.5154 - val_loss: 1.3253 - val_accuracy: 0.5238\n",
      "Epoch 209/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3155 - accuracy: 0.5199 - val_loss: 1.3197 - val_accuracy: 0.5219\n",
      "Epoch 210/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3123 - accuracy: 0.5207 - val_loss: 1.3913 - val_accuracy: 0.5033\n",
      "Epoch 211/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3173 - accuracy: 0.5136 - val_loss: 1.3311 - val_accuracy: 0.5201\n",
      "Epoch 212/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3211 - accuracy: 0.5134 - val_loss: 1.3587 - val_accuracy: 0.4984\n",
      "Epoch 213/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3199 - accuracy: 0.5164 - val_loss: 1.3283 - val_accuracy: 0.5277\n",
      "Epoch 214/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3157 - accuracy: 0.5166 - val_loss: 1.3343 - val_accuracy: 0.5199\n",
      "Epoch 215/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3169 - accuracy: 0.5174 - val_loss: 1.3397 - val_accuracy: 0.5109\n",
      "Epoch 216/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3164 - accuracy: 0.5161 - val_loss: 1.3357 - val_accuracy: 0.5120\n",
      "Epoch 217/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3129 - accuracy: 0.5173 - val_loss: 1.3275 - val_accuracy: 0.5170\n",
      "Epoch 218/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3193 - accuracy: 0.5146 - val_loss: 1.3218 - val_accuracy: 0.5198\n",
      "Epoch 219/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3161 - accuracy: 0.5182 - val_loss: 1.3280 - val_accuracy: 0.5241\n",
      "Epoch 220/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3140 - accuracy: 0.5180 - val_loss: 1.3271 - val_accuracy: 0.5319\n",
      "Epoch 221/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3131 - accuracy: 0.5188 - val_loss: 1.3234 - val_accuracy: 0.5151\n",
      "Epoch 222/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3108 - accuracy: 0.5203 - val_loss: 1.3184 - val_accuracy: 0.5209\n",
      "Epoch 223/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3139 - accuracy: 0.5165 - val_loss: 1.3526 - val_accuracy: 0.5181\n",
      "Epoch 224/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3119 - accuracy: 0.5203 - val_loss: 1.3373 - val_accuracy: 0.5111\n",
      "Epoch 225/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3145 - accuracy: 0.5176 - val_loss: 1.3754 - val_accuracy: 0.5017\n",
      "Epoch 226/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3147 - accuracy: 0.5170 - val_loss: 1.3287 - val_accuracy: 0.5177\n",
      "Epoch 227/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3080 - accuracy: 0.5203 - val_loss: 1.3165 - val_accuracy: 0.5276\n",
      "Epoch 228/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3177 - accuracy: 0.5149 - val_loss: 1.3533 - val_accuracy: 0.5081\n",
      "Epoch 229/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5153 - val_loss: 1.3192 - val_accuracy: 0.5286\n",
      "Epoch 230/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5179 - val_loss: 1.3211 - val_accuracy: 0.5258\n",
      "Epoch 231/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3113 - accuracy: 0.5176 - val_loss: 1.3307 - val_accuracy: 0.5262\n",
      "Epoch 232/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3115 - accuracy: 0.5193 - val_loss: 1.3375 - val_accuracy: 0.5209\n",
      "Epoch 233/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3121 - accuracy: 0.5194 - val_loss: 1.3263 - val_accuracy: 0.5254\n",
      "Epoch 234/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3109 - accuracy: 0.5182 - val_loss: 1.3466 - val_accuracy: 0.5129\n",
      "Epoch 235/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3114 - accuracy: 0.5152 - val_loss: 1.3286 - val_accuracy: 0.5304\n",
      "Epoch 236/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3093 - accuracy: 0.5188 - val_loss: 1.3696 - val_accuracy: 0.5023\n",
      "Epoch 237/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3119 - accuracy: 0.5217 - val_loss: 1.3293 - val_accuracy: 0.5191\n",
      "Epoch 238/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3118 - accuracy: 0.5180 - val_loss: 1.3197 - val_accuracy: 0.5290\n",
      "Epoch 239/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3109 - accuracy: 0.5181 - val_loss: 1.3514 - val_accuracy: 0.5090\n",
      "Epoch 240/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3137 - accuracy: 0.5160 - val_loss: 1.3181 - val_accuracy: 0.5258\n",
      "Epoch 241/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3102 - accuracy: 0.5211 - val_loss: 1.3355 - val_accuracy: 0.5181\n",
      "Epoch 242/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3180 - accuracy: 0.5140 - val_loss: 1.3321 - val_accuracy: 0.5114\n",
      "Epoch 243/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3093 - accuracy: 0.5216 - val_loss: 1.3186 - val_accuracy: 0.5244\n",
      "Epoch 244/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3104 - accuracy: 0.5205 - val_loss: 1.3334 - val_accuracy: 0.5233\n",
      "Epoch 245/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3091 - accuracy: 0.5200 - val_loss: 1.3218 - val_accuracy: 0.5219\n",
      "Epoch 246/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3132 - accuracy: 0.5193 - val_loss: 1.3300 - val_accuracy: 0.5263\n",
      "Epoch 247/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3104 - accuracy: 0.5179 - val_loss: 1.3181 - val_accuracy: 0.5229\n",
      "Epoch 248/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3066 - accuracy: 0.5195 - val_loss: 1.3506 - val_accuracy: 0.5126\n",
      "Epoch 249/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3150 - accuracy: 0.5173 - val_loss: 1.3373 - val_accuracy: 0.5254\n",
      "Epoch 250/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3130 - accuracy: 0.5212 - val_loss: 1.3227 - val_accuracy: 0.5246\n",
      "Epoch 251/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5173 - val_loss: 1.3285 - val_accuracy: 0.5238\n",
      "Epoch 252/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3082 - accuracy: 0.5195 - val_loss: 1.3229 - val_accuracy: 0.5244\n",
      "Epoch 253/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3096 - accuracy: 0.5208 - val_loss: 1.3258 - val_accuracy: 0.5149\n",
      "Epoch 254/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3126 - accuracy: 0.5183 - val_loss: 1.3423 - val_accuracy: 0.5181\n",
      "Epoch 255/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3084 - accuracy: 0.5163 - val_loss: 1.3513 - val_accuracy: 0.5109\n",
      "Epoch 256/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3094 - accuracy: 0.5180 - val_loss: 1.3400 - val_accuracy: 0.5137\n",
      "Epoch 257/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3061 - accuracy: 0.5186 - val_loss: 1.3343 - val_accuracy: 0.5184\n",
      "Epoch 258/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3122 - accuracy: 0.5190 - val_loss: 1.3175 - val_accuracy: 0.5252\n",
      "Epoch 259/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3059 - accuracy: 0.5219 - val_loss: 1.3297 - val_accuracy: 0.5199\n",
      "Epoch 260/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3078 - accuracy: 0.5199 - val_loss: 1.3218 - val_accuracy: 0.5279\n",
      "Epoch 261/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3033 - accuracy: 0.5218 - val_loss: 1.3175 - val_accuracy: 0.5257\n",
      "Epoch 262/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3042 - accuracy: 0.5209 - val_loss: 1.3405 - val_accuracy: 0.5171\n",
      "Epoch 263/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3079 - accuracy: 0.5205 - val_loss: 1.3140 - val_accuracy: 0.5307\n",
      "Epoch 264/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3072 - accuracy: 0.5202 - val_loss: 1.3232 - val_accuracy: 0.5160\n",
      "Epoch 265/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3078 - accuracy: 0.5186 - val_loss: 1.3266 - val_accuracy: 0.5177\n",
      "Epoch 266/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3124 - accuracy: 0.5169 - val_loss: 1.3420 - val_accuracy: 0.5153\n",
      "Epoch 267/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3084 - accuracy: 0.5196 - val_loss: 1.3311 - val_accuracy: 0.5160\n",
      "Epoch 268/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3049 - accuracy: 0.5209 - val_loss: 1.3177 - val_accuracy: 0.5260\n",
      "Epoch 269/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3091 - accuracy: 0.5221 - val_loss: 1.3306 - val_accuracy: 0.5176\n",
      "Epoch 270/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3092 - accuracy: 0.5198 - val_loss: 1.3191 - val_accuracy: 0.5199\n",
      "Epoch 271/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3072 - accuracy: 0.5212 - val_loss: 1.3334 - val_accuracy: 0.5076\n",
      "Epoch 272/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3083 - accuracy: 0.5213 - val_loss: 1.3163 - val_accuracy: 0.5226\n",
      "Epoch 273/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3026 - accuracy: 0.5210 - val_loss: 1.3353 - val_accuracy: 0.5163\n",
      "Epoch 274/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3099 - accuracy: 0.5207 - val_loss: 1.3192 - val_accuracy: 0.5193\n",
      "Epoch 275/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3009 - accuracy: 0.5244 - val_loss: 1.3318 - val_accuracy: 0.5196\n",
      "Epoch 276/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3065 - accuracy: 0.5203 - val_loss: 1.3161 - val_accuracy: 0.5305\n",
      "Epoch 277/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3112 - accuracy: 0.5200 - val_loss: 1.3134 - val_accuracy: 0.5265\n",
      "Epoch 278/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3093 - accuracy: 0.5204 - val_loss: 1.3236 - val_accuracy: 0.5135\n",
      "Epoch 279/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3030 - accuracy: 0.5220 - val_loss: 1.3187 - val_accuracy: 0.5279\n",
      "Epoch 280/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3021 - accuracy: 0.5213 - val_loss: 1.3336 - val_accuracy: 0.5185\n",
      "Epoch 281/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3039 - accuracy: 0.5198 - val_loss: 1.3392 - val_accuracy: 0.5205\n",
      "Epoch 282/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3120 - accuracy: 0.5219 - val_loss: 1.3450 - val_accuracy: 0.5135\n",
      "Epoch 283/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3025 - accuracy: 0.5232 - val_loss: 1.3398 - val_accuracy: 0.5219\n",
      "Epoch 284/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3041 - accuracy: 0.5235 - val_loss: 1.3234 - val_accuracy: 0.5296\n",
      "Epoch 285/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3039 - accuracy: 0.5222 - val_loss: 1.3168 - val_accuracy: 0.5216\n",
      "Epoch 286/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3012 - accuracy: 0.5230 - val_loss: 1.3373 - val_accuracy: 0.5240\n",
      "Epoch 287/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3032 - accuracy: 0.5248 - val_loss: 1.3168 - val_accuracy: 0.5201\n",
      "Epoch 288/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3020 - accuracy: 0.5240 - val_loss: 1.3383 - val_accuracy: 0.5260\n",
      "Epoch 289/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3012 - accuracy: 0.5228 - val_loss: 1.3248 - val_accuracy: 0.5269\n",
      "Epoch 290/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3046 - accuracy: 0.5199 - val_loss: 1.3267 - val_accuracy: 0.5243\n",
      "Epoch 291/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3069 - accuracy: 0.5212 - val_loss: 1.3161 - val_accuracy: 0.5215\n",
      "Epoch 292/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3047 - accuracy: 0.5232 - val_loss: 1.3185 - val_accuracy: 0.5285\n",
      "Epoch 293/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3001 - accuracy: 0.5202 - val_loss: 1.3444 - val_accuracy: 0.5148\n",
      "Epoch 294/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3018 - accuracy: 0.5221 - val_loss: 1.3204 - val_accuracy: 0.5187\n",
      "Epoch 295/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2997 - accuracy: 0.5218 - val_loss: 1.3353 - val_accuracy: 0.5089\n",
      "Epoch 296/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3003 - accuracy: 0.5248 - val_loss: 1.3161 - val_accuracy: 0.5249\n",
      "Epoch 297/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3055 - accuracy: 0.5210 - val_loss: 1.3313 - val_accuracy: 0.5154\n",
      "Epoch 298/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3005 - accuracy: 0.5212 - val_loss: 1.3491 - val_accuracy: 0.5149\n",
      "Epoch 299/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3023 - accuracy: 0.5267 - val_loss: 1.3289 - val_accuracy: 0.5205\n",
      "Epoch 300/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3041 - accuracy: 0.5186 - val_loss: 1.3165 - val_accuracy: 0.5209\n",
      "Epoch 301/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3034 - accuracy: 0.5235 - val_loss: 1.3171 - val_accuracy: 0.5210\n",
      "Epoch 302/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3013 - accuracy: 0.5203 - val_loss: 1.3207 - val_accuracy: 0.5249\n",
      "Epoch 303/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3069 - accuracy: 0.5233 - val_loss: 1.3172 - val_accuracy: 0.5232\n",
      "Epoch 304/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3023 - accuracy: 0.5219 - val_loss: 1.3315 - val_accuracy: 0.5274\n",
      "Epoch 305/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3048 - accuracy: 0.5209 - val_loss: 1.3167 - val_accuracy: 0.5304\n",
      "Epoch 306/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3004 - accuracy: 0.5233 - val_loss: 1.3128 - val_accuracy: 0.5294\n",
      "Epoch 307/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2977 - accuracy: 0.5226 - val_loss: 1.3279 - val_accuracy: 0.5248\n",
      "Epoch 308/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3047 - accuracy: 0.5206 - val_loss: 1.3122 - val_accuracy: 0.5285\n",
      "Epoch 309/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3002 - accuracy: 0.5237 - val_loss: 1.3208 - val_accuracy: 0.5196\n",
      "Epoch 310/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3022 - accuracy: 0.5203 - val_loss: 1.3157 - val_accuracy: 0.5272\n",
      "Epoch 311/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3021 - accuracy: 0.5219 - val_loss: 1.3237 - val_accuracy: 0.5163\n",
      "Epoch 312/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3012 - accuracy: 0.5238 - val_loss: 1.3257 - val_accuracy: 0.5279\n",
      "Epoch 313/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2975 - accuracy: 0.5238 - val_loss: 1.3255 - val_accuracy: 0.5296\n",
      "Epoch 314/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3031 - accuracy: 0.5247 - val_loss: 1.3258 - val_accuracy: 0.5240\n",
      "Epoch 315/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3015 - accuracy: 0.5246 - val_loss: 1.3235 - val_accuracy: 0.5244\n",
      "Epoch 316/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3063 - accuracy: 0.5184 - val_loss: 1.3184 - val_accuracy: 0.5276\n",
      "Epoch 317/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3026 - accuracy: 0.5222 - val_loss: 1.3626 - val_accuracy: 0.5104\n",
      "Epoch 318/555\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3044 - accuracy: 0.5199 - val_loss: 1.3269 - val_accuracy: 0.5277\n",
      "Epoch 319/555\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3108 - accuracy: 0.5179 - val_loss: 1.3151 - val_accuracy: 0.5210\n",
      "Epoch 320/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2997 - accuracy: 0.5258 - val_loss: 1.3174 - val_accuracy: 0.5241\n",
      "Epoch 321/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2988 - accuracy: 0.5242 - val_loss: 1.3238 - val_accuracy: 0.5248\n",
      "Epoch 322/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2982 - accuracy: 0.5256 - val_loss: 1.3176 - val_accuracy: 0.5314\n",
      "Epoch 323/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2999 - accuracy: 0.5238 - val_loss: 1.3127 - val_accuracy: 0.5263\n",
      "Epoch 324/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2981 - accuracy: 0.5245 - val_loss: 1.3143 - val_accuracy: 0.5230\n",
      "Epoch 325/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3026 - accuracy: 0.5224 - val_loss: 1.3507 - val_accuracy: 0.5159\n",
      "Epoch 326/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3023 - accuracy: 0.5231 - val_loss: 1.3174 - val_accuracy: 0.5272\n",
      "Epoch 327/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3019 - accuracy: 0.5225 - val_loss: 1.3387 - val_accuracy: 0.5167\n",
      "Epoch 328/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2985 - accuracy: 0.5251 - val_loss: 1.3311 - val_accuracy: 0.5154\n",
      "Epoch 329/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3003 - accuracy: 0.5255 - val_loss: 1.3206 - val_accuracy: 0.5209\n",
      "Epoch 330/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3014 - accuracy: 0.5250 - val_loss: 1.3133 - val_accuracy: 0.5291\n",
      "Epoch 331/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2959 - accuracy: 0.5268 - val_loss: 1.3127 - val_accuracy: 0.5252\n",
      "Epoch 332/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3019 - accuracy: 0.5246 - val_loss: 1.3416 - val_accuracy: 0.5177\n",
      "Epoch 333/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3003 - accuracy: 0.5217 - val_loss: 1.3363 - val_accuracy: 0.5221\n",
      "Epoch 334/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2990 - accuracy: 0.5224 - val_loss: 1.3188 - val_accuracy: 0.5165\n",
      "Epoch 335/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2974 - accuracy: 0.5265 - val_loss: 1.3147 - val_accuracy: 0.5240\n",
      "Epoch 336/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3011 - accuracy: 0.5227 - val_loss: 1.3170 - val_accuracy: 0.5258\n",
      "Epoch 337/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2961 - accuracy: 0.5238 - val_loss: 1.3347 - val_accuracy: 0.5288\n",
      "Epoch 338/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2971 - accuracy: 0.5268 - val_loss: 1.3231 - val_accuracy: 0.5229\n",
      "Epoch 339/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3015 - accuracy: 0.5232 - val_loss: 1.3115 - val_accuracy: 0.5269\n",
      "Epoch 340/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3004 - accuracy: 0.5236 - val_loss: 1.3118 - val_accuracy: 0.5332\n",
      "Epoch 341/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2994 - accuracy: 0.5236 - val_loss: 1.3273 - val_accuracy: 0.5339\n",
      "Epoch 342/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2925 - accuracy: 0.5253 - val_loss: 1.3168 - val_accuracy: 0.5229\n",
      "Epoch 343/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3032 - accuracy: 0.5227 - val_loss: 1.3185 - val_accuracy: 0.5238\n",
      "Epoch 344/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3013 - accuracy: 0.5232 - val_loss: 1.3178 - val_accuracy: 0.5271\n",
      "Epoch 345/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2974 - accuracy: 0.5255 - val_loss: 1.3373 - val_accuracy: 0.5224\n",
      "Epoch 346/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2981 - accuracy: 0.5251 - val_loss: 1.3168 - val_accuracy: 0.5290\n",
      "Epoch 347/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3031 - accuracy: 0.5258 - val_loss: 1.3287 - val_accuracy: 0.5201\n",
      "Epoch 348/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2966 - accuracy: 0.5265 - val_loss: 1.3154 - val_accuracy: 0.5198\n",
      "Epoch 349/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2981 - accuracy: 0.5237 - val_loss: 1.3125 - val_accuracy: 0.5291\n",
      "Epoch 350/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2965 - accuracy: 0.5264 - val_loss: 1.3143 - val_accuracy: 0.5268\n",
      "Epoch 351/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2982 - accuracy: 0.5252 - val_loss: 1.3291 - val_accuracy: 0.5223\n",
      "Epoch 352/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2992 - accuracy: 0.5241 - val_loss: 1.3144 - val_accuracy: 0.5302\n",
      "Epoch 353/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2981 - accuracy: 0.5255 - val_loss: 1.3093 - val_accuracy: 0.5327\n",
      "Epoch 354/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3011 - accuracy: 0.5236 - val_loss: 1.3269 - val_accuracy: 0.5190\n",
      "Epoch 355/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2967 - accuracy: 0.5235 - val_loss: 1.3100 - val_accuracy: 0.5328\n",
      "Epoch 356/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2959 - accuracy: 0.5253 - val_loss: 1.3180 - val_accuracy: 0.5241\n",
      "Epoch 357/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2959 - accuracy: 0.5248 - val_loss: 1.3238 - val_accuracy: 0.5237\n",
      "Epoch 358/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3005 - accuracy: 0.5243 - val_loss: 1.3208 - val_accuracy: 0.5196\n",
      "Epoch 359/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2942 - accuracy: 0.5261 - val_loss: 1.3202 - val_accuracy: 0.5195\n",
      "Epoch 360/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2946 - accuracy: 0.5274 - val_loss: 1.3422 - val_accuracy: 0.5159\n",
      "Epoch 361/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2961 - accuracy: 0.5294 - val_loss: 1.3279 - val_accuracy: 0.5159\n",
      "Epoch 362/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2979 - accuracy: 0.5251 - val_loss: 1.3197 - val_accuracy: 0.5246\n",
      "Epoch 363/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2995 - accuracy: 0.5224 - val_loss: 1.3218 - val_accuracy: 0.5266\n",
      "Epoch 364/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2984 - accuracy: 0.5268 - val_loss: 1.3255 - val_accuracy: 0.5185\n",
      "Epoch 365/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2958 - accuracy: 0.5264 - val_loss: 1.3212 - val_accuracy: 0.5241\n",
      "Epoch 366/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2996 - accuracy: 0.5271 - val_loss: 1.3153 - val_accuracy: 0.5233\n",
      "Epoch 367/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2922 - accuracy: 0.5249 - val_loss: 1.3129 - val_accuracy: 0.5274\n",
      "Epoch 368/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2939 - accuracy: 0.5290 - val_loss: 1.3162 - val_accuracy: 0.5304\n",
      "Epoch 369/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2956 - accuracy: 0.5246 - val_loss: 1.3225 - val_accuracy: 0.5243\n",
      "Epoch 370/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2965 - accuracy: 0.5243 - val_loss: 1.3221 - val_accuracy: 0.5216\n",
      "Epoch 371/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2980 - accuracy: 0.5204 - val_loss: 1.3183 - val_accuracy: 0.5277\n",
      "Epoch 372/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2930 - accuracy: 0.5271 - val_loss: 1.3165 - val_accuracy: 0.5316\n",
      "Epoch 373/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2954 - accuracy: 0.5266 - val_loss: 1.3226 - val_accuracy: 0.5268\n",
      "Epoch 374/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3002 - accuracy: 0.5242 - val_loss: 1.3516 - val_accuracy: 0.5187\n",
      "Epoch 375/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2928 - accuracy: 0.5287 - val_loss: 1.3203 - val_accuracy: 0.5163\n",
      "Epoch 376/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2942 - accuracy: 0.5288 - val_loss: 1.3290 - val_accuracy: 0.5260\n",
      "Epoch 377/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2936 - accuracy: 0.5258 - val_loss: 1.3467 - val_accuracy: 0.5173\n",
      "Epoch 378/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2918 - accuracy: 0.5295 - val_loss: 1.3205 - val_accuracy: 0.5240\n",
      "Epoch 379/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2932 - accuracy: 0.5264 - val_loss: 1.3111 - val_accuracy: 0.5263\n",
      "Epoch 380/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2941 - accuracy: 0.5286 - val_loss: 1.3224 - val_accuracy: 0.5246\n",
      "Epoch 381/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2956 - accuracy: 0.5235 - val_loss: 1.3187 - val_accuracy: 0.5244\n",
      "Epoch 382/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2941 - accuracy: 0.5291 - val_loss: 1.3173 - val_accuracy: 0.5274\n",
      "Epoch 383/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2934 - accuracy: 0.5249 - val_loss: 1.3109 - val_accuracy: 0.5288\n",
      "Epoch 384/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2956 - accuracy: 0.5255 - val_loss: 1.3373 - val_accuracy: 0.5219\n",
      "Epoch 385/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2956 - accuracy: 0.5259 - val_loss: 1.3122 - val_accuracy: 0.5311\n",
      "Epoch 386/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2868 - accuracy: 0.5285 - val_loss: 1.3106 - val_accuracy: 0.5293\n",
      "Epoch 387/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2967 - accuracy: 0.5248 - val_loss: 1.3101 - val_accuracy: 0.5265\n",
      "Epoch 388/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2927 - accuracy: 0.5288 - val_loss: 1.3307 - val_accuracy: 0.5168\n",
      "Epoch 389/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2921 - accuracy: 0.5274 - val_loss: 1.3064 - val_accuracy: 0.5327\n",
      "Epoch 390/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2940 - accuracy: 0.5265 - val_loss: 1.3176 - val_accuracy: 0.5218\n",
      "Epoch 391/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2921 - accuracy: 0.5265 - val_loss: 1.3394 - val_accuracy: 0.5111\n",
      "Epoch 392/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3010 - accuracy: 0.5251 - val_loss: 1.3454 - val_accuracy: 0.5129\n",
      "Epoch 393/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3013 - accuracy: 0.5226 - val_loss: 1.3306 - val_accuracy: 0.5213\n",
      "Epoch 394/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2923 - accuracy: 0.5293 - val_loss: 1.3267 - val_accuracy: 0.5165\n",
      "Epoch 395/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2896 - accuracy: 0.5267 - val_loss: 1.3093 - val_accuracy: 0.5271\n",
      "Epoch 396/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2906 - accuracy: 0.5301 - val_loss: 1.3361 - val_accuracy: 0.5205\n",
      "Epoch 397/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2945 - accuracy: 0.5292 - val_loss: 1.3271 - val_accuracy: 0.5177\n",
      "Epoch 398/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2940 - accuracy: 0.5248 - val_loss: 1.3371 - val_accuracy: 0.5170\n",
      "Epoch 399/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2921 - accuracy: 0.5290 - val_loss: 1.3106 - val_accuracy: 0.5311\n",
      "Epoch 400/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2906 - accuracy: 0.5289 - val_loss: 1.3136 - val_accuracy: 0.5268\n",
      "Epoch 401/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2970 - accuracy: 0.5263 - val_loss: 1.3248 - val_accuracy: 0.5254\n",
      "Epoch 402/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2965 - accuracy: 0.5255 - val_loss: 1.3196 - val_accuracy: 0.5283\n",
      "Epoch 403/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2888 - accuracy: 0.5271 - val_loss: 1.3242 - val_accuracy: 0.5241\n",
      "Epoch 404/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2925 - accuracy: 0.5271 - val_loss: 1.3228 - val_accuracy: 0.5271\n",
      "Epoch 405/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2902 - accuracy: 0.5284 - val_loss: 1.3227 - val_accuracy: 0.5207\n",
      "Epoch 406/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2883 - accuracy: 0.5260 - val_loss: 1.3196 - val_accuracy: 0.5314\n",
      "Epoch 407/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2907 - accuracy: 0.5295 - val_loss: 1.3216 - val_accuracy: 0.5254\n",
      "Epoch 408/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2933 - accuracy: 0.5248 - val_loss: 1.3146 - val_accuracy: 0.5263\n",
      "Epoch 409/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2871 - accuracy: 0.5278 - val_loss: 1.3151 - val_accuracy: 0.5263\n",
      "Epoch 410/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2923 - accuracy: 0.5274 - val_loss: 1.3107 - val_accuracy: 0.5314\n",
      "Epoch 411/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2920 - accuracy: 0.5298 - val_loss: 1.3575 - val_accuracy: 0.5157\n",
      "Epoch 412/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2901 - accuracy: 0.5265 - val_loss: 1.3237 - val_accuracy: 0.5257\n",
      "Epoch 413/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2943 - accuracy: 0.5265 - val_loss: 1.3224 - val_accuracy: 0.5290\n",
      "Epoch 414/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2945 - accuracy: 0.5278 - val_loss: 1.3184 - val_accuracy: 0.5271\n",
      "Epoch 415/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2926 - accuracy: 0.5237 - val_loss: 1.3365 - val_accuracy: 0.5196\n",
      "Epoch 416/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2902 - accuracy: 0.5238 - val_loss: 1.3207 - val_accuracy: 0.5184\n",
      "Epoch 417/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2983 - accuracy: 0.5224 - val_loss: 1.3224 - val_accuracy: 0.5156\n",
      "Epoch 418/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2896 - accuracy: 0.5298 - val_loss: 1.3105 - val_accuracy: 0.5226\n",
      "Epoch 419/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2884 - accuracy: 0.5280 - val_loss: 1.3391 - val_accuracy: 0.5157\n",
      "Epoch 420/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2933 - accuracy: 0.5261 - val_loss: 1.3079 - val_accuracy: 0.5332\n",
      "Epoch 421/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2912 - accuracy: 0.5281 - val_loss: 1.3286 - val_accuracy: 0.5230\n",
      "Epoch 422/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2894 - accuracy: 0.5286 - val_loss: 1.3163 - val_accuracy: 0.5248\n",
      "Epoch 423/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2935 - accuracy: 0.5244 - val_loss: 1.3301 - val_accuracy: 0.5257\n",
      "Epoch 424/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2942 - accuracy: 0.5280 - val_loss: 1.3180 - val_accuracy: 0.5216\n",
      "Epoch 425/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2890 - accuracy: 0.5278 - val_loss: 1.3198 - val_accuracy: 0.5277\n",
      "Epoch 426/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2936 - accuracy: 0.5275 - val_loss: 1.3051 - val_accuracy: 0.5339\n",
      "Epoch 427/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2878 - accuracy: 0.5278 - val_loss: 1.3186 - val_accuracy: 0.5252\n",
      "Epoch 428/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2909 - accuracy: 0.5256 - val_loss: 1.3242 - val_accuracy: 0.5226\n",
      "Epoch 429/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2926 - accuracy: 0.5266 - val_loss: 1.3302 - val_accuracy: 0.5321\n",
      "Epoch 430/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2920 - accuracy: 0.5276 - val_loss: 1.3329 - val_accuracy: 0.5160\n",
      "Epoch 431/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2889 - accuracy: 0.5268 - val_loss: 1.3207 - val_accuracy: 0.5202\n",
      "Epoch 432/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2931 - accuracy: 0.5261 - val_loss: 1.3207 - val_accuracy: 0.5305\n",
      "Epoch 433/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2931 - accuracy: 0.5239 - val_loss: 1.3188 - val_accuracy: 0.5265\n",
      "Epoch 434/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2884 - accuracy: 0.5278 - val_loss: 1.3070 - val_accuracy: 0.5288\n",
      "Epoch 435/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2900 - accuracy: 0.5272 - val_loss: 1.3186 - val_accuracy: 0.5254\n",
      "Epoch 436/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2860 - accuracy: 0.5296 - val_loss: 1.3067 - val_accuracy: 0.5300\n",
      "Epoch 437/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2854 - accuracy: 0.5288 - val_loss: 1.3111 - val_accuracy: 0.5347\n",
      "Epoch 438/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2908 - accuracy: 0.5297 - val_loss: 1.3265 - val_accuracy: 0.5134\n",
      "Epoch 439/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2896 - accuracy: 0.5267 - val_loss: 1.3108 - val_accuracy: 0.5272\n",
      "Epoch 440/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2942 - accuracy: 0.5260 - val_loss: 1.3226 - val_accuracy: 0.5224\n",
      "Epoch 441/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2936 - accuracy: 0.5258 - val_loss: 1.3137 - val_accuracy: 0.5262\n",
      "Epoch 442/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2907 - accuracy: 0.5262 - val_loss: 1.3128 - val_accuracy: 0.5308\n",
      "Epoch 443/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2880 - accuracy: 0.5282 - val_loss: 1.3174 - val_accuracy: 0.5221\n",
      "Epoch 444/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2908 - accuracy: 0.5255 - val_loss: 1.3096 - val_accuracy: 0.5328\n",
      "Epoch 445/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2862 - accuracy: 0.5288 - val_loss: 1.3178 - val_accuracy: 0.5243\n",
      "Epoch 446/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2868 - accuracy: 0.5299 - val_loss: 1.3108 - val_accuracy: 0.5272\n",
      "Epoch 447/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2884 - accuracy: 0.5286 - val_loss: 1.3203 - val_accuracy: 0.5198\n",
      "Epoch 448/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2860 - accuracy: 0.5289 - val_loss: 1.3152 - val_accuracy: 0.5294\n",
      "Epoch 449/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2844 - accuracy: 0.5265 - val_loss: 1.3222 - val_accuracy: 0.5260\n",
      "Epoch 450/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2900 - accuracy: 0.5254 - val_loss: 1.3251 - val_accuracy: 0.5212\n",
      "Epoch 451/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2937 - accuracy: 0.5239 - val_loss: 1.3221 - val_accuracy: 0.5254\n",
      "Epoch 452/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2897 - accuracy: 0.5287 - val_loss: 1.3114 - val_accuracy: 0.5338\n",
      "Epoch 453/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2864 - accuracy: 0.5291 - val_loss: 1.3175 - val_accuracy: 0.5276\n",
      "Epoch 454/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2845 - accuracy: 0.5276 - val_loss: 1.3171 - val_accuracy: 0.5240\n",
      "Epoch 455/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2890 - accuracy: 0.5279 - val_loss: 1.3507 - val_accuracy: 0.5198\n",
      "Epoch 456/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2833 - accuracy: 0.5268 - val_loss: 1.3164 - val_accuracy: 0.5230\n",
      "Epoch 457/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2912 - accuracy: 0.5246 - val_loss: 1.3248 - val_accuracy: 0.5308\n",
      "Epoch 458/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2883 - accuracy: 0.5284 - val_loss: 1.3295 - val_accuracy: 0.5244\n",
      "Epoch 459/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2857 - accuracy: 0.5264 - val_loss: 1.3609 - val_accuracy: 0.5146\n",
      "Epoch 460/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2916 - accuracy: 0.5253 - val_loss: 1.3598 - val_accuracy: 0.5079\n",
      "Epoch 461/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2891 - accuracy: 0.5280 - val_loss: 1.3834 - val_accuracy: 0.5005\n",
      "Epoch 462/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2903 - accuracy: 0.5250 - val_loss: 1.3093 - val_accuracy: 0.5285\n",
      "Epoch 463/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2833 - accuracy: 0.5309 - val_loss: 1.3200 - val_accuracy: 0.5322\n",
      "Epoch 464/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2866 - accuracy: 0.5300 - val_loss: 1.3046 - val_accuracy: 0.5293\n",
      "Epoch 465/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2870 - accuracy: 0.5274 - val_loss: 1.3206 - val_accuracy: 0.5276\n",
      "Epoch 466/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2909 - accuracy: 0.5269 - val_loss: 1.3135 - val_accuracy: 0.5251\n",
      "Epoch 467/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2878 - accuracy: 0.5279 - val_loss: 1.3188 - val_accuracy: 0.5327\n",
      "Epoch 468/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2871 - accuracy: 0.5284 - val_loss: 1.3306 - val_accuracy: 0.5219\n",
      "Epoch 469/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2850 - accuracy: 0.5276 - val_loss: 1.3256 - val_accuracy: 0.5223\n",
      "Epoch 470/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2847 - accuracy: 0.5265 - val_loss: 1.3192 - val_accuracy: 0.5227\n",
      "Epoch 471/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2912 - accuracy: 0.5275 - val_loss: 1.3439 - val_accuracy: 0.5176\n",
      "Epoch 472/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2873 - accuracy: 0.5290 - val_loss: 1.3236 - val_accuracy: 0.5185\n",
      "Epoch 473/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2837 - accuracy: 0.5294 - val_loss: 1.3172 - val_accuracy: 0.5219\n",
      "Epoch 474/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2807 - accuracy: 0.5304 - val_loss: 1.3106 - val_accuracy: 0.5229\n",
      "Epoch 475/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2874 - accuracy: 0.5296 - val_loss: 1.3181 - val_accuracy: 0.5265\n",
      "Epoch 476/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5317 - val_loss: 1.3231 - val_accuracy: 0.5302\n",
      "Epoch 477/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2889 - accuracy: 0.5303 - val_loss: 1.3241 - val_accuracy: 0.5265\n",
      "Epoch 478/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2842 - accuracy: 0.5299 - val_loss: 1.3346 - val_accuracy: 0.5230\n",
      "Epoch 479/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2928 - accuracy: 0.5220 - val_loss: 1.3097 - val_accuracy: 0.5342\n",
      "Epoch 480/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5291 - val_loss: 1.3225 - val_accuracy: 0.5285\n",
      "Epoch 481/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2854 - accuracy: 0.5269 - val_loss: 1.3111 - val_accuracy: 0.5308\n",
      "Epoch 482/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2808 - accuracy: 0.5301 - val_loss: 1.3042 - val_accuracy: 0.5352\n",
      "Epoch 483/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2827 - accuracy: 0.5293 - val_loss: 1.3192 - val_accuracy: 0.5215\n",
      "Epoch 484/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2834 - accuracy: 0.5311 - val_loss: 1.3413 - val_accuracy: 0.5181\n",
      "Epoch 485/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5288 - val_loss: 1.3051 - val_accuracy: 0.5330\n",
      "Epoch 486/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2879 - accuracy: 0.5280 - val_loss: 1.3100 - val_accuracy: 0.5338\n",
      "Epoch 487/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2819 - accuracy: 0.5325 - val_loss: 1.3201 - val_accuracy: 0.5248\n",
      "Epoch 488/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2856 - accuracy: 0.5283 - val_loss: 1.3045 - val_accuracy: 0.5297\n",
      "Epoch 489/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2822 - accuracy: 0.5302 - val_loss: 1.3053 - val_accuracy: 0.5339\n",
      "Epoch 490/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2845 - accuracy: 0.5266 - val_loss: 1.3091 - val_accuracy: 0.5375\n",
      "Epoch 491/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2837 - accuracy: 0.5294 - val_loss: 1.3109 - val_accuracy: 0.5280\n",
      "Epoch 492/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2819 - accuracy: 0.5274 - val_loss: 1.3168 - val_accuracy: 0.5279\n",
      "Epoch 493/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2795 - accuracy: 0.5284 - val_loss: 1.3111 - val_accuracy: 0.5276\n",
      "Epoch 494/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2793 - accuracy: 0.5330 - val_loss: 1.3179 - val_accuracy: 0.5305\n",
      "Epoch 495/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2794 - accuracy: 0.5322 - val_loss: 1.3160 - val_accuracy: 0.5283\n",
      "Epoch 496/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2856 - accuracy: 0.5306 - val_loss: 1.3188 - val_accuracy: 0.5268\n",
      "Epoch 497/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2827 - accuracy: 0.5330 - val_loss: 1.3355 - val_accuracy: 0.5207\n",
      "Epoch 498/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2844 - accuracy: 0.5295 - val_loss: 1.3074 - val_accuracy: 0.5279\n",
      "Epoch 499/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2807 - accuracy: 0.5314 - val_loss: 1.3172 - val_accuracy: 0.5332\n",
      "Epoch 500/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2841 - accuracy: 0.5262 - val_loss: 1.3214 - val_accuracy: 0.5307\n",
      "Epoch 501/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2848 - accuracy: 0.5299 - val_loss: 1.3139 - val_accuracy: 0.5322\n",
      "Epoch 502/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2836 - accuracy: 0.5298 - val_loss: 1.3069 - val_accuracy: 0.5335\n",
      "Epoch 503/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2902 - accuracy: 0.5274 - val_loss: 1.3243 - val_accuracy: 0.5263\n",
      "Epoch 504/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2806 - accuracy: 0.5306 - val_loss: 1.3157 - val_accuracy: 0.5224\n",
      "Epoch 505/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2822 - accuracy: 0.5288 - val_loss: 1.3113 - val_accuracy: 0.5283\n",
      "Epoch 506/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2780 - accuracy: 0.5306 - val_loss: 1.3047 - val_accuracy: 0.5297\n",
      "Epoch 507/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2815 - accuracy: 0.5291 - val_loss: 1.3064 - val_accuracy: 0.5305\n",
      "Epoch 508/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2802 - accuracy: 0.5315 - val_loss: 1.3227 - val_accuracy: 0.5230\n",
      "Epoch 509/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5291 - val_loss: 1.3130 - val_accuracy: 0.5254\n",
      "Epoch 510/555\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2810 - accuracy: 0.5300 - val_loss: 1.2992 - val_accuracy: 0.5350\n",
      "Epoch 511/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2817 - accuracy: 0.5318 - val_loss: 1.3169 - val_accuracy: 0.5268\n",
      "Epoch 512/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2791 - accuracy: 0.5302 - val_loss: 1.3088 - val_accuracy: 0.5269\n",
      "Epoch 513/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2796 - accuracy: 0.5316 - val_loss: 1.3014 - val_accuracy: 0.5316\n",
      "Epoch 514/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2785 - accuracy: 0.5317 - val_loss: 1.3040 - val_accuracy: 0.5297\n",
      "Epoch 515/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2783 - accuracy: 0.5311 - val_loss: 1.3316 - val_accuracy: 0.5185\n",
      "Epoch 516/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2843 - accuracy: 0.5313 - val_loss: 1.3117 - val_accuracy: 0.5299\n",
      "Epoch 517/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2796 - accuracy: 0.5313 - val_loss: 1.3249 - val_accuracy: 0.5246\n",
      "Epoch 518/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2801 - accuracy: 0.5310 - val_loss: 1.3062 - val_accuracy: 0.5266\n",
      "Epoch 519/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2763 - accuracy: 0.5295 - val_loss: 1.3033 - val_accuracy: 0.5344\n",
      "Epoch 520/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2794 - accuracy: 0.5311 - val_loss: 1.3108 - val_accuracy: 0.5277\n",
      "Epoch 521/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2795 - accuracy: 0.5297 - val_loss: 1.3228 - val_accuracy: 0.5276\n",
      "Epoch 522/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2814 - accuracy: 0.5317 - val_loss: 1.3107 - val_accuracy: 0.5366\n",
      "Epoch 523/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2765 - accuracy: 0.5330 - val_loss: 1.3119 - val_accuracy: 0.5280\n",
      "Epoch 524/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2783 - accuracy: 0.5321 - val_loss: 1.3108 - val_accuracy: 0.5296\n",
      "Epoch 525/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2771 - accuracy: 0.5298 - val_loss: 1.3194 - val_accuracy: 0.5279\n",
      "Epoch 526/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2757 - accuracy: 0.5340 - val_loss: 1.3226 - val_accuracy: 0.5272\n",
      "Epoch 527/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2866 - accuracy: 0.5271 - val_loss: 1.3036 - val_accuracy: 0.5335\n",
      "Epoch 528/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2780 - accuracy: 0.5328 - val_loss: 1.3113 - val_accuracy: 0.5280\n",
      "Epoch 529/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2798 - accuracy: 0.5310 - val_loss: 1.3042 - val_accuracy: 0.5374\n",
      "Epoch 530/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2778 - accuracy: 0.5337 - val_loss: 1.3054 - val_accuracy: 0.5310\n",
      "Epoch 531/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2800 - accuracy: 0.5315 - val_loss: 1.3053 - val_accuracy: 0.5282\n",
      "Epoch 532/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2752 - accuracy: 0.5291 - val_loss: 1.3075 - val_accuracy: 0.5307\n",
      "Epoch 533/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2787 - accuracy: 0.5328 - val_loss: 1.3013 - val_accuracy: 0.5347\n",
      "Epoch 534/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2775 - accuracy: 0.5301 - val_loss: 1.3039 - val_accuracy: 0.5346\n",
      "Epoch 535/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2770 - accuracy: 0.5308 - val_loss: 1.3164 - val_accuracy: 0.5314\n",
      "Epoch 536/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2772 - accuracy: 0.5290 - val_loss: 1.3081 - val_accuracy: 0.5344\n",
      "Epoch 537/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2770 - accuracy: 0.5334 - val_loss: 1.3133 - val_accuracy: 0.5328\n",
      "Epoch 538/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2744 - accuracy: 0.5312 - val_loss: 1.3164 - val_accuracy: 0.5230\n",
      "Epoch 539/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2791 - accuracy: 0.5292 - val_loss: 1.3043 - val_accuracy: 0.5356\n",
      "Epoch 540/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2794 - accuracy: 0.5298 - val_loss: 1.3027 - val_accuracy: 0.5372\n",
      "Epoch 541/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2760 - accuracy: 0.5301 - val_loss: 1.3260 - val_accuracy: 0.5240\n",
      "Epoch 542/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2735 - accuracy: 0.5346 - val_loss: 1.3237 - val_accuracy: 0.5248\n",
      "Epoch 543/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2736 - accuracy: 0.5325 - val_loss: 1.3567 - val_accuracy: 0.5135\n",
      "Epoch 544/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2790 - accuracy: 0.5332 - val_loss: 1.3072 - val_accuracy: 0.5327\n",
      "Epoch 545/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2759 - accuracy: 0.5307 - val_loss: 1.3310 - val_accuracy: 0.5204\n",
      "Epoch 546/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2741 - accuracy: 0.5298 - val_loss: 1.3220 - val_accuracy: 0.5322\n",
      "Epoch 547/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2751 - accuracy: 0.5344 - val_loss: 1.3053 - val_accuracy: 0.5372\n",
      "Epoch 548/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2734 - accuracy: 0.5343 - val_loss: 1.3295 - val_accuracy: 0.5199\n",
      "Epoch 549/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2768 - accuracy: 0.5334 - val_loss: 1.2989 - val_accuracy: 0.5360\n",
      "Epoch 550/555\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2730 - accuracy: 0.5327 - val_loss: 1.3132 - val_accuracy: 0.5299\n",
      "Epoch 551/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2764 - accuracy: 0.5307 - val_loss: 1.3171 - val_accuracy: 0.5291\n",
      "Epoch 552/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2741 - accuracy: 0.5286 - val_loss: 1.3023 - val_accuracy: 0.5355\n",
      "Epoch 553/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2719 - accuracy: 0.5334 - val_loss: 1.2991 - val_accuracy: 0.5369\n",
      "Epoch 554/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5322 - val_loss: 1.3097 - val_accuracy: 0.5258\n",
      "Epoch 555/555\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2731 - accuracy: 0.5304 - val_loss: 1.2978 - val_accuracy: 0.5313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5c5729fa0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=best_epoch, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f38298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step\n",
      "(array([0, 1, 2, 3, 6, 7], dtype=int64), array([4902, 2296,  168,    3,   74, 2146], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64), array([3428, 1921, 1193,  300,   71,  353,  605, 1718], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64), array([6987, 3963, 2451,  579,  132,  597, 1170, 3587], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.argmax(model.predict(X_test), axis=1), return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbc4fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 3ms/step - loss: 1.3264 - accuracy: 0.5162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3264199495315552, 0.516216516494751]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b5fdf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.8293 - accuracy: 0.3508 - val_loss: 1.7393 - val_accuracy: 0.3579\n",
      "Epoch 2/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.7143 - accuracy: 0.3595 - val_loss: 1.6958 - val_accuracy: 0.3579\n",
      "Epoch 3/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6915 - accuracy: 0.3595 - val_loss: 1.6848 - val_accuracy: 0.3579\n",
      "Epoch 4/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6846 - accuracy: 0.3595 - val_loss: 1.6801 - val_accuracy: 0.3579\n",
      "Epoch 5/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.6793 - accuracy: 0.3608 - val_loss: 1.6712 - val_accuracy: 0.3639\n",
      "Epoch 6/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6710 - accuracy: 0.3670 - val_loss: 1.6626 - val_accuracy: 0.3674\n",
      "Epoch 7/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6632 - accuracy: 0.3707 - val_loss: 1.6552 - val_accuracy: 0.3702\n",
      "Epoch 8/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6593 - accuracy: 0.3704 - val_loss: 1.6576 - val_accuracy: 0.3686\n",
      "Epoch 9/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6438 - accuracy: 0.3736 - val_loss: 1.6336 - val_accuracy: 0.3815\n",
      "Epoch 10/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6393 - accuracy: 0.3815 - val_loss: 1.6308 - val_accuracy: 0.3773\n",
      "Epoch 11/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6089 - accuracy: 0.4041 - val_loss: 1.5902 - val_accuracy: 0.4128\n",
      "Epoch 12/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5823 - accuracy: 0.4146 - val_loss: 1.5687 - val_accuracy: 0.4097\n",
      "Epoch 13/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5683 - accuracy: 0.4129 - val_loss: 1.5531 - val_accuracy: 0.4197\n",
      "Epoch 14/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5609 - accuracy: 0.4130 - val_loss: 1.5419 - val_accuracy: 0.4257\n",
      "Epoch 15/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5514 - accuracy: 0.4134 - val_loss: 1.5984 - val_accuracy: 0.3848\n",
      "Epoch 16/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5363 - accuracy: 0.4198 - val_loss: 1.5296 - val_accuracy: 0.4189\n",
      "Epoch 17/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5242 - accuracy: 0.4203 - val_loss: 1.5261 - val_accuracy: 0.4167\n",
      "Epoch 18/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5180 - accuracy: 0.4214 - val_loss: 1.5184 - val_accuracy: 0.4189\n",
      "Epoch 19/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5147 - accuracy: 0.4209 - val_loss: 1.5013 - val_accuracy: 0.4234\n",
      "Epoch 20/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5021 - accuracy: 0.4206 - val_loss: 1.5040 - val_accuracy: 0.4237\n",
      "Epoch 21/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5000 - accuracy: 0.4229 - val_loss: 1.5176 - val_accuracy: 0.4211\n",
      "Epoch 22/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4971 - accuracy: 0.4213 - val_loss: 1.4955 - val_accuracy: 0.4229\n",
      "Epoch 23/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4870 - accuracy: 0.4272 - val_loss: 1.4773 - val_accuracy: 0.4278\n",
      "Epoch 24/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4825 - accuracy: 0.4324 - val_loss: 1.4694 - val_accuracy: 0.4342\n",
      "Epoch 25/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4814 - accuracy: 0.4306 - val_loss: 1.4743 - val_accuracy: 0.4317\n",
      "Epoch 26/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4665 - accuracy: 0.4426 - val_loss: 1.4599 - val_accuracy: 0.4475\n",
      "Epoch 27/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4601 - accuracy: 0.4501 - val_loss: 1.4622 - val_accuracy: 0.4398\n",
      "Epoch 28/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4602 - accuracy: 0.4473 - val_loss: 1.4536 - val_accuracy: 0.4469\n",
      "Epoch 29/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4662 - accuracy: 0.4420 - val_loss: 1.5123 - val_accuracy: 0.4220\n",
      "Epoch 30/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4522 - accuracy: 0.4532 - val_loss: 1.4420 - val_accuracy: 0.4644\n",
      "Epoch 31/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4455 - accuracy: 0.4588 - val_loss: 1.4447 - val_accuracy: 0.4650\n",
      "Epoch 32/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4382 - accuracy: 0.4624 - val_loss: 1.4380 - val_accuracy: 0.4616\n",
      "Epoch 33/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4353 - accuracy: 0.4628 - val_loss: 1.4425 - val_accuracy: 0.4644\n",
      "Epoch 34/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4283 - accuracy: 0.4693 - val_loss: 1.4231 - val_accuracy: 0.4742\n",
      "Epoch 35/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4261 - accuracy: 0.4670 - val_loss: 1.4221 - val_accuracy: 0.4728\n",
      "Epoch 36/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4187 - accuracy: 0.4720 - val_loss: 1.4133 - val_accuracy: 0.4768\n",
      "Epoch 37/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4254 - accuracy: 0.4663 - val_loss: 1.4227 - val_accuracy: 0.4670\n",
      "Epoch 38/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4118 - accuracy: 0.4699 - val_loss: 1.4089 - val_accuracy: 0.4787\n",
      "Epoch 39/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4127 - accuracy: 0.4701 - val_loss: 1.4119 - val_accuracy: 0.4689\n",
      "Epoch 40/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4152 - accuracy: 0.4733 - val_loss: 1.4119 - val_accuracy: 0.4715\n",
      "Epoch 41/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4070 - accuracy: 0.4739 - val_loss: 1.4033 - val_accuracy: 0.4779\n",
      "Epoch 42/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4129 - accuracy: 0.4686 - val_loss: 1.3999 - val_accuracy: 0.4809\n",
      "Epoch 43/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4076 - accuracy: 0.4731 - val_loss: 1.4070 - val_accuracy: 0.4801\n",
      "Epoch 44/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4076 - accuracy: 0.4764 - val_loss: 1.4007 - val_accuracy: 0.4770\n",
      "Epoch 45/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4006 - accuracy: 0.4742 - val_loss: 1.3924 - val_accuracy: 0.4846\n",
      "Epoch 46/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4025 - accuracy: 0.4795 - val_loss: 1.4142 - val_accuracy: 0.4723\n",
      "Epoch 47/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4052 - accuracy: 0.4753 - val_loss: 1.4007 - val_accuracy: 0.4796\n",
      "Epoch 48/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4061 - accuracy: 0.4742 - val_loss: 1.4077 - val_accuracy: 0.4840\n",
      "Epoch 49/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3980 - accuracy: 0.4766 - val_loss: 1.3878 - val_accuracy: 0.4922\n",
      "Epoch 50/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4014 - accuracy: 0.4788 - val_loss: 1.3930 - val_accuracy: 0.4851\n",
      "Epoch 51/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3907 - accuracy: 0.4837 - val_loss: 1.4001 - val_accuracy: 0.4779\n",
      "Epoch 52/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3939 - accuracy: 0.4833 - val_loss: 1.3955 - val_accuracy: 0.4872\n",
      "Epoch 53/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3901 - accuracy: 0.4835 - val_loss: 1.3847 - val_accuracy: 0.4872\n",
      "Epoch 54/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3899 - accuracy: 0.4848 - val_loss: 1.4109 - val_accuracy: 0.4679\n",
      "Epoch 55/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3894 - accuracy: 0.4832 - val_loss: 1.3865 - val_accuracy: 0.4914\n",
      "Epoch 56/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3910 - accuracy: 0.4840 - val_loss: 1.3811 - val_accuracy: 0.4935\n",
      "Epoch 57/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3844 - accuracy: 0.4879 - val_loss: 1.3815 - val_accuracy: 0.4932\n",
      "Epoch 58/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3844 - accuracy: 0.4852 - val_loss: 1.3917 - val_accuracy: 0.4899\n",
      "Epoch 59/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3811 - accuracy: 0.4877 - val_loss: 1.3876 - val_accuracy: 0.4869\n",
      "Epoch 60/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3865 - accuracy: 0.4877 - val_loss: 1.3843 - val_accuracy: 0.4907\n",
      "Epoch 61/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3820 - accuracy: 0.4867 - val_loss: 1.3732 - val_accuracy: 0.4936\n",
      "Epoch 62/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3798 - accuracy: 0.4892 - val_loss: 1.3762 - val_accuracy: 0.4938\n",
      "Epoch 63/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3788 - accuracy: 0.4913 - val_loss: 1.3755 - val_accuracy: 0.4981\n",
      "Epoch 64/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3772 - accuracy: 0.4907 - val_loss: 1.3702 - val_accuracy: 0.4956\n",
      "Epoch 65/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3751 - accuracy: 0.4919 - val_loss: 1.3880 - val_accuracy: 0.4872\n",
      "Epoch 66/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3742 - accuracy: 0.4916 - val_loss: 1.3723 - val_accuracy: 0.4960\n",
      "Epoch 67/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3812 - accuracy: 0.4897 - val_loss: 1.3734 - val_accuracy: 0.4941\n",
      "Epoch 68/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3725 - accuracy: 0.4968 - val_loss: 1.3695 - val_accuracy: 0.4983\n",
      "Epoch 69/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3758 - accuracy: 0.4889 - val_loss: 1.3732 - val_accuracy: 0.4984\n",
      "Epoch 70/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3716 - accuracy: 0.4948 - val_loss: 1.3656 - val_accuracy: 0.5017\n",
      "Epoch 71/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3705 - accuracy: 0.4929 - val_loss: 1.3806 - val_accuracy: 0.4924\n",
      "Epoch 72/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3691 - accuracy: 0.4947 - val_loss: 1.3628 - val_accuracy: 0.4981\n",
      "Epoch 73/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3697 - accuracy: 0.4948 - val_loss: 1.3679 - val_accuracy: 0.5014\n",
      "Epoch 74/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3719 - accuracy: 0.4956 - val_loss: 1.3702 - val_accuracy: 0.5019\n",
      "Epoch 75/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3657 - accuracy: 0.4959 - val_loss: 1.3696 - val_accuracy: 0.5009\n",
      "Epoch 76/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3708 - accuracy: 0.4917 - val_loss: 1.3704 - val_accuracy: 0.4950\n",
      "Epoch 77/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3658 - accuracy: 0.4987 - val_loss: 1.3622 - val_accuracy: 0.4998\n",
      "Epoch 78/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3644 - accuracy: 0.4952 - val_loss: 1.3583 - val_accuracy: 0.5023\n",
      "Epoch 79/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3644 - accuracy: 0.4983 - val_loss: 1.3726 - val_accuracy: 0.4989\n",
      "Epoch 80/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3613 - accuracy: 0.4988 - val_loss: 1.3631 - val_accuracy: 0.5011\n",
      "Epoch 81/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3632 - accuracy: 0.4966 - val_loss: 1.3782 - val_accuracy: 0.4896\n",
      "Epoch 82/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3655 - accuracy: 0.4983 - val_loss: 1.3579 - val_accuracy: 0.5014\n",
      "Epoch 83/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3614 - accuracy: 0.5002 - val_loss: 1.3889 - val_accuracy: 0.4865\n",
      "Epoch 84/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3603 - accuracy: 0.5009 - val_loss: 1.3840 - val_accuracy: 0.5011\n",
      "Epoch 85/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3598 - accuracy: 0.4995 - val_loss: 1.3708 - val_accuracy: 0.5054\n",
      "Epoch 86/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3585 - accuracy: 0.5018 - val_loss: 1.3620 - val_accuracy: 0.4975\n",
      "Epoch 87/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3605 - accuracy: 0.4989 - val_loss: 1.3695 - val_accuracy: 0.5053\n",
      "Epoch 88/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3617 - accuracy: 0.4979 - val_loss: 1.3584 - val_accuracy: 0.5012\n",
      "Epoch 89/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3594 - accuracy: 0.4960 - val_loss: 1.4011 - val_accuracy: 0.4872\n",
      "Epoch 90/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3662 - accuracy: 0.4946 - val_loss: 1.3591 - val_accuracy: 0.5022\n",
      "Epoch 91/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3595 - accuracy: 0.4984 - val_loss: 1.3565 - val_accuracy: 0.5037\n",
      "Epoch 92/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3593 - accuracy: 0.5002 - val_loss: 1.3558 - val_accuracy: 0.4974\n",
      "Epoch 93/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3584 - accuracy: 0.4970 - val_loss: 1.3579 - val_accuracy: 0.5012\n",
      "Epoch 94/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3640 - accuracy: 0.4985 - val_loss: 1.3562 - val_accuracy: 0.5031\n",
      "Epoch 95/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3697 - accuracy: 0.4907 - val_loss: 1.3537 - val_accuracy: 0.5019\n",
      "Epoch 96/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3592 - accuracy: 0.4995 - val_loss: 1.3603 - val_accuracy: 0.4984\n",
      "Epoch 97/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3549 - accuracy: 0.4996 - val_loss: 1.3535 - val_accuracy: 0.5081\n",
      "Epoch 98/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3590 - accuracy: 0.4969 - val_loss: 1.3508 - val_accuracy: 0.5070\n",
      "Epoch 99/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3609 - accuracy: 0.4977 - val_loss: 1.3743 - val_accuracy: 0.4942\n",
      "Epoch 100/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3579 - accuracy: 0.4982 - val_loss: 1.3520 - val_accuracy: 0.5037\n",
      "Epoch 101/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3626 - accuracy: 0.4988 - val_loss: 1.3638 - val_accuracy: 0.4930\n",
      "Epoch 102/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3623 - accuracy: 0.4970 - val_loss: 1.3654 - val_accuracy: 0.5003\n",
      "Epoch 103/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3601 - accuracy: 0.5020 - val_loss: 1.4014 - val_accuracy: 0.4847\n",
      "Epoch 104/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3552 - accuracy: 0.4998 - val_loss: 1.3517 - val_accuracy: 0.5092\n",
      "Epoch 105/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3523 - accuracy: 0.5020 - val_loss: 1.3557 - val_accuracy: 0.4997\n",
      "Epoch 106/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3513 - accuracy: 0.5013 - val_loss: 1.3467 - val_accuracy: 0.5081\n",
      "Epoch 107/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3561 - accuracy: 0.4993 - val_loss: 1.3602 - val_accuracy: 0.5083\n",
      "Epoch 108/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3524 - accuracy: 0.5048 - val_loss: 1.3635 - val_accuracy: 0.4960\n",
      "Epoch 109/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3567 - accuracy: 0.4980 - val_loss: 1.3709 - val_accuracy: 0.4924\n",
      "Epoch 110/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3545 - accuracy: 0.5007 - val_loss: 1.3535 - val_accuracy: 0.5023\n",
      "Epoch 111/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3504 - accuracy: 0.4999 - val_loss: 1.3710 - val_accuracy: 0.5054\n",
      "Epoch 112/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3525 - accuracy: 0.5039 - val_loss: 1.3556 - val_accuracy: 0.5053\n",
      "Epoch 113/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3546 - accuracy: 0.5020 - val_loss: 1.3595 - val_accuracy: 0.5064\n",
      "Epoch 114/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3557 - accuracy: 0.4985 - val_loss: 1.3521 - val_accuracy: 0.5042\n",
      "Epoch 115/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3548 - accuracy: 0.5011 - val_loss: 1.3642 - val_accuracy: 0.5016\n",
      "Epoch 116/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3529 - accuracy: 0.5015 - val_loss: 1.3608 - val_accuracy: 0.4992\n",
      "Epoch 117/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3505 - accuracy: 0.5038 - val_loss: 1.3484 - val_accuracy: 0.5025\n",
      "Epoch 118/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3490 - accuracy: 0.5037 - val_loss: 1.3453 - val_accuracy: 0.5059\n",
      "Epoch 119/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3570 - accuracy: 0.4996 - val_loss: 1.3631 - val_accuracy: 0.4964\n",
      "Epoch 120/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.3555 - accuracy: 0.5011 - val_loss: 1.3526 - val_accuracy: 0.5014\n",
      "Epoch 121/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3524 - accuracy: 0.5031 - val_loss: 1.3565 - val_accuracy: 0.5087\n",
      "Epoch 122/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3564 - accuracy: 0.4995 - val_loss: 1.3442 - val_accuracy: 0.5090\n",
      "Epoch 123/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3550 - accuracy: 0.4991 - val_loss: 1.3518 - val_accuracy: 0.5103\n",
      "Epoch 124/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3520 - accuracy: 0.5041 - val_loss: 1.4010 - val_accuracy: 0.4900\n",
      "Epoch 125/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3524 - accuracy: 0.5009 - val_loss: 1.3829 - val_accuracy: 0.4896\n",
      "Epoch 126/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3518 - accuracy: 0.5020 - val_loss: 1.3492 - val_accuracy: 0.5040\n",
      "Epoch 127/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3539 - accuracy: 0.5002 - val_loss: 1.3792 - val_accuracy: 0.4888\n",
      "Epoch 128/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3506 - accuracy: 0.5007 - val_loss: 1.3506 - val_accuracy: 0.5054\n",
      "Epoch 129/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3447 - accuracy: 0.5050 - val_loss: 1.3863 - val_accuracy: 0.4983\n",
      "Epoch 130/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3501 - accuracy: 0.5000 - val_loss: 1.3480 - val_accuracy: 0.5048\n",
      "Epoch 131/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3492 - accuracy: 0.5064 - val_loss: 1.3464 - val_accuracy: 0.5064\n",
      "Epoch 132/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3445 - accuracy: 0.5044 - val_loss: 1.3837 - val_accuracy: 0.4972\n",
      "Epoch 133/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3495 - accuracy: 0.5054 - val_loss: 1.3615 - val_accuracy: 0.4988\n",
      "Epoch 134/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3478 - accuracy: 0.5038 - val_loss: 1.3557 - val_accuracy: 0.4964\n",
      "Epoch 135/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3449 - accuracy: 0.5026 - val_loss: 1.3543 - val_accuracy: 0.5073\n",
      "Epoch 136/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3472 - accuracy: 0.5047 - val_loss: 1.3538 - val_accuracy: 0.5081\n",
      "Epoch 137/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3453 - accuracy: 0.5023 - val_loss: 1.3591 - val_accuracy: 0.4932\n",
      "Epoch 138/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3430 - accuracy: 0.5048 - val_loss: 1.3557 - val_accuracy: 0.5047\n",
      "Epoch 139/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3446 - accuracy: 0.5044 - val_loss: 1.3516 - val_accuracy: 0.5003\n",
      "Epoch 140/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3456 - accuracy: 0.5070 - val_loss: 1.3421 - val_accuracy: 0.5039\n",
      "Epoch 141/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3468 - accuracy: 0.5029 - val_loss: 1.3381 - val_accuracy: 0.5084\n",
      "Epoch 142/750\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.3437 - accuracy: 0.5070 - val_loss: 1.3608 - val_accuracy: 0.5002\n",
      "Epoch 143/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3463 - accuracy: 0.5061 - val_loss: 1.3558 - val_accuracy: 0.4997\n",
      "Epoch 144/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3446 - accuracy: 0.5023 - val_loss: 1.3364 - val_accuracy: 0.5128\n",
      "Epoch 145/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3421 - accuracy: 0.5041 - val_loss: 1.3633 - val_accuracy: 0.4950\n",
      "Epoch 146/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3459 - accuracy: 0.5043 - val_loss: 1.3362 - val_accuracy: 0.5100\n",
      "Epoch 147/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3409 - accuracy: 0.5057 - val_loss: 1.3431 - val_accuracy: 0.5064\n",
      "Epoch 148/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3436 - accuracy: 0.5053 - val_loss: 1.3471 - val_accuracy: 0.5030\n",
      "Epoch 149/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3468 - accuracy: 0.5059 - val_loss: 1.3371 - val_accuracy: 0.5068\n",
      "Epoch 150/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3422 - accuracy: 0.5053 - val_loss: 1.3394 - val_accuracy: 0.5062\n",
      "Epoch 151/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3403 - accuracy: 0.5052 - val_loss: 1.3460 - val_accuracy: 0.5030\n",
      "Epoch 152/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3430 - accuracy: 0.5043 - val_loss: 1.3543 - val_accuracy: 0.5045\n",
      "Epoch 153/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3367 - accuracy: 0.5090 - val_loss: 1.3462 - val_accuracy: 0.5078\n",
      "Epoch 154/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3426 - accuracy: 0.5081 - val_loss: 1.4149 - val_accuracy: 0.4879\n",
      "Epoch 155/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3481 - accuracy: 0.5035 - val_loss: 1.3446 - val_accuracy: 0.5070\n",
      "Epoch 156/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3482 - accuracy: 0.5031 - val_loss: 1.3360 - val_accuracy: 0.5098\n",
      "Epoch 157/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3391 - accuracy: 0.5075 - val_loss: 1.3473 - val_accuracy: 0.5121\n",
      "Epoch 158/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3418 - accuracy: 0.5048 - val_loss: 1.3331 - val_accuracy: 0.5126\n",
      "Epoch 159/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3403 - accuracy: 0.5059 - val_loss: 1.3450 - val_accuracy: 0.5042\n",
      "Epoch 160/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3408 - accuracy: 0.5021 - val_loss: 1.3380 - val_accuracy: 0.5062\n",
      "Epoch 161/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3391 - accuracy: 0.5061 - val_loss: 1.3689 - val_accuracy: 0.4919\n",
      "Epoch 162/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3391 - accuracy: 0.5066 - val_loss: 1.3535 - val_accuracy: 0.5087\n",
      "Epoch 163/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3428 - accuracy: 0.5034 - val_loss: 1.3567 - val_accuracy: 0.5023\n",
      "Epoch 164/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3398 - accuracy: 0.5050 - val_loss: 1.3482 - val_accuracy: 0.5062\n",
      "Epoch 165/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3366 - accuracy: 0.5090 - val_loss: 1.3433 - val_accuracy: 0.5053\n",
      "Epoch 166/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3370 - accuracy: 0.5065 - val_loss: 1.3412 - val_accuracy: 0.5025\n",
      "Epoch 167/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3390 - accuracy: 0.5051 - val_loss: 1.3478 - val_accuracy: 0.4991\n",
      "Epoch 168/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3360 - accuracy: 0.5093 - val_loss: 1.3308 - val_accuracy: 0.5123\n",
      "Epoch 169/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3366 - accuracy: 0.5074 - val_loss: 1.3359 - val_accuracy: 0.5090\n",
      "Epoch 170/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3402 - accuracy: 0.5062 - val_loss: 1.3297 - val_accuracy: 0.5115\n",
      "Epoch 171/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3409 - accuracy: 0.5075 - val_loss: 1.3344 - val_accuracy: 0.5163\n",
      "Epoch 172/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3356 - accuracy: 0.5087 - val_loss: 1.3414 - val_accuracy: 0.5072\n",
      "Epoch 173/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3414 - accuracy: 0.5048 - val_loss: 1.3449 - val_accuracy: 0.5104\n",
      "Epoch 174/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3348 - accuracy: 0.5066 - val_loss: 1.3286 - val_accuracy: 0.5111\n",
      "Epoch 175/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3341 - accuracy: 0.5071 - val_loss: 1.3399 - val_accuracy: 0.5148\n",
      "Epoch 176/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3373 - accuracy: 0.5069 - val_loss: 1.3494 - val_accuracy: 0.5064\n",
      "Epoch 177/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3346 - accuracy: 0.5073 - val_loss: 1.3384 - val_accuracy: 0.5054\n",
      "Epoch 178/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3323 - accuracy: 0.5093 - val_loss: 1.3289 - val_accuracy: 0.5120\n",
      "Epoch 179/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3394 - accuracy: 0.5074 - val_loss: 1.3325 - val_accuracy: 0.5115\n",
      "Epoch 180/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3427 - accuracy: 0.5034 - val_loss: 1.3455 - val_accuracy: 0.5084\n",
      "Epoch 181/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3343 - accuracy: 0.5077 - val_loss: 1.3352 - val_accuracy: 0.5092\n",
      "Epoch 182/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3363 - accuracy: 0.5094 - val_loss: 1.3452 - val_accuracy: 0.5000\n",
      "Epoch 183/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3343 - accuracy: 0.5077 - val_loss: 1.3300 - val_accuracy: 0.5135\n",
      "Epoch 184/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3296 - accuracy: 0.5127 - val_loss: 1.3321 - val_accuracy: 0.5143\n",
      "Epoch 185/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3317 - accuracy: 0.5100 - val_loss: 1.3414 - val_accuracy: 0.5111\n",
      "Epoch 186/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3318 - accuracy: 0.5117 - val_loss: 1.3816 - val_accuracy: 0.4958\n",
      "Epoch 187/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3375 - accuracy: 0.5103 - val_loss: 1.3276 - val_accuracy: 0.5128\n",
      "Epoch 188/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3306 - accuracy: 0.5118 - val_loss: 1.3348 - val_accuracy: 0.5058\n",
      "Epoch 189/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3315 - accuracy: 0.5084 - val_loss: 1.3378 - val_accuracy: 0.5053\n",
      "Epoch 190/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3310 - accuracy: 0.5090 - val_loss: 1.3305 - val_accuracy: 0.5140\n",
      "Epoch 191/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3322 - accuracy: 0.5066 - val_loss: 1.3608 - val_accuracy: 0.4995\n",
      "Epoch 192/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3346 - accuracy: 0.5068 - val_loss: 1.3361 - val_accuracy: 0.5109\n",
      "Epoch 193/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3304 - accuracy: 0.5103 - val_loss: 1.3706 - val_accuracy: 0.4952\n",
      "Epoch 194/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3290 - accuracy: 0.5121 - val_loss: 1.3343 - val_accuracy: 0.5076\n",
      "Epoch 195/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3314 - accuracy: 0.5085 - val_loss: 1.3461 - val_accuracy: 0.5012\n",
      "Epoch 196/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3374 - accuracy: 0.5044 - val_loss: 1.3453 - val_accuracy: 0.5051\n",
      "Epoch 197/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3341 - accuracy: 0.5074 - val_loss: 1.3500 - val_accuracy: 0.5078\n",
      "Epoch 198/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3360 - accuracy: 0.5087 - val_loss: 1.3253 - val_accuracy: 0.5179\n",
      "Epoch 199/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3297 - accuracy: 0.5088 - val_loss: 1.3332 - val_accuracy: 0.5109\n",
      "Epoch 200/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3384 - accuracy: 0.5070 - val_loss: 1.3349 - val_accuracy: 0.5135\n",
      "Epoch 201/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3317 - accuracy: 0.5073 - val_loss: 1.3466 - val_accuracy: 0.5042\n",
      "Epoch 202/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3302 - accuracy: 0.5117 - val_loss: 1.3334 - val_accuracy: 0.5101\n",
      "Epoch 203/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3268 - accuracy: 0.5110 - val_loss: 1.3324 - val_accuracy: 0.5137\n",
      "Epoch 204/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3353 - accuracy: 0.5107 - val_loss: 1.3325 - val_accuracy: 0.5095\n",
      "Epoch 205/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3274 - accuracy: 0.5094 - val_loss: 1.3253 - val_accuracy: 0.5160\n",
      "Epoch 206/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3280 - accuracy: 0.5124 - val_loss: 1.3444 - val_accuracy: 0.5103\n",
      "Epoch 207/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3269 - accuracy: 0.5111 - val_loss: 1.3415 - val_accuracy: 0.5120\n",
      "Epoch 208/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3290 - accuracy: 0.5109 - val_loss: 1.3263 - val_accuracy: 0.5174\n",
      "Epoch 209/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3270 - accuracy: 0.5110 - val_loss: 1.3452 - val_accuracy: 0.5040\n",
      "Epoch 210/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5106 - val_loss: 1.3286 - val_accuracy: 0.5185\n",
      "Epoch 211/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3295 - accuracy: 0.5113 - val_loss: 1.3266 - val_accuracy: 0.5137\n",
      "Epoch 212/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3292 - accuracy: 0.5076 - val_loss: 1.3394 - val_accuracy: 0.5140\n",
      "Epoch 213/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3350 - accuracy: 0.5098 - val_loss: 1.3318 - val_accuracy: 0.5139\n",
      "Epoch 214/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3261 - accuracy: 0.5132 - val_loss: 1.3327 - val_accuracy: 0.5139\n",
      "Epoch 215/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3284 - accuracy: 0.5119 - val_loss: 1.3713 - val_accuracy: 0.5039\n",
      "Epoch 216/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3331 - accuracy: 0.5096 - val_loss: 1.3336 - val_accuracy: 0.5075\n",
      "Epoch 217/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3279 - accuracy: 0.5118 - val_loss: 1.3382 - val_accuracy: 0.5070\n",
      "Epoch 218/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3291 - accuracy: 0.5095 - val_loss: 1.3385 - val_accuracy: 0.5067\n",
      "Epoch 219/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3305 - accuracy: 0.5078 - val_loss: 1.3234 - val_accuracy: 0.5149\n",
      "Epoch 220/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3250 - accuracy: 0.5116 - val_loss: 1.3490 - val_accuracy: 0.5112\n",
      "Epoch 221/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3283 - accuracy: 0.5116 - val_loss: 1.3290 - val_accuracy: 0.5092\n",
      "Epoch 222/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3293 - accuracy: 0.5121 - val_loss: 1.3262 - val_accuracy: 0.5134\n",
      "Epoch 223/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3258 - accuracy: 0.5136 - val_loss: 1.3250 - val_accuracy: 0.5173\n",
      "Epoch 224/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3324 - accuracy: 0.5101 - val_loss: 1.3253 - val_accuracy: 0.5170\n",
      "Epoch 225/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3261 - accuracy: 0.5127 - val_loss: 1.3362 - val_accuracy: 0.5140\n",
      "Epoch 226/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3232 - accuracy: 0.5110 - val_loss: 1.3246 - val_accuracy: 0.5154\n",
      "Epoch 227/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3245 - accuracy: 0.5101 - val_loss: 1.3305 - val_accuracy: 0.5129\n",
      "Epoch 228/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3258 - accuracy: 0.5123 - val_loss: 1.3249 - val_accuracy: 0.5143\n",
      "Epoch 229/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3253 - accuracy: 0.5117 - val_loss: 1.3230 - val_accuracy: 0.5137\n",
      "Epoch 230/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3285 - accuracy: 0.5109 - val_loss: 1.3385 - val_accuracy: 0.5051\n",
      "Epoch 231/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3250 - accuracy: 0.5113 - val_loss: 1.3319 - val_accuracy: 0.5159\n",
      "Epoch 232/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3222 - accuracy: 0.5123 - val_loss: 1.3367 - val_accuracy: 0.5109\n",
      "Epoch 233/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3247 - accuracy: 0.5136 - val_loss: 1.3211 - val_accuracy: 0.5171\n",
      "Epoch 234/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3273 - accuracy: 0.5108 - val_loss: 1.3266 - val_accuracy: 0.5112\n",
      "Epoch 235/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3264 - accuracy: 0.5110 - val_loss: 1.3492 - val_accuracy: 0.5115\n",
      "Epoch 236/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3231 - accuracy: 0.5120 - val_loss: 1.3296 - val_accuracy: 0.5098\n",
      "Epoch 237/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3211 - accuracy: 0.5134 - val_loss: 1.3321 - val_accuracy: 0.5135\n",
      "Epoch 238/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3303 - accuracy: 0.5081 - val_loss: 1.3307 - val_accuracy: 0.5162\n",
      "Epoch 239/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3264 - accuracy: 0.5141 - val_loss: 1.3254 - val_accuracy: 0.5128\n",
      "Epoch 240/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3233 - accuracy: 0.5096 - val_loss: 1.3841 - val_accuracy: 0.4947\n",
      "Epoch 241/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3239 - accuracy: 0.5130 - val_loss: 1.3409 - val_accuracy: 0.5111\n",
      "Epoch 242/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3267 - accuracy: 0.5088 - val_loss: 1.3214 - val_accuracy: 0.5151\n",
      "Epoch 243/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3261 - accuracy: 0.5113 - val_loss: 1.3280 - val_accuracy: 0.5163\n",
      "Epoch 244/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3240 - accuracy: 0.5138 - val_loss: 1.3210 - val_accuracy: 0.5154\n",
      "Epoch 245/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3246 - accuracy: 0.5133 - val_loss: 1.3322 - val_accuracy: 0.5168\n",
      "Epoch 246/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3205 - accuracy: 0.5146 - val_loss: 1.3229 - val_accuracy: 0.5146\n",
      "Epoch 247/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3216 - accuracy: 0.5130 - val_loss: 1.3239 - val_accuracy: 0.5159\n",
      "Epoch 248/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3241 - accuracy: 0.5122 - val_loss: 1.3331 - val_accuracy: 0.5090\n",
      "Epoch 249/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3289 - accuracy: 0.5117 - val_loss: 1.3668 - val_accuracy: 0.4953\n",
      "Epoch 250/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3266 - accuracy: 0.5146 - val_loss: 1.3198 - val_accuracy: 0.5168\n",
      "Epoch 251/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3179 - accuracy: 0.5131 - val_loss: 1.3334 - val_accuracy: 0.5156\n",
      "Epoch 252/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3263 - accuracy: 0.5112 - val_loss: 1.3239 - val_accuracy: 0.5137\n",
      "Epoch 253/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3225 - accuracy: 0.5159 - val_loss: 1.3286 - val_accuracy: 0.5117\n",
      "Epoch 254/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3213 - accuracy: 0.5153 - val_loss: 1.3299 - val_accuracy: 0.5181\n",
      "Epoch 255/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3264 - accuracy: 0.5098 - val_loss: 1.3267 - val_accuracy: 0.5165\n",
      "Epoch 256/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3212 - accuracy: 0.5160 - val_loss: 1.3256 - val_accuracy: 0.5139\n",
      "Epoch 257/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3223 - accuracy: 0.5119 - val_loss: 1.3478 - val_accuracy: 0.5137\n",
      "Epoch 258/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3213 - accuracy: 0.5114 - val_loss: 1.3303 - val_accuracy: 0.5114\n",
      "Epoch 259/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3177 - accuracy: 0.5157 - val_loss: 1.3205 - val_accuracy: 0.5224\n",
      "Epoch 260/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3256 - accuracy: 0.5120 - val_loss: 1.3428 - val_accuracy: 0.5167\n",
      "Epoch 261/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3251 - accuracy: 0.5114 - val_loss: 1.3228 - val_accuracy: 0.5145\n",
      "Epoch 262/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3228 - accuracy: 0.5123 - val_loss: 1.3336 - val_accuracy: 0.5132\n",
      "Epoch 263/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3274 - accuracy: 0.5123 - val_loss: 1.3272 - val_accuracy: 0.5188\n",
      "Epoch 264/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3183 - accuracy: 0.5166 - val_loss: 1.3594 - val_accuracy: 0.5068\n",
      "Epoch 265/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3228 - accuracy: 0.5140 - val_loss: 1.3509 - val_accuracy: 0.4994\n",
      "Epoch 266/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3191 - accuracy: 0.5140 - val_loss: 1.3194 - val_accuracy: 0.5230\n",
      "Epoch 267/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3187 - accuracy: 0.5146 - val_loss: 1.3293 - val_accuracy: 0.5118\n",
      "Epoch 268/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3184 - accuracy: 0.5144 - val_loss: 1.3563 - val_accuracy: 0.4910\n",
      "Epoch 269/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3189 - accuracy: 0.5133 - val_loss: 1.3246 - val_accuracy: 0.5159\n",
      "Epoch 270/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3183 - accuracy: 0.5142 - val_loss: 1.3149 - val_accuracy: 0.5241\n",
      "Epoch 271/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3163 - accuracy: 0.5130 - val_loss: 1.3239 - val_accuracy: 0.5188\n",
      "Epoch 272/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3179 - accuracy: 0.5147 - val_loss: 1.3293 - val_accuracy: 0.5139\n",
      "Epoch 273/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3192 - accuracy: 0.5133 - val_loss: 1.3258 - val_accuracy: 0.5170\n",
      "Epoch 274/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3259 - accuracy: 0.5130 - val_loss: 1.3488 - val_accuracy: 0.5106\n",
      "Epoch 275/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3184 - accuracy: 0.5133 - val_loss: 1.3261 - val_accuracy: 0.5174\n",
      "Epoch 276/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3160 - accuracy: 0.5168 - val_loss: 1.3329 - val_accuracy: 0.5139\n",
      "Epoch 277/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3171 - accuracy: 0.5131 - val_loss: 1.3189 - val_accuracy: 0.5135\n",
      "Epoch 278/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3227 - accuracy: 0.5141 - val_loss: 1.3312 - val_accuracy: 0.5205\n",
      "Epoch 279/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3191 - accuracy: 0.5137 - val_loss: 1.3149 - val_accuracy: 0.5202\n",
      "Epoch 280/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3157 - accuracy: 0.5167 - val_loss: 1.3184 - val_accuracy: 0.5163\n",
      "Epoch 281/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3157 - accuracy: 0.5163 - val_loss: 1.3254 - val_accuracy: 0.5140\n",
      "Epoch 282/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3187 - accuracy: 0.5123 - val_loss: 1.3194 - val_accuracy: 0.5165\n",
      "Epoch 283/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3171 - accuracy: 0.5156 - val_loss: 1.3162 - val_accuracy: 0.5237\n",
      "Epoch 284/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3168 - accuracy: 0.5140 - val_loss: 1.3285 - val_accuracy: 0.5154\n",
      "Epoch 285/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3161 - accuracy: 0.5162 - val_loss: 1.3236 - val_accuracy: 0.5196\n",
      "Epoch 286/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3188 - accuracy: 0.5154 - val_loss: 1.3228 - val_accuracy: 0.5227\n",
      "Epoch 287/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3139 - accuracy: 0.5145 - val_loss: 1.3160 - val_accuracy: 0.5162\n",
      "Epoch 288/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3201 - accuracy: 0.5143 - val_loss: 1.3175 - val_accuracy: 0.5224\n",
      "Epoch 289/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3174 - accuracy: 0.5175 - val_loss: 1.3302 - val_accuracy: 0.5129\n",
      "Epoch 290/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3189 - accuracy: 0.5118 - val_loss: 1.3178 - val_accuracy: 0.5223\n",
      "Epoch 291/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3162 - accuracy: 0.5161 - val_loss: 1.3173 - val_accuracy: 0.5176\n",
      "Epoch 292/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3189 - accuracy: 0.5108 - val_loss: 1.3281 - val_accuracy: 0.5129\n",
      "Epoch 293/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3146 - accuracy: 0.5187 - val_loss: 1.3243 - val_accuracy: 0.5171\n",
      "Epoch 294/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3159 - accuracy: 0.5159 - val_loss: 1.3188 - val_accuracy: 0.5162\n",
      "Epoch 295/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3097 - accuracy: 0.5169 - val_loss: 1.3162 - val_accuracy: 0.5165\n",
      "Epoch 296/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3136 - accuracy: 0.5153 - val_loss: 1.3217 - val_accuracy: 0.5153\n",
      "Epoch 297/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3145 - accuracy: 0.5168 - val_loss: 1.3226 - val_accuracy: 0.5165\n",
      "Epoch 298/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3159 - accuracy: 0.5166 - val_loss: 1.3250 - val_accuracy: 0.5112\n",
      "Epoch 299/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3144 - accuracy: 0.5178 - val_loss: 1.3822 - val_accuracy: 0.4972\n",
      "Epoch 300/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3114 - accuracy: 0.5135 - val_loss: 1.3166 - val_accuracy: 0.5204\n",
      "Epoch 301/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3122 - accuracy: 0.5181 - val_loss: 1.3117 - val_accuracy: 0.5215\n",
      "Epoch 302/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3076 - accuracy: 0.5158 - val_loss: 1.3090 - val_accuracy: 0.5248\n",
      "Epoch 303/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3094 - accuracy: 0.5169 - val_loss: 1.3155 - val_accuracy: 0.5227\n",
      "Epoch 304/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3142 - accuracy: 0.5170 - val_loss: 1.3115 - val_accuracy: 0.5263\n",
      "Epoch 305/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3102 - accuracy: 0.5135 - val_loss: 1.3116 - val_accuracy: 0.5229\n",
      "Epoch 306/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3105 - accuracy: 0.5185 - val_loss: 1.3425 - val_accuracy: 0.5114\n",
      "Epoch 307/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3140 - accuracy: 0.5150 - val_loss: 1.3092 - val_accuracy: 0.5241\n",
      "Epoch 308/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3153 - accuracy: 0.5153 - val_loss: 1.3198 - val_accuracy: 0.5207\n",
      "Epoch 309/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3137 - accuracy: 0.5172 - val_loss: 1.3376 - val_accuracy: 0.5086\n",
      "Epoch 310/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3135 - accuracy: 0.5175 - val_loss: 1.3157 - val_accuracy: 0.5171\n",
      "Epoch 311/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3114 - accuracy: 0.5188 - val_loss: 1.3119 - val_accuracy: 0.5218\n",
      "Epoch 312/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3091 - accuracy: 0.5203 - val_loss: 1.3290 - val_accuracy: 0.5193\n",
      "Epoch 313/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3080 - accuracy: 0.5176 - val_loss: 1.3155 - val_accuracy: 0.5196\n",
      "Epoch 314/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3057 - accuracy: 0.5196 - val_loss: 1.3109 - val_accuracy: 0.5209\n",
      "Epoch 315/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3172 - accuracy: 0.5169 - val_loss: 1.3197 - val_accuracy: 0.5196\n",
      "Epoch 316/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3098 - accuracy: 0.5161 - val_loss: 1.3254 - val_accuracy: 0.5204\n",
      "Epoch 317/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3123 - accuracy: 0.5161 - val_loss: 1.3181 - val_accuracy: 0.5202\n",
      "Epoch 318/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3097 - accuracy: 0.5179 - val_loss: 1.3040 - val_accuracy: 0.5260\n",
      "Epoch 319/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3119 - accuracy: 0.5166 - val_loss: 1.3409 - val_accuracy: 0.5125\n",
      "Epoch 320/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3115 - accuracy: 0.5159 - val_loss: 1.3122 - val_accuracy: 0.5249\n",
      "Epoch 321/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3091 - accuracy: 0.5179 - val_loss: 1.3050 - val_accuracy: 0.5268\n",
      "Epoch 322/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3052 - accuracy: 0.5202 - val_loss: 1.3146 - val_accuracy: 0.5204\n",
      "Epoch 323/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3170 - accuracy: 0.5154 - val_loss: 1.3293 - val_accuracy: 0.5142\n",
      "Epoch 324/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3101 - accuracy: 0.5171 - val_loss: 1.3113 - val_accuracy: 0.5276\n",
      "Epoch 325/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3092 - accuracy: 0.5175 - val_loss: 1.3255 - val_accuracy: 0.5210\n",
      "Epoch 326/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3043 - accuracy: 0.5196 - val_loss: 1.3078 - val_accuracy: 0.5252\n",
      "Epoch 327/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3059 - accuracy: 0.5190 - val_loss: 1.3175 - val_accuracy: 0.5246\n",
      "Epoch 328/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3100 - accuracy: 0.5167 - val_loss: 1.3137 - val_accuracy: 0.5257\n",
      "Epoch 329/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3053 - accuracy: 0.5207 - val_loss: 1.3087 - val_accuracy: 0.5218\n",
      "Epoch 330/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3087 - accuracy: 0.5172 - val_loss: 1.3304 - val_accuracy: 0.5157\n",
      "Epoch 331/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3099 - accuracy: 0.5149 - val_loss: 1.3168 - val_accuracy: 0.5202\n",
      "Epoch 332/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3089 - accuracy: 0.5159 - val_loss: 1.3225 - val_accuracy: 0.5187\n",
      "Epoch 333/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3095 - accuracy: 0.5192 - val_loss: 1.3283 - val_accuracy: 0.5151\n",
      "Epoch 334/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3139 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5163\n",
      "Epoch 335/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3089 - accuracy: 0.5156 - val_loss: 1.3474 - val_accuracy: 0.5098\n",
      "Epoch 336/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3098 - accuracy: 0.5166 - val_loss: 1.3130 - val_accuracy: 0.5226\n",
      "Epoch 337/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3073 - accuracy: 0.5173 - val_loss: 1.3226 - val_accuracy: 0.5159\n",
      "Epoch 338/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3119 - accuracy: 0.5163 - val_loss: 1.3118 - val_accuracy: 0.5302\n",
      "Epoch 339/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3089 - accuracy: 0.5161 - val_loss: 1.3050 - val_accuracy: 0.5248\n",
      "Epoch 340/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3028 - accuracy: 0.5193 - val_loss: 1.3204 - val_accuracy: 0.5171\n",
      "Epoch 341/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3076 - accuracy: 0.5187 - val_loss: 1.3162 - val_accuracy: 0.5232\n",
      "Epoch 342/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3045 - accuracy: 0.5222 - val_loss: 1.3071 - val_accuracy: 0.5304\n",
      "Epoch 343/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3030 - accuracy: 0.5189 - val_loss: 1.3529 - val_accuracy: 0.5129\n",
      "Epoch 344/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3086 - accuracy: 0.5204 - val_loss: 1.3389 - val_accuracy: 0.5165\n",
      "Epoch 345/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3057 - accuracy: 0.5192 - val_loss: 1.3077 - val_accuracy: 0.5249\n",
      "Epoch 346/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3062 - accuracy: 0.5185 - val_loss: 1.3067 - val_accuracy: 0.5218\n",
      "Epoch 347/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3054 - accuracy: 0.5167 - val_loss: 1.3008 - val_accuracy: 0.5277\n",
      "Epoch 348/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3028 - accuracy: 0.5205 - val_loss: 1.3221 - val_accuracy: 0.5216\n",
      "Epoch 349/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3019 - accuracy: 0.5202 - val_loss: 1.3092 - val_accuracy: 0.5230\n",
      "Epoch 350/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3048 - accuracy: 0.5176 - val_loss: 1.3277 - val_accuracy: 0.5223\n",
      "Epoch 351/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3076 - accuracy: 0.5183 - val_loss: 1.3157 - val_accuracy: 0.5249\n",
      "Epoch 352/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3041 - accuracy: 0.5193 - val_loss: 1.3306 - val_accuracy: 0.5226\n",
      "Epoch 353/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3069 - accuracy: 0.5189 - val_loss: 1.3075 - val_accuracy: 0.5240\n",
      "Epoch 354/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3079 - accuracy: 0.5194 - val_loss: 1.3107 - val_accuracy: 0.5233\n",
      "Epoch 355/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3023 - accuracy: 0.5229 - val_loss: 1.3324 - val_accuracy: 0.5201\n",
      "Epoch 356/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3096 - accuracy: 0.5185 - val_loss: 1.3031 - val_accuracy: 0.5307\n",
      "Epoch 357/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3033 - accuracy: 0.5198 - val_loss: 1.3028 - val_accuracy: 0.5277\n",
      "Epoch 358/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3040 - accuracy: 0.5189 - val_loss: 1.3046 - val_accuracy: 0.5316\n",
      "Epoch 359/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2986 - accuracy: 0.5228 - val_loss: 1.3056 - val_accuracy: 0.5238\n",
      "Epoch 360/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3039 - accuracy: 0.5206 - val_loss: 1.3057 - val_accuracy: 0.5268\n",
      "Epoch 361/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3025 - accuracy: 0.5204 - val_loss: 1.3189 - val_accuracy: 0.5210\n",
      "Epoch 362/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3033 - accuracy: 0.5201 - val_loss: 1.3043 - val_accuracy: 0.5290\n",
      "Epoch 363/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2987 - accuracy: 0.5209 - val_loss: 1.3377 - val_accuracy: 0.4911\n",
      "Epoch 364/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3016 - accuracy: 0.5213 - val_loss: 1.3175 - val_accuracy: 0.5216\n",
      "Epoch 365/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3024 - accuracy: 0.5201 - val_loss: 1.3194 - val_accuracy: 0.5223\n",
      "Epoch 366/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3054 - accuracy: 0.5204 - val_loss: 1.3180 - val_accuracy: 0.5218\n",
      "Epoch 367/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3045 - accuracy: 0.5189 - val_loss: 1.3080 - val_accuracy: 0.5294\n",
      "Epoch 368/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3041 - accuracy: 0.5201 - val_loss: 1.3356 - val_accuracy: 0.5176\n",
      "Epoch 369/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3039 - accuracy: 0.5209 - val_loss: 1.3063 - val_accuracy: 0.5322\n",
      "Epoch 370/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3067 - accuracy: 0.5196 - val_loss: 1.3084 - val_accuracy: 0.5195\n",
      "Epoch 371/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3037 - accuracy: 0.5205 - val_loss: 1.3138 - val_accuracy: 0.5248\n",
      "Epoch 372/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3012 - accuracy: 0.5206 - val_loss: 1.3013 - val_accuracy: 0.5310\n",
      "Epoch 373/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2997 - accuracy: 0.5222 - val_loss: 1.3084 - val_accuracy: 0.5277\n",
      "Epoch 374/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3017 - accuracy: 0.5212 - val_loss: 1.3023 - val_accuracy: 0.5257\n",
      "Epoch 375/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3022 - accuracy: 0.5211 - val_loss: 1.3220 - val_accuracy: 0.5199\n",
      "Epoch 376/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3034 - accuracy: 0.5188 - val_loss: 1.3014 - val_accuracy: 0.5258\n",
      "Epoch 377/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2985 - accuracy: 0.5222 - val_loss: 1.3055 - val_accuracy: 0.5285\n",
      "Epoch 378/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3066 - accuracy: 0.5198 - val_loss: 1.3071 - val_accuracy: 0.5304\n",
      "Epoch 379/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3018 - accuracy: 0.5198 - val_loss: 1.3063 - val_accuracy: 0.5204\n",
      "Epoch 380/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3016 - accuracy: 0.5221 - val_loss: 1.3005 - val_accuracy: 0.5307\n",
      "Epoch 381/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3029 - accuracy: 0.5216 - val_loss: 1.3110 - val_accuracy: 0.5213\n",
      "Epoch 382/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3033 - accuracy: 0.5182 - val_loss: 1.3428 - val_accuracy: 0.5068\n",
      "Epoch 383/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3048 - accuracy: 0.5214 - val_loss: 1.3138 - val_accuracy: 0.5232\n",
      "Epoch 384/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2979 - accuracy: 0.5211 - val_loss: 1.2959 - val_accuracy: 0.5288\n",
      "Epoch 385/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2993 - accuracy: 0.5198 - val_loss: 1.3204 - val_accuracy: 0.5182\n",
      "Epoch 386/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3029 - accuracy: 0.5227 - val_loss: 1.2993 - val_accuracy: 0.5286\n",
      "Epoch 387/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3023 - accuracy: 0.5210 - val_loss: 1.3026 - val_accuracy: 0.5318\n",
      "Epoch 388/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3012 - accuracy: 0.5211 - val_loss: 1.3064 - val_accuracy: 0.5243\n",
      "Epoch 389/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3027 - accuracy: 0.5209 - val_loss: 1.3127 - val_accuracy: 0.5207\n",
      "Epoch 390/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2963 - accuracy: 0.5237 - val_loss: 1.3019 - val_accuracy: 0.5282\n",
      "Epoch 391/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3005 - accuracy: 0.5213 - val_loss: 1.2996 - val_accuracy: 0.5269\n",
      "Epoch 392/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3032 - accuracy: 0.5219 - val_loss: 1.3029 - val_accuracy: 0.5293\n",
      "Epoch 393/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3023 - accuracy: 0.5208 - val_loss: 1.3081 - val_accuracy: 0.5244\n",
      "Epoch 394/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3058 - accuracy: 0.5186 - val_loss: 1.3101 - val_accuracy: 0.5213\n",
      "Epoch 395/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3006 - accuracy: 0.5222 - val_loss: 1.3101 - val_accuracy: 0.5226\n",
      "Epoch 396/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2964 - accuracy: 0.5232 - val_loss: 1.2993 - val_accuracy: 0.5277\n",
      "Epoch 397/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2979 - accuracy: 0.5219 - val_loss: 1.3423 - val_accuracy: 0.5154\n",
      "Epoch 398/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3016 - accuracy: 0.5211 - val_loss: 1.3151 - val_accuracy: 0.5276\n",
      "Epoch 399/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2979 - accuracy: 0.5228 - val_loss: 1.3032 - val_accuracy: 0.5324\n",
      "Epoch 400/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3008 - accuracy: 0.5215 - val_loss: 1.2996 - val_accuracy: 0.5333\n",
      "Epoch 401/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3012 - accuracy: 0.5238 - val_loss: 1.3014 - val_accuracy: 0.5296\n",
      "Epoch 402/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2997 - accuracy: 0.5212 - val_loss: 1.3045 - val_accuracy: 0.5229\n",
      "Epoch 403/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3033 - accuracy: 0.5224 - val_loss: 1.3095 - val_accuracy: 0.5229\n",
      "Epoch 404/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3029 - accuracy: 0.5225 - val_loss: 1.3257 - val_accuracy: 0.5188\n",
      "Epoch 405/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2963 - accuracy: 0.5236 - val_loss: 1.3098 - val_accuracy: 0.5285\n",
      "Epoch 406/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2987 - accuracy: 0.5251 - val_loss: 1.3089 - val_accuracy: 0.5260\n",
      "Epoch 407/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2986 - accuracy: 0.5223 - val_loss: 1.2982 - val_accuracy: 0.5282\n",
      "Epoch 408/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2958 - accuracy: 0.5205 - val_loss: 1.2995 - val_accuracy: 0.5350\n",
      "Epoch 409/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2934 - accuracy: 0.5189 - val_loss: 1.3001 - val_accuracy: 0.5252\n",
      "Epoch 410/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3078 - accuracy: 0.5192 - val_loss: 1.3530 - val_accuracy: 0.5188\n",
      "Epoch 411/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2960 - accuracy: 0.5230 - val_loss: 1.3038 - val_accuracy: 0.5266\n",
      "Epoch 412/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2934 - accuracy: 0.5235 - val_loss: 1.3025 - val_accuracy: 0.5327\n",
      "Epoch 413/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2914 - accuracy: 0.5273 - val_loss: 1.2991 - val_accuracy: 0.5316\n",
      "Epoch 414/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2954 - accuracy: 0.5251 - val_loss: 1.3118 - val_accuracy: 0.5252\n",
      "Epoch 415/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2950 - accuracy: 0.5219 - val_loss: 1.3378 - val_accuracy: 0.5146\n",
      "Epoch 416/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2967 - accuracy: 0.5229 - val_loss: 1.3002 - val_accuracy: 0.5288\n",
      "Epoch 417/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2903 - accuracy: 0.5261 - val_loss: 1.3134 - val_accuracy: 0.5209\n",
      "Epoch 418/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2957 - accuracy: 0.5242 - val_loss: 1.3193 - val_accuracy: 0.5272\n",
      "Epoch 419/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2957 - accuracy: 0.5229 - val_loss: 1.3148 - val_accuracy: 0.5244\n",
      "Epoch 420/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2950 - accuracy: 0.5246 - val_loss: 1.3071 - val_accuracy: 0.5300\n",
      "Epoch 421/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2973 - accuracy: 0.5233 - val_loss: 1.3245 - val_accuracy: 0.5258\n",
      "Epoch 422/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2919 - accuracy: 0.5258 - val_loss: 1.3042 - val_accuracy: 0.5260\n",
      "Epoch 423/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2935 - accuracy: 0.5232 - val_loss: 1.2994 - val_accuracy: 0.5297\n",
      "Epoch 424/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2985 - accuracy: 0.5247 - val_loss: 1.3053 - val_accuracy: 0.5294\n",
      "Epoch 425/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2941 - accuracy: 0.5242 - val_loss: 1.3071 - val_accuracy: 0.5276\n",
      "Epoch 426/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2943 - accuracy: 0.5215 - val_loss: 1.3072 - val_accuracy: 0.5227\n",
      "Epoch 427/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2938 - accuracy: 0.5230 - val_loss: 1.3000 - val_accuracy: 0.5311\n",
      "Epoch 428/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2909 - accuracy: 0.5251 - val_loss: 1.3098 - val_accuracy: 0.5286\n",
      "Epoch 429/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2926 - accuracy: 0.5225 - val_loss: 1.3087 - val_accuracy: 0.5232\n",
      "Epoch 430/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2913 - accuracy: 0.5242 - val_loss: 1.2955 - val_accuracy: 0.5327\n",
      "Epoch 431/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2975 - accuracy: 0.5231 - val_loss: 1.3025 - val_accuracy: 0.5286\n",
      "Epoch 432/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2902 - accuracy: 0.5264 - val_loss: 1.3078 - val_accuracy: 0.5260\n",
      "Epoch 433/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2910 - accuracy: 0.5271 - val_loss: 1.2963 - val_accuracy: 0.5356\n",
      "Epoch 434/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2916 - accuracy: 0.5258 - val_loss: 1.3111 - val_accuracy: 0.5352\n",
      "Epoch 435/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2903 - accuracy: 0.5242 - val_loss: 1.3022 - val_accuracy: 0.5296\n",
      "Epoch 436/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2937 - accuracy: 0.5233 - val_loss: 1.3093 - val_accuracy: 0.5257\n",
      "Epoch 437/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2961 - accuracy: 0.5257 - val_loss: 1.3000 - val_accuracy: 0.5302\n",
      "Epoch 438/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2970 - accuracy: 0.5217 - val_loss: 1.2999 - val_accuracy: 0.5304\n",
      "Epoch 439/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2912 - accuracy: 0.5245 - val_loss: 1.2964 - val_accuracy: 0.5335\n",
      "Epoch 440/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2920 - accuracy: 0.5232 - val_loss: 1.2974 - val_accuracy: 0.5272\n",
      "Epoch 441/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2938 - accuracy: 0.5261 - val_loss: 1.3177 - val_accuracy: 0.5241\n",
      "Epoch 442/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2924 - accuracy: 0.5245 - val_loss: 1.2970 - val_accuracy: 0.5280\n",
      "Epoch 443/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2961 - accuracy: 0.5238 - val_loss: 1.3026 - val_accuracy: 0.5311\n",
      "Epoch 444/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2955 - accuracy: 0.5242 - val_loss: 1.3124 - val_accuracy: 0.5308\n",
      "Epoch 445/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2968 - accuracy: 0.5248 - val_loss: 1.2990 - val_accuracy: 0.5290\n",
      "Epoch 446/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2924 - accuracy: 0.5256 - val_loss: 1.3251 - val_accuracy: 0.5224\n",
      "Epoch 447/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2925 - accuracy: 0.5230 - val_loss: 1.3077 - val_accuracy: 0.5304\n",
      "Epoch 448/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2872 - accuracy: 0.5258 - val_loss: 1.3165 - val_accuracy: 0.5238\n",
      "Epoch 449/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2963 - accuracy: 0.5243 - val_loss: 1.3062 - val_accuracy: 0.5263\n",
      "Epoch 450/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2907 - accuracy: 0.5253 - val_loss: 1.2997 - val_accuracy: 0.5269\n",
      "Epoch 451/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2915 - accuracy: 0.5281 - val_loss: 1.2899 - val_accuracy: 0.5360\n",
      "Epoch 452/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2895 - accuracy: 0.5263 - val_loss: 1.3012 - val_accuracy: 0.5310\n",
      "Epoch 453/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2931 - accuracy: 0.5235 - val_loss: 1.2993 - val_accuracy: 0.5271\n",
      "Epoch 454/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2915 - accuracy: 0.5283 - val_loss: 1.2968 - val_accuracy: 0.5335\n",
      "Epoch 455/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2905 - accuracy: 0.5255 - val_loss: 1.3040 - val_accuracy: 0.5302\n",
      "Epoch 456/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2890 - accuracy: 0.5257 - val_loss: 1.2910 - val_accuracy: 0.5316\n",
      "Epoch 457/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2923 - accuracy: 0.5234 - val_loss: 1.2969 - val_accuracy: 0.5319\n",
      "Epoch 458/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2893 - accuracy: 0.5266 - val_loss: 1.2992 - val_accuracy: 0.5293\n",
      "Epoch 459/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2934 - accuracy: 0.5270 - val_loss: 1.2996 - val_accuracy: 0.5319\n",
      "Epoch 460/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2920 - accuracy: 0.5247 - val_loss: 1.3106 - val_accuracy: 0.5230\n",
      "Epoch 461/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2918 - accuracy: 0.5238 - val_loss: 1.3233 - val_accuracy: 0.5174\n",
      "Epoch 462/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2929 - accuracy: 0.5237 - val_loss: 1.2932 - val_accuracy: 0.5308\n",
      "Epoch 463/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2939 - accuracy: 0.5235 - val_loss: 1.2976 - val_accuracy: 0.5336\n",
      "Epoch 464/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2907 - accuracy: 0.5254 - val_loss: 1.2934 - val_accuracy: 0.5313\n",
      "Epoch 465/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2892 - accuracy: 0.5266 - val_loss: 1.2938 - val_accuracy: 0.5324\n",
      "Epoch 466/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2893 - accuracy: 0.5230 - val_loss: 1.3151 - val_accuracy: 0.5212\n",
      "Epoch 467/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2907 - accuracy: 0.5258 - val_loss: 1.2975 - val_accuracy: 0.5339\n",
      "Epoch 468/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2881 - accuracy: 0.5262 - val_loss: 1.3015 - val_accuracy: 0.5279\n",
      "Epoch 469/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5276 - val_loss: 1.2953 - val_accuracy: 0.5341\n",
      "Epoch 470/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2945 - accuracy: 0.5255 - val_loss: 1.3115 - val_accuracy: 0.5249\n",
      "Epoch 471/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2972 - accuracy: 0.5196 - val_loss: 1.2906 - val_accuracy: 0.5349\n",
      "Epoch 472/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2926 - accuracy: 0.5249 - val_loss: 1.2931 - val_accuracy: 0.5350\n",
      "Epoch 473/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2942 - accuracy: 0.5252 - val_loss: 1.2913 - val_accuracy: 0.5318\n",
      "Epoch 474/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2937 - accuracy: 0.5237 - val_loss: 1.3176 - val_accuracy: 0.5277\n",
      "Epoch 475/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2887 - accuracy: 0.5256 - val_loss: 1.3138 - val_accuracy: 0.5207\n",
      "Epoch 476/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2903 - accuracy: 0.5233 - val_loss: 1.3048 - val_accuracy: 0.5322\n",
      "Epoch 477/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2939 - accuracy: 0.5235 - val_loss: 1.3018 - val_accuracy: 0.5265\n",
      "Epoch 478/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2873 - accuracy: 0.5249 - val_loss: 1.2889 - val_accuracy: 0.5375\n",
      "Epoch 479/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2917 - accuracy: 0.5238 - val_loss: 1.3064 - val_accuracy: 0.5233\n",
      "Epoch 480/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2903 - accuracy: 0.5258 - val_loss: 1.3150 - val_accuracy: 0.5262\n",
      "Epoch 481/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2858 - accuracy: 0.5278 - val_loss: 1.2906 - val_accuracy: 0.5336\n",
      "Epoch 482/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2863 - accuracy: 0.5279 - val_loss: 1.2893 - val_accuracy: 0.5383\n",
      "Epoch 483/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2976 - accuracy: 0.5249 - val_loss: 1.2938 - val_accuracy: 0.5290\n",
      "Epoch 484/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2870 - accuracy: 0.5263 - val_loss: 1.2915 - val_accuracy: 0.5356\n",
      "Epoch 485/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2848 - accuracy: 0.5263 - val_loss: 1.3010 - val_accuracy: 0.5308\n",
      "Epoch 486/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2881 - accuracy: 0.5283 - val_loss: 1.3084 - val_accuracy: 0.5257\n",
      "Epoch 487/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2851 - accuracy: 0.5285 - val_loss: 1.3141 - val_accuracy: 0.5235\n",
      "Epoch 488/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2925 - accuracy: 0.5238 - val_loss: 1.3016 - val_accuracy: 0.5276\n",
      "Epoch 489/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2855 - accuracy: 0.5272 - val_loss: 1.2951 - val_accuracy: 0.5311\n",
      "Epoch 490/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2875 - accuracy: 0.5251 - val_loss: 1.2998 - val_accuracy: 0.5285\n",
      "Epoch 491/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2853 - accuracy: 0.5265 - val_loss: 1.2955 - val_accuracy: 0.5316\n",
      "Epoch 492/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2870 - accuracy: 0.5255 - val_loss: 1.3034 - val_accuracy: 0.5260\n",
      "Epoch 493/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2900 - accuracy: 0.5276 - val_loss: 1.3133 - val_accuracy: 0.5249\n",
      "Epoch 494/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2878 - accuracy: 0.5245 - val_loss: 1.2949 - val_accuracy: 0.5297\n",
      "Epoch 495/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2875 - accuracy: 0.5290 - val_loss: 1.3124 - val_accuracy: 0.5276\n",
      "Epoch 496/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2848 - accuracy: 0.5289 - val_loss: 1.2983 - val_accuracy: 0.5290\n",
      "Epoch 497/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2880 - accuracy: 0.5268 - val_loss: 1.2940 - val_accuracy: 0.5313\n",
      "Epoch 498/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2889 - accuracy: 0.5245 - val_loss: 1.2927 - val_accuracy: 0.5402\n",
      "Epoch 499/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2906 - accuracy: 0.5226 - val_loss: 1.3054 - val_accuracy: 0.5276\n",
      "Epoch 500/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2870 - accuracy: 0.5271 - val_loss: 1.2911 - val_accuracy: 0.5353\n",
      "Epoch 501/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2859 - accuracy: 0.5268 - val_loss: 1.3146 - val_accuracy: 0.5252\n",
      "Epoch 502/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2906 - accuracy: 0.5269 - val_loss: 1.2938 - val_accuracy: 0.5333\n",
      "Epoch 503/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2910 - accuracy: 0.5255 - val_loss: 1.2939 - val_accuracy: 0.5304\n",
      "Epoch 504/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2861 - accuracy: 0.5264 - val_loss: 1.3105 - val_accuracy: 0.5314\n",
      "Epoch 505/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2881 - accuracy: 0.5278 - val_loss: 1.2974 - val_accuracy: 0.5318\n",
      "Epoch 506/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2847 - accuracy: 0.5254 - val_loss: 1.2901 - val_accuracy: 0.5353\n",
      "Epoch 507/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2869 - accuracy: 0.5259 - val_loss: 1.2935 - val_accuracy: 0.5344\n",
      "Epoch 508/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2845 - accuracy: 0.5260 - val_loss: 1.2948 - val_accuracy: 0.5300\n",
      "Epoch 509/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2861 - accuracy: 0.5258 - val_loss: 1.3000 - val_accuracy: 0.5269\n",
      "Epoch 510/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2880 - accuracy: 0.5273 - val_loss: 1.2955 - val_accuracy: 0.5372\n",
      "Epoch 511/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2880 - accuracy: 0.5255 - val_loss: 1.2929 - val_accuracy: 0.5342\n",
      "Epoch 512/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2855 - accuracy: 0.5271 - val_loss: 1.2920 - val_accuracy: 0.5342\n",
      "Epoch 513/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2893 - accuracy: 0.5253 - val_loss: 1.2918 - val_accuracy: 0.5300\n",
      "Epoch 514/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2906 - accuracy: 0.5248 - val_loss: 1.3021 - val_accuracy: 0.5332\n",
      "Epoch 515/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2879 - accuracy: 0.5261 - val_loss: 1.3002 - val_accuracy: 0.5282\n",
      "Epoch 516/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2883 - accuracy: 0.5261 - val_loss: 1.2928 - val_accuracy: 0.5395\n",
      "Epoch 517/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2861 - accuracy: 0.5287 - val_loss: 1.3027 - val_accuracy: 0.5249\n",
      "Epoch 518/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2888 - accuracy: 0.5262 - val_loss: 1.3002 - val_accuracy: 0.5296\n",
      "Epoch 519/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2866 - accuracy: 0.5285 - val_loss: 1.2921 - val_accuracy: 0.5335\n",
      "Epoch 520/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2830 - accuracy: 0.5298 - val_loss: 1.3071 - val_accuracy: 0.5279\n",
      "Epoch 521/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2875 - accuracy: 0.5295 - val_loss: 1.2953 - val_accuracy: 0.5366\n",
      "Epoch 522/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2868 - accuracy: 0.5262 - val_loss: 1.2931 - val_accuracy: 0.5310\n",
      "Epoch 523/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2896 - accuracy: 0.5249 - val_loss: 1.2907 - val_accuracy: 0.5336\n",
      "Epoch 524/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2905 - accuracy: 0.5258 - val_loss: 1.2983 - val_accuracy: 0.5286\n",
      "Epoch 525/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2884 - accuracy: 0.5274 - val_loss: 1.2923 - val_accuracy: 0.5344\n",
      "Epoch 526/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2825 - accuracy: 0.5278 - val_loss: 1.2932 - val_accuracy: 0.5310\n",
      "Epoch 527/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2890 - accuracy: 0.5274 - val_loss: 1.2937 - val_accuracy: 0.5360\n",
      "Epoch 528/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2898 - accuracy: 0.5258 - val_loss: 1.2984 - val_accuracy: 0.5277\n",
      "Epoch 529/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2876 - accuracy: 0.5276 - val_loss: 1.2923 - val_accuracy: 0.5339\n",
      "Epoch 530/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2836 - accuracy: 0.5270 - val_loss: 1.2917 - val_accuracy: 0.5372\n",
      "Epoch 531/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2883 - accuracy: 0.5266 - val_loss: 1.3052 - val_accuracy: 0.5252\n",
      "Epoch 532/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2855 - accuracy: 0.5295 - val_loss: 1.3006 - val_accuracy: 0.5304\n",
      "Epoch 533/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2849 - accuracy: 0.5270 - val_loss: 1.2935 - val_accuracy: 0.5342\n",
      "Epoch 534/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2830 - accuracy: 0.5281 - val_loss: 1.2855 - val_accuracy: 0.5358\n",
      "Epoch 535/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2862 - accuracy: 0.5247 - val_loss: 1.2899 - val_accuracy: 0.5375\n",
      "Epoch 536/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2860 - accuracy: 0.5274 - val_loss: 1.3108 - val_accuracy: 0.5255\n",
      "Epoch 537/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2926 - accuracy: 0.5225 - val_loss: 1.2932 - val_accuracy: 0.5330\n",
      "Epoch 538/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5278 - val_loss: 1.2914 - val_accuracy: 0.5378\n",
      "Epoch 539/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2888 - accuracy: 0.5291 - val_loss: 1.2943 - val_accuracy: 0.5288\n",
      "Epoch 540/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2865 - accuracy: 0.5291 - val_loss: 1.2885 - val_accuracy: 0.5335\n",
      "Epoch 541/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2861 - accuracy: 0.5265 - val_loss: 1.2985 - val_accuracy: 0.5296\n",
      "Epoch 542/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2873 - accuracy: 0.5264 - val_loss: 1.3140 - val_accuracy: 0.5244\n",
      "Epoch 543/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2877 - accuracy: 0.5261 - val_loss: 1.2970 - val_accuracy: 0.5265\n",
      "Epoch 544/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2821 - accuracy: 0.5287 - val_loss: 1.3006 - val_accuracy: 0.5302\n",
      "Epoch 545/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2883 - accuracy: 0.5255 - val_loss: 1.3030 - val_accuracy: 0.5246\n",
      "Epoch 546/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2841 - accuracy: 0.5267 - val_loss: 1.2924 - val_accuracy: 0.5318\n",
      "Epoch 547/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2845 - accuracy: 0.5277 - val_loss: 1.2908 - val_accuracy: 0.5336\n",
      "Epoch 548/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5259 - val_loss: 1.2933 - val_accuracy: 0.5297\n",
      "Epoch 549/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2914 - accuracy: 0.5279 - val_loss: 1.3017 - val_accuracy: 0.5276\n",
      "Epoch 550/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2860 - accuracy: 0.5299 - val_loss: 1.2875 - val_accuracy: 0.5344\n",
      "Epoch 551/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2880 - accuracy: 0.5274 - val_loss: 1.2894 - val_accuracy: 0.5383\n",
      "Epoch 552/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2847 - accuracy: 0.5261 - val_loss: 1.3078 - val_accuracy: 0.5219\n",
      "Epoch 553/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2805 - accuracy: 0.5283 - val_loss: 1.2867 - val_accuracy: 0.5356\n",
      "Epoch 554/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2905 - accuracy: 0.5268 - val_loss: 1.2935 - val_accuracy: 0.5361\n",
      "Epoch 555/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2878 - accuracy: 0.5282 - val_loss: 1.2919 - val_accuracy: 0.5356\n",
      "Epoch 556/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2858 - accuracy: 0.5288 - val_loss: 1.3057 - val_accuracy: 0.5310\n",
      "Epoch 557/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2866 - accuracy: 0.5272 - val_loss: 1.2872 - val_accuracy: 0.5356\n",
      "Epoch 558/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2853 - accuracy: 0.5285 - val_loss: 1.2952 - val_accuracy: 0.5313\n",
      "Epoch 559/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2885 - accuracy: 0.5286 - val_loss: 1.3161 - val_accuracy: 0.5235\n",
      "Epoch 560/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2863 - accuracy: 0.5264 - val_loss: 1.3022 - val_accuracy: 0.5271\n",
      "Epoch 561/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2878 - accuracy: 0.5251 - val_loss: 1.3055 - val_accuracy: 0.5254\n",
      "Epoch 562/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2848 - accuracy: 0.5284 - val_loss: 1.2928 - val_accuracy: 0.5341\n",
      "Epoch 563/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2866 - accuracy: 0.5287 - val_loss: 1.2874 - val_accuracy: 0.5360\n",
      "Epoch 564/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2859 - accuracy: 0.5282 - val_loss: 1.2927 - val_accuracy: 0.5307\n",
      "Epoch 565/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2871 - accuracy: 0.5271 - val_loss: 1.3120 - val_accuracy: 0.5233\n",
      "Epoch 566/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2864 - accuracy: 0.5258 - val_loss: 1.3119 - val_accuracy: 0.5223\n",
      "Epoch 567/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.2840 - accuracy: 0.5267 - val_loss: 1.2900 - val_accuracy: 0.5374\n",
      "Epoch 568/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2932 - accuracy: 0.5225 - val_loss: 1.3085 - val_accuracy: 0.5233\n",
      "Epoch 569/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2849 - accuracy: 0.5262 - val_loss: 1.2920 - val_accuracy: 0.5314\n",
      "Epoch 570/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2881 - accuracy: 0.5261 - val_loss: 1.2909 - val_accuracy: 0.5361\n",
      "Epoch 571/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2840 - accuracy: 0.5280 - val_loss: 1.2878 - val_accuracy: 0.5363\n",
      "Epoch 572/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2847 - accuracy: 0.5274 - val_loss: 1.2983 - val_accuracy: 0.5339\n",
      "Epoch 573/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2833 - accuracy: 0.5294 - val_loss: 1.2967 - val_accuracy: 0.5294\n",
      "Epoch 574/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2897 - accuracy: 0.5273 - val_loss: 1.2988 - val_accuracy: 0.5288\n",
      "Epoch 575/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2862 - accuracy: 0.5278 - val_loss: 1.2862 - val_accuracy: 0.5332\n",
      "Epoch 576/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2844 - accuracy: 0.5268 - val_loss: 1.2865 - val_accuracy: 0.5364\n",
      "Epoch 577/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2862 - accuracy: 0.5280 - val_loss: 1.3011 - val_accuracy: 0.5268\n",
      "Epoch 578/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2877 - accuracy: 0.5253 - val_loss: 1.2896 - val_accuracy: 0.5369\n",
      "Epoch 579/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2849 - accuracy: 0.5278 - val_loss: 1.2998 - val_accuracy: 0.5316\n",
      "Epoch 580/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2842 - accuracy: 0.5283 - val_loss: 1.3094 - val_accuracy: 0.5332\n",
      "Epoch 581/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2842 - accuracy: 0.5284 - val_loss: 1.2980 - val_accuracy: 0.5280\n",
      "Epoch 582/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2855 - accuracy: 0.5274 - val_loss: 1.2909 - val_accuracy: 0.5350\n",
      "Epoch 583/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2880 - accuracy: 0.5264 - val_loss: 1.2879 - val_accuracy: 0.5324\n",
      "Epoch 584/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2819 - accuracy: 0.5276 - val_loss: 1.2934 - val_accuracy: 0.5341\n",
      "Epoch 585/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2850 - accuracy: 0.5281 - val_loss: 1.2972 - val_accuracy: 0.5347\n",
      "Epoch 586/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5291 - val_loss: 1.2866 - val_accuracy: 0.5361\n",
      "Epoch 587/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2833 - accuracy: 0.5292 - val_loss: 1.2859 - val_accuracy: 0.5364\n",
      "Epoch 588/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2844 - accuracy: 0.5274 - val_loss: 1.2956 - val_accuracy: 0.5347\n",
      "Epoch 589/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2950 - accuracy: 0.5271 - val_loss: 1.3250 - val_accuracy: 0.5257\n",
      "Epoch 590/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2860 - accuracy: 0.5286 - val_loss: 1.2903 - val_accuracy: 0.5360\n",
      "Epoch 591/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2816 - accuracy: 0.5304 - val_loss: 1.3020 - val_accuracy: 0.5304\n",
      "Epoch 592/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2865 - accuracy: 0.5288 - val_loss: 1.2959 - val_accuracy: 0.5294\n",
      "Epoch 593/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2851 - accuracy: 0.5302 - val_loss: 1.3001 - val_accuracy: 0.5304\n",
      "Epoch 594/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2839 - accuracy: 0.5288 - val_loss: 1.3005 - val_accuracy: 0.5336\n",
      "Epoch 595/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2812 - accuracy: 0.5292 - val_loss: 1.2948 - val_accuracy: 0.5276\n",
      "Epoch 596/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2846 - accuracy: 0.5259 - val_loss: 1.3068 - val_accuracy: 0.5280\n",
      "Epoch 597/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2828 - accuracy: 0.5275 - val_loss: 1.2895 - val_accuracy: 0.5330\n",
      "Epoch 598/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.2832 - accuracy: 0.5292 - val_loss: 1.2893 - val_accuracy: 0.5361\n",
      "Epoch 599/750\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.2869 - accuracy: 0.5278 - val_loss: 1.2952 - val_accuracy: 0.5294\n",
      "Epoch 600/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2825 - accuracy: 0.5297 - val_loss: 1.2925 - val_accuracy: 0.5300\n",
      "Epoch 601/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2835 - accuracy: 0.5271 - val_loss: 1.2874 - val_accuracy: 0.5361\n",
      "Epoch 602/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2874 - accuracy: 0.5242 - val_loss: 1.2953 - val_accuracy: 0.5280\n",
      "Epoch 603/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2829 - accuracy: 0.5281 - val_loss: 1.2869 - val_accuracy: 0.5391\n",
      "Epoch 604/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2817 - accuracy: 0.5269 - val_loss: 1.3098 - val_accuracy: 0.5248\n",
      "Epoch 605/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2854 - accuracy: 0.5307 - val_loss: 1.2938 - val_accuracy: 0.5332\n",
      "Epoch 606/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2883 - accuracy: 0.5284 - val_loss: 1.2932 - val_accuracy: 0.5372\n",
      "Epoch 607/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2837 - accuracy: 0.5274 - val_loss: 1.3056 - val_accuracy: 0.5255\n",
      "Epoch 608/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2909 - accuracy: 0.5246 - val_loss: 1.3240 - val_accuracy: 0.5227\n",
      "Epoch 609/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2845 - accuracy: 0.5276 - val_loss: 1.2870 - val_accuracy: 0.5335\n",
      "Epoch 610/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2859 - accuracy: 0.5274 - val_loss: 1.2910 - val_accuracy: 0.5372\n",
      "Epoch 611/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2878 - accuracy: 0.5258 - val_loss: 1.2900 - val_accuracy: 0.5355\n",
      "Epoch 612/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5228 - val_loss: 1.3066 - val_accuracy: 0.5352\n",
      "Epoch 613/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2851 - accuracy: 0.5280 - val_loss: 1.2989 - val_accuracy: 0.5276\n",
      "Epoch 614/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2839 - accuracy: 0.5273 - val_loss: 1.2924 - val_accuracy: 0.5296\n",
      "Epoch 615/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2849 - accuracy: 0.5243 - val_loss: 1.3153 - val_accuracy: 0.5276\n",
      "Epoch 616/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2834 - accuracy: 0.5288 - val_loss: 1.3016 - val_accuracy: 0.5302\n",
      "Epoch 617/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2897 - accuracy: 0.5275 - val_loss: 1.2955 - val_accuracy: 0.5300\n",
      "Epoch 618/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2844 - accuracy: 0.5269 - val_loss: 1.2942 - val_accuracy: 0.5333\n",
      "Epoch 619/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2906 - accuracy: 0.5282 - val_loss: 1.2862 - val_accuracy: 0.5383\n",
      "Epoch 620/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2805 - accuracy: 0.5289 - val_loss: 1.2872 - val_accuracy: 0.5355\n",
      "Epoch 621/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2834 - accuracy: 0.5311 - val_loss: 1.3007 - val_accuracy: 0.5304\n",
      "Epoch 622/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2824 - accuracy: 0.5301 - val_loss: 1.3118 - val_accuracy: 0.5240\n",
      "Epoch 623/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2834 - accuracy: 0.5276 - val_loss: 1.2992 - val_accuracy: 0.5293\n",
      "Epoch 624/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2832 - accuracy: 0.5298 - val_loss: 1.3002 - val_accuracy: 0.5321\n",
      "Epoch 625/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2830 - accuracy: 0.5283 - val_loss: 1.3012 - val_accuracy: 0.5321\n",
      "Epoch 626/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2874 - accuracy: 0.5277 - val_loss: 1.3018 - val_accuracy: 0.5258\n",
      "Epoch 627/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2838 - accuracy: 0.5274 - val_loss: 1.2875 - val_accuracy: 0.5386\n",
      "Epoch 628/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2876 - accuracy: 0.5260 - val_loss: 1.3003 - val_accuracy: 0.5283\n",
      "Epoch 629/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2870 - accuracy: 0.5300 - val_loss: 1.2923 - val_accuracy: 0.5360\n",
      "Epoch 630/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2825 - accuracy: 0.5288 - val_loss: 1.2828 - val_accuracy: 0.5361\n",
      "Epoch 631/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2798 - accuracy: 0.5304 - val_loss: 1.3100 - val_accuracy: 0.5226\n",
      "Epoch 632/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5294 - val_loss: 1.2873 - val_accuracy: 0.5335\n",
      "Epoch 633/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2841 - accuracy: 0.5271 - val_loss: 1.2966 - val_accuracy: 0.5358\n",
      "Epoch 634/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2790 - accuracy: 0.5280 - val_loss: 1.2925 - val_accuracy: 0.5307\n",
      "Epoch 635/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2842 - accuracy: 0.5300 - val_loss: 1.2991 - val_accuracy: 0.5349\n",
      "Epoch 636/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2852 - accuracy: 0.5271 - val_loss: 1.3091 - val_accuracy: 0.5204\n",
      "Epoch 637/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2835 - accuracy: 0.5311 - val_loss: 1.3027 - val_accuracy: 0.5316\n",
      "Epoch 638/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2894 - accuracy: 0.5235 - val_loss: 1.3040 - val_accuracy: 0.5240\n",
      "Epoch 639/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2821 - accuracy: 0.5255 - val_loss: 1.2862 - val_accuracy: 0.5349\n",
      "Epoch 640/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2856 - accuracy: 0.5281 - val_loss: 1.2909 - val_accuracy: 0.5352\n",
      "Epoch 641/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2820 - accuracy: 0.5260 - val_loss: 1.2846 - val_accuracy: 0.5341\n",
      "Epoch 642/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2838 - accuracy: 0.5284 - val_loss: 1.2890 - val_accuracy: 0.5341\n",
      "Epoch 643/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2839 - accuracy: 0.5313 - val_loss: 1.2879 - val_accuracy: 0.5318\n",
      "Epoch 644/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2843 - accuracy: 0.5242 - val_loss: 1.2858 - val_accuracy: 0.5363\n",
      "Epoch 645/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2806 - accuracy: 0.5288 - val_loss: 1.2892 - val_accuracy: 0.5327\n",
      "Epoch 646/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2905 - accuracy: 0.5268 - val_loss: 1.3031 - val_accuracy: 0.5313\n",
      "Epoch 647/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2824 - accuracy: 0.5275 - val_loss: 1.2899 - val_accuracy: 0.5360\n",
      "Epoch 648/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2806 - accuracy: 0.5271 - val_loss: 1.3015 - val_accuracy: 0.5257\n",
      "Epoch 649/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2861 - accuracy: 0.5273 - val_loss: 1.2909 - val_accuracy: 0.5335\n",
      "Epoch 650/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2832 - accuracy: 0.5298 - val_loss: 1.2889 - val_accuracy: 0.5366\n",
      "Epoch 651/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2837 - accuracy: 0.5269 - val_loss: 1.2925 - val_accuracy: 0.5313\n",
      "Epoch 652/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2793 - accuracy: 0.5285 - val_loss: 1.2910 - val_accuracy: 0.5367\n",
      "Epoch 653/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2797 - accuracy: 0.5301 - val_loss: 1.2918 - val_accuracy: 0.5374\n",
      "Epoch 654/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2833 - accuracy: 0.5281 - val_loss: 1.2981 - val_accuracy: 0.5339\n",
      "Epoch 655/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2844 - accuracy: 0.5248 - val_loss: 1.3049 - val_accuracy: 0.5269\n",
      "Epoch 656/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2862 - accuracy: 0.5255 - val_loss: 1.2927 - val_accuracy: 0.5375\n",
      "Epoch 657/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5300 - val_loss: 1.2982 - val_accuracy: 0.5304\n",
      "Epoch 658/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2793 - accuracy: 0.5323 - val_loss: 1.2934 - val_accuracy: 0.5308\n",
      "Epoch 659/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2810 - accuracy: 0.5294 - val_loss: 1.2959 - val_accuracy: 0.5361\n",
      "Epoch 660/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2814 - accuracy: 0.5277 - val_loss: 1.3028 - val_accuracy: 0.5304\n",
      "Epoch 661/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5268 - val_loss: 1.2984 - val_accuracy: 0.5321\n",
      "Epoch 662/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2824 - accuracy: 0.5275 - val_loss: 1.3018 - val_accuracy: 0.5266\n",
      "Epoch 663/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2825 - accuracy: 0.5268 - val_loss: 1.2895 - val_accuracy: 0.5367\n",
      "Epoch 664/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2847 - accuracy: 0.5286 - val_loss: 1.2954 - val_accuracy: 0.5372\n",
      "Epoch 665/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2821 - accuracy: 0.5272 - val_loss: 1.2962 - val_accuracy: 0.5297\n",
      "Epoch 666/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2815 - accuracy: 0.5296 - val_loss: 1.2961 - val_accuracy: 0.5269\n",
      "Epoch 667/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2831 - accuracy: 0.5267 - val_loss: 1.3112 - val_accuracy: 0.5193\n",
      "Epoch 668/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2830 - accuracy: 0.5309 - val_loss: 1.3012 - val_accuracy: 0.5293\n",
      "Epoch 669/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2813 - accuracy: 0.5280 - val_loss: 1.2840 - val_accuracy: 0.5369\n",
      "Epoch 670/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2840 - accuracy: 0.5299 - val_loss: 1.3024 - val_accuracy: 0.5257\n",
      "Epoch 671/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2824 - accuracy: 0.5288 - val_loss: 1.2988 - val_accuracy: 0.5294\n",
      "Epoch 672/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2816 - accuracy: 0.5301 - val_loss: 1.3013 - val_accuracy: 0.5316\n",
      "Epoch 673/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2794 - accuracy: 0.5278 - val_loss: 1.2965 - val_accuracy: 0.5336\n",
      "Epoch 674/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2823 - accuracy: 0.5289 - val_loss: 1.2836 - val_accuracy: 0.5363\n",
      "Epoch 675/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2863 - accuracy: 0.5278 - val_loss: 1.3135 - val_accuracy: 0.5288\n",
      "Epoch 676/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2821 - accuracy: 0.5284 - val_loss: 1.3003 - val_accuracy: 0.5279\n",
      "Epoch 677/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2889 - accuracy: 0.5257 - val_loss: 1.2908 - val_accuracy: 0.5347\n",
      "Epoch 678/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2787 - accuracy: 0.5307 - val_loss: 1.2903 - val_accuracy: 0.5339\n",
      "Epoch 679/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2816 - accuracy: 0.5293 - val_loss: 1.2940 - val_accuracy: 0.5361\n",
      "Epoch 680/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2791 - accuracy: 0.5299 - val_loss: 1.2882 - val_accuracy: 0.5313\n",
      "Epoch 681/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2795 - accuracy: 0.5286 - val_loss: 1.2945 - val_accuracy: 0.5370\n",
      "Epoch 682/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2820 - accuracy: 0.5286 - val_loss: 1.3255 - val_accuracy: 0.5198\n",
      "Epoch 683/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2896 - accuracy: 0.5274 - val_loss: 1.2837 - val_accuracy: 0.5384\n",
      "Epoch 684/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2815 - accuracy: 0.5291 - val_loss: 1.3065 - val_accuracy: 0.5311\n",
      "Epoch 685/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2796 - accuracy: 0.5298 - val_loss: 1.2871 - val_accuracy: 0.5322\n",
      "Epoch 686/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2821 - accuracy: 0.5301 - val_loss: 1.2884 - val_accuracy: 0.5314\n",
      "Epoch 687/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2856 - accuracy: 0.5269 - val_loss: 1.2966 - val_accuracy: 0.5302\n",
      "Epoch 688/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2791 - accuracy: 0.5307 - val_loss: 1.2992 - val_accuracy: 0.5338\n",
      "Epoch 689/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5322 - val_loss: 1.2907 - val_accuracy: 0.5310\n",
      "Epoch 690/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2816 - accuracy: 0.5286 - val_loss: 1.2964 - val_accuracy: 0.5361\n",
      "Epoch 691/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2817 - accuracy: 0.5298 - val_loss: 1.2982 - val_accuracy: 0.5304\n",
      "Epoch 692/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2837 - accuracy: 0.5257 - val_loss: 1.3118 - val_accuracy: 0.5252\n",
      "Epoch 693/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2846 - accuracy: 0.5304 - val_loss: 1.2918 - val_accuracy: 0.5333\n",
      "Epoch 694/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5267 - val_loss: 1.2845 - val_accuracy: 0.5367\n",
      "Epoch 695/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5278 - val_loss: 1.2857 - val_accuracy: 0.5380\n",
      "Epoch 696/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2846 - accuracy: 0.5286 - val_loss: 1.3076 - val_accuracy: 0.5307\n",
      "Epoch 697/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2824 - accuracy: 0.5285 - val_loss: 1.2823 - val_accuracy: 0.5364\n",
      "Epoch 698/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2797 - accuracy: 0.5300 - val_loss: 1.3037 - val_accuracy: 0.5338\n",
      "Epoch 699/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2803 - accuracy: 0.5284 - val_loss: 1.2959 - val_accuracy: 0.5293\n",
      "Epoch 700/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2861 - accuracy: 0.5276 - val_loss: 1.2880 - val_accuracy: 0.5327\n",
      "Epoch 701/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2808 - accuracy: 0.5313 - val_loss: 1.2931 - val_accuracy: 0.5391\n",
      "Epoch 702/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2838 - accuracy: 0.5280 - val_loss: 1.3002 - val_accuracy: 0.5286\n",
      "Epoch 703/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2823 - accuracy: 0.5271 - val_loss: 1.2853 - val_accuracy: 0.5375\n",
      "Epoch 704/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2815 - accuracy: 0.5297 - val_loss: 1.2834 - val_accuracy: 0.5349\n",
      "Epoch 705/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2845 - accuracy: 0.5271 - val_loss: 1.3332 - val_accuracy: 0.5201\n",
      "Epoch 706/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2795 - accuracy: 0.5297 - val_loss: 1.2993 - val_accuracy: 0.5268\n",
      "Epoch 707/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2812 - accuracy: 0.5300 - val_loss: 1.2919 - val_accuracy: 0.5363\n",
      "Epoch 708/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.2809 - accuracy: 0.5280 - val_loss: 1.2938 - val_accuracy: 0.5314\n",
      "Epoch 709/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2804 - accuracy: 0.5269 - val_loss: 1.3091 - val_accuracy: 0.5221\n",
      "Epoch 710/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2816 - accuracy: 0.5312 - val_loss: 1.2902 - val_accuracy: 0.5361\n",
      "Epoch 711/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2818 - accuracy: 0.5279 - val_loss: 1.3049 - val_accuracy: 0.5305\n",
      "Epoch 712/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2807 - accuracy: 0.5307 - val_loss: 1.2845 - val_accuracy: 0.5338\n",
      "Epoch 713/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5283 - val_loss: 1.2842 - val_accuracy: 0.5349\n",
      "Epoch 714/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2800 - accuracy: 0.5295 - val_loss: 1.2933 - val_accuracy: 0.5325\n",
      "Epoch 715/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2857 - accuracy: 0.5266 - val_loss: 1.3038 - val_accuracy: 0.5288\n",
      "Epoch 716/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2820 - accuracy: 0.5286 - val_loss: 1.2935 - val_accuracy: 0.5338\n",
      "Epoch 717/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2796 - accuracy: 0.5307 - val_loss: 1.2832 - val_accuracy: 0.5372\n",
      "Epoch 718/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2836 - accuracy: 0.5296 - val_loss: 1.2973 - val_accuracy: 0.5304\n",
      "Epoch 719/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2832 - accuracy: 0.5308 - val_loss: 1.3165 - val_accuracy: 0.5204\n",
      "Epoch 720/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2854 - accuracy: 0.5294 - val_loss: 1.2961 - val_accuracy: 0.5254\n",
      "Epoch 721/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2808 - accuracy: 0.5293 - val_loss: 1.2905 - val_accuracy: 0.5299\n",
      "Epoch 722/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2807 - accuracy: 0.5284 - val_loss: 1.2986 - val_accuracy: 0.5311\n",
      "Epoch 723/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2807 - accuracy: 0.5301 - val_loss: 1.2980 - val_accuracy: 0.5338\n",
      "Epoch 724/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2810 - accuracy: 0.5320 - val_loss: 1.3001 - val_accuracy: 0.5313\n",
      "Epoch 725/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2816 - accuracy: 0.5294 - val_loss: 1.3382 - val_accuracy: 0.5244\n",
      "Epoch 726/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2844 - accuracy: 0.5291 - val_loss: 1.2974 - val_accuracy: 0.5332\n",
      "Epoch 727/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2827 - accuracy: 0.5293 - val_loss: 1.2896 - val_accuracy: 0.5347\n",
      "Epoch 728/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2834 - accuracy: 0.5285 - val_loss: 1.2897 - val_accuracy: 0.5313\n",
      "Epoch 729/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2799 - accuracy: 0.5294 - val_loss: 1.2955 - val_accuracy: 0.5324\n",
      "Epoch 730/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2811 - accuracy: 0.5301 - val_loss: 1.3009 - val_accuracy: 0.5327\n",
      "Epoch 731/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2825 - accuracy: 0.5274 - val_loss: 1.3051 - val_accuracy: 0.5350\n",
      "Epoch 732/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2850 - accuracy: 0.5294 - val_loss: 1.2920 - val_accuracy: 0.5363\n",
      "Epoch 733/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2785 - accuracy: 0.5307 - val_loss: 1.2861 - val_accuracy: 0.5364\n",
      "Epoch 734/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2765 - accuracy: 0.5303 - val_loss: 1.2990 - val_accuracy: 0.5268\n",
      "Epoch 735/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2796 - accuracy: 0.5301 - val_loss: 1.2829 - val_accuracy: 0.5377\n",
      "Epoch 736/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2792 - accuracy: 0.5284 - val_loss: 1.2920 - val_accuracy: 0.5378\n",
      "Epoch 737/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2807 - accuracy: 0.5278 - val_loss: 1.2918 - val_accuracy: 0.5353\n",
      "Epoch 738/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2837 - accuracy: 0.5290 - val_loss: 1.2980 - val_accuracy: 0.5353\n",
      "Epoch 739/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2788 - accuracy: 0.5303 - val_loss: 1.3068 - val_accuracy: 0.5252\n",
      "Epoch 740/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2895 - accuracy: 0.5277 - val_loss: 1.2830 - val_accuracy: 0.5361\n",
      "Epoch 741/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2796 - accuracy: 0.5292 - val_loss: 1.3075 - val_accuracy: 0.5276\n",
      "Epoch 742/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2845 - accuracy: 0.5275 - val_loss: 1.2819 - val_accuracy: 0.5391\n",
      "Epoch 743/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2814 - accuracy: 0.5313 - val_loss: 1.2936 - val_accuracy: 0.5330\n",
      "Epoch 744/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2777 - accuracy: 0.5298 - val_loss: 1.2901 - val_accuracy: 0.5335\n",
      "Epoch 745/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2787 - accuracy: 0.5300 - val_loss: 1.2994 - val_accuracy: 0.5294\n",
      "Epoch 746/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2853 - accuracy: 0.5298 - val_loss: 1.2978 - val_accuracy: 0.5330\n",
      "Epoch 747/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2828 - accuracy: 0.5288 - val_loss: 1.2944 - val_accuracy: 0.5302\n",
      "Epoch 748/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2783 - accuracy: 0.5294 - val_loss: 1.2898 - val_accuracy: 0.5353\n",
      "Epoch 749/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2804 - accuracy: 0.5269 - val_loss: 1.2972 - val_accuracy: 0.5328\n",
      "Epoch 750/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.2798 - accuracy: 0.5291 - val_loss: 1.2930 - val_accuracy: 0.5293\n",
      "Epoch 1/750\n",
      "408/408 [==============================] - 3s 5ms/step - loss: 1.9996 - accuracy: 0.3458 - val_loss: 1.9705 - val_accuracy: 0.3529\n",
      "Epoch 2/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.9493 - accuracy: 0.3581 - val_loss: 1.9279 - val_accuracy: 0.3574\n",
      "Epoch 3/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.9099 - accuracy: 0.3592 - val_loss: 1.8909 - val_accuracy: 0.3579\n",
      "Epoch 4/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.8753 - accuracy: 0.3595 - val_loss: 1.8586 - val_accuracy: 0.3579\n",
      "Epoch 5/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.8453 - accuracy: 0.3595 - val_loss: 1.8304 - val_accuracy: 0.3579\n",
      "Epoch 6/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.8190 - accuracy: 0.3595 - val_loss: 1.8058 - val_accuracy: 0.3579\n",
      "Epoch 7/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7961 - accuracy: 0.3595 - val_loss: 1.7844 - val_accuracy: 0.3579\n",
      "Epoch 8/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7764 - accuracy: 0.3595 - val_loss: 1.7660 - val_accuracy: 0.3579\n",
      "Epoch 9/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7596 - accuracy: 0.3595 - val_loss: 1.7505 - val_accuracy: 0.3579\n",
      "Epoch 10/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7453 - accuracy: 0.3595 - val_loss: 1.7373 - val_accuracy: 0.3579\n",
      "Epoch 11/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7333 - accuracy: 0.3595 - val_loss: 1.7262 - val_accuracy: 0.3579\n",
      "Epoch 12/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7232 - accuracy: 0.3595 - val_loss: 1.7170 - val_accuracy: 0.3579\n",
      "Epoch 13/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7148 - accuracy: 0.3595 - val_loss: 1.7094 - val_accuracy: 0.3579\n",
      "Epoch 14/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7080 - accuracy: 0.3595 - val_loss: 1.7032 - val_accuracy: 0.3579\n",
      "Epoch 15/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7024 - accuracy: 0.3595 - val_loss: 1.6979 - val_accuracy: 0.3579\n",
      "Epoch 16/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.6976 - accuracy: 0.3595 - val_loss: 1.6935 - val_accuracy: 0.3579\n",
      "Epoch 17/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6936 - accuracy: 0.3595 - val_loss: 1.6899 - val_accuracy: 0.3579\n",
      "Epoch 18/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6902 - accuracy: 0.3595 - val_loss: 1.6870 - val_accuracy: 0.3579\n",
      "Epoch 19/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6874 - accuracy: 0.3595 - val_loss: 1.6841 - val_accuracy: 0.3579\n",
      "Epoch 20/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6849 - accuracy: 0.3595 - val_loss: 1.6818 - val_accuracy: 0.3579\n",
      "Epoch 21/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6827 - accuracy: 0.3595 - val_loss: 1.6797 - val_accuracy: 0.3579\n",
      "Epoch 22/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6808 - accuracy: 0.3595 - val_loss: 1.6779 - val_accuracy: 0.3579\n",
      "Epoch 23/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6791 - accuracy: 0.3595 - val_loss: 1.6763 - val_accuracy: 0.3579\n",
      "Epoch 24/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6749 - val_accuracy: 0.3579\n",
      "Epoch 25/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6762 - accuracy: 0.3595 - val_loss: 1.6735 - val_accuracy: 0.3579\n",
      "Epoch 26/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6749 - accuracy: 0.3595 - val_loss: 1.6722 - val_accuracy: 0.3579\n",
      "Epoch 27/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6738 - accuracy: 0.3598 - val_loss: 1.6711 - val_accuracy: 0.3591\n",
      "Epoch 28/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6726 - accuracy: 0.3611 - val_loss: 1.6701 - val_accuracy: 0.3596\n",
      "Epoch 29/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6716 - accuracy: 0.3625 - val_loss: 1.6690 - val_accuracy: 0.3635\n",
      "Epoch 30/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6706 - accuracy: 0.3644 - val_loss: 1.6680 - val_accuracy: 0.3646\n",
      "Epoch 31/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6696 - accuracy: 0.3650 - val_loss: 1.6670 - val_accuracy: 0.3646\n",
      "Epoch 32/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6686 - accuracy: 0.3653 - val_loss: 1.6661 - val_accuracy: 0.3658\n",
      "Epoch 33/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6677 - accuracy: 0.3656 - val_loss: 1.6651 - val_accuracy: 0.3666\n",
      "Epoch 34/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6670 - accuracy: 0.3662 - val_loss: 1.6642 - val_accuracy: 0.3666\n",
      "Epoch 35/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6659 - accuracy: 0.3670 - val_loss: 1.6634 - val_accuracy: 0.3669\n",
      "Epoch 36/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6650 - accuracy: 0.3674 - val_loss: 1.6624 - val_accuracy: 0.3671\n",
      "Epoch 37/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6641 - accuracy: 0.3679 - val_loss: 1.6616 - val_accuracy: 0.3671\n",
      "Epoch 38/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6632 - accuracy: 0.3677 - val_loss: 1.6617 - val_accuracy: 0.3682\n",
      "Epoch 39/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6624 - accuracy: 0.3683 - val_loss: 1.6610 - val_accuracy: 0.3686\n",
      "Epoch 40/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6616 - accuracy: 0.3692 - val_loss: 1.6588 - val_accuracy: 0.3683\n",
      "Epoch 41/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6606 - accuracy: 0.3693 - val_loss: 1.6579 - val_accuracy: 0.3685\n",
      "Epoch 42/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6597 - accuracy: 0.3694 - val_loss: 1.6569 - val_accuracy: 0.3686\n",
      "Epoch 43/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6588 - accuracy: 0.3696 - val_loss: 1.6560 - val_accuracy: 0.3686\n",
      "Epoch 44/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6580 - accuracy: 0.3697 - val_loss: 1.6550 - val_accuracy: 0.3686\n",
      "Epoch 45/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6569 - accuracy: 0.3697 - val_loss: 1.6555 - val_accuracy: 0.3688\n",
      "Epoch 46/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6560 - accuracy: 0.3700 - val_loss: 1.6532 - val_accuracy: 0.3685\n",
      "Epoch 47/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6547 - accuracy: 0.3697 - val_loss: 1.6530 - val_accuracy: 0.3689\n",
      "Epoch 48/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6539 - accuracy: 0.3698 - val_loss: 1.6509 - val_accuracy: 0.3686\n",
      "Epoch 49/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6527 - accuracy: 0.3701 - val_loss: 1.6499 - val_accuracy: 0.3685\n",
      "Epoch 50/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6517 - accuracy: 0.3700 - val_loss: 1.6488 - val_accuracy: 0.3689\n",
      "Epoch 51/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6505 - accuracy: 0.3703 - val_loss: 1.6480 - val_accuracy: 0.3688\n",
      "Epoch 52/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6495 - accuracy: 0.3702 - val_loss: 1.6465 - val_accuracy: 0.3688\n",
      "Epoch 53/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6485 - accuracy: 0.3703 - val_loss: 1.6455 - val_accuracy: 0.3686\n",
      "Epoch 54/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6471 - accuracy: 0.3703 - val_loss: 1.6442 - val_accuracy: 0.3688\n",
      "Epoch 55/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6460 - accuracy: 0.3708 - val_loss: 1.6430 - val_accuracy: 0.3688\n",
      "Epoch 56/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6447 - accuracy: 0.3706 - val_loss: 1.6420 - val_accuracy: 0.3692\n",
      "Epoch 57/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6434 - accuracy: 0.3709 - val_loss: 1.6405 - val_accuracy: 0.3692\n",
      "Epoch 58/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6421 - accuracy: 0.3707 - val_loss: 1.6398 - val_accuracy: 0.3691\n",
      "Epoch 59/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6410 - accuracy: 0.3706 - val_loss: 1.6377 - val_accuracy: 0.3694\n",
      "Epoch 60/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6394 - accuracy: 0.3706 - val_loss: 1.6364 - val_accuracy: 0.3699\n",
      "Epoch 61/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6377 - accuracy: 0.3710 - val_loss: 1.6349 - val_accuracy: 0.3702\n",
      "Epoch 62/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6364 - accuracy: 0.3713 - val_loss: 1.6334 - val_accuracy: 0.3702\n",
      "Epoch 63/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6350 - accuracy: 0.3714 - val_loss: 1.6321 - val_accuracy: 0.3699\n",
      "Epoch 64/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6335 - accuracy: 0.3715 - val_loss: 1.6303 - val_accuracy: 0.3703\n",
      "Epoch 65/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6319 - accuracy: 0.3721 - val_loss: 1.6295 - val_accuracy: 0.3714\n",
      "Epoch 66/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6303 - accuracy: 0.3726 - val_loss: 1.6272 - val_accuracy: 0.3705\n",
      "Epoch 67/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6289 - accuracy: 0.3730 - val_loss: 1.6256 - val_accuracy: 0.3716\n",
      "Epoch 68/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6273 - accuracy: 0.3733 - val_loss: 1.6243 - val_accuracy: 0.3731\n",
      "Epoch 69/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6254 - accuracy: 0.3739 - val_loss: 1.6222 - val_accuracy: 0.3720\n",
      "Epoch 70/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6237 - accuracy: 0.3743 - val_loss: 1.6211 - val_accuracy: 0.3714\n",
      "Epoch 71/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6221 - accuracy: 0.3759 - val_loss: 1.6189 - val_accuracy: 0.3731\n",
      "Epoch 72/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6203 - accuracy: 0.3767 - val_loss: 1.6173 - val_accuracy: 0.3730\n",
      "Epoch 73/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6185 - accuracy: 0.3762 - val_loss: 1.6164 - val_accuracy: 0.3808\n",
      "Epoch 74/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6164 - accuracy: 0.3775 - val_loss: 1.6136 - val_accuracy: 0.3744\n",
      "Epoch 75/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6143 - accuracy: 0.3789 - val_loss: 1.6112 - val_accuracy: 0.3772\n",
      "Epoch 76/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6126 - accuracy: 0.3798 - val_loss: 1.6093 - val_accuracy: 0.3787\n",
      "Epoch 77/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6104 - accuracy: 0.3817 - val_loss: 1.6073 - val_accuracy: 0.3815\n",
      "Epoch 78/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6085 - accuracy: 0.3818 - val_loss: 1.6062 - val_accuracy: 0.3896\n",
      "Epoch 79/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6066 - accuracy: 0.3835 - val_loss: 1.6035 - val_accuracy: 0.3847\n",
      "Epoch 80/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6046 - accuracy: 0.3845 - val_loss: 1.6012 - val_accuracy: 0.3856\n",
      "Epoch 81/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6022 - accuracy: 0.3863 - val_loss: 1.6002 - val_accuracy: 0.3831\n",
      "Epoch 82/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6007 - accuracy: 0.3874 - val_loss: 1.5971 - val_accuracy: 0.3906\n",
      "Epoch 83/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5981 - accuracy: 0.3913 - val_loss: 1.5956 - val_accuracy: 0.3854\n",
      "Epoch 84/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5961 - accuracy: 0.3920 - val_loss: 1.5931 - val_accuracy: 0.3923\n",
      "Epoch 85/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5938 - accuracy: 0.3918 - val_loss: 1.5921 - val_accuracy: 0.4016\n",
      "Epoch 86/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5917 - accuracy: 0.3940 - val_loss: 1.5894 - val_accuracy: 0.3885\n",
      "Epoch 87/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5895 - accuracy: 0.3964 - val_loss: 1.5872 - val_accuracy: 0.3927\n",
      "Epoch 88/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5872 - accuracy: 0.3992 - val_loss: 1.5868 - val_accuracy: 0.3873\n",
      "Epoch 89/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5851 - accuracy: 0.4000 - val_loss: 1.5821 - val_accuracy: 0.3990\n",
      "Epoch 90/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5830 - accuracy: 0.4006 - val_loss: 1.5801 - val_accuracy: 0.4036\n",
      "Epoch 91/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5806 - accuracy: 0.4029 - val_loss: 1.5794 - val_accuracy: 0.4026\n",
      "Epoch 92/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5789 - accuracy: 0.4042 - val_loss: 1.5774 - val_accuracy: 0.4060\n",
      "Epoch 93/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5763 - accuracy: 0.4065 - val_loss: 1.5736 - val_accuracy: 0.4077\n",
      "Epoch 94/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5740 - accuracy: 0.4091 - val_loss: 1.5730 - val_accuracy: 0.3994\n",
      "Epoch 95/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5717 - accuracy: 0.4106 - val_loss: 1.5719 - val_accuracy: 0.3976\n",
      "Epoch 96/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5697 - accuracy: 0.4121 - val_loss: 1.5677 - val_accuracy: 0.4226\n",
      "Epoch 97/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5674 - accuracy: 0.4170 - val_loss: 1.5671 - val_accuracy: 0.4041\n",
      "Epoch 98/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5657 - accuracy: 0.4163 - val_loss: 1.5644 - val_accuracy: 0.4099\n",
      "Epoch 99/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5632 - accuracy: 0.4183 - val_loss: 1.5608 - val_accuracy: 0.4184\n",
      "Epoch 100/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5607 - accuracy: 0.4219 - val_loss: 1.5588 - val_accuracy: 0.4197\n",
      "Epoch 101/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5587 - accuracy: 0.4216 - val_loss: 1.5573 - val_accuracy: 0.4158\n",
      "Epoch 102/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5567 - accuracy: 0.4247 - val_loss: 1.5549 - val_accuracy: 0.4181\n",
      "Epoch 103/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5542 - accuracy: 0.4272 - val_loss: 1.5559 - val_accuracy: 0.4454\n",
      "Epoch 104/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5526 - accuracy: 0.4303 - val_loss: 1.5523 - val_accuracy: 0.4170\n",
      "Epoch 105/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5503 - accuracy: 0.4299 - val_loss: 1.5483 - val_accuracy: 0.4290\n",
      "Epoch 106/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5478 - accuracy: 0.4316 - val_loss: 1.5481 - val_accuracy: 0.4217\n",
      "Epoch 107/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5460 - accuracy: 0.4312 - val_loss: 1.5446 - val_accuracy: 0.4343\n",
      "Epoch 108/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5439 - accuracy: 0.4339 - val_loss: 1.5427 - val_accuracy: 0.4270\n",
      "Epoch 109/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5419 - accuracy: 0.4353 - val_loss: 1.5412 - val_accuracy: 0.4413\n",
      "Epoch 110/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5401 - accuracy: 0.4310 - val_loss: 1.5395 - val_accuracy: 0.4301\n",
      "Epoch 111/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5381 - accuracy: 0.4315 - val_loss: 1.5382 - val_accuracy: 0.4217\n",
      "Epoch 112/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5364 - accuracy: 0.4275 - val_loss: 1.5350 - val_accuracy: 0.4275\n",
      "Epoch 113/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5343 - accuracy: 0.4332 - val_loss: 1.5337 - val_accuracy: 0.4284\n",
      "Epoch 114/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5328 - accuracy: 0.4342 - val_loss: 1.5321 - val_accuracy: 0.4257\n",
      "Epoch 115/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5307 - accuracy: 0.4340 - val_loss: 1.5300 - val_accuracy: 0.4284\n",
      "Epoch 116/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5286 - accuracy: 0.4356 - val_loss: 1.5280 - val_accuracy: 0.4321\n",
      "Epoch 117/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5270 - accuracy: 0.4372 - val_loss: 1.5271 - val_accuracy: 0.4351\n",
      "Epoch 118/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5254 - accuracy: 0.4390 - val_loss: 1.5262 - val_accuracy: 0.4488\n",
      "Epoch 119/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5235 - accuracy: 0.4411 - val_loss: 1.5237 - val_accuracy: 0.4317\n",
      "Epoch 120/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5219 - accuracy: 0.4399 - val_loss: 1.5220 - val_accuracy: 0.4457\n",
      "Epoch 121/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5207 - accuracy: 0.4409 - val_loss: 1.5197 - val_accuracy: 0.4384\n",
      "Epoch 122/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5186 - accuracy: 0.4434 - val_loss: 1.5185 - val_accuracy: 0.4352\n",
      "Epoch 123/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5171 - accuracy: 0.4436 - val_loss: 1.5167 - val_accuracy: 0.4469\n",
      "Epoch 124/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5155 - accuracy: 0.4466 - val_loss: 1.5156 - val_accuracy: 0.4362\n",
      "Epoch 125/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5136 - accuracy: 0.4456 - val_loss: 1.5140 - val_accuracy: 0.4374\n",
      "Epoch 126/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5119 - accuracy: 0.4488 - val_loss: 1.5137 - val_accuracy: 0.4352\n",
      "Epoch 127/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5111 - accuracy: 0.4479 - val_loss: 1.5118 - val_accuracy: 0.4433\n",
      "Epoch 128/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5098 - accuracy: 0.4502 - val_loss: 1.5093 - val_accuracy: 0.4461\n",
      "Epoch 129/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5078 - accuracy: 0.4518 - val_loss: 1.5078 - val_accuracy: 0.4500\n",
      "Epoch 130/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5066 - accuracy: 0.4509 - val_loss: 1.5064 - val_accuracy: 0.4491\n",
      "Epoch 131/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5048 - accuracy: 0.4525 - val_loss: 1.5068 - val_accuracy: 0.4443\n",
      "Epoch 132/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5040 - accuracy: 0.4532 - val_loss: 1.5046 - val_accuracy: 0.4458\n",
      "Epoch 133/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5022 - accuracy: 0.4544 - val_loss: 1.5026 - val_accuracy: 0.4519\n",
      "Epoch 134/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5009 - accuracy: 0.4540 - val_loss: 1.5028 - val_accuracy: 0.4418\n",
      "Epoch 135/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4997 - accuracy: 0.4563 - val_loss: 1.5030 - val_accuracy: 0.4390\n",
      "Epoch 136/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4985 - accuracy: 0.4574 - val_loss: 1.5005 - val_accuracy: 0.4541\n",
      "Epoch 137/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4976 - accuracy: 0.4560 - val_loss: 1.4985 - val_accuracy: 0.4580\n",
      "Epoch 138/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4963 - accuracy: 0.4549 - val_loss: 1.4983 - val_accuracy: 0.4432\n",
      "Epoch 139/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4947 - accuracy: 0.4563 - val_loss: 1.4979 - val_accuracy: 0.4684\n",
      "Epoch 140/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4942 - accuracy: 0.4581 - val_loss: 1.4962 - val_accuracy: 0.4505\n",
      "Epoch 141/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4925 - accuracy: 0.4605 - val_loss: 1.4940 - val_accuracy: 0.4527\n",
      "Epoch 142/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4916 - accuracy: 0.4592 - val_loss: 1.4937 - val_accuracy: 0.4527\n",
      "Epoch 143/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4908 - accuracy: 0.4608 - val_loss: 1.4916 - val_accuracy: 0.4539\n",
      "Epoch 144/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4893 - accuracy: 0.4583 - val_loss: 1.4929 - val_accuracy: 0.4710\n",
      "Epoch 145/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4888 - accuracy: 0.4601 - val_loss: 1.4902 - val_accuracy: 0.4522\n",
      "Epoch 146/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4876 - accuracy: 0.4621 - val_loss: 1.4885 - val_accuracy: 0.4623\n",
      "Epoch 147/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4866 - accuracy: 0.4600 - val_loss: 1.4882 - val_accuracy: 0.4549\n",
      "Epoch 148/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4855 - accuracy: 0.4634 - val_loss: 1.4881 - val_accuracy: 0.4547\n",
      "Epoch 149/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4847 - accuracy: 0.4630 - val_loss: 1.4857 - val_accuracy: 0.4622\n",
      "Epoch 150/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4832 - accuracy: 0.4650 - val_loss: 1.4856 - val_accuracy: 0.4628\n",
      "Epoch 151/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4824 - accuracy: 0.4641 - val_loss: 1.4871 - val_accuracy: 0.4617\n",
      "Epoch 152/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4816 - accuracy: 0.4649 - val_loss: 1.4844 - val_accuracy: 0.4552\n",
      "Epoch 153/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4811 - accuracy: 0.4643 - val_loss: 1.4825 - val_accuracy: 0.4578\n",
      "Epoch 154/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4801 - accuracy: 0.4653 - val_loss: 1.4814 - val_accuracy: 0.4626\n",
      "Epoch 155/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4789 - accuracy: 0.4650 - val_loss: 1.4818 - val_accuracy: 0.4542\n",
      "Epoch 156/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4781 - accuracy: 0.4663 - val_loss: 1.4810 - val_accuracy: 0.4572\n",
      "Epoch 157/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4774 - accuracy: 0.4670 - val_loss: 1.4800 - val_accuracy: 0.4570\n",
      "Epoch 158/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4762 - accuracy: 0.4676 - val_loss: 1.4799 - val_accuracy: 0.4628\n",
      "Epoch 159/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4758 - accuracy: 0.4689 - val_loss: 1.4805 - val_accuracy: 0.4595\n",
      "Epoch 160/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4753 - accuracy: 0.4681 - val_loss: 1.4766 - val_accuracy: 0.4640\n",
      "Epoch 161/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4743 - accuracy: 0.4671 - val_loss: 1.4766 - val_accuracy: 0.4718\n",
      "Epoch 162/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4728 - accuracy: 0.4692 - val_loss: 1.4767 - val_accuracy: 0.4561\n",
      "Epoch 163/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4714 - accuracy: 0.4670 - val_loss: 1.4739 - val_accuracy: 0.4651\n",
      "Epoch 164/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4701 - accuracy: 0.4689 - val_loss: 1.4721 - val_accuracy: 0.4667\n",
      "Epoch 165/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4690 - accuracy: 0.4657 - val_loss: 1.4715 - val_accuracy: 0.4648\n",
      "Epoch 166/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4680 - accuracy: 0.4697 - val_loss: 1.4705 - val_accuracy: 0.4662\n",
      "Epoch 167/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4670 - accuracy: 0.4709 - val_loss: 1.4704 - val_accuracy: 0.4751\n",
      "Epoch 168/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4663 - accuracy: 0.4701 - val_loss: 1.4689 - val_accuracy: 0.4673\n",
      "Epoch 169/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4650 - accuracy: 0.4720 - val_loss: 1.4681 - val_accuracy: 0.4704\n",
      "Epoch 170/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4639 - accuracy: 0.4709 - val_loss: 1.4705 - val_accuracy: 0.4556\n",
      "Epoch 171/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4636 - accuracy: 0.4705 - val_loss: 1.4678 - val_accuracy: 0.4591\n",
      "Epoch 172/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4628 - accuracy: 0.4689 - val_loss: 1.4672 - val_accuracy: 0.4724\n",
      "Epoch 173/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4621 - accuracy: 0.4700 - val_loss: 1.4649 - val_accuracy: 0.4682\n",
      "Epoch 174/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4607 - accuracy: 0.4709 - val_loss: 1.4651 - val_accuracy: 0.4650\n",
      "Epoch 175/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4601 - accuracy: 0.4729 - val_loss: 1.4644 - val_accuracy: 0.4630\n",
      "Epoch 176/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4593 - accuracy: 0.4696 - val_loss: 1.4632 - val_accuracy: 0.4650\n",
      "Epoch 177/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4583 - accuracy: 0.4716 - val_loss: 1.4615 - val_accuracy: 0.4701\n",
      "Epoch 178/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4574 - accuracy: 0.4719 - val_loss: 1.4618 - val_accuracy: 0.4648\n",
      "Epoch 179/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4567 - accuracy: 0.4709 - val_loss: 1.4626 - val_accuracy: 0.4749\n",
      "Epoch 180/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4558 - accuracy: 0.4720 - val_loss: 1.4602 - val_accuracy: 0.4720\n",
      "Epoch 181/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4555 - accuracy: 0.4710 - val_loss: 1.4585 - val_accuracy: 0.4704\n",
      "Epoch 182/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4545 - accuracy: 0.4715 - val_loss: 1.4592 - val_accuracy: 0.4723\n",
      "Epoch 183/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4541 - accuracy: 0.4743 - val_loss: 1.4579 - val_accuracy: 0.4756\n",
      "Epoch 184/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4533 - accuracy: 0.4742 - val_loss: 1.4574 - val_accuracy: 0.4662\n",
      "Epoch 185/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4528 - accuracy: 0.4738 - val_loss: 1.4565 - val_accuracy: 0.4686\n",
      "Epoch 186/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4513 - accuracy: 0.4759 - val_loss: 1.4563 - val_accuracy: 0.4647\n",
      "Epoch 187/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4506 - accuracy: 0.4734 - val_loss: 1.4544 - val_accuracy: 0.4773\n",
      "Epoch 188/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4498 - accuracy: 0.4744 - val_loss: 1.4529 - val_accuracy: 0.4770\n",
      "Epoch 189/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4489 - accuracy: 0.4756 - val_loss: 1.4533 - val_accuracy: 0.4664\n",
      "Epoch 190/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4486 - accuracy: 0.4756 - val_loss: 1.4519 - val_accuracy: 0.4720\n",
      "Epoch 191/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4475 - accuracy: 0.4749 - val_loss: 1.4506 - val_accuracy: 0.4770\n",
      "Epoch 192/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4468 - accuracy: 0.4776 - val_loss: 1.4507 - val_accuracy: 0.4700\n",
      "Epoch 193/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4463 - accuracy: 0.4767 - val_loss: 1.4490 - val_accuracy: 0.4773\n",
      "Epoch 194/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4447 - accuracy: 0.4794 - val_loss: 1.4483 - val_accuracy: 0.4731\n",
      "Epoch 195/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4444 - accuracy: 0.4758 - val_loss: 1.4499 - val_accuracy: 0.4686\n",
      "Epoch 196/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4436 - accuracy: 0.4790 - val_loss: 1.4507 - val_accuracy: 0.4682\n",
      "Epoch 197/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4425 - accuracy: 0.4780 - val_loss: 1.4457 - val_accuracy: 0.4734\n",
      "Epoch 198/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4424 - accuracy: 0.4805 - val_loss: 1.4460 - val_accuracy: 0.4742\n",
      "Epoch 199/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4410 - accuracy: 0.4795 - val_loss: 1.4449 - val_accuracy: 0.4815\n",
      "Epoch 200/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4401 - accuracy: 0.4806 - val_loss: 1.4439 - val_accuracy: 0.4790\n",
      "Epoch 201/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4391 - accuracy: 0.4804 - val_loss: 1.4448 - val_accuracy: 0.4726\n",
      "Epoch 202/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4386 - accuracy: 0.4791 - val_loss: 1.4428 - val_accuracy: 0.4781\n",
      "Epoch 203/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4381 - accuracy: 0.4795 - val_loss: 1.4431 - val_accuracy: 0.4714\n",
      "Epoch 204/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4373 - accuracy: 0.4798 - val_loss: 1.4418 - val_accuracy: 0.4731\n",
      "Epoch 205/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4365 - accuracy: 0.4808 - val_loss: 1.4413 - val_accuracy: 0.4759\n",
      "Epoch 206/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4359 - accuracy: 0.4847 - val_loss: 1.4416 - val_accuracy: 0.4798\n",
      "Epoch 207/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4349 - accuracy: 0.4809 - val_loss: 1.4392 - val_accuracy: 0.4770\n",
      "Epoch 208/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4343 - accuracy: 0.4835 - val_loss: 1.4383 - val_accuracy: 0.4799\n",
      "Epoch 209/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4338 - accuracy: 0.4782 - val_loss: 1.4386 - val_accuracy: 0.4832\n",
      "Epoch 210/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4331 - accuracy: 0.4827 - val_loss: 1.4437 - val_accuracy: 0.4654\n",
      "Epoch 211/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4322 - accuracy: 0.4827 - val_loss: 1.4380 - val_accuracy: 0.4754\n",
      "Epoch 212/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4317 - accuracy: 0.4831 - val_loss: 1.4362 - val_accuracy: 0.4798\n",
      "Epoch 213/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4315 - accuracy: 0.4824 - val_loss: 1.4354 - val_accuracy: 0.4796\n",
      "Epoch 214/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4305 - accuracy: 0.4817 - val_loss: 1.4348 - val_accuracy: 0.4827\n",
      "Epoch 215/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4296 - accuracy: 0.4824 - val_loss: 1.4351 - val_accuracy: 0.4760\n",
      "Epoch 216/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4294 - accuracy: 0.4836 - val_loss: 1.4342 - val_accuracy: 0.4802\n",
      "Epoch 217/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4288 - accuracy: 0.4844 - val_loss: 1.4342 - val_accuracy: 0.4776\n",
      "Epoch 218/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4278 - accuracy: 0.4828 - val_loss: 1.4338 - val_accuracy: 0.4832\n",
      "Epoch 219/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4277 - accuracy: 0.4834 - val_loss: 1.4322 - val_accuracy: 0.4793\n",
      "Epoch 220/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4263 - accuracy: 0.4836 - val_loss: 1.4317 - val_accuracy: 0.4802\n",
      "Epoch 221/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4268 - accuracy: 0.4820 - val_loss: 1.4324 - val_accuracy: 0.4785\n",
      "Epoch 222/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4256 - accuracy: 0.4841 - val_loss: 1.4321 - val_accuracy: 0.4776\n",
      "Epoch 223/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4251 - accuracy: 0.4842 - val_loss: 1.4304 - val_accuracy: 0.4798\n",
      "Epoch 224/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4247 - accuracy: 0.4841 - val_loss: 1.4311 - val_accuracy: 0.4788\n",
      "Epoch 225/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4244 - accuracy: 0.4846 - val_loss: 1.4300 - val_accuracy: 0.4823\n",
      "Epoch 226/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4237 - accuracy: 0.4844 - val_loss: 1.4290 - val_accuracy: 0.4799\n",
      "Epoch 227/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4230 - accuracy: 0.4838 - val_loss: 1.4284 - val_accuracy: 0.4826\n",
      "Epoch 228/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4227 - accuracy: 0.4832 - val_loss: 1.4278 - val_accuracy: 0.4807\n",
      "Epoch 229/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4221 - accuracy: 0.4855 - val_loss: 1.4294 - val_accuracy: 0.4777\n",
      "Epoch 230/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4217 - accuracy: 0.4841 - val_loss: 1.4264 - val_accuracy: 0.4857\n",
      "Epoch 231/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4214 - accuracy: 0.4847 - val_loss: 1.4263 - val_accuracy: 0.4847\n",
      "Epoch 232/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4213 - accuracy: 0.4847 - val_loss: 1.4261 - val_accuracy: 0.4852\n",
      "Epoch 233/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4201 - accuracy: 0.4843 - val_loss: 1.4252 - val_accuracy: 0.4829\n",
      "Epoch 234/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4199 - accuracy: 0.4865 - val_loss: 1.4249 - val_accuracy: 0.4829\n",
      "Epoch 235/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4194 - accuracy: 0.4850 - val_loss: 1.4242 - val_accuracy: 0.4846\n",
      "Epoch 236/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4185 - accuracy: 0.4870 - val_loss: 1.4240 - val_accuracy: 0.4819\n",
      "Epoch 237/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4185 - accuracy: 0.4862 - val_loss: 1.4242 - val_accuracy: 0.4827\n",
      "Epoch 238/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4176 - accuracy: 0.4847 - val_loss: 1.4250 - val_accuracy: 0.4844\n",
      "Epoch 239/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4173 - accuracy: 0.4862 - val_loss: 1.4231 - val_accuracy: 0.4826\n",
      "Epoch 240/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4170 - accuracy: 0.4852 - val_loss: 1.4238 - val_accuracy: 0.4795\n",
      "Epoch 241/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4166 - accuracy: 0.4857 - val_loss: 1.4248 - val_accuracy: 0.4779\n",
      "Epoch 242/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4162 - accuracy: 0.4868 - val_loss: 1.4236 - val_accuracy: 0.4829\n",
      "Epoch 243/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4154 - accuracy: 0.4852 - val_loss: 1.4259 - val_accuracy: 0.4815\n",
      "Epoch 244/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4153 - accuracy: 0.4870 - val_loss: 1.4247 - val_accuracy: 0.4879\n",
      "Epoch 245/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4153 - accuracy: 0.4854 - val_loss: 1.4205 - val_accuracy: 0.4858\n",
      "Epoch 246/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4144 - accuracy: 0.4857 - val_loss: 1.4198 - val_accuracy: 0.4855\n",
      "Epoch 247/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4142 - accuracy: 0.4865 - val_loss: 1.4212 - val_accuracy: 0.4810\n",
      "Epoch 248/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4135 - accuracy: 0.4857 - val_loss: 1.4196 - val_accuracy: 0.4826\n",
      "Epoch 249/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4124 - accuracy: 0.4875 - val_loss: 1.4224 - val_accuracy: 0.4788\n",
      "Epoch 250/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4129 - accuracy: 0.4879 - val_loss: 1.4192 - val_accuracy: 0.4833\n",
      "Epoch 251/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4125 - accuracy: 0.4878 - val_loss: 1.4205 - val_accuracy: 0.4879\n",
      "Epoch 252/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4119 - accuracy: 0.4870 - val_loss: 1.4192 - val_accuracy: 0.4826\n",
      "Epoch 253/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4121 - accuracy: 0.4856 - val_loss: 1.4189 - val_accuracy: 0.4888\n",
      "Epoch 254/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4112 - accuracy: 0.4873 - val_loss: 1.4172 - val_accuracy: 0.4868\n",
      "Epoch 255/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4107 - accuracy: 0.4854 - val_loss: 1.4162 - val_accuracy: 0.4849\n",
      "Epoch 256/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4108 - accuracy: 0.4876 - val_loss: 1.4165 - val_accuracy: 0.4827\n",
      "Epoch 257/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4099 - accuracy: 0.4880 - val_loss: 1.4158 - val_accuracy: 0.4832\n",
      "Epoch 258/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4103 - accuracy: 0.4864 - val_loss: 1.4157 - val_accuracy: 0.4857\n",
      "Epoch 259/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4094 - accuracy: 0.4890 - val_loss: 1.4157 - val_accuracy: 0.4861\n",
      "Epoch 260/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4093 - accuracy: 0.4873 - val_loss: 1.4143 - val_accuracy: 0.4855\n",
      "Epoch 261/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4084 - accuracy: 0.4882 - val_loss: 1.4145 - val_accuracy: 0.4900\n",
      "Epoch 262/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4083 - accuracy: 0.4875 - val_loss: 1.4148 - val_accuracy: 0.4893\n",
      "Epoch 263/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4080 - accuracy: 0.4896 - val_loss: 1.4135 - val_accuracy: 0.4844\n",
      "Epoch 264/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4078 - accuracy: 0.4872 - val_loss: 1.4132 - val_accuracy: 0.4869\n",
      "Epoch 265/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4071 - accuracy: 0.4892 - val_loss: 1.4129 - val_accuracy: 0.4863\n",
      "Epoch 266/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4064 - accuracy: 0.4900 - val_loss: 1.4136 - val_accuracy: 0.4907\n",
      "Epoch 267/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4066 - accuracy: 0.4883 - val_loss: 1.4145 - val_accuracy: 0.4896\n",
      "Epoch 268/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4056 - accuracy: 0.4904 - val_loss: 1.4120 - val_accuracy: 0.4855\n",
      "Epoch 269/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4061 - accuracy: 0.4887 - val_loss: 1.4114 - val_accuracy: 0.4861\n",
      "Epoch 270/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4056 - accuracy: 0.4891 - val_loss: 1.4120 - val_accuracy: 0.4849\n",
      "Epoch 271/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4053 - accuracy: 0.4906 - val_loss: 1.4114 - val_accuracy: 0.4874\n",
      "Epoch 272/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4045 - accuracy: 0.4910 - val_loss: 1.4115 - val_accuracy: 0.4874\n",
      "Epoch 273/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4041 - accuracy: 0.4906 - val_loss: 1.4120 - val_accuracy: 0.4855\n",
      "Epoch 274/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4037 - accuracy: 0.4894 - val_loss: 1.4123 - val_accuracy: 0.4847\n",
      "Epoch 275/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4032 - accuracy: 0.4900 - val_loss: 1.4125 - val_accuracy: 0.4872\n",
      "Epoch 276/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4033 - accuracy: 0.4897 - val_loss: 1.4098 - val_accuracy: 0.4844\n",
      "Epoch 277/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4025 - accuracy: 0.4903 - val_loss: 1.4086 - val_accuracy: 0.4888\n",
      "Epoch 278/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4025 - accuracy: 0.4911 - val_loss: 1.4093 - val_accuracy: 0.4900\n",
      "Epoch 279/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4022 - accuracy: 0.4906 - val_loss: 1.4086 - val_accuracy: 0.4861\n",
      "Epoch 280/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4013 - accuracy: 0.4912 - val_loss: 1.4100 - val_accuracy: 0.4844\n",
      "Epoch 281/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4012 - accuracy: 0.4919 - val_loss: 1.4075 - val_accuracy: 0.4875\n",
      "Epoch 282/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4009 - accuracy: 0.4909 - val_loss: 1.4105 - val_accuracy: 0.4921\n",
      "Epoch 283/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4008 - accuracy: 0.4919 - val_loss: 1.4070 - val_accuracy: 0.4897\n",
      "Epoch 284/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4005 - accuracy: 0.4906 - val_loss: 1.4067 - val_accuracy: 0.4886\n",
      "Epoch 285/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3996 - accuracy: 0.4926 - val_loss: 1.4067 - val_accuracy: 0.4882\n",
      "Epoch 286/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3998 - accuracy: 0.4922 - val_loss: 1.4076 - val_accuracy: 0.4905\n",
      "Epoch 287/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3992 - accuracy: 0.4924 - val_loss: 1.4062 - val_accuracy: 0.4905\n",
      "Epoch 288/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3994 - accuracy: 0.4913 - val_loss: 1.4060 - val_accuracy: 0.4891\n",
      "Epoch 289/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3987 - accuracy: 0.4934 - val_loss: 1.4057 - val_accuracy: 0.4891\n",
      "Epoch 290/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3980 - accuracy: 0.4935 - val_loss: 1.4074 - val_accuracy: 0.4855\n",
      "Epoch 291/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3981 - accuracy: 0.4927 - val_loss: 1.4062 - val_accuracy: 0.4860\n",
      "Epoch 292/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3981 - accuracy: 0.4918 - val_loss: 1.4053 - val_accuracy: 0.4877\n",
      "Epoch 293/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3971 - accuracy: 0.4936 - val_loss: 1.4036 - val_accuracy: 0.4910\n",
      "Epoch 294/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3967 - accuracy: 0.4927 - val_loss: 1.4035 - val_accuracy: 0.4889\n",
      "Epoch 295/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3963 - accuracy: 0.4931 - val_loss: 1.4058 - val_accuracy: 0.4866\n",
      "Epoch 296/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3965 - accuracy: 0.4933 - val_loss: 1.4029 - val_accuracy: 0.4917\n",
      "Epoch 297/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3963 - accuracy: 0.4931 - val_loss: 1.4023 - val_accuracy: 0.4944\n",
      "Epoch 298/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3953 - accuracy: 0.4955 - val_loss: 1.4036 - val_accuracy: 0.4877\n",
      "Epoch 299/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3955 - accuracy: 0.4930 - val_loss: 1.4043 - val_accuracy: 0.4866\n",
      "Epoch 300/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3951 - accuracy: 0.4943 - val_loss: 1.4052 - val_accuracy: 0.4927\n",
      "Epoch 301/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3949 - accuracy: 0.4933 - val_loss: 1.4009 - val_accuracy: 0.4917\n",
      "Epoch 302/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3943 - accuracy: 0.4942 - val_loss: 1.4014 - val_accuracy: 0.4902\n",
      "Epoch 303/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3944 - accuracy: 0.4940 - val_loss: 1.4010 - val_accuracy: 0.4899\n",
      "Epoch 304/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3936 - accuracy: 0.4940 - val_loss: 1.4054 - val_accuracy: 0.4861\n",
      "Epoch 305/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3933 - accuracy: 0.4952 - val_loss: 1.4010 - val_accuracy: 0.4882\n",
      "Epoch 306/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3924 - accuracy: 0.4942 - val_loss: 1.4009 - val_accuracy: 0.4882\n",
      "Epoch 307/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3936 - accuracy: 0.4943 - val_loss: 1.4005 - val_accuracy: 0.4914\n",
      "Epoch 308/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3927 - accuracy: 0.4940 - val_loss: 1.3986 - val_accuracy: 0.4947\n",
      "Epoch 309/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3920 - accuracy: 0.4951 - val_loss: 1.4036 - val_accuracy: 0.4961\n",
      "Epoch 310/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3922 - accuracy: 0.4953 - val_loss: 1.3988 - val_accuracy: 0.4905\n",
      "Epoch 311/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3919 - accuracy: 0.4945 - val_loss: 1.3998 - val_accuracy: 0.4952\n",
      "Epoch 312/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3913 - accuracy: 0.4948 - val_loss: 1.3974 - val_accuracy: 0.4935\n",
      "Epoch 313/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3905 - accuracy: 0.4952 - val_loss: 1.3985 - val_accuracy: 0.4894\n",
      "Epoch 314/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3908 - accuracy: 0.4966 - val_loss: 1.3974 - val_accuracy: 0.4917\n",
      "Epoch 315/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3902 - accuracy: 0.4965 - val_loss: 1.4013 - val_accuracy: 0.4894\n",
      "Epoch 316/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3899 - accuracy: 0.4958 - val_loss: 1.3970 - val_accuracy: 0.4933\n",
      "Epoch 317/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3897 - accuracy: 0.4981 - val_loss: 1.3978 - val_accuracy: 0.4930\n",
      "Epoch 318/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3894 - accuracy: 0.4960 - val_loss: 1.3970 - val_accuracy: 0.4964\n",
      "Epoch 319/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3894 - accuracy: 0.4964 - val_loss: 1.3966 - val_accuracy: 0.4911\n",
      "Epoch 320/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3890 - accuracy: 0.4975 - val_loss: 1.3974 - val_accuracy: 0.4949\n",
      "Epoch 321/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3888 - accuracy: 0.4964 - val_loss: 1.3947 - val_accuracy: 0.4952\n",
      "Epoch 322/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3887 - accuracy: 0.4959 - val_loss: 1.3945 - val_accuracy: 0.4919\n",
      "Epoch 323/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3876 - accuracy: 0.4962 - val_loss: 1.3955 - val_accuracy: 0.4950\n",
      "Epoch 324/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3874 - accuracy: 0.4975 - val_loss: 1.3995 - val_accuracy: 0.4941\n",
      "Epoch 325/750\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.3877 - accuracy: 0.4963 - val_loss: 1.3942 - val_accuracy: 0.4936\n",
      "Epoch 326/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3872 - accuracy: 0.4965 - val_loss: 1.3954 - val_accuracy: 0.4935\n",
      "Epoch 327/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3868 - accuracy: 0.4978 - val_loss: 1.3932 - val_accuracy: 0.4960\n",
      "Epoch 328/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3870 - accuracy: 0.4957 - val_loss: 1.3938 - val_accuracy: 0.4927\n",
      "Epoch 329/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3861 - accuracy: 0.4985 - val_loss: 1.3927 - val_accuracy: 0.4924\n",
      "Epoch 330/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3864 - accuracy: 0.4975 - val_loss: 1.3924 - val_accuracy: 0.4935\n",
      "Epoch 331/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3859 - accuracy: 0.4972 - val_loss: 1.3925 - val_accuracy: 0.4922\n",
      "Epoch 332/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3854 - accuracy: 0.4979 - val_loss: 1.3924 - val_accuracy: 0.4944\n",
      "Epoch 333/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3855 - accuracy: 0.4982 - val_loss: 1.3938 - val_accuracy: 0.5006\n",
      "Epoch 334/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3852 - accuracy: 0.4986 - val_loss: 1.3923 - val_accuracy: 0.4953\n",
      "Epoch 335/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3851 - accuracy: 0.4967 - val_loss: 1.3923 - val_accuracy: 0.4984\n",
      "Epoch 336/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3850 - accuracy: 0.4962 - val_loss: 1.3917 - val_accuracy: 0.4944\n",
      "Epoch 337/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3847 - accuracy: 0.4974 - val_loss: 1.3904 - val_accuracy: 0.4974\n",
      "Epoch 338/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3841 - accuracy: 0.4985 - val_loss: 1.3904 - val_accuracy: 0.4952\n",
      "Epoch 339/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3836 - accuracy: 0.4975 - val_loss: 1.3922 - val_accuracy: 0.4933\n",
      "Epoch 340/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3836 - accuracy: 0.4988 - val_loss: 1.3895 - val_accuracy: 0.4961\n",
      "Epoch 341/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3830 - accuracy: 0.4975 - val_loss: 1.3904 - val_accuracy: 0.4925\n",
      "Epoch 342/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3830 - accuracy: 0.4984 - val_loss: 1.3907 - val_accuracy: 0.4932\n",
      "Epoch 343/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3828 - accuracy: 0.4983 - val_loss: 1.3891 - val_accuracy: 0.4975\n",
      "Epoch 344/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3821 - accuracy: 0.4993 - val_loss: 1.3894 - val_accuracy: 0.4961\n",
      "Epoch 345/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3820 - accuracy: 0.4969 - val_loss: 1.3889 - val_accuracy: 0.5003\n",
      "Epoch 346/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3814 - accuracy: 0.4996 - val_loss: 1.3911 - val_accuracy: 0.4910\n",
      "Epoch 347/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3820 - accuracy: 0.4980 - val_loss: 1.3886 - val_accuracy: 0.4963\n",
      "Epoch 348/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3816 - accuracy: 0.4991 - val_loss: 1.3877 - val_accuracy: 0.4992\n",
      "Epoch 349/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3814 - accuracy: 0.4981 - val_loss: 1.3872 - val_accuracy: 0.4966\n",
      "Epoch 350/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3806 - accuracy: 0.5008 - val_loss: 1.3913 - val_accuracy: 0.4924\n",
      "Epoch 351/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3809 - accuracy: 0.4983 - val_loss: 1.3912 - val_accuracy: 0.4936\n",
      "Epoch 352/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3807 - accuracy: 0.4988 - val_loss: 1.3916 - val_accuracy: 0.4953\n",
      "Epoch 353/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3803 - accuracy: 0.4979 - val_loss: 1.3873 - val_accuracy: 0.4970\n",
      "Epoch 354/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3807 - accuracy: 0.4990 - val_loss: 1.3854 - val_accuracy: 0.4988\n",
      "Epoch 355/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3796 - accuracy: 0.5002 - val_loss: 1.3868 - val_accuracy: 0.4988\n",
      "Epoch 356/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3795 - accuracy: 0.5004 - val_loss: 1.3853 - val_accuracy: 0.4967\n",
      "Epoch 357/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3794 - accuracy: 0.4984 - val_loss: 1.3873 - val_accuracy: 0.4938\n",
      "Epoch 358/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3785 - accuracy: 0.4988 - val_loss: 1.3884 - val_accuracy: 0.5054\n",
      "Epoch 359/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3790 - accuracy: 0.5001 - val_loss: 1.3852 - val_accuracy: 0.4977\n",
      "Epoch 360/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3782 - accuracy: 0.4986 - val_loss: 1.3885 - val_accuracy: 0.5003\n",
      "Epoch 361/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3780 - accuracy: 0.5005 - val_loss: 1.3862 - val_accuracy: 0.4964\n",
      "Epoch 362/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3778 - accuracy: 0.4990 - val_loss: 1.3874 - val_accuracy: 0.5053\n",
      "Epoch 363/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3777 - accuracy: 0.5014 - val_loss: 1.3837 - val_accuracy: 0.4991\n",
      "Epoch 364/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3775 - accuracy: 0.4998 - val_loss: 1.3840 - val_accuracy: 0.4989\n",
      "Epoch 365/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3772 - accuracy: 0.4997 - val_loss: 1.3831 - val_accuracy: 0.5006\n",
      "Epoch 366/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3772 - accuracy: 0.5005 - val_loss: 1.3831 - val_accuracy: 0.4960\n",
      "Epoch 367/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3767 - accuracy: 0.5013 - val_loss: 1.3852 - val_accuracy: 0.4946\n",
      "Epoch 368/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3768 - accuracy: 0.5000 - val_loss: 1.3834 - val_accuracy: 0.4974\n",
      "Epoch 369/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3766 - accuracy: 0.5014 - val_loss: 1.3831 - val_accuracy: 0.4944\n",
      "Epoch 370/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3766 - accuracy: 0.5002 - val_loss: 1.3829 - val_accuracy: 0.4969\n",
      "Epoch 371/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3762 - accuracy: 0.4990 - val_loss: 1.3839 - val_accuracy: 0.4964\n",
      "Epoch 372/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3757 - accuracy: 0.5028 - val_loss: 1.3826 - val_accuracy: 0.4998\n",
      "Epoch 373/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3763 - accuracy: 0.5016 - val_loss: 1.3812 - val_accuracy: 0.4986\n",
      "Epoch 374/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3750 - accuracy: 0.5032 - val_loss: 1.3848 - val_accuracy: 0.5005\n",
      "Epoch 375/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3756 - accuracy: 0.5009 - val_loss: 1.3807 - val_accuracy: 0.4974\n",
      "Epoch 376/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3746 - accuracy: 0.5028 - val_loss: 1.3824 - val_accuracy: 0.5028\n",
      "Epoch 377/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3739 - accuracy: 0.5031 - val_loss: 1.3807 - val_accuracy: 0.4988\n",
      "Epoch 378/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3744 - accuracy: 0.5018 - val_loss: 1.3844 - val_accuracy: 0.5011\n",
      "Epoch 379/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3742 - accuracy: 0.5021 - val_loss: 1.3799 - val_accuracy: 0.5037\n",
      "Epoch 380/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3739 - accuracy: 0.5007 - val_loss: 1.3810 - val_accuracy: 0.4977\n",
      "Epoch 381/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3737 - accuracy: 0.5015 - val_loss: 1.3790 - val_accuracy: 0.5006\n",
      "Epoch 382/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3728 - accuracy: 0.5018 - val_loss: 1.3809 - val_accuracy: 0.4975\n",
      "Epoch 383/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3737 - accuracy: 0.5018 - val_loss: 1.3787 - val_accuracy: 0.5025\n",
      "Epoch 384/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3732 - accuracy: 0.5035 - val_loss: 1.3798 - val_accuracy: 0.4977\n",
      "Epoch 385/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3723 - accuracy: 0.5023 - val_loss: 1.3792 - val_accuracy: 0.4963\n",
      "Epoch 386/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3716 - accuracy: 0.5013 - val_loss: 1.3852 - val_accuracy: 0.5014\n",
      "Epoch 387/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3728 - accuracy: 0.5017 - val_loss: 1.3780 - val_accuracy: 0.5039\n",
      "Epoch 388/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3718 - accuracy: 0.5038 - val_loss: 1.3769 - val_accuracy: 0.4998\n",
      "Epoch 389/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3721 - accuracy: 0.5025 - val_loss: 1.3795 - val_accuracy: 0.4969\n",
      "Epoch 390/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3716 - accuracy: 0.5011 - val_loss: 1.3769 - val_accuracy: 0.5036\n",
      "Epoch 391/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3713 - accuracy: 0.5028 - val_loss: 1.3780 - val_accuracy: 0.4986\n",
      "Epoch 392/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3712 - accuracy: 0.5023 - val_loss: 1.3766 - val_accuracy: 0.5037\n",
      "Epoch 393/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3709 - accuracy: 0.5037 - val_loss: 1.3766 - val_accuracy: 0.5022\n",
      "Epoch 394/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3704 - accuracy: 0.5020 - val_loss: 1.3768 - val_accuracy: 0.5065\n",
      "Epoch 395/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3706 - accuracy: 0.5026 - val_loss: 1.3774 - val_accuracy: 0.5037\n",
      "Epoch 396/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3701 - accuracy: 0.5019 - val_loss: 1.3754 - val_accuracy: 0.5006\n",
      "Epoch 397/750\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3703 - accuracy: 0.5039 - val_loss: 1.3752 - val_accuracy: 0.5003\n",
      "Epoch 398/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3697 - accuracy: 0.5043 - val_loss: 1.3754 - val_accuracy: 0.5008\n",
      "Epoch 399/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3694 - accuracy: 0.5037 - val_loss: 1.3769 - val_accuracy: 0.4988\n",
      "Epoch 400/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3698 - accuracy: 0.5032 - val_loss: 1.3745 - val_accuracy: 0.5003\n",
      "Epoch 401/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3691 - accuracy: 0.5012 - val_loss: 1.3770 - val_accuracy: 0.4997\n",
      "Epoch 402/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3690 - accuracy: 0.5012 - val_loss: 1.3768 - val_accuracy: 0.4991\n",
      "Epoch 403/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3693 - accuracy: 0.5039 - val_loss: 1.3756 - val_accuracy: 0.5022\n",
      "Epoch 404/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3683 - accuracy: 0.5018 - val_loss: 1.3769 - val_accuracy: 0.5017\n",
      "Epoch 405/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3687 - accuracy: 0.5025 - val_loss: 1.3736 - val_accuracy: 0.5030\n",
      "Epoch 406/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3676 - accuracy: 0.5031 - val_loss: 1.3755 - val_accuracy: 0.4992\n",
      "Epoch 407/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3678 - accuracy: 0.5038 - val_loss: 1.3765 - val_accuracy: 0.5072\n",
      "Epoch 408/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3683 - accuracy: 0.5022 - val_loss: 1.3729 - val_accuracy: 0.5022\n",
      "Epoch 409/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3677 - accuracy: 0.5015 - val_loss: 1.3740 - val_accuracy: 0.5040\n",
      "Epoch 410/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3672 - accuracy: 0.5043 - val_loss: 1.3763 - val_accuracy: 0.4998\n",
      "Epoch 411/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3665 - accuracy: 0.5044 - val_loss: 1.3773 - val_accuracy: 0.4974\n",
      "Epoch 412/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3669 - accuracy: 0.5040 - val_loss: 1.3741 - val_accuracy: 0.5017\n",
      "Epoch 413/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3664 - accuracy: 0.5033 - val_loss: 1.3720 - val_accuracy: 0.5039\n",
      "Epoch 414/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3664 - accuracy: 0.5037 - val_loss: 1.3742 - val_accuracy: 0.4969\n",
      "Epoch 415/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3667 - accuracy: 0.5030 - val_loss: 1.3728 - val_accuracy: 0.5011\n",
      "Epoch 416/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3659 - accuracy: 0.5019 - val_loss: 1.3742 - val_accuracy: 0.5089\n",
      "Epoch 417/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3663 - accuracy: 0.5049 - val_loss: 1.3722 - val_accuracy: 0.5031\n",
      "Epoch 418/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3653 - accuracy: 0.5031 - val_loss: 1.3702 - val_accuracy: 0.5058\n",
      "Epoch 419/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3650 - accuracy: 0.5040 - val_loss: 1.3704 - val_accuracy: 0.5028\n",
      "Epoch 420/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3652 - accuracy: 0.5043 - val_loss: 1.3726 - val_accuracy: 0.5064\n",
      "Epoch 421/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3645 - accuracy: 0.5043 - val_loss: 1.3711 - val_accuracy: 0.5037\n",
      "Epoch 422/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3645 - accuracy: 0.5034 - val_loss: 1.3702 - val_accuracy: 0.5047\n",
      "Epoch 423/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3648 - accuracy: 0.5071 - val_loss: 1.3693 - val_accuracy: 0.5051\n",
      "Epoch 424/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3646 - accuracy: 0.5038 - val_loss: 1.3701 - val_accuracy: 0.5047\n",
      "Epoch 425/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3641 - accuracy: 0.5038 - val_loss: 1.3698 - val_accuracy: 0.5017\n",
      "Epoch 426/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3643 - accuracy: 0.5038 - val_loss: 1.3691 - val_accuracy: 0.5005\n",
      "Epoch 427/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3637 - accuracy: 0.5043 - val_loss: 1.3697 - val_accuracy: 0.5059\n",
      "Epoch 428/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3637 - accuracy: 0.5034 - val_loss: 1.3686 - val_accuracy: 0.5095\n",
      "Epoch 429/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3629 - accuracy: 0.5024 - val_loss: 1.3696 - val_accuracy: 0.5097\n",
      "Epoch 430/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3627 - accuracy: 0.5059 - val_loss: 1.3687 - val_accuracy: 0.5081\n",
      "Epoch 431/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3628 - accuracy: 0.5069 - val_loss: 1.3678 - val_accuracy: 0.5040\n",
      "Epoch 432/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3626 - accuracy: 0.5041 - val_loss: 1.3680 - val_accuracy: 0.5003\n",
      "Epoch 433/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3623 - accuracy: 0.5043 - val_loss: 1.3704 - val_accuracy: 0.5031\n",
      "Epoch 434/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3623 - accuracy: 0.5030 - val_loss: 1.3675 - val_accuracy: 0.5026\n",
      "Epoch 435/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3621 - accuracy: 0.5027 - val_loss: 1.3684 - val_accuracy: 0.5084\n",
      "Epoch 436/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3620 - accuracy: 0.5037 - val_loss: 1.3689 - val_accuracy: 0.5054\n",
      "Epoch 437/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3622 - accuracy: 0.5032 - val_loss: 1.3668 - val_accuracy: 0.5031\n",
      "Epoch 438/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3618 - accuracy: 0.5044 - val_loss: 1.3686 - val_accuracy: 0.5006\n",
      "Epoch 439/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3607 - accuracy: 0.5054 - val_loss: 1.3679 - val_accuracy: 0.5044\n",
      "Epoch 440/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3608 - accuracy: 0.5041 - val_loss: 1.3662 - val_accuracy: 0.5030\n",
      "Epoch 441/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3604 - accuracy: 0.5041 - val_loss: 1.3676 - val_accuracy: 0.4974\n",
      "Epoch 442/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3607 - accuracy: 0.5048 - val_loss: 1.3659 - val_accuracy: 0.5045\n",
      "Epoch 443/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3603 - accuracy: 0.5061 - val_loss: 1.3669 - val_accuracy: 0.5072\n",
      "Epoch 444/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3601 - accuracy: 0.5051 - val_loss: 1.3652 - val_accuracy: 0.5059\n",
      "Epoch 445/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3600 - accuracy: 0.5060 - val_loss: 1.3672 - val_accuracy: 0.5075\n",
      "Epoch 446/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3601 - accuracy: 0.5039 - val_loss: 1.3680 - val_accuracy: 0.5081\n",
      "Epoch 447/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3598 - accuracy: 0.5058 - val_loss: 1.3669 - val_accuracy: 0.4997\n",
      "Epoch 448/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3599 - accuracy: 0.5049 - val_loss: 1.3665 - val_accuracy: 0.5062\n",
      "Epoch 449/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3597 - accuracy: 0.5047 - val_loss: 1.3662 - val_accuracy: 0.4995\n",
      "Epoch 450/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3591 - accuracy: 0.5064 - val_loss: 1.3646 - val_accuracy: 0.5051\n",
      "Epoch 451/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3584 - accuracy: 0.5078 - val_loss: 1.3640 - val_accuracy: 0.5067\n",
      "Epoch 452/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3594 - accuracy: 0.5034 - val_loss: 1.3653 - val_accuracy: 0.5073\n",
      "Epoch 453/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3578 - accuracy: 0.5058 - val_loss: 1.3626 - val_accuracy: 0.5095\n",
      "Epoch 454/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3584 - accuracy: 0.5057 - val_loss: 1.3651 - val_accuracy: 0.5072\n",
      "Epoch 455/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3580 - accuracy: 0.5063 - val_loss: 1.3654 - val_accuracy: 0.5070\n",
      "Epoch 456/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3578 - accuracy: 0.5040 - val_loss: 1.3625 - val_accuracy: 0.5061\n",
      "Epoch 457/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3578 - accuracy: 0.5063 - val_loss: 1.3663 - val_accuracy: 0.5033\n",
      "Epoch 458/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3569 - accuracy: 0.5057 - val_loss: 1.3626 - val_accuracy: 0.5081\n",
      "Epoch 459/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3574 - accuracy: 0.5044 - val_loss: 1.3631 - val_accuracy: 0.5047\n",
      "Epoch 460/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3576 - accuracy: 0.5043 - val_loss: 1.3638 - val_accuracy: 0.5048\n",
      "Epoch 461/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3568 - accuracy: 0.5075 - val_loss: 1.3634 - val_accuracy: 0.5045\n",
      "Epoch 462/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3565 - accuracy: 0.5066 - val_loss: 1.3630 - val_accuracy: 0.5056\n",
      "Epoch 463/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3573 - accuracy: 0.5088 - val_loss: 1.3618 - val_accuracy: 0.5036\n",
      "Epoch 464/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3561 - accuracy: 0.5058 - val_loss: 1.3614 - val_accuracy: 0.5107\n",
      "Epoch 465/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3561 - accuracy: 0.5046 - val_loss: 1.3636 - val_accuracy: 0.5048\n",
      "Epoch 466/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3558 - accuracy: 0.5081 - val_loss: 1.3616 - val_accuracy: 0.5008\n",
      "Epoch 467/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3550 - accuracy: 0.5064 - val_loss: 1.3647 - val_accuracy: 0.5125\n",
      "Epoch 468/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3558 - accuracy: 0.5045 - val_loss: 1.3602 - val_accuracy: 0.5054\n",
      "Epoch 469/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3552 - accuracy: 0.5061 - val_loss: 1.3599 - val_accuracy: 0.5090\n",
      "Epoch 470/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3556 - accuracy: 0.5060 - val_loss: 1.3608 - val_accuracy: 0.5059\n",
      "Epoch 471/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3553 - accuracy: 0.5074 - val_loss: 1.3599 - val_accuracy: 0.5075\n",
      "Epoch 472/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3553 - accuracy: 0.5067 - val_loss: 1.3598 - val_accuracy: 0.5053\n",
      "Epoch 473/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3549 - accuracy: 0.5060 - val_loss: 1.3595 - val_accuracy: 0.5114\n",
      "Epoch 474/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3545 - accuracy: 0.5084 - val_loss: 1.3608 - val_accuracy: 0.5132\n",
      "Epoch 475/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3539 - accuracy: 0.5067 - val_loss: 1.3587 - val_accuracy: 0.5140\n",
      "Epoch 476/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3534 - accuracy: 0.5060 - val_loss: 1.3639 - val_accuracy: 0.5076\n",
      "Epoch 477/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3539 - accuracy: 0.5049 - val_loss: 1.3628 - val_accuracy: 0.5068\n",
      "Epoch 478/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3535 - accuracy: 0.5056 - val_loss: 1.3615 - val_accuracy: 0.5006\n",
      "Epoch 479/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3532 - accuracy: 0.5067 - val_loss: 1.3579 - val_accuracy: 0.5126\n",
      "Epoch 480/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3532 - accuracy: 0.5065 - val_loss: 1.3615 - val_accuracy: 0.5008\n",
      "Epoch 481/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3531 - accuracy: 0.5067 - val_loss: 1.3601 - val_accuracy: 0.5115\n",
      "Epoch 482/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3527 - accuracy: 0.5071 - val_loss: 1.3593 - val_accuracy: 0.5022\n",
      "Epoch 483/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3528 - accuracy: 0.5058 - val_loss: 1.3591 - val_accuracy: 0.5090\n",
      "Epoch 484/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3529 - accuracy: 0.5062 - val_loss: 1.3570 - val_accuracy: 0.5118\n",
      "Epoch 485/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3519 - accuracy: 0.5063 - val_loss: 1.3576 - val_accuracy: 0.5051\n",
      "Epoch 486/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3526 - accuracy: 0.5062 - val_loss: 1.3598 - val_accuracy: 0.5025\n",
      "Epoch 487/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3521 - accuracy: 0.5074 - val_loss: 1.3583 - val_accuracy: 0.5037\n",
      "Epoch 488/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3519 - accuracy: 0.5058 - val_loss: 1.3607 - val_accuracy: 0.5016\n",
      "Epoch 489/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3517 - accuracy: 0.5073 - val_loss: 1.3578 - val_accuracy: 0.5061\n",
      "Epoch 490/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3517 - accuracy: 0.5077 - val_loss: 1.3560 - val_accuracy: 0.5073\n",
      "Epoch 491/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3515 - accuracy: 0.5070 - val_loss: 1.3607 - val_accuracy: 0.5086\n",
      "Epoch 492/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3515 - accuracy: 0.5061 - val_loss: 1.3558 - val_accuracy: 0.5059\n",
      "Epoch 493/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3513 - accuracy: 0.5062 - val_loss: 1.3611 - val_accuracy: 0.5064\n",
      "Epoch 494/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3516 - accuracy: 0.5074 - val_loss: 1.3551 - val_accuracy: 0.5103\n",
      "Epoch 495/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3505 - accuracy: 0.5070 - val_loss: 1.3555 - val_accuracy: 0.5042\n",
      "Epoch 496/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3508 - accuracy: 0.5077 - val_loss: 1.3559 - val_accuracy: 0.5054\n",
      "Epoch 497/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3502 - accuracy: 0.5070 - val_loss: 1.3553 - val_accuracy: 0.5114\n",
      "Epoch 498/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3504 - accuracy: 0.5063 - val_loss: 1.3570 - val_accuracy: 0.5014\n",
      "Epoch 499/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3500 - accuracy: 0.5067 - val_loss: 1.3584 - val_accuracy: 0.5128\n",
      "Epoch 500/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3501 - accuracy: 0.5061 - val_loss: 1.3552 - val_accuracy: 0.5087\n",
      "Epoch 501/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3496 - accuracy: 0.5062 - val_loss: 1.3590 - val_accuracy: 0.5114\n",
      "Epoch 502/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3499 - accuracy: 0.5069 - val_loss: 1.3557 - val_accuracy: 0.5106\n",
      "Epoch 503/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3496 - accuracy: 0.5080 - val_loss: 1.3554 - val_accuracy: 0.5090\n",
      "Epoch 504/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3494 - accuracy: 0.5085 - val_loss: 1.3541 - val_accuracy: 0.5067\n",
      "Epoch 505/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3488 - accuracy: 0.5070 - val_loss: 1.3576 - val_accuracy: 0.5117\n",
      "Epoch 506/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3484 - accuracy: 0.5072 - val_loss: 1.3556 - val_accuracy: 0.5040\n",
      "Epoch 507/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3489 - accuracy: 0.5072 - val_loss: 1.3575 - val_accuracy: 0.5039\n",
      "Epoch 508/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3494 - accuracy: 0.5070 - val_loss: 1.3542 - val_accuracy: 0.5067\n",
      "Epoch 509/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3490 - accuracy: 0.5092 - val_loss: 1.3535 - val_accuracy: 0.5084\n",
      "Epoch 510/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3480 - accuracy: 0.5081 - val_loss: 1.3555 - val_accuracy: 0.5072\n",
      "Epoch 511/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3481 - accuracy: 0.5067 - val_loss: 1.3574 - val_accuracy: 0.5101\n",
      "Epoch 512/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3486 - accuracy: 0.5070 - val_loss: 1.3560 - val_accuracy: 0.5047\n",
      "Epoch 513/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3473 - accuracy: 0.5066 - val_loss: 1.3540 - val_accuracy: 0.5067\n",
      "Epoch 514/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3483 - accuracy: 0.5074 - val_loss: 1.3555 - val_accuracy: 0.5023\n",
      "Epoch 515/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3476 - accuracy: 0.5081 - val_loss: 1.3521 - val_accuracy: 0.5079\n",
      "Epoch 516/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3477 - accuracy: 0.5070 - val_loss: 1.3530 - val_accuracy: 0.5112\n",
      "Epoch 517/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3471 - accuracy: 0.5097 - val_loss: 1.3524 - val_accuracy: 0.5061\n",
      "Epoch 518/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3470 - accuracy: 0.5087 - val_loss: 1.3531 - val_accuracy: 0.5120\n",
      "Epoch 519/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3472 - accuracy: 0.5074 - val_loss: 1.3514 - val_accuracy: 0.5104\n",
      "Epoch 520/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3464 - accuracy: 0.5071 - val_loss: 1.3529 - val_accuracy: 0.5103\n",
      "Epoch 521/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3470 - accuracy: 0.5074 - val_loss: 1.3512 - val_accuracy: 0.5104\n",
      "Epoch 522/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3468 - accuracy: 0.5068 - val_loss: 1.3524 - val_accuracy: 0.5100\n",
      "Epoch 523/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3465 - accuracy: 0.5086 - val_loss: 1.3514 - val_accuracy: 0.5079\n",
      "Epoch 524/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3466 - accuracy: 0.5094 - val_loss: 1.3570 - val_accuracy: 0.5120\n",
      "Epoch 525/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3458 - accuracy: 0.5093 - val_loss: 1.3520 - val_accuracy: 0.5070\n",
      "Epoch 526/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3462 - accuracy: 0.5100 - val_loss: 1.3505 - val_accuracy: 0.5100\n",
      "Epoch 527/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3456 - accuracy: 0.5083 - val_loss: 1.3537 - val_accuracy: 0.5040\n",
      "Epoch 528/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3453 - accuracy: 0.5089 - val_loss: 1.3500 - val_accuracy: 0.5090\n",
      "Epoch 529/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3456 - accuracy: 0.5080 - val_loss: 1.3523 - val_accuracy: 0.5070\n",
      "Epoch 530/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3453 - accuracy: 0.5096 - val_loss: 1.3525 - val_accuracy: 0.5072\n",
      "Epoch 531/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3448 - accuracy: 0.5083 - val_loss: 1.3541 - val_accuracy: 0.5112\n",
      "Epoch 532/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3444 - accuracy: 0.5075 - val_loss: 1.3515 - val_accuracy: 0.5059\n",
      "Epoch 533/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3457 - accuracy: 0.5071 - val_loss: 1.3507 - val_accuracy: 0.5065\n",
      "Epoch 534/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3450 - accuracy: 0.5087 - val_loss: 1.3494 - val_accuracy: 0.5107\n",
      "Epoch 535/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3445 - accuracy: 0.5098 - val_loss: 1.3491 - val_accuracy: 0.5103\n",
      "Epoch 536/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3448 - accuracy: 0.5086 - val_loss: 1.3514 - val_accuracy: 0.5076\n",
      "Epoch 537/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3445 - accuracy: 0.5082 - val_loss: 1.3491 - val_accuracy: 0.5070\n",
      "Epoch 538/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3448 - accuracy: 0.5090 - val_loss: 1.3486 - val_accuracy: 0.5076\n",
      "Epoch 539/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3438 - accuracy: 0.5090 - val_loss: 1.3488 - val_accuracy: 0.5125\n",
      "Epoch 540/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3448 - accuracy: 0.5066 - val_loss: 1.3483 - val_accuracy: 0.5101\n",
      "Epoch 541/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3438 - accuracy: 0.5085 - val_loss: 1.3576 - val_accuracy: 0.5034\n",
      "Epoch 542/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3441 - accuracy: 0.5079 - val_loss: 1.3480 - val_accuracy: 0.5098\n",
      "Epoch 543/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3438 - accuracy: 0.5101 - val_loss: 1.3511 - val_accuracy: 0.5059\n",
      "Epoch 544/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3431 - accuracy: 0.5093 - val_loss: 1.3505 - val_accuracy: 0.5143\n",
      "Epoch 545/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3437 - accuracy: 0.5100 - val_loss: 1.3494 - val_accuracy: 0.5075\n",
      "Epoch 546/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3436 - accuracy: 0.5079 - val_loss: 1.3488 - val_accuracy: 0.5103\n",
      "Epoch 547/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3426 - accuracy: 0.5096 - val_loss: 1.3502 - val_accuracy: 0.5047\n",
      "Epoch 548/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3430 - accuracy: 0.5102 - val_loss: 1.3483 - val_accuracy: 0.5072\n",
      "Epoch 549/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3428 - accuracy: 0.5104 - val_loss: 1.3481 - val_accuracy: 0.5075\n",
      "Epoch 550/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3428 - accuracy: 0.5097 - val_loss: 1.3475 - val_accuracy: 0.5068\n",
      "Epoch 551/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3422 - accuracy: 0.5098 - val_loss: 1.3475 - val_accuracy: 0.5087\n",
      "Epoch 552/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3431 - accuracy: 0.5109 - val_loss: 1.3506 - val_accuracy: 0.5031\n",
      "Epoch 553/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3423 - accuracy: 0.5112 - val_loss: 1.3473 - val_accuracy: 0.5140\n",
      "Epoch 554/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3429 - accuracy: 0.5075 - val_loss: 1.3493 - val_accuracy: 0.5070\n",
      "Epoch 555/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3425 - accuracy: 0.5075 - val_loss: 1.3466 - val_accuracy: 0.5111\n",
      "Epoch 556/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3419 - accuracy: 0.5095 - val_loss: 1.3464 - val_accuracy: 0.5095\n",
      "Epoch 557/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3419 - accuracy: 0.5094 - val_loss: 1.3501 - val_accuracy: 0.5064\n",
      "Epoch 558/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3417 - accuracy: 0.5099 - val_loss: 1.3499 - val_accuracy: 0.5040\n",
      "Epoch 559/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3416 - accuracy: 0.5102 - val_loss: 1.3478 - val_accuracy: 0.5073\n",
      "Epoch 560/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3412 - accuracy: 0.5083 - val_loss: 1.3466 - val_accuracy: 0.5089\n",
      "Epoch 561/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3413 - accuracy: 0.5095 - val_loss: 1.3488 - val_accuracy: 0.5090\n",
      "Epoch 562/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3412 - accuracy: 0.5096 - val_loss: 1.3487 - val_accuracy: 0.5042\n",
      "Epoch 563/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3409 - accuracy: 0.5104 - val_loss: 1.3469 - val_accuracy: 0.5084\n",
      "Epoch 564/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3410 - accuracy: 0.5112 - val_loss: 1.3449 - val_accuracy: 0.5093\n",
      "Epoch 565/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3410 - accuracy: 0.5104 - val_loss: 1.3447 - val_accuracy: 0.5092\n",
      "Epoch 566/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3407 - accuracy: 0.5101 - val_loss: 1.3460 - val_accuracy: 0.5036\n",
      "Epoch 567/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3407 - accuracy: 0.5097 - val_loss: 1.3442 - val_accuracy: 0.5126\n",
      "Epoch 568/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3406 - accuracy: 0.5100 - val_loss: 1.3455 - val_accuracy: 0.5090\n",
      "Epoch 569/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3397 - accuracy: 0.5107 - val_loss: 1.3453 - val_accuracy: 0.5079\n",
      "Epoch 570/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3398 - accuracy: 0.5108 - val_loss: 1.3447 - val_accuracy: 0.5129\n",
      "Epoch 571/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3401 - accuracy: 0.5107 - val_loss: 1.3460 - val_accuracy: 0.5083\n",
      "Epoch 572/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3395 - accuracy: 0.5111 - val_loss: 1.3449 - val_accuracy: 0.5139\n",
      "Epoch 573/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3394 - accuracy: 0.5112 - val_loss: 1.3450 - val_accuracy: 0.5064\n",
      "Epoch 574/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3394 - accuracy: 0.5110 - val_loss: 1.3442 - val_accuracy: 0.5076\n",
      "Epoch 575/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3400 - accuracy: 0.5111 - val_loss: 1.3451 - val_accuracy: 0.5040\n",
      "Epoch 576/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3393 - accuracy: 0.5106 - val_loss: 1.3461 - val_accuracy: 0.5070\n",
      "Epoch 577/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3398 - accuracy: 0.5098 - val_loss: 1.3433 - val_accuracy: 0.5114\n",
      "Epoch 578/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3392 - accuracy: 0.5093 - val_loss: 1.3458 - val_accuracy: 0.5058\n",
      "Epoch 579/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3391 - accuracy: 0.5098 - val_loss: 1.3463 - val_accuracy: 0.5111\n",
      "Epoch 580/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3387 - accuracy: 0.5112 - val_loss: 1.3439 - val_accuracy: 0.5142\n",
      "Epoch 581/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3386 - accuracy: 0.5119 - val_loss: 1.3445 - val_accuracy: 0.5072\n",
      "Epoch 582/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3389 - accuracy: 0.5090 - val_loss: 1.3431 - val_accuracy: 0.5068\n",
      "Epoch 583/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3383 - accuracy: 0.5110 - val_loss: 1.3443 - val_accuracy: 0.5089\n",
      "Epoch 584/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3393 - accuracy: 0.5110 - val_loss: 1.3450 - val_accuracy: 0.5062\n",
      "Epoch 585/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3380 - accuracy: 0.5109 - val_loss: 1.3443 - val_accuracy: 0.5087\n",
      "Epoch 586/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3381 - accuracy: 0.5117 - val_loss: 1.3430 - val_accuracy: 0.5081\n",
      "Epoch 587/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3378 - accuracy: 0.5117 - val_loss: 1.3456 - val_accuracy: 0.5106\n",
      "Epoch 588/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3380 - accuracy: 0.5120 - val_loss: 1.3477 - val_accuracy: 0.5092\n",
      "Epoch 589/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3385 - accuracy: 0.5118 - val_loss: 1.3430 - val_accuracy: 0.5111\n",
      "Epoch 590/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3373 - accuracy: 0.5116 - val_loss: 1.3443 - val_accuracy: 0.5140\n",
      "Epoch 591/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3372 - accuracy: 0.5117 - val_loss: 1.3453 - val_accuracy: 0.5050\n",
      "Epoch 592/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3379 - accuracy: 0.5095 - val_loss: 1.3426 - val_accuracy: 0.5073\n",
      "Epoch 593/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3375 - accuracy: 0.5111 - val_loss: 1.3418 - val_accuracy: 0.5093\n",
      "Epoch 594/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3374 - accuracy: 0.5120 - val_loss: 1.3445 - val_accuracy: 0.5153\n",
      "Epoch 595/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3370 - accuracy: 0.5108 - val_loss: 1.3416 - val_accuracy: 0.5109\n",
      "Epoch 596/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3372 - accuracy: 0.5111 - val_loss: 1.3408 - val_accuracy: 0.5115\n",
      "Epoch 597/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3372 - accuracy: 0.5113 - val_loss: 1.3434 - val_accuracy: 0.5107\n",
      "Epoch 598/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3369 - accuracy: 0.5114 - val_loss: 1.3421 - val_accuracy: 0.5112\n",
      "Epoch 599/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3365 - accuracy: 0.5104 - val_loss: 1.3456 - val_accuracy: 0.5050\n",
      "Epoch 600/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3368 - accuracy: 0.5106 - val_loss: 1.3457 - val_accuracy: 0.5134\n",
      "Epoch 601/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3362 - accuracy: 0.5113 - val_loss: 1.3413 - val_accuracy: 0.5157\n",
      "Epoch 602/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3364 - accuracy: 0.5101 - val_loss: 1.3410 - val_accuracy: 0.5101\n",
      "Epoch 603/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3362 - accuracy: 0.5113 - val_loss: 1.3426 - val_accuracy: 0.5070\n",
      "Epoch 604/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3358 - accuracy: 0.5117 - val_loss: 1.3439 - val_accuracy: 0.5076\n",
      "Epoch 605/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3362 - accuracy: 0.5106 - val_loss: 1.3490 - val_accuracy: 0.5047\n",
      "Epoch 606/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3359 - accuracy: 0.5123 - val_loss: 1.3404 - val_accuracy: 0.5093\n",
      "Epoch 607/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3354 - accuracy: 0.5125 - val_loss: 1.3400 - val_accuracy: 0.5097\n",
      "Epoch 608/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3361 - accuracy: 0.5084 - val_loss: 1.3399 - val_accuracy: 0.5103\n",
      "Epoch 609/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3360 - accuracy: 0.5120 - val_loss: 1.3399 - val_accuracy: 0.5089\n",
      "Epoch 610/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3353 - accuracy: 0.5132 - val_loss: 1.3404 - val_accuracy: 0.5101\n",
      "Epoch 611/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3355 - accuracy: 0.5113 - val_loss: 1.3450 - val_accuracy: 0.5078\n",
      "Epoch 612/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3352 - accuracy: 0.5104 - val_loss: 1.3421 - val_accuracy: 0.5093\n",
      "Epoch 613/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3348 - accuracy: 0.5118 - val_loss: 1.3431 - val_accuracy: 0.5093\n",
      "Epoch 614/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3353 - accuracy: 0.5114 - val_loss: 1.3406 - val_accuracy: 0.5160\n",
      "Epoch 615/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3346 - accuracy: 0.5108 - val_loss: 1.3440 - val_accuracy: 0.5092\n",
      "Epoch 616/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3351 - accuracy: 0.5110 - val_loss: 1.3392 - val_accuracy: 0.5097\n",
      "Epoch 617/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3347 - accuracy: 0.5110 - val_loss: 1.3395 - val_accuracy: 0.5129\n",
      "Epoch 618/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3348 - accuracy: 0.5101 - val_loss: 1.3385 - val_accuracy: 0.5115\n",
      "Epoch 619/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3345 - accuracy: 0.5104 - val_loss: 1.3397 - val_accuracy: 0.5115\n",
      "Epoch 620/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3345 - accuracy: 0.5119 - val_loss: 1.3401 - val_accuracy: 0.5083\n",
      "Epoch 621/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3338 - accuracy: 0.5141 - val_loss: 1.3448 - val_accuracy: 0.5139\n",
      "Epoch 622/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3347 - accuracy: 0.5132 - val_loss: 1.3391 - val_accuracy: 0.5112\n",
      "Epoch 623/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3343 - accuracy: 0.5112 - val_loss: 1.3395 - val_accuracy: 0.5135\n",
      "Epoch 624/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3342 - accuracy: 0.5117 - val_loss: 1.3381 - val_accuracy: 0.5104\n",
      "Epoch 625/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3338 - accuracy: 0.5104 - val_loss: 1.3387 - val_accuracy: 0.5067\n",
      "Epoch 626/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3339 - accuracy: 0.5088 - val_loss: 1.3383 - val_accuracy: 0.5131\n",
      "Epoch 627/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3337 - accuracy: 0.5115 - val_loss: 1.3395 - val_accuracy: 0.5100\n",
      "Epoch 628/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3335 - accuracy: 0.5119 - val_loss: 1.3387 - val_accuracy: 0.5092\n",
      "Epoch 629/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3331 - accuracy: 0.5123 - val_loss: 1.3411 - val_accuracy: 0.5163\n",
      "Epoch 630/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3332 - accuracy: 0.5115 - val_loss: 1.3384 - val_accuracy: 0.5072\n",
      "Epoch 631/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3335 - accuracy: 0.5114 - val_loss: 1.3394 - val_accuracy: 0.5068\n",
      "Epoch 632/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3327 - accuracy: 0.5129 - val_loss: 1.3386 - val_accuracy: 0.5092\n",
      "Epoch 633/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3331 - accuracy: 0.5127 - val_loss: 1.3405 - val_accuracy: 0.5149\n",
      "Epoch 634/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3332 - accuracy: 0.5120 - val_loss: 1.3379 - val_accuracy: 0.5107\n",
      "Epoch 635/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3325 - accuracy: 0.5117 - val_loss: 1.3380 - val_accuracy: 0.5115\n",
      "Epoch 636/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3325 - accuracy: 0.5117 - val_loss: 1.3412 - val_accuracy: 0.5168\n",
      "Epoch 637/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3327 - accuracy: 0.5144 - val_loss: 1.3395 - val_accuracy: 0.5059\n",
      "Epoch 638/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3325 - accuracy: 0.5110 - val_loss: 1.3405 - val_accuracy: 0.5059\n",
      "Epoch 639/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3327 - accuracy: 0.5114 - val_loss: 1.3361 - val_accuracy: 0.5157\n",
      "Epoch 640/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3322 - accuracy: 0.5127 - val_loss: 1.3367 - val_accuracy: 0.5111\n",
      "Epoch 641/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3324 - accuracy: 0.5134 - val_loss: 1.3389 - val_accuracy: 0.5079\n",
      "Epoch 642/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3323 - accuracy: 0.5120 - val_loss: 1.3366 - val_accuracy: 0.5103\n",
      "Epoch 643/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3327 - accuracy: 0.5133 - val_loss: 1.3364 - val_accuracy: 0.5118\n",
      "Epoch 644/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3314 - accuracy: 0.5100 - val_loss: 1.3370 - val_accuracy: 0.5151\n",
      "Epoch 645/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3327 - accuracy: 0.5113 - val_loss: 1.3375 - val_accuracy: 0.5137\n",
      "Epoch 646/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3319 - accuracy: 0.5122 - val_loss: 1.3378 - val_accuracy: 0.5083\n",
      "Epoch 647/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3319 - accuracy: 0.5115 - val_loss: 1.3354 - val_accuracy: 0.5135\n",
      "Epoch 648/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3317 - accuracy: 0.5101 - val_loss: 1.3396 - val_accuracy: 0.5115\n",
      "Epoch 649/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3319 - accuracy: 0.5113 - val_loss: 1.3355 - val_accuracy: 0.5121\n",
      "Epoch 650/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3313 - accuracy: 0.5118 - val_loss: 1.3354 - val_accuracy: 0.5132\n",
      "Epoch 651/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3319 - accuracy: 0.5115 - val_loss: 1.3365 - val_accuracy: 0.5075\n",
      "Epoch 652/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3314 - accuracy: 0.5126 - val_loss: 1.3368 - val_accuracy: 0.5129\n",
      "Epoch 653/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3316 - accuracy: 0.5108 - val_loss: 1.3359 - val_accuracy: 0.5089\n",
      "Epoch 654/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3315 - accuracy: 0.5123 - val_loss: 1.3359 - val_accuracy: 0.5092\n",
      "Epoch 655/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3307 - accuracy: 0.5121 - val_loss: 1.3385 - val_accuracy: 0.5140\n",
      "Epoch 656/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3310 - accuracy: 0.5114 - val_loss: 1.3355 - val_accuracy: 0.5095\n",
      "Epoch 657/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3309 - accuracy: 0.5125 - val_loss: 1.3354 - val_accuracy: 0.5087\n",
      "Epoch 658/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3309 - accuracy: 0.5119 - val_loss: 1.3367 - val_accuracy: 0.5137\n",
      "Epoch 659/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3308 - accuracy: 0.5104 - val_loss: 1.3347 - val_accuracy: 0.5123\n",
      "Epoch 660/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3300 - accuracy: 0.5133 - val_loss: 1.3389 - val_accuracy: 0.5076\n",
      "Epoch 661/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3302 - accuracy: 0.5119 - val_loss: 1.3383 - val_accuracy: 0.5126\n",
      "Epoch 662/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3299 - accuracy: 0.5118 - val_loss: 1.3379 - val_accuracy: 0.5114\n",
      "Epoch 663/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3305 - accuracy: 0.5111 - val_loss: 1.3381 - val_accuracy: 0.5097\n",
      "Epoch 664/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3307 - accuracy: 0.5131 - val_loss: 1.3343 - val_accuracy: 0.5148\n",
      "Epoch 665/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3296 - accuracy: 0.5133 - val_loss: 1.3357 - val_accuracy: 0.5151\n",
      "Epoch 666/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3304 - accuracy: 0.5127 - val_loss: 1.3343 - val_accuracy: 0.5120\n",
      "Epoch 667/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3299 - accuracy: 0.5108 - val_loss: 1.3349 - val_accuracy: 0.5149\n",
      "Epoch 668/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3290 - accuracy: 0.5143 - val_loss: 1.3348 - val_accuracy: 0.5165\n",
      "Epoch 669/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3305 - accuracy: 0.5121 - val_loss: 1.3340 - val_accuracy: 0.5154\n",
      "Epoch 670/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3292 - accuracy: 0.5127 - val_loss: 1.3354 - val_accuracy: 0.5087\n",
      "Epoch 671/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3297 - accuracy: 0.5123 - val_loss: 1.3334 - val_accuracy: 0.5132\n",
      "Epoch 672/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3296 - accuracy: 0.5117 - val_loss: 1.3389 - val_accuracy: 0.5163\n",
      "Epoch 673/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3294 - accuracy: 0.5120 - val_loss: 1.3332 - val_accuracy: 0.5137\n",
      "Epoch 674/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3289 - accuracy: 0.5123 - val_loss: 1.3350 - val_accuracy: 0.5101\n",
      "Epoch 675/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3283 - accuracy: 0.5127 - val_loss: 1.3350 - val_accuracy: 0.5090\n",
      "Epoch 676/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3289 - accuracy: 0.5133 - val_loss: 1.3356 - val_accuracy: 0.5163\n",
      "Epoch 677/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3287 - accuracy: 0.5134 - val_loss: 1.3332 - val_accuracy: 0.5109\n",
      "Epoch 678/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3289 - accuracy: 0.5136 - val_loss: 1.3361 - val_accuracy: 0.5076\n",
      "Epoch 679/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3286 - accuracy: 0.5120 - val_loss: 1.3363 - val_accuracy: 0.5111\n",
      "Epoch 680/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3285 - accuracy: 0.5120 - val_loss: 1.3348 - val_accuracy: 0.5129\n",
      "Epoch 681/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3288 - accuracy: 0.5134 - val_loss: 1.3328 - val_accuracy: 0.5109\n",
      "Epoch 682/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3281 - accuracy: 0.5142 - val_loss: 1.3381 - val_accuracy: 0.5101\n",
      "Epoch 683/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3285 - accuracy: 0.5133 - val_loss: 1.3323 - val_accuracy: 0.5149\n",
      "Epoch 684/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3288 - accuracy: 0.5115 - val_loss: 1.3355 - val_accuracy: 0.5154\n",
      "Epoch 685/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3278 - accuracy: 0.5131 - val_loss: 1.3396 - val_accuracy: 0.5117\n",
      "Epoch 686/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3280 - accuracy: 0.5131 - val_loss: 1.3347 - val_accuracy: 0.5148\n",
      "Epoch 687/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3279 - accuracy: 0.5139 - val_loss: 1.3328 - val_accuracy: 0.5171\n",
      "Epoch 688/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3287 - accuracy: 0.5131 - val_loss: 1.3364 - val_accuracy: 0.5143\n",
      "Epoch 689/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3285 - accuracy: 0.5105 - val_loss: 1.3325 - val_accuracy: 0.5131\n",
      "Epoch 690/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3280 - accuracy: 0.5143 - val_loss: 1.3350 - val_accuracy: 0.5089\n",
      "Epoch 691/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3279 - accuracy: 0.5132 - val_loss: 1.3322 - val_accuracy: 0.5114\n",
      "Epoch 692/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3275 - accuracy: 0.5132 - val_loss: 1.3351 - val_accuracy: 0.5114\n",
      "Epoch 693/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3278 - accuracy: 0.5134 - val_loss: 1.3338 - val_accuracy: 0.5126\n",
      "Epoch 694/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3267 - accuracy: 0.5140 - val_loss: 1.3338 - val_accuracy: 0.5135\n",
      "Epoch 695/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3274 - accuracy: 0.5126 - val_loss: 1.3340 - val_accuracy: 0.5145\n",
      "Epoch 696/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3272 - accuracy: 0.5134 - val_loss: 1.3331 - val_accuracy: 0.5104\n",
      "Epoch 697/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5136 - val_loss: 1.3312 - val_accuracy: 0.5148\n",
      "Epoch 698/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5149 - val_loss: 1.3323 - val_accuracy: 0.5129\n",
      "Epoch 699/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3273 - accuracy: 0.5135 - val_loss: 1.3316 - val_accuracy: 0.5121\n",
      "Epoch 700/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5133 - val_loss: 1.3332 - val_accuracy: 0.5098\n",
      "Epoch 701/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3267 - accuracy: 0.5130 - val_loss: 1.3397 - val_accuracy: 0.5125\n",
      "Epoch 702/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3272 - accuracy: 0.5145 - val_loss: 1.3314 - val_accuracy: 0.5117\n",
      "Epoch 703/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3264 - accuracy: 0.5120 - val_loss: 1.3309 - val_accuracy: 0.5148\n",
      "Epoch 704/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5146 - val_loss: 1.3356 - val_accuracy: 0.5167\n",
      "Epoch 705/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3266 - accuracy: 0.5150 - val_loss: 1.3307 - val_accuracy: 0.5134\n",
      "Epoch 706/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3266 - accuracy: 0.5143 - val_loss: 1.3304 - val_accuracy: 0.5157\n",
      "Epoch 707/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3268 - accuracy: 0.5132 - val_loss: 1.3318 - val_accuracy: 0.5120\n",
      "Epoch 708/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3264 - accuracy: 0.5134 - val_loss: 1.3318 - val_accuracy: 0.5151\n",
      "Epoch 709/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3259 - accuracy: 0.5143 - val_loss: 1.3319 - val_accuracy: 0.5117\n",
      "Epoch 710/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3263 - accuracy: 0.5123 - val_loss: 1.3328 - val_accuracy: 0.5106\n",
      "Epoch 711/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3262 - accuracy: 0.5150 - val_loss: 1.3299 - val_accuracy: 0.5151\n",
      "Epoch 712/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3261 - accuracy: 0.5140 - val_loss: 1.3298 - val_accuracy: 0.5162\n",
      "Epoch 713/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3263 - accuracy: 0.5131 - val_loss: 1.3306 - val_accuracy: 0.5146\n",
      "Epoch 714/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3254 - accuracy: 0.5146 - val_loss: 1.3304 - val_accuracy: 0.5151\n",
      "Epoch 715/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3256 - accuracy: 0.5143 - val_loss: 1.3299 - val_accuracy: 0.5165\n",
      "Epoch 716/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3263 - accuracy: 0.5124 - val_loss: 1.3301 - val_accuracy: 0.5187\n",
      "Epoch 717/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3259 - accuracy: 0.5144 - val_loss: 1.3305 - val_accuracy: 0.5125\n",
      "Epoch 718/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3263 - accuracy: 0.5133 - val_loss: 1.3298 - val_accuracy: 0.5153\n",
      "Epoch 719/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3259 - accuracy: 0.5135 - val_loss: 1.3296 - val_accuracy: 0.5137\n",
      "Epoch 720/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3257 - accuracy: 0.5142 - val_loss: 1.3302 - val_accuracy: 0.5131\n",
      "Epoch 721/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3258 - accuracy: 0.5146 - val_loss: 1.3296 - val_accuracy: 0.5187\n",
      "Epoch 722/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3254 - accuracy: 0.5133 - val_loss: 1.3288 - val_accuracy: 0.5140\n",
      "Epoch 723/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3247 - accuracy: 0.5141 - val_loss: 1.3296 - val_accuracy: 0.5123\n",
      "Epoch 724/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3247 - accuracy: 0.5153 - val_loss: 1.3289 - val_accuracy: 0.5134\n",
      "Epoch 725/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3247 - accuracy: 0.5146 - val_loss: 1.3304 - val_accuracy: 0.5167\n",
      "Epoch 726/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3248 - accuracy: 0.5149 - val_loss: 1.3307 - val_accuracy: 0.5112\n",
      "Epoch 727/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3245 - accuracy: 0.5153 - val_loss: 1.3314 - val_accuracy: 0.5095\n",
      "Epoch 728/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3245 - accuracy: 0.5130 - val_loss: 1.3310 - val_accuracy: 0.5184\n",
      "Epoch 729/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3243 - accuracy: 0.5132 - val_loss: 1.3289 - val_accuracy: 0.5134\n",
      "Epoch 730/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3240 - accuracy: 0.5156 - val_loss: 1.3315 - val_accuracy: 0.5090\n",
      "Epoch 731/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3243 - accuracy: 0.5148 - val_loss: 1.3293 - val_accuracy: 0.5160\n",
      "Epoch 732/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3240 - accuracy: 0.5145 - val_loss: 1.3316 - val_accuracy: 0.5198\n",
      "Epoch 733/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3238 - accuracy: 0.5143 - val_loss: 1.3295 - val_accuracy: 0.5135\n",
      "Epoch 734/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3238 - accuracy: 0.5142 - val_loss: 1.3290 - val_accuracy: 0.5157\n",
      "Epoch 735/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3241 - accuracy: 0.5139 - val_loss: 1.3309 - val_accuracy: 0.5104\n",
      "Epoch 736/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3241 - accuracy: 0.5139 - val_loss: 1.3297 - val_accuracy: 0.5196\n",
      "Epoch 737/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3237 - accuracy: 0.5130 - val_loss: 1.3313 - val_accuracy: 0.5210\n",
      "Epoch 738/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3238 - accuracy: 0.5140 - val_loss: 1.3302 - val_accuracy: 0.5205\n",
      "Epoch 739/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3235 - accuracy: 0.5149 - val_loss: 1.3273 - val_accuracy: 0.5173\n",
      "Epoch 740/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3232 - accuracy: 0.5149 - val_loss: 1.3294 - val_accuracy: 0.5201\n",
      "Epoch 741/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3231 - accuracy: 0.5133 - val_loss: 1.3273 - val_accuracy: 0.5143\n",
      "Epoch 742/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3232 - accuracy: 0.5153 - val_loss: 1.3293 - val_accuracy: 0.5167\n",
      "Epoch 743/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3232 - accuracy: 0.5149 - val_loss: 1.3286 - val_accuracy: 0.5120\n",
      "Epoch 744/750\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3231 - accuracy: 0.5139 - val_loss: 1.3279 - val_accuracy: 0.5216\n",
      "Epoch 745/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3231 - accuracy: 0.5135 - val_loss: 1.3284 - val_accuracy: 0.5118\n",
      "Epoch 746/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3229 - accuracy: 0.5152 - val_loss: 1.3283 - val_accuracy: 0.5170\n",
      "Epoch 747/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3234 - accuracy: 0.5140 - val_loss: 1.3288 - val_accuracy: 0.5227\n",
      "Epoch 748/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3227 - accuracy: 0.5161 - val_loss: 1.3320 - val_accuracy: 0.5137\n",
      "Epoch 749/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3234 - accuracy: 0.5149 - val_loss: 1.3279 - val_accuracy: 0.5148\n",
      "Epoch 750/750\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3230 - accuracy: 0.5159 - val_loss: 1.3345 - val_accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "model_b = build_model_b()\n",
    "model_c = build_model_c()\n",
    "\n",
    "hist1 = model_b.fit(X_train, y_train, epochs=750, validation_split=0.33)\n",
    "hist2 = model_c.fit(X_train, y_train, epochs=750, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2899e224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(hist1.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e0a187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/498\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.6971 - accuracy: 0.3591 - val_loss: 1.6764 - val_accuracy: 0.3579\n",
      "Epoch 2/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6795 - accuracy: 0.3595 - val_loss: 1.6767 - val_accuracy: 0.3579\n",
      "Epoch 3/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6789 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 4/498\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.6786 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 5/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 6/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6751 - val_accuracy: 0.3580\n",
      "Epoch 7/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3596 - val_loss: 1.6750 - val_accuracy: 0.3580\n",
      "Epoch 8/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6750 - val_accuracy: 0.3583\n",
      "Epoch 9/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6748 - val_accuracy: 0.3580\n",
      "Epoch 10/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3598 - val_loss: 1.6750 - val_accuracy: 0.3580\n",
      "Epoch 11/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6764 - accuracy: 0.3601 - val_loss: 1.6761 - val_accuracy: 0.3580\n",
      "Epoch 12/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3598 - val_loss: 1.6747 - val_accuracy: 0.3580\n",
      "Epoch 13/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6764 - accuracy: 0.3600 - val_loss: 1.6748 - val_accuracy: 0.3571\n",
      "Epoch 14/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6762 - accuracy: 0.3601 - val_loss: 1.6751 - val_accuracy: 0.3573\n",
      "Epoch 15/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6761 - accuracy: 0.3601 - val_loss: 1.6746 - val_accuracy: 0.3573\n",
      "Epoch 16/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6761 - accuracy: 0.3601 - val_loss: 1.6747 - val_accuracy: 0.3573\n",
      "Epoch 17/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6759 - accuracy: 0.3601 - val_loss: 1.6747 - val_accuracy: 0.3574\n",
      "Epoch 18/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6757 - accuracy: 0.3601 - val_loss: 1.6747 - val_accuracy: 0.3573\n",
      "Epoch 19/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6756 - accuracy: 0.3602 - val_loss: 1.6748 - val_accuracy: 0.3574\n",
      "Epoch 20/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6753 - accuracy: 0.3603 - val_loss: 1.6743 - val_accuracy: 0.3577\n",
      "Epoch 21/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6753 - accuracy: 0.3602 - val_loss: 1.6742 - val_accuracy: 0.3576\n",
      "Epoch 22/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6697 - accuracy: 0.3637 - val_loss: 1.6608 - val_accuracy: 0.3685\n",
      "Epoch 23/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6620 - accuracy: 0.3690 - val_loss: 1.6638 - val_accuracy: 0.3677\n",
      "Epoch 24/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6606 - accuracy: 0.3691 - val_loss: 1.6552 - val_accuracy: 0.3683\n",
      "Epoch 25/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6585 - accuracy: 0.3694 - val_loss: 1.6612 - val_accuracy: 0.3678\n",
      "Epoch 26/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6538 - accuracy: 0.3723 - val_loss: 1.6543 - val_accuracy: 0.3683\n",
      "Epoch 27/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6414 - accuracy: 0.3740 - val_loss: 1.6139 - val_accuracy: 0.3770\n",
      "Epoch 28/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6017 - accuracy: 0.3986 - val_loss: 1.5672 - val_accuracy: 0.4194\n",
      "Epoch 29/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5739 - accuracy: 0.4104 - val_loss: 1.5498 - val_accuracy: 0.4270\n",
      "Epoch 30/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5515 - accuracy: 0.4120 - val_loss: 1.5298 - val_accuracy: 0.4242\n",
      "Epoch 31/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5296 - accuracy: 0.4182 - val_loss: 1.5211 - val_accuracy: 0.4223\n",
      "Epoch 32/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5203 - accuracy: 0.4226 - val_loss: 1.4994 - val_accuracy: 0.4390\n",
      "Epoch 33/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5186 - accuracy: 0.4234 - val_loss: 1.5199 - val_accuracy: 0.4200\n",
      "Epoch 34/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4943 - accuracy: 0.4367 - val_loss: 1.5536 - val_accuracy: 0.4273\n",
      "Epoch 35/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4967 - accuracy: 0.4318 - val_loss: 1.5312 - val_accuracy: 0.4128\n",
      "Epoch 36/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4835 - accuracy: 0.4430 - val_loss: 1.4714 - val_accuracy: 0.4566\n",
      "Epoch 37/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4717 - accuracy: 0.4499 - val_loss: 1.4805 - val_accuracy: 0.4408\n",
      "Epoch 38/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4580 - accuracy: 0.4555 - val_loss: 1.4491 - val_accuracy: 0.4658\n",
      "Epoch 39/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4573 - accuracy: 0.4557 - val_loss: 1.4513 - val_accuracy: 0.4746\n",
      "Epoch 40/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4549 - accuracy: 0.4587 - val_loss: 1.4504 - val_accuracy: 0.4665\n",
      "Epoch 41/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4469 - accuracy: 0.4595 - val_loss: 1.4529 - val_accuracy: 0.4670\n",
      "Epoch 42/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4413 - accuracy: 0.4643 - val_loss: 1.4422 - val_accuracy: 0.4648\n",
      "Epoch 43/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4434 - accuracy: 0.4605 - val_loss: 1.4431 - val_accuracy: 0.4721\n",
      "Epoch 44/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4447 - accuracy: 0.4601 - val_loss: 1.4390 - val_accuracy: 0.4682\n",
      "Epoch 45/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4396 - accuracy: 0.4648 - val_loss: 1.4297 - val_accuracy: 0.4770\n",
      "Epoch 46/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4378 - accuracy: 0.4674 - val_loss: 1.4296 - val_accuracy: 0.4756\n",
      "Epoch 47/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4337 - accuracy: 0.4686 - val_loss: 1.4394 - val_accuracy: 0.4815\n",
      "Epoch 48/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4354 - accuracy: 0.4706 - val_loss: 1.4286 - val_accuracy: 0.4731\n",
      "Epoch 49/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4291 - accuracy: 0.4696 - val_loss: 1.4277 - val_accuracy: 0.4756\n",
      "Epoch 50/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4309 - accuracy: 0.4710 - val_loss: 1.4447 - val_accuracy: 0.4679\n",
      "Epoch 51/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4317 - accuracy: 0.4673 - val_loss: 1.4228 - val_accuracy: 0.4793\n",
      "Epoch 52/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4299 - accuracy: 0.4692 - val_loss: 1.4286 - val_accuracy: 0.4737\n",
      "Epoch 53/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4257 - accuracy: 0.4715 - val_loss: 1.4237 - val_accuracy: 0.4749\n",
      "Epoch 54/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4452 - accuracy: 0.4656 - val_loss: 1.4275 - val_accuracy: 0.4833\n",
      "Epoch 55/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4245 - accuracy: 0.4724 - val_loss: 1.4199 - val_accuracy: 0.4801\n",
      "Epoch 56/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4266 - accuracy: 0.4749 - val_loss: 1.4257 - val_accuracy: 0.4768\n",
      "Epoch 57/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4242 - accuracy: 0.4739 - val_loss: 1.4237 - val_accuracy: 0.4851\n",
      "Epoch 58/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4213 - accuracy: 0.4762 - val_loss: 1.4231 - val_accuracy: 0.4793\n",
      "Epoch 59/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4218 - accuracy: 0.4745 - val_loss: 1.4331 - val_accuracy: 0.4795\n",
      "Epoch 60/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4239 - accuracy: 0.4729 - val_loss: 1.4231 - val_accuracy: 0.4776\n",
      "Epoch 61/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4210 - accuracy: 0.4758 - val_loss: 1.4178 - val_accuracy: 0.4824\n",
      "Epoch 62/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4193 - accuracy: 0.4763 - val_loss: 1.4299 - val_accuracy: 0.4773\n",
      "Epoch 63/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4187 - accuracy: 0.4790 - val_loss: 1.4295 - val_accuracy: 0.4746\n",
      "Epoch 64/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4172 - accuracy: 0.4785 - val_loss: 1.4147 - val_accuracy: 0.4832\n",
      "Epoch 65/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4145 - accuracy: 0.4781 - val_loss: 1.4343 - val_accuracy: 0.4787\n",
      "Epoch 66/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4146 - accuracy: 0.4792 - val_loss: 1.4230 - val_accuracy: 0.4851\n",
      "Epoch 67/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4194 - accuracy: 0.4756 - val_loss: 1.4132 - val_accuracy: 0.4832\n",
      "Epoch 68/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4163 - accuracy: 0.4775 - val_loss: 1.4292 - val_accuracy: 0.4777\n",
      "Epoch 69/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4183 - accuracy: 0.4771 - val_loss: 1.4448 - val_accuracy: 0.4692\n",
      "Epoch 70/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4177 - accuracy: 0.4765 - val_loss: 1.4300 - val_accuracy: 0.4751\n",
      "Epoch 71/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4176 - accuracy: 0.4768 - val_loss: 1.4250 - val_accuracy: 0.4804\n",
      "Epoch 72/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4140 - accuracy: 0.4811 - val_loss: 1.4146 - val_accuracy: 0.4868\n",
      "Epoch 73/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4082 - accuracy: 0.4817 - val_loss: 1.4233 - val_accuracy: 0.4777\n",
      "Epoch 74/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4040 - accuracy: 0.4851 - val_loss: 1.4106 - val_accuracy: 0.4841\n",
      "Epoch 75/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4096 - accuracy: 0.4837 - val_loss: 1.4121 - val_accuracy: 0.4871\n",
      "Epoch 76/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4089 - accuracy: 0.4837 - val_loss: 1.4083 - val_accuracy: 0.4917\n",
      "Epoch 77/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4058 - accuracy: 0.4870 - val_loss: 1.4178 - val_accuracy: 0.4857\n",
      "Epoch 78/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4077 - accuracy: 0.4831 - val_loss: 1.4131 - val_accuracy: 0.4886\n",
      "Epoch 79/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4049 - accuracy: 0.4856 - val_loss: 1.4119 - val_accuracy: 0.4833\n",
      "Epoch 80/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4152 - accuracy: 0.4811 - val_loss: 1.4186 - val_accuracy: 0.4805\n",
      "Epoch 81/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4053 - accuracy: 0.4854 - val_loss: 1.4047 - val_accuracy: 0.4900\n",
      "Epoch 82/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4064 - accuracy: 0.4824 - val_loss: 1.4155 - val_accuracy: 0.4805\n",
      "Epoch 83/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4075 - accuracy: 0.4877 - val_loss: 1.4297 - val_accuracy: 0.4871\n",
      "Epoch 84/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4043 - accuracy: 0.4816 - val_loss: 1.4034 - val_accuracy: 0.4922\n",
      "Epoch 85/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4010 - accuracy: 0.4871 - val_loss: 1.4081 - val_accuracy: 0.4832\n",
      "Epoch 86/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3981 - accuracy: 0.4888 - val_loss: 1.4106 - val_accuracy: 0.4888\n",
      "Epoch 87/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4055 - accuracy: 0.4821 - val_loss: 1.4068 - val_accuracy: 0.4969\n",
      "Epoch 88/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4012 - accuracy: 0.4870 - val_loss: 1.4047 - val_accuracy: 0.4919\n",
      "Epoch 89/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4000 - accuracy: 0.4894 - val_loss: 1.4201 - val_accuracy: 0.4858\n",
      "Epoch 90/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4024 - accuracy: 0.4860 - val_loss: 1.4050 - val_accuracy: 0.4910\n",
      "Epoch 91/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3990 - accuracy: 0.4887 - val_loss: 1.4065 - val_accuracy: 0.4998\n",
      "Epoch 92/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4017 - accuracy: 0.4860 - val_loss: 1.4327 - val_accuracy: 0.4762\n",
      "Epoch 93/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3982 - accuracy: 0.4900 - val_loss: 1.4012 - val_accuracy: 0.4967\n",
      "Epoch 94/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4047 - accuracy: 0.4894 - val_loss: 1.4036 - val_accuracy: 0.4942\n",
      "Epoch 95/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3992 - accuracy: 0.4886 - val_loss: 1.4017 - val_accuracy: 0.4914\n",
      "Epoch 96/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4010 - accuracy: 0.4887 - val_loss: 1.4252 - val_accuracy: 0.4763\n",
      "Epoch 97/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3984 - accuracy: 0.4873 - val_loss: 1.4004 - val_accuracy: 0.4984\n",
      "Epoch 98/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3963 - accuracy: 0.4882 - val_loss: 1.4102 - val_accuracy: 0.4871\n",
      "Epoch 99/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3963 - accuracy: 0.4885 - val_loss: 1.4008 - val_accuracy: 0.4967\n",
      "Epoch 100/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3990 - accuracy: 0.4927 - val_loss: 1.4064 - val_accuracy: 0.4903\n",
      "Epoch 101/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3955 - accuracy: 0.4883 - val_loss: 1.3993 - val_accuracy: 0.4941\n",
      "Epoch 102/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3946 - accuracy: 0.4906 - val_loss: 1.3983 - val_accuracy: 0.4942\n",
      "Epoch 103/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3993 - accuracy: 0.4908 - val_loss: 1.4040 - val_accuracy: 0.4880\n",
      "Epoch 104/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3964 - accuracy: 0.4911 - val_loss: 1.4072 - val_accuracy: 0.4894\n",
      "Epoch 105/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3979 - accuracy: 0.4882 - val_loss: 1.4177 - val_accuracy: 0.4860\n",
      "Epoch 106/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3966 - accuracy: 0.4918 - val_loss: 1.4006 - val_accuracy: 0.4961\n",
      "Epoch 107/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3930 - accuracy: 0.4907 - val_loss: 1.4037 - val_accuracy: 0.4893\n",
      "Epoch 108/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3983 - accuracy: 0.4877 - val_loss: 1.3980 - val_accuracy: 0.4949\n",
      "Epoch 109/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3947 - accuracy: 0.4906 - val_loss: 1.4230 - val_accuracy: 0.4889\n",
      "Epoch 110/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3989 - accuracy: 0.4893 - val_loss: 1.3955 - val_accuracy: 0.4960\n",
      "Epoch 111/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3922 - accuracy: 0.4894 - val_loss: 1.3996 - val_accuracy: 0.5008\n",
      "Epoch 112/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3943 - accuracy: 0.4931 - val_loss: 1.3940 - val_accuracy: 0.4995\n",
      "Epoch 113/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3915 - accuracy: 0.4944 - val_loss: 1.4010 - val_accuracy: 0.4960\n",
      "Epoch 114/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3895 - accuracy: 0.4912 - val_loss: 1.3977 - val_accuracy: 0.4963\n",
      "Epoch 115/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3900 - accuracy: 0.4929 - val_loss: 1.3983 - val_accuracy: 0.4984\n",
      "Epoch 116/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3942 - accuracy: 0.4900 - val_loss: 1.4171 - val_accuracy: 0.4840\n",
      "Epoch 117/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3906 - accuracy: 0.4942 - val_loss: 1.3987 - val_accuracy: 0.4897\n",
      "Epoch 118/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3868 - accuracy: 0.4965 - val_loss: 1.3914 - val_accuracy: 0.4984\n",
      "Epoch 119/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3860 - accuracy: 0.4922 - val_loss: 1.4222 - val_accuracy: 0.4907\n",
      "Epoch 120/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3872 - accuracy: 0.4930 - val_loss: 1.3933 - val_accuracy: 0.4936\n",
      "Epoch 121/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3826 - accuracy: 0.4930 - val_loss: 1.3877 - val_accuracy: 0.4911\n",
      "Epoch 122/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3790 - accuracy: 0.4934 - val_loss: 1.3897 - val_accuracy: 0.4944\n",
      "Epoch 123/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3781 - accuracy: 0.4945 - val_loss: 1.4239 - val_accuracy: 0.4837\n",
      "Epoch 124/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3779 - accuracy: 0.4963 - val_loss: 1.3836 - val_accuracy: 0.4974\n",
      "Epoch 125/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3787 - accuracy: 0.4917 - val_loss: 1.3852 - val_accuracy: 0.4950\n",
      "Epoch 126/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3733 - accuracy: 0.4952 - val_loss: 1.3738 - val_accuracy: 0.5002\n",
      "Epoch 127/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3696 - accuracy: 0.4978 - val_loss: 1.3963 - val_accuracy: 0.4907\n",
      "Epoch 128/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3703 - accuracy: 0.4977 - val_loss: 1.3759 - val_accuracy: 0.5014\n",
      "Epoch 129/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3723 - accuracy: 0.4963 - val_loss: 1.3725 - val_accuracy: 0.5005\n",
      "Epoch 130/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3694 - accuracy: 0.4983 - val_loss: 1.3909 - val_accuracy: 0.4938\n",
      "Epoch 131/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3688 - accuracy: 0.4964 - val_loss: 1.3745 - val_accuracy: 0.5016\n",
      "Epoch 132/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3703 - accuracy: 0.4980 - val_loss: 1.3718 - val_accuracy: 0.5044\n",
      "Epoch 133/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3681 - accuracy: 0.4955 - val_loss: 1.3687 - val_accuracy: 0.5006\n",
      "Epoch 134/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3681 - accuracy: 0.4942 - val_loss: 1.3736 - val_accuracy: 0.4966\n",
      "Epoch 135/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3675 - accuracy: 0.4999 - val_loss: 1.3746 - val_accuracy: 0.4970\n",
      "Epoch 136/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3696 - accuracy: 0.4942 - val_loss: 1.3901 - val_accuracy: 0.4969\n",
      "Epoch 137/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3691 - accuracy: 0.4949 - val_loss: 1.3796 - val_accuracy: 0.4958\n",
      "Epoch 138/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3677 - accuracy: 0.4949 - val_loss: 1.3677 - val_accuracy: 0.5030\n",
      "Epoch 139/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3691 - accuracy: 0.4965 - val_loss: 1.3817 - val_accuracy: 0.4933\n",
      "Epoch 140/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3659 - accuracy: 0.4942 - val_loss: 1.3777 - val_accuracy: 0.4964\n",
      "Epoch 141/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3634 - accuracy: 0.4996 - val_loss: 1.3666 - val_accuracy: 0.5050\n",
      "Epoch 142/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3650 - accuracy: 0.4981 - val_loss: 1.4291 - val_accuracy: 0.4843\n",
      "Epoch 143/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3683 - accuracy: 0.4968 - val_loss: 1.3840 - val_accuracy: 0.4958\n",
      "Epoch 144/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3671 - accuracy: 0.4966 - val_loss: 1.3662 - val_accuracy: 0.5005\n",
      "Epoch 145/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3597 - accuracy: 0.4982 - val_loss: 1.3629 - val_accuracy: 0.5048\n",
      "Epoch 146/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3600 - accuracy: 0.4986 - val_loss: 1.3651 - val_accuracy: 0.5020\n",
      "Epoch 147/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3613 - accuracy: 0.4967 - val_loss: 1.3670 - val_accuracy: 0.4997\n",
      "Epoch 148/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3616 - accuracy: 0.4996 - val_loss: 1.3769 - val_accuracy: 0.4944\n",
      "Epoch 149/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3620 - accuracy: 0.5004 - val_loss: 1.3663 - val_accuracy: 0.5025\n",
      "Epoch 150/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3618 - accuracy: 0.4972 - val_loss: 1.3961 - val_accuracy: 0.4947\n",
      "Epoch 151/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3650 - accuracy: 0.4974 - val_loss: 1.3742 - val_accuracy: 0.4983\n",
      "Epoch 152/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3681 - accuracy: 0.4955 - val_loss: 1.3752 - val_accuracy: 0.4944\n",
      "Epoch 153/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3654 - accuracy: 0.4985 - val_loss: 1.3720 - val_accuracy: 0.5002\n",
      "Epoch 154/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3580 - accuracy: 0.5015 - val_loss: 1.3862 - val_accuracy: 0.4953\n",
      "Epoch 155/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3581 - accuracy: 0.5008 - val_loss: 1.3602 - val_accuracy: 0.5017\n",
      "Epoch 156/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3653 - accuracy: 0.4965 - val_loss: 1.3636 - val_accuracy: 0.5019\n",
      "Epoch 157/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3556 - accuracy: 0.5025 - val_loss: 1.3664 - val_accuracy: 0.4988\n",
      "Epoch 158/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3596 - accuracy: 0.4998 - val_loss: 1.3611 - val_accuracy: 0.5031\n",
      "Epoch 159/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3576 - accuracy: 0.4997 - val_loss: 1.3588 - val_accuracy: 0.5086\n",
      "Epoch 160/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3598 - accuracy: 0.4989 - val_loss: 1.3602 - val_accuracy: 0.5065\n",
      "Epoch 161/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3595 - accuracy: 0.5018 - val_loss: 1.3885 - val_accuracy: 0.4958\n",
      "Epoch 162/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3615 - accuracy: 0.4979 - val_loss: 1.3710 - val_accuracy: 0.4949\n",
      "Epoch 163/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3580 - accuracy: 0.5012 - val_loss: 1.3589 - val_accuracy: 0.5028\n",
      "Epoch 164/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3564 - accuracy: 0.4986 - val_loss: 1.3908 - val_accuracy: 0.4913\n",
      "Epoch 165/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3590 - accuracy: 0.4993 - val_loss: 1.3558 - val_accuracy: 0.5050\n",
      "Epoch 166/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3566 - accuracy: 0.5023 - val_loss: 1.3639 - val_accuracy: 0.5037\n",
      "Epoch 167/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3536 - accuracy: 0.4989 - val_loss: 1.3590 - val_accuracy: 0.5037\n",
      "Epoch 168/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3546 - accuracy: 0.4992 - val_loss: 1.3621 - val_accuracy: 0.5048\n",
      "Epoch 169/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3526 - accuracy: 0.5023 - val_loss: 1.3537 - val_accuracy: 0.5039\n",
      "Epoch 170/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3554 - accuracy: 0.5008 - val_loss: 1.3652 - val_accuracy: 0.5090\n",
      "Epoch 171/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3553 - accuracy: 0.5002 - val_loss: 1.3678 - val_accuracy: 0.4977\n",
      "Epoch 172/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3633 - accuracy: 0.4994 - val_loss: 1.3637 - val_accuracy: 0.5014\n",
      "Epoch 173/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3563 - accuracy: 0.4992 - val_loss: 1.3803 - val_accuracy: 0.4967\n",
      "Epoch 174/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3597 - accuracy: 0.4979 - val_loss: 1.3546 - val_accuracy: 0.5037\n",
      "Epoch 175/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3522 - accuracy: 0.5008 - val_loss: 1.3516 - val_accuracy: 0.5059\n",
      "Epoch 176/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3559 - accuracy: 0.5029 - val_loss: 1.3600 - val_accuracy: 0.5065\n",
      "Epoch 177/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3512 - accuracy: 0.5015 - val_loss: 1.3559 - val_accuracy: 0.5030\n",
      "Epoch 178/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3511 - accuracy: 0.5028 - val_loss: 1.3591 - val_accuracy: 0.5017\n",
      "Epoch 179/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3523 - accuracy: 0.5005 - val_loss: 1.3566 - val_accuracy: 0.5045\n",
      "Epoch 180/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3514 - accuracy: 0.5018 - val_loss: 1.3518 - val_accuracy: 0.5062\n",
      "Epoch 181/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3502 - accuracy: 0.5035 - val_loss: 1.3489 - val_accuracy: 0.5089\n",
      "Epoch 182/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3519 - accuracy: 0.5018 - val_loss: 1.3549 - val_accuracy: 0.4994\n",
      "Epoch 183/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3495 - accuracy: 0.5024 - val_loss: 1.3556 - val_accuracy: 0.5111\n",
      "Epoch 184/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3519 - accuracy: 0.5033 - val_loss: 1.3543 - val_accuracy: 0.5023\n",
      "Epoch 185/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3511 - accuracy: 0.5030 - val_loss: 1.3560 - val_accuracy: 0.5042\n",
      "Epoch 186/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3520 - accuracy: 0.5035 - val_loss: 1.3548 - val_accuracy: 0.4998\n",
      "Epoch 187/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3527 - accuracy: 0.5030 - val_loss: 1.3556 - val_accuracy: 0.5047\n",
      "Epoch 188/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3500 - accuracy: 0.5052 - val_loss: 1.3735 - val_accuracy: 0.5022\n",
      "Epoch 189/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3485 - accuracy: 0.5048 - val_loss: 1.3514 - val_accuracy: 0.5014\n",
      "Epoch 190/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3493 - accuracy: 0.5044 - val_loss: 1.3697 - val_accuracy: 0.5014\n",
      "Epoch 191/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3523 - accuracy: 0.5011 - val_loss: 1.3542 - val_accuracy: 0.5051\n",
      "Epoch 192/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3513 - accuracy: 0.5020 - val_loss: 1.3532 - val_accuracy: 0.5058\n",
      "Epoch 193/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3506 - accuracy: 0.5038 - val_loss: 1.3619 - val_accuracy: 0.5026\n",
      "Epoch 194/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3501 - accuracy: 0.5033 - val_loss: 1.3642 - val_accuracy: 0.4981\n",
      "Epoch 195/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3506 - accuracy: 0.5025 - val_loss: 1.3576 - val_accuracy: 0.5044\n",
      "Epoch 196/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3460 - accuracy: 0.5052 - val_loss: 1.3855 - val_accuracy: 0.4986\n",
      "Epoch 197/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3485 - accuracy: 0.5048 - val_loss: 1.3475 - val_accuracy: 0.5062\n",
      "Epoch 198/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3500 - accuracy: 0.5049 - val_loss: 1.3518 - val_accuracy: 0.5090\n",
      "Epoch 199/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3482 - accuracy: 0.5025 - val_loss: 1.3627 - val_accuracy: 0.5011\n",
      "Epoch 200/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3475 - accuracy: 0.5053 - val_loss: 1.3476 - val_accuracy: 0.5092\n",
      "Epoch 201/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3462 - accuracy: 0.5031 - val_loss: 1.3494 - val_accuracy: 0.5090\n",
      "Epoch 202/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3451 - accuracy: 0.5045 - val_loss: 1.3607 - val_accuracy: 0.4984\n",
      "Epoch 203/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3463 - accuracy: 0.5049 - val_loss: 1.3523 - val_accuracy: 0.5054\n",
      "Epoch 204/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3476 - accuracy: 0.5027 - val_loss: 1.3447 - val_accuracy: 0.5072\n",
      "Epoch 205/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3422 - accuracy: 0.5062 - val_loss: 1.3480 - val_accuracy: 0.5092\n",
      "Epoch 206/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3459 - accuracy: 0.5025 - val_loss: 1.3636 - val_accuracy: 0.5073\n",
      "Epoch 207/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3460 - accuracy: 0.5060 - val_loss: 1.3490 - val_accuracy: 0.5089\n",
      "Epoch 208/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3462 - accuracy: 0.5028 - val_loss: 1.3520 - val_accuracy: 0.5025\n",
      "Epoch 209/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3434 - accuracy: 0.5031 - val_loss: 1.3497 - val_accuracy: 0.5072\n",
      "Epoch 210/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3484 - accuracy: 0.5069 - val_loss: 1.3529 - val_accuracy: 0.5073\n",
      "Epoch 211/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3486 - accuracy: 0.5032 - val_loss: 1.3471 - val_accuracy: 0.5111\n",
      "Epoch 212/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3436 - accuracy: 0.5033 - val_loss: 1.3503 - val_accuracy: 0.5104\n",
      "Epoch 213/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3447 - accuracy: 0.5059 - val_loss: 1.3448 - val_accuracy: 0.5084\n",
      "Epoch 214/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3491 - accuracy: 0.4999 - val_loss: 1.3455 - val_accuracy: 0.5042\n",
      "Epoch 215/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3443 - accuracy: 0.5031 - val_loss: 1.3594 - val_accuracy: 0.5053\n",
      "Epoch 216/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3456 - accuracy: 0.5043 - val_loss: 1.3753 - val_accuracy: 0.5034\n",
      "Epoch 217/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3447 - accuracy: 0.5052 - val_loss: 1.3456 - val_accuracy: 0.5107\n",
      "Epoch 218/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3435 - accuracy: 0.5050 - val_loss: 1.3650 - val_accuracy: 0.5031\n",
      "Epoch 219/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3436 - accuracy: 0.5025 - val_loss: 1.3503 - val_accuracy: 0.5011\n",
      "Epoch 220/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3483 - accuracy: 0.5049 - val_loss: 1.3412 - val_accuracy: 0.5098\n",
      "Epoch 221/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3432 - accuracy: 0.5025 - val_loss: 1.3524 - val_accuracy: 0.5100\n",
      "Epoch 222/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3435 - accuracy: 0.5054 - val_loss: 1.3672 - val_accuracy: 0.5103\n",
      "Epoch 223/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3440 - accuracy: 0.5048 - val_loss: 1.3585 - val_accuracy: 0.5047\n",
      "Epoch 224/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3430 - accuracy: 0.5042 - val_loss: 1.3486 - val_accuracy: 0.5098\n",
      "Epoch 225/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3418 - accuracy: 0.5021 - val_loss: 1.3482 - val_accuracy: 0.5068\n",
      "Epoch 226/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3425 - accuracy: 0.5057 - val_loss: 1.3458 - val_accuracy: 0.5121\n",
      "Epoch 227/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3462 - accuracy: 0.5048 - val_loss: 1.3571 - val_accuracy: 0.5040\n",
      "Epoch 228/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3448 - accuracy: 0.5040 - val_loss: 1.3561 - val_accuracy: 0.5005\n",
      "Epoch 229/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3434 - accuracy: 0.5049 - val_loss: 1.3526 - val_accuracy: 0.5034\n",
      "Epoch 230/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3432 - accuracy: 0.5055 - val_loss: 1.3442 - val_accuracy: 0.5062\n",
      "Epoch 231/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3440 - accuracy: 0.5028 - val_loss: 1.3485 - val_accuracy: 0.5062\n",
      "Epoch 232/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3415 - accuracy: 0.5050 - val_loss: 1.3521 - val_accuracy: 0.5059\n",
      "Epoch 233/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3461 - accuracy: 0.5052 - val_loss: 1.3571 - val_accuracy: 0.5039\n",
      "Epoch 234/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3410 - accuracy: 0.5050 - val_loss: 1.3487 - val_accuracy: 0.5086\n",
      "Epoch 235/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3389 - accuracy: 0.5077 - val_loss: 1.3432 - val_accuracy: 0.5145\n",
      "Epoch 236/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3392 - accuracy: 0.5069 - val_loss: 1.3616 - val_accuracy: 0.5014\n",
      "Epoch 237/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3419 - accuracy: 0.5054 - val_loss: 1.3914 - val_accuracy: 0.4952\n",
      "Epoch 238/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3449 - accuracy: 0.5071 - val_loss: 1.3455 - val_accuracy: 0.5078\n",
      "Epoch 239/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3429 - accuracy: 0.5063 - val_loss: 1.3490 - val_accuracy: 0.5062\n",
      "Epoch 240/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3411 - accuracy: 0.5051 - val_loss: 1.3528 - val_accuracy: 0.5020\n",
      "Epoch 241/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3407 - accuracy: 0.5045 - val_loss: 1.3437 - val_accuracy: 0.5076\n",
      "Epoch 242/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3426 - accuracy: 0.5064 - val_loss: 1.3440 - val_accuracy: 0.5148\n",
      "Epoch 243/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3424 - accuracy: 0.5081 - val_loss: 1.3409 - val_accuracy: 0.5104\n",
      "Epoch 244/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3436 - accuracy: 0.5040 - val_loss: 1.3446 - val_accuracy: 0.5084\n",
      "Epoch 245/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3420 - accuracy: 0.5069 - val_loss: 1.3408 - val_accuracy: 0.5103\n",
      "Epoch 246/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3389 - accuracy: 0.5038 - val_loss: 1.3448 - val_accuracy: 0.5120\n",
      "Epoch 247/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3462 - accuracy: 0.5046 - val_loss: 1.3462 - val_accuracy: 0.5142\n",
      "Epoch 248/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3418 - accuracy: 0.5051 - val_loss: 1.3523 - val_accuracy: 0.5040\n",
      "Epoch 249/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3377 - accuracy: 0.5061 - val_loss: 1.3568 - val_accuracy: 0.5053\n",
      "Epoch 250/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3416 - accuracy: 0.5064 - val_loss: 1.3417 - val_accuracy: 0.5092\n",
      "Epoch 251/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3363 - accuracy: 0.5054 - val_loss: 1.3512 - val_accuracy: 0.5101\n",
      "Epoch 252/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3373 - accuracy: 0.5058 - val_loss: 1.3485 - val_accuracy: 0.5092\n",
      "Epoch 253/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3375 - accuracy: 0.5078 - val_loss: 1.3385 - val_accuracy: 0.5126\n",
      "Epoch 254/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3378 - accuracy: 0.5133 - val_loss: 1.3404 - val_accuracy: 0.5163\n",
      "Epoch 255/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3348 - accuracy: 0.5108 - val_loss: 1.3345 - val_accuracy: 0.5210\n",
      "Epoch 256/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3331 - accuracy: 0.5116 - val_loss: 1.3361 - val_accuracy: 0.5174\n",
      "Epoch 257/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3355 - accuracy: 0.5101 - val_loss: 1.3352 - val_accuracy: 0.5159\n",
      "Epoch 258/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3347 - accuracy: 0.5118 - val_loss: 1.3372 - val_accuracy: 0.5162\n",
      "Epoch 259/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3348 - accuracy: 0.5131 - val_loss: 1.3377 - val_accuracy: 0.5121\n",
      "Epoch 260/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3303 - accuracy: 0.5107 - val_loss: 1.3406 - val_accuracy: 0.5142\n",
      "Epoch 261/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3326 - accuracy: 0.5146 - val_loss: 1.3557 - val_accuracy: 0.5134\n",
      "Epoch 262/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3302 - accuracy: 0.5140 - val_loss: 1.3381 - val_accuracy: 0.5109\n",
      "Epoch 263/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3298 - accuracy: 0.5131 - val_loss: 1.3480 - val_accuracy: 0.5090\n",
      "Epoch 264/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3345 - accuracy: 0.5102 - val_loss: 1.3538 - val_accuracy: 0.5140\n",
      "Epoch 265/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3290 - accuracy: 0.5122 - val_loss: 1.3452 - val_accuracy: 0.5209\n",
      "Epoch 266/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3327 - accuracy: 0.5159 - val_loss: 1.3542 - val_accuracy: 0.5115\n",
      "Epoch 267/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3310 - accuracy: 0.5124 - val_loss: 1.3353 - val_accuracy: 0.5198\n",
      "Epoch 268/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3315 - accuracy: 0.5151 - val_loss: 1.3279 - val_accuracy: 0.5226\n",
      "Epoch 269/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3269 - accuracy: 0.5154 - val_loss: 1.3430 - val_accuracy: 0.5160\n",
      "Epoch 270/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3281 - accuracy: 0.5135 - val_loss: 1.3568 - val_accuracy: 0.5103\n",
      "Epoch 271/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3279 - accuracy: 0.5156 - val_loss: 1.3298 - val_accuracy: 0.5174\n",
      "Epoch 272/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3280 - accuracy: 0.5120 - val_loss: 1.3275 - val_accuracy: 0.5210\n",
      "Epoch 273/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3272 - accuracy: 0.5159 - val_loss: 1.3418 - val_accuracy: 0.5176\n",
      "Epoch 274/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3256 - accuracy: 0.5170 - val_loss: 1.3576 - val_accuracy: 0.5090\n",
      "Epoch 275/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3282 - accuracy: 0.5158 - val_loss: 1.3255 - val_accuracy: 0.5219\n",
      "Epoch 276/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3249 - accuracy: 0.5159 - val_loss: 1.3336 - val_accuracy: 0.5145\n",
      "Epoch 277/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3253 - accuracy: 0.5174 - val_loss: 1.3324 - val_accuracy: 0.5254\n",
      "Epoch 278/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3277 - accuracy: 0.5158 - val_loss: 1.3259 - val_accuracy: 0.5224\n",
      "Epoch 279/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3223 - accuracy: 0.5188 - val_loss: 1.3295 - val_accuracy: 0.5282\n",
      "Epoch 280/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3275 - accuracy: 0.5143 - val_loss: 1.3291 - val_accuracy: 0.5207\n",
      "Epoch 281/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3254 - accuracy: 0.5157 - val_loss: 1.3338 - val_accuracy: 0.5199\n",
      "Epoch 282/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3315 - accuracy: 0.5143 - val_loss: 1.3585 - val_accuracy: 0.5148\n",
      "Epoch 283/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3269 - accuracy: 0.5163 - val_loss: 1.3261 - val_accuracy: 0.5244\n",
      "Epoch 284/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3254 - accuracy: 0.5163 - val_loss: 1.3492 - val_accuracy: 0.5149\n",
      "Epoch 285/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3220 - accuracy: 0.5155 - val_loss: 1.3246 - val_accuracy: 0.5252\n",
      "Epoch 286/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3228 - accuracy: 0.5169 - val_loss: 1.3350 - val_accuracy: 0.5167\n",
      "Epoch 287/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3248 - accuracy: 0.5175 - val_loss: 1.3321 - val_accuracy: 0.5195\n",
      "Epoch 288/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3255 - accuracy: 0.5154 - val_loss: 1.3523 - val_accuracy: 0.5145\n",
      "Epoch 289/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3272 - accuracy: 0.5157 - val_loss: 1.3236 - val_accuracy: 0.5230\n",
      "Epoch 290/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3257 - accuracy: 0.5157 - val_loss: 1.3284 - val_accuracy: 0.5210\n",
      "Epoch 291/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3273 - accuracy: 0.5175 - val_loss: 1.3215 - val_accuracy: 0.5252\n",
      "Epoch 292/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3283 - accuracy: 0.5143 - val_loss: 1.3206 - val_accuracy: 0.5249\n",
      "Epoch 293/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3238 - accuracy: 0.5171 - val_loss: 1.3234 - val_accuracy: 0.5232\n",
      "Epoch 294/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3222 - accuracy: 0.5183 - val_loss: 1.3251 - val_accuracy: 0.5235\n",
      "Epoch 295/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3259 - accuracy: 0.5178 - val_loss: 1.3223 - val_accuracy: 0.5246\n",
      "Epoch 296/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3232 - accuracy: 0.5185 - val_loss: 1.3260 - val_accuracy: 0.5233\n",
      "Epoch 297/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3253 - accuracy: 0.5173 - val_loss: 1.3299 - val_accuracy: 0.5219\n",
      "Epoch 298/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3243 - accuracy: 0.5191 - val_loss: 1.3253 - val_accuracy: 0.5213\n",
      "Epoch 299/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3198 - accuracy: 0.5207 - val_loss: 1.3259 - val_accuracy: 0.5207\n",
      "Epoch 300/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3258 - accuracy: 0.5140 - val_loss: 1.3333 - val_accuracy: 0.5210\n",
      "Epoch 301/498\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.3271 - accuracy: 0.5146 - val_loss: 1.3212 - val_accuracy: 0.5254\n",
      "Epoch 302/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3194 - accuracy: 0.5165 - val_loss: 1.3230 - val_accuracy: 0.5224\n",
      "Epoch 303/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3233 - accuracy: 0.5160 - val_loss: 1.3241 - val_accuracy: 0.5237\n",
      "Epoch 304/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3210 - accuracy: 0.5181 - val_loss: 1.3344 - val_accuracy: 0.5171\n",
      "Epoch 305/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3252 - accuracy: 0.5158 - val_loss: 1.3292 - val_accuracy: 0.5232\n",
      "Epoch 306/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3248 - accuracy: 0.5172 - val_loss: 1.3353 - val_accuracy: 0.5184\n",
      "Epoch 307/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3215 - accuracy: 0.5171 - val_loss: 1.3361 - val_accuracy: 0.5176\n",
      "Epoch 308/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3183 - accuracy: 0.5162 - val_loss: 1.3389 - val_accuracy: 0.5145\n",
      "Epoch 309/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3183 - accuracy: 0.5175 - val_loss: 1.3518 - val_accuracy: 0.5134\n",
      "Epoch 310/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3241 - accuracy: 0.5147 - val_loss: 1.3260 - val_accuracy: 0.5230\n",
      "Epoch 311/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3276 - accuracy: 0.5187 - val_loss: 1.3325 - val_accuracy: 0.5174\n",
      "Epoch 312/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3204 - accuracy: 0.5160 - val_loss: 1.3594 - val_accuracy: 0.5084\n",
      "Epoch 313/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3209 - accuracy: 0.5187 - val_loss: 1.3271 - val_accuracy: 0.5188\n",
      "Epoch 314/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3209 - accuracy: 0.5169 - val_loss: 1.3234 - val_accuracy: 0.5235\n",
      "Epoch 315/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3208 - accuracy: 0.5173 - val_loss: 1.3227 - val_accuracy: 0.5235\n",
      "Epoch 316/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3218 - accuracy: 0.5169 - val_loss: 1.3277 - val_accuracy: 0.5265\n",
      "Epoch 317/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3172 - accuracy: 0.5226 - val_loss: 1.3282 - val_accuracy: 0.5257\n",
      "Epoch 318/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3192 - accuracy: 0.5192 - val_loss: 1.3467 - val_accuracy: 0.5129\n",
      "Epoch 319/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3239 - accuracy: 0.5174 - val_loss: 1.3364 - val_accuracy: 0.5153\n",
      "Epoch 320/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3214 - accuracy: 0.5198 - val_loss: 1.3203 - val_accuracy: 0.5272\n",
      "Epoch 321/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3219 - accuracy: 0.5173 - val_loss: 1.3266 - val_accuracy: 0.5219\n",
      "Epoch 322/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3157 - accuracy: 0.5182 - val_loss: 1.3318 - val_accuracy: 0.5212\n",
      "Epoch 323/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3215 - accuracy: 0.5187 - val_loss: 1.3452 - val_accuracy: 0.5184\n",
      "Epoch 324/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3159 - accuracy: 0.5185 - val_loss: 1.3315 - val_accuracy: 0.5191\n",
      "Epoch 325/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3212 - accuracy: 0.5198 - val_loss: 1.3237 - val_accuracy: 0.5229\n",
      "Epoch 326/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3159 - accuracy: 0.5201 - val_loss: 1.3319 - val_accuracy: 0.5223\n",
      "Epoch 327/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3215 - accuracy: 0.5182 - val_loss: 1.3228 - val_accuracy: 0.5244\n",
      "Epoch 328/498\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3206 - accuracy: 0.5197 - val_loss: 1.3186 - val_accuracy: 0.5240\n",
      "Epoch 329/498\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3179 - accuracy: 0.5208 - val_loss: 1.3257 - val_accuracy: 0.5238\n",
      "Epoch 330/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3160 - accuracy: 0.5214 - val_loss: 1.3196 - val_accuracy: 0.5252\n",
      "Epoch 331/498\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3180 - accuracy: 0.5186 - val_loss: 1.3322 - val_accuracy: 0.5167\n",
      "Epoch 332/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3181 - accuracy: 0.5193 - val_loss: 1.3205 - val_accuracy: 0.5243\n",
      "Epoch 333/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3157 - accuracy: 0.5185 - val_loss: 1.3315 - val_accuracy: 0.5223\n",
      "Epoch 334/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3182 - accuracy: 0.5224 - val_loss: 1.3558 - val_accuracy: 0.5103\n",
      "Epoch 335/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3175 - accuracy: 0.5172 - val_loss: 1.3279 - val_accuracy: 0.5285\n",
      "Epoch 336/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3177 - accuracy: 0.5199 - val_loss: 1.3290 - val_accuracy: 0.5241\n",
      "Epoch 337/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3193 - accuracy: 0.5189 - val_loss: 1.3351 - val_accuracy: 0.5205\n",
      "Epoch 338/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3183 - accuracy: 0.5191 - val_loss: 1.3214 - val_accuracy: 0.5294\n",
      "Epoch 339/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3192 - accuracy: 0.5180 - val_loss: 1.3225 - val_accuracy: 0.5216\n",
      "Epoch 340/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3140 - accuracy: 0.5226 - val_loss: 1.3218 - val_accuracy: 0.5246\n",
      "Epoch 341/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3173 - accuracy: 0.5205 - val_loss: 1.3162 - val_accuracy: 0.5238\n",
      "Epoch 342/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3201 - accuracy: 0.5205 - val_loss: 1.3228 - val_accuracy: 0.5207\n",
      "Epoch 343/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3145 - accuracy: 0.5205 - val_loss: 1.3240 - val_accuracy: 0.5238\n",
      "Epoch 344/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3182 - accuracy: 0.5202 - val_loss: 1.3405 - val_accuracy: 0.5182\n",
      "Epoch 345/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3173 - accuracy: 0.5208 - val_loss: 1.3340 - val_accuracy: 0.5201\n",
      "Epoch 346/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3167 - accuracy: 0.5190 - val_loss: 1.3379 - val_accuracy: 0.5146\n",
      "Epoch 347/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3172 - accuracy: 0.5215 - val_loss: 1.3261 - val_accuracy: 0.5252\n",
      "Epoch 348/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3191 - accuracy: 0.5176 - val_loss: 1.3241 - val_accuracy: 0.5210\n",
      "Epoch 349/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3177 - accuracy: 0.5195 - val_loss: 1.3329 - val_accuracy: 0.5224\n",
      "Epoch 350/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3183 - accuracy: 0.5227 - val_loss: 1.3219 - val_accuracy: 0.5232\n",
      "Epoch 351/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3169 - accuracy: 0.5205 - val_loss: 1.3205 - val_accuracy: 0.5215\n",
      "Epoch 352/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3226 - accuracy: 0.5176 - val_loss: 1.3204 - val_accuracy: 0.5221\n",
      "Epoch 353/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3202 - accuracy: 0.5186 - val_loss: 1.3226 - val_accuracy: 0.5215\n",
      "Epoch 354/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5196 - val_loss: 1.3259 - val_accuracy: 0.5224\n",
      "Epoch 355/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3157 - accuracy: 0.5205 - val_loss: 1.3166 - val_accuracy: 0.5265\n",
      "Epoch 356/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3154 - accuracy: 0.5192 - val_loss: 1.3578 - val_accuracy: 0.5100\n",
      "Epoch 357/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3180 - accuracy: 0.5192 - val_loss: 1.3363 - val_accuracy: 0.5170\n",
      "Epoch 358/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3172 - accuracy: 0.5219 - val_loss: 1.3307 - val_accuracy: 0.5216\n",
      "Epoch 359/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3138 - accuracy: 0.5191 - val_loss: 1.3198 - val_accuracy: 0.5274\n",
      "Epoch 360/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3158 - accuracy: 0.5219 - val_loss: 1.3227 - val_accuracy: 0.5237\n",
      "Epoch 361/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3133 - accuracy: 0.5194 - val_loss: 1.3294 - val_accuracy: 0.5221\n",
      "Epoch 362/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3149 - accuracy: 0.5218 - val_loss: 1.3183 - val_accuracy: 0.5263\n",
      "Epoch 363/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3167 - accuracy: 0.5209 - val_loss: 1.3194 - val_accuracy: 0.5260\n",
      "Epoch 364/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3193 - accuracy: 0.5182 - val_loss: 1.3330 - val_accuracy: 0.5209\n",
      "Epoch 365/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5196 - val_loss: 1.3254 - val_accuracy: 0.5258\n",
      "Epoch 366/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3165 - accuracy: 0.5227 - val_loss: 1.3250 - val_accuracy: 0.5221\n",
      "Epoch 367/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3160 - accuracy: 0.5191 - val_loss: 1.3220 - val_accuracy: 0.5235\n",
      "Epoch 368/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5192 - val_loss: 1.3259 - val_accuracy: 0.5235\n",
      "Epoch 369/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3151 - accuracy: 0.5211 - val_loss: 1.3229 - val_accuracy: 0.5226\n",
      "Epoch 370/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3134 - accuracy: 0.5236 - val_loss: 1.3274 - val_accuracy: 0.5233\n",
      "Epoch 371/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3164 - accuracy: 0.5209 - val_loss: 1.3175 - val_accuracy: 0.5248\n",
      "Epoch 372/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3144 - accuracy: 0.5206 - val_loss: 1.3312 - val_accuracy: 0.5196\n",
      "Epoch 373/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3122 - accuracy: 0.5192 - val_loss: 1.3475 - val_accuracy: 0.5109\n",
      "Epoch 374/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3173 - accuracy: 0.5196 - val_loss: 1.3444 - val_accuracy: 0.5179\n",
      "Epoch 375/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3143 - accuracy: 0.5228 - val_loss: 1.3275 - val_accuracy: 0.5193\n",
      "Epoch 376/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3143 - accuracy: 0.5203 - val_loss: 1.3242 - val_accuracy: 0.5268\n",
      "Epoch 377/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3145 - accuracy: 0.5224 - val_loss: 1.3367 - val_accuracy: 0.5168\n",
      "Epoch 378/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3106 - accuracy: 0.5221 - val_loss: 1.3182 - val_accuracy: 0.5300\n",
      "Epoch 379/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3157 - accuracy: 0.5217 - val_loss: 1.3198 - val_accuracy: 0.5241\n",
      "Epoch 380/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3155 - accuracy: 0.5215 - val_loss: 1.3183 - val_accuracy: 0.5266\n",
      "Epoch 381/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3152 - accuracy: 0.5219 - val_loss: 1.3228 - val_accuracy: 0.5257\n",
      "Epoch 382/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3135 - accuracy: 0.5200 - val_loss: 1.3283 - val_accuracy: 0.5224\n",
      "Epoch 383/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3164 - accuracy: 0.5183 - val_loss: 1.3200 - val_accuracy: 0.5268\n",
      "Epoch 384/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3164 - accuracy: 0.5209 - val_loss: 1.3255 - val_accuracy: 0.5277\n",
      "Epoch 385/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3149 - accuracy: 0.5194 - val_loss: 1.3176 - val_accuracy: 0.5255\n",
      "Epoch 386/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3166 - accuracy: 0.5222 - val_loss: 1.3298 - val_accuracy: 0.5240\n",
      "Epoch 387/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3146 - accuracy: 0.5218 - val_loss: 1.3178 - val_accuracy: 0.5226\n",
      "Epoch 388/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3149 - accuracy: 0.5203 - val_loss: 1.3514 - val_accuracy: 0.5112\n",
      "Epoch 389/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3133 - accuracy: 0.5228 - val_loss: 1.3243 - val_accuracy: 0.5258\n",
      "Epoch 390/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3128 - accuracy: 0.5235 - val_loss: 1.3192 - val_accuracy: 0.5218\n",
      "Epoch 391/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3122 - accuracy: 0.5213 - val_loss: 1.3192 - val_accuracy: 0.5240\n",
      "Epoch 392/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3189 - accuracy: 0.5172 - val_loss: 1.3440 - val_accuracy: 0.5184\n",
      "Epoch 393/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3154 - accuracy: 0.5219 - val_loss: 1.3268 - val_accuracy: 0.5224\n",
      "Epoch 394/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3127 - accuracy: 0.5209 - val_loss: 1.3304 - val_accuracy: 0.5185\n",
      "Epoch 395/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3131 - accuracy: 0.5227 - val_loss: 1.3279 - val_accuracy: 0.5176\n",
      "Epoch 396/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3156 - accuracy: 0.5202 - val_loss: 1.3301 - val_accuracy: 0.5227\n",
      "Epoch 397/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3173 - accuracy: 0.5191 - val_loss: 1.3563 - val_accuracy: 0.5090\n",
      "Epoch 398/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3134 - accuracy: 0.5248 - val_loss: 1.3644 - val_accuracy: 0.5031\n",
      "Epoch 399/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3194 - accuracy: 0.5206 - val_loss: 1.3427 - val_accuracy: 0.5177\n",
      "Epoch 400/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3114 - accuracy: 0.5197 - val_loss: 1.3195 - val_accuracy: 0.5280\n",
      "Epoch 401/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3090 - accuracy: 0.5219 - val_loss: 1.3142 - val_accuracy: 0.5293\n",
      "Epoch 402/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3173 - accuracy: 0.5235 - val_loss: 1.3431 - val_accuracy: 0.5191\n",
      "Epoch 403/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3116 - accuracy: 0.5225 - val_loss: 1.3141 - val_accuracy: 0.5319\n",
      "Epoch 404/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3098 - accuracy: 0.5212 - val_loss: 1.3132 - val_accuracy: 0.5307\n",
      "Epoch 405/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3113 - accuracy: 0.5222 - val_loss: 1.3228 - val_accuracy: 0.5297\n",
      "Epoch 406/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3125 - accuracy: 0.5229 - val_loss: 1.3357 - val_accuracy: 0.5191\n",
      "Epoch 407/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3113 - accuracy: 0.5231 - val_loss: 1.3614 - val_accuracy: 0.5083\n",
      "Epoch 408/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3130 - accuracy: 0.5193 - val_loss: 1.3329 - val_accuracy: 0.5196\n",
      "Epoch 409/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3126 - accuracy: 0.5233 - val_loss: 1.3434 - val_accuracy: 0.5168\n",
      "Epoch 410/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3127 - accuracy: 0.5209 - val_loss: 1.3625 - val_accuracy: 0.5112\n",
      "Epoch 411/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3121 - accuracy: 0.5250 - val_loss: 1.3353 - val_accuracy: 0.5201\n",
      "Epoch 412/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3127 - accuracy: 0.5206 - val_loss: 1.3309 - val_accuracy: 0.5226\n",
      "Epoch 413/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3115 - accuracy: 0.5224 - val_loss: 1.3198 - val_accuracy: 0.5311\n",
      "Epoch 414/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3089 - accuracy: 0.5258 - val_loss: 1.3285 - val_accuracy: 0.5226\n",
      "Epoch 415/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3124 - accuracy: 0.5205 - val_loss: 1.3170 - val_accuracy: 0.5291\n",
      "Epoch 416/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3111 - accuracy: 0.5228 - val_loss: 1.3178 - val_accuracy: 0.5310\n",
      "Epoch 417/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3098 - accuracy: 0.5219 - val_loss: 1.3321 - val_accuracy: 0.5237\n",
      "Epoch 418/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3110 - accuracy: 0.5237 - val_loss: 1.3172 - val_accuracy: 0.5283\n",
      "Epoch 419/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3146 - accuracy: 0.5225 - val_loss: 1.3231 - val_accuracy: 0.5246\n",
      "Epoch 420/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3108 - accuracy: 0.5227 - val_loss: 1.3244 - val_accuracy: 0.5296\n",
      "Epoch 421/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3115 - accuracy: 0.5225 - val_loss: 1.3136 - val_accuracy: 0.5276\n",
      "Epoch 422/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3107 - accuracy: 0.5190 - val_loss: 1.3137 - val_accuracy: 0.5280\n",
      "Epoch 423/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3103 - accuracy: 0.5236 - val_loss: 1.3163 - val_accuracy: 0.5325\n",
      "Epoch 424/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3133 - accuracy: 0.5207 - val_loss: 1.3265 - val_accuracy: 0.5241\n",
      "Epoch 425/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3117 - accuracy: 0.5247 - val_loss: 1.3189 - val_accuracy: 0.5286\n",
      "Epoch 426/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3118 - accuracy: 0.5217 - val_loss: 1.3177 - val_accuracy: 0.5232\n",
      "Epoch 427/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3109 - accuracy: 0.5224 - val_loss: 1.3206 - val_accuracy: 0.5235\n",
      "Epoch 428/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3106 - accuracy: 0.5223 - val_loss: 1.3381 - val_accuracy: 0.5215\n",
      "Epoch 429/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3140 - accuracy: 0.5228 - val_loss: 1.3299 - val_accuracy: 0.5196\n",
      "Epoch 430/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3113 - accuracy: 0.5222 - val_loss: 1.3209 - val_accuracy: 0.5255\n",
      "Epoch 431/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3074 - accuracy: 0.5228 - val_loss: 1.3146 - val_accuracy: 0.5283\n",
      "Epoch 432/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3089 - accuracy: 0.5240 - val_loss: 1.3302 - val_accuracy: 0.5260\n",
      "Epoch 433/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3116 - accuracy: 0.5204 - val_loss: 1.3335 - val_accuracy: 0.5190\n",
      "Epoch 434/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3100 - accuracy: 0.5227 - val_loss: 1.3205 - val_accuracy: 0.5268\n",
      "Epoch 435/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3093 - accuracy: 0.5258 - val_loss: 1.3229 - val_accuracy: 0.5291\n",
      "Epoch 436/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3091 - accuracy: 0.5235 - val_loss: 1.3173 - val_accuracy: 0.5255\n",
      "Epoch 437/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3081 - accuracy: 0.5227 - val_loss: 1.3212 - val_accuracy: 0.5229\n",
      "Epoch 438/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3066 - accuracy: 0.5253 - val_loss: 1.3223 - val_accuracy: 0.5202\n",
      "Epoch 439/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3105 - accuracy: 0.5216 - val_loss: 1.3262 - val_accuracy: 0.5193\n",
      "Epoch 440/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3102 - accuracy: 0.5243 - val_loss: 1.3274 - val_accuracy: 0.5202\n",
      "Epoch 441/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3115 - accuracy: 0.5218 - val_loss: 1.3168 - val_accuracy: 0.5227\n",
      "Epoch 442/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3105 - accuracy: 0.5234 - val_loss: 1.3272 - val_accuracy: 0.5252\n",
      "Epoch 443/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3072 - accuracy: 0.5246 - val_loss: 1.3374 - val_accuracy: 0.5210\n",
      "Epoch 444/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3112 - accuracy: 0.5233 - val_loss: 1.3244 - val_accuracy: 0.5272\n",
      "Epoch 445/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3086 - accuracy: 0.5255 - val_loss: 1.3168 - val_accuracy: 0.5254\n",
      "Epoch 446/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3143 - accuracy: 0.5204 - val_loss: 1.3204 - val_accuracy: 0.5252\n",
      "Epoch 447/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3077 - accuracy: 0.5234 - val_loss: 1.3140 - val_accuracy: 0.5263\n",
      "Epoch 448/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3103 - accuracy: 0.5200 - val_loss: 1.3215 - val_accuracy: 0.5246\n",
      "Epoch 449/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3081 - accuracy: 0.5227 - val_loss: 1.3202 - val_accuracy: 0.5207\n",
      "Epoch 450/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3089 - accuracy: 0.5224 - val_loss: 1.3154 - val_accuracy: 0.5258\n",
      "Epoch 451/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3114 - accuracy: 0.5226 - val_loss: 1.3209 - val_accuracy: 0.5207\n",
      "Epoch 452/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3099 - accuracy: 0.5251 - val_loss: 1.3244 - val_accuracy: 0.5233\n",
      "Epoch 453/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3096 - accuracy: 0.5259 - val_loss: 1.3185 - val_accuracy: 0.5288\n",
      "Epoch 454/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3064 - accuracy: 0.5229 - val_loss: 1.3158 - val_accuracy: 0.5313\n",
      "Epoch 455/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3069 - accuracy: 0.5258 - val_loss: 1.3292 - val_accuracy: 0.5218\n",
      "Epoch 456/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3087 - accuracy: 0.5217 - val_loss: 1.3571 - val_accuracy: 0.5128\n",
      "Epoch 457/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3105 - accuracy: 0.5217 - val_loss: 1.3192 - val_accuracy: 0.5251\n",
      "Epoch 458/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3087 - accuracy: 0.5228 - val_loss: 1.3184 - val_accuracy: 0.5307\n",
      "Epoch 459/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3121 - accuracy: 0.5232 - val_loss: 1.3339 - val_accuracy: 0.5167\n",
      "Epoch 460/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3061 - accuracy: 0.5251 - val_loss: 1.3231 - val_accuracy: 0.5257\n",
      "Epoch 461/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3109 - accuracy: 0.5231 - val_loss: 1.3245 - val_accuracy: 0.5237\n",
      "Epoch 462/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3092 - accuracy: 0.5217 - val_loss: 1.3130 - val_accuracy: 0.5318\n",
      "Epoch 463/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3111 - accuracy: 0.5227 - val_loss: 1.3333 - val_accuracy: 0.5207\n",
      "Epoch 464/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3080 - accuracy: 0.5213 - val_loss: 1.3542 - val_accuracy: 0.5167\n",
      "Epoch 465/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3111 - accuracy: 0.5210 - val_loss: 1.3337 - val_accuracy: 0.5202\n",
      "Epoch 466/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3123 - accuracy: 0.5250 - val_loss: 1.3282 - val_accuracy: 0.5248\n",
      "Epoch 467/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3069 - accuracy: 0.5246 - val_loss: 1.3328 - val_accuracy: 0.5198\n",
      "Epoch 468/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3112 - accuracy: 0.5256 - val_loss: 1.3220 - val_accuracy: 0.5215\n",
      "Epoch 469/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3079 - accuracy: 0.5235 - val_loss: 1.3257 - val_accuracy: 0.5276\n",
      "Epoch 470/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3091 - accuracy: 0.5225 - val_loss: 1.3177 - val_accuracy: 0.5271\n",
      "Epoch 471/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3082 - accuracy: 0.5219 - val_loss: 1.3160 - val_accuracy: 0.5279\n",
      "Epoch 472/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3095 - accuracy: 0.5222 - val_loss: 1.3204 - val_accuracy: 0.5263\n",
      "Epoch 473/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3062 - accuracy: 0.5250 - val_loss: 1.3173 - val_accuracy: 0.5293\n",
      "Epoch 474/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3107 - accuracy: 0.5217 - val_loss: 1.3418 - val_accuracy: 0.5198\n",
      "Epoch 475/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3105 - accuracy: 0.5239 - val_loss: 1.3154 - val_accuracy: 0.5244\n",
      "Epoch 476/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3074 - accuracy: 0.5237 - val_loss: 1.3140 - val_accuracy: 0.5269\n",
      "Epoch 477/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3091 - accuracy: 0.5260 - val_loss: 1.3241 - val_accuracy: 0.5229\n",
      "Epoch 478/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3099 - accuracy: 0.5216 - val_loss: 1.3266 - val_accuracy: 0.5240\n",
      "Epoch 479/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3150 - accuracy: 0.5179 - val_loss: 1.3565 - val_accuracy: 0.5131\n",
      "Epoch 480/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3087 - accuracy: 0.5225 - val_loss: 1.3262 - val_accuracy: 0.5244\n",
      "Epoch 481/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3079 - accuracy: 0.5224 - val_loss: 1.3261 - val_accuracy: 0.5224\n",
      "Epoch 482/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3066 - accuracy: 0.5239 - val_loss: 1.3223 - val_accuracy: 0.5274\n",
      "Epoch 483/498\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3091 - accuracy: 0.5236 - val_loss: 1.3293 - val_accuracy: 0.5241\n",
      "Epoch 484/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3087 - accuracy: 0.5217 - val_loss: 1.3176 - val_accuracy: 0.5280\n",
      "Epoch 485/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3086 - accuracy: 0.5253 - val_loss: 1.3416 - val_accuracy: 0.5160\n",
      "Epoch 486/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3111 - accuracy: 0.5233 - val_loss: 1.3230 - val_accuracy: 0.5212\n",
      "Epoch 487/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3111 - accuracy: 0.5205 - val_loss: 1.3214 - val_accuracy: 0.5199\n",
      "Epoch 488/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3079 - accuracy: 0.5248 - val_loss: 1.3128 - val_accuracy: 0.5288\n",
      "Epoch 489/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3061 - accuracy: 0.5263 - val_loss: 1.3174 - val_accuracy: 0.5268\n",
      "Epoch 490/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3060 - accuracy: 0.5258 - val_loss: 1.3185 - val_accuracy: 0.5229\n",
      "Epoch 491/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3088 - accuracy: 0.5231 - val_loss: 1.3266 - val_accuracy: 0.5229\n",
      "Epoch 492/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3065 - accuracy: 0.5268 - val_loss: 1.3350 - val_accuracy: 0.5199\n",
      "Epoch 493/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3057 - accuracy: 0.5250 - val_loss: 1.3216 - val_accuracy: 0.5272\n",
      "Epoch 494/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3091 - accuracy: 0.5217 - val_loss: 1.3172 - val_accuracy: 0.5279\n",
      "Epoch 495/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3095 - accuracy: 0.5212 - val_loss: 1.3165 - val_accuracy: 0.5324\n",
      "Epoch 496/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3085 - accuracy: 0.5219 - val_loss: 1.3262 - val_accuracy: 0.5233\n",
      "Epoch 497/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3096 - accuracy: 0.5242 - val_loss: 1.3264 - val_accuracy: 0.5255\n",
      "Epoch 498/498\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3077 - accuracy: 0.5240 - val_loss: 1.3112 - val_accuracy: 0.5302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e725f283a0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_epoch = hist1.history[\"val_accuracy\"]\n",
    "best_epoch_b = val_acc_epoch.index(max(val_acc_epoch)) + 1\n",
    "\n",
    "model_b = build_model_b()\n",
    "model_b.fit(X_train, y_train, epochs=best_epoch_b, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e98cb18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 6, 7], dtype=int64),\n",
       " array([4558, 2466,  220,    3,    3, 2339], dtype=int64))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(model_b.predict(X_test), axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "323d6b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8ZElEQVR4nO3dd3xUVdrA8d+TSaP3EggSQESwgBhQbAu2BVZFrOjq6q6KDV/dV1zBXcvq+i7r2is2XHctiCLIKgqIKBZUAgalSpESagi9pM7z/nFvMjXJBDKZSfJ8P5985t5zz73zjGWeOefec46oKsYYY0ykEmIdgDHGmNrFEocxxpgqscRhjDGmSixxGGOMqRJLHMYYY6okMdYB1ITWrVtrRkZGrMMwxphaZcGCBdtVtU1web1IHBkZGWRlZcU6DGOMqVVEZF24cuuqMsYYUyWWOIwxxlSJJQ5jjDFVEtXEISKDRWSFiKwSkTFhjg8Ukd0iku3+3eeWdxKROSKyTESWiMjtfuc8ICIb/c4ZGs3PYIwxJlDUbo6LiAd4DjgHyAHmi8g0VV0aVPVLVT0vqKwYuFNVF4pIE2CBiMzyO/cJVX00WrEbY4wpXzRbHP2BVaq6RlULgYnAsEhOVNXNqrrQ3d4LLAM6Ri1SY4wxEYtm4ugIbPDbzyH8l/8AEVkkIh+LyDHBB0UkAzgB+M6veJSI/CgiE0SkRbg3F5GRIpIlIlm5ubmH/imMMcYEiGbikDBlwXO4LwQ6q2pv4BlgasAFRBoDk4E7VHWPW/wC0A3oA2wGHgv35qr6kqpmqmpmmzYh41eMMabu2p8HS6ZE7fLRTBw5QCe//XRgk38FVd2jqvvc7elAkoi0BhCRJJyk8aaqvu93zlZVLVFVL/AyTpeYMcYYgIM74dWz4d1rYe/WqLxFNBPHfKC7iHQRkWRgBDDNv4KItBcRcbf7u/HkuWWvAstU9fGgc9L8docDi6P4GYwxJv7lroBvngVVePJ42LHGKS8pjMrbRe2pKlUtFpFRwAzAA0xQ1SUicpN7fDxwCXCziBQDB4ERqqoichpwNfCTiGS7l7zHbZU8IiJ9cLq91gI3RuszGGNMXCsuhMJ9MOMeWPUpLP8ICvb4Hc+PyttKfVg6NjMzU22uKmNMnfPOVbDsv9CsE+zeEHp85BfQoc8hX15EFqhqZnC5jRw3xph4VlwAf2sHiybCw2nw3UvgLYE5/+ckDYD95Tw5WnQwKiHVi9lxjTEmruzPA08SpDatvG7eKqfLacY9UHQAPr4LWnWFL/7hq1Nel1TRgeqJN4i1OIwxJlhxAaz/1tle+B947TdVO3/7KvhxEmxZDPu2wS9fBh7/Z1d4tl/4c798DNZ87mwXHoAN7hC25Ea+OtP/FFEYhfn7qxZ3hCxxGGPqrpIiX3fNT+/5unZKffMMPNDM6frx98kYmPBrJwFMGwXrvoIZf3ZuRkfizYvh/Rtg/KnwaHd4/TznxjXAxoXO674toecVHoDZD8K/h8HOdfDK2fDhH32fpdSO1aHnnv3XkKK73prHnBXbIou5CixxGGPiR0kxeL3Vd703LoaH2zvbk69zbib7m/2g81q4L7B80w/O6xfjfGXznoU5D8NDbZ2EEk5JEfzrPNi5NvTYzrVOS+LlQWVF6vVCwT52fvYUr014nq2rFvrqP3U8bFvi29+7ubxPCcCCraH/3K5K/JReaRF0h1WRJQ5jTHiq8NHo0G6WaHqoFbx/vbN9YAdMvh7y94Svu205LHrH2d68CP6vI+xxv1wP7oT3roNfvnD2K2spFOzjkxkf8v7Lf3Per7QF8tO7AdX0h/9ASQHM/quvzrznnJbLxgWwdQmsDf/Pa/OOvUyd9n5A2a/uf5vtj/ajxdz7+P36sfzjjf+GPTcSbywIbVn0S/iZdk1TD/ma5bHEYYwJb80cmP8yzLoX9lUw35sq/DK3+loKiyc7r18/5XxxZ70aeLy4AHath+dPgikjfXUL9zlxgPNFvvg93znbAiflPlBYzDUTvsdbOhph7iMMnvdbLtr4TxjXCbb8GDa0vfvdm83LpsGDLSl+6SznpvXMv8DLZ/LuxzPL/ViLvv2U43YEHh/o/Y7WRb4JNY5M2BR8GtcV3lnuNf0dJIW7ikaGHojCkAtLHMYYn9wVTp//+u9g7ddO2aYf4NEjYdsyyFkQes7KmfD6+fDdeCjKD/11v2cTLHUnjVgyxXmiKNjf2sOnDwSWJXicV29xYPnbI+DJ43z7JcVwcBcAO0uS2VdQzNr1QUtl5/m6lh6YtoRe983gi59zKSlNdgv+FRpTGE0l8PHWxE2B48Mu3fBwuecO9synW0Jgd9NNiYEtjFsSAybXAKBRC99kGSUJyeVe/8j2zRkx/KKyfRX3n19BOS22w2CJwxjjUIWVs5ztn951un/8PX8yvHKm72kjcFoZb13mbM8YCw+3g6f7+I7n74bHe8Kkq2Hzj878Se9d67QaZj8E+7c728UH4asnAt5uj5t/SpZ9WFb2QfZGWP1ZQL2PJ78Kq2cDcO97Czj2/hmsXPNLYOyTryvbfPMbXxKJ5QDofZpKB9kR9tjBY0aUbT913dl8du4n7Lx8Gp6xG2DAqMDK4nyNjz6rCyce39tXfOzFzsaB8O9xOCxxGGMcXz0BM//sbJcUln8z9uBO57W4wOnGCrZno9Pq+Hmm7+YzwIunO6+/zIXsN+HLR+Gf3dDXQhfxfGzK17z4lTMS2rM5m6+zFjL351xun5gdUnfIUt+jqY0kn4EJP3COJ0zLyNWU/YzwfMYtnqkkS0m59Q7HUfmvV3h89Yi5NBZ37EXLroEHfzeNBpe+CKnNAJCGrTjzlAG06PkrSEqFXwe1ahq5s397iyG5ITywG8ash2Pd1sfB6k8cNgDQmLrE64WpNztfIOc9UXHdLx+DDn2hm/uUT9ZrvmN7N5d/U7rUd+OdJ43C2DB5LJ2WvQKN24U9vmXWU7jPOiEbQ6cDOmrhgywho2z/nfcnM8/bi7MSwjyG6qcxB7iv+cfgN+5tbfvBZGz5pGz/ofT5DN0+ocLrBEht5rScqmDm6HMg/D8a6HcDXXsc79u/5r/wxSOw+H0o3AudT3XKb/rauc9U2SDBsx+A9fPgaL+FVFObQcNWznYUWhw2V5UxtdlfW8KAW+Hch5z9Xet9/f/3bHJuNPe+whmlDM6YBkkABP7m/lL98xZISGTb/x1L25IwYwuCXfQytD/O6bqqhEoColW/aT7XezxnJPhuUC/3duLohDBzMUWg5JyH8cz6c4V1tNMAZMO88Af73wjfvxh6TkIS4i0KrX/heOhzhXOvKNj1n0H6ic72w2nOyO77d4GIM1AwbzV0HlDJJwJWfuqMFQG46Svn30ew/D3O/an2x0HDlpVfMwybq8qYusDrdW4Gg3NPQkvgm6d9x/f6ffHPfhCm3QZfuisTFOU7YxreuJhJMz/31Xu4PftfHsr+osh+RK5Yt5GC8YNCyvcmhn45+SeNpd7OEV0fCEgaQNWTRnKTsk1Pu6NDDi/x9PTt3LMJucp9AuvIcwAoTvQbpd0uaGHSE5yxIFLaEjjvCTjTr8uuzxXO65XvwuVvwl1rfMeapfu2b5kH1053kgZA47aRJQ2A7mfDfTvh5nnhkwY4LZWuvzrkpFERSxzGxKtNP8DujYFl7/7OGesAAWst7N64kowxH/HVwp98p69d7mzkLneSzMNut9HaL1n9deB4gkZbvscb5utgs4Z+6Xzw7TJSvKGT571V9KsKP87vCsdUeLzKznmw/GO3+q003aZnyOFjeveDy9+AYc85U3mkNIYxG2CY07+UmOD3z8I/cVz+Bpz/NIzNgYFjnbLeV8AZo+GU/4Gz7vPVPepc6HkeNGoFV0+B7uf67kcAtMiAjFOr8IGDJCRAu16Hfv5hsMRhTDSVFB16H/NLA53Rw/78p8wo9M1D1OzlTE6QlSxavqKsLHfzegD0wA4KdgUmoLFJb7PU25k92qCsLPhRUYBvvaFfuicnLA0pA5hYeFq5HwWgZbuOfH3muyHleunrLOpwefkndjwxtCy5MfQaVv45zTr6tpt28G0fcYrzWlwAPc8vaz0Azi/0Rm2h/fFw4fNw8atOIkjxu8fQ83znMeGUJtD/BudGdJL7z/Dch+D0csZcdDsTfvuu82VfB9jNcWOiaerNzqOtDVo6vz4veCay80rvPQaPYShVeCBkmowpKfezrPAoAEpU6CbOYLKNmzfyx0fe4d2UwEtML+lPZsLPDPQEPXbrR5qkBdxoBjg+cT0o5DY6ijb7fy4rv+H8gag+hMy6F1r3gO2+JMaNc5mZ5j4qWvo07TkPQXJD5JgL6Z3UAN56J3wQGac7o7L9lRQ6v9jT+0HOfKfsqvehZRcoCJo+pLQrCJwv+/XfBCTdAAkJcFPQyO+ifDhqCHQ5I/w59VDdSH/GxKvSKSsO7oCF/w5fZ8cvTiIAvJsXs2rR17B9Zdnh85/5isUbdzN5QU5Z2UPjHmTOxNCnpnqW/MwubUQuzcse90zPX8m7KU63zkLvkWV1f9E09tEg5BoAA4rGw8WvcvoNj4Yca67OE0ZtbvowoPzKAd2Q0hlcG7f1Heh2FqT1JsSp/wP9rg8sO/IcaHVkYFnpjX1/pd10pfcMLnoZjjzLebQ1zW2lDfoznP+Us33Zv6HfDb44up8bes3yJKXClRNhwC2Rn1PHWYvDmBjYsjufp2avpH3xRm5fejnaYwh9V/6BH7yXEvS1yfKNeZz3zFc0IJ+L3WmH7vW+AOU8ALVbG7GHhrSXnSHHkhq1cBZpBnbTiPykZuCFHzpeyQkb3yqr98GY4dAklVYVfYiGLZ0v5v/e7uyLQMe+TjfSMRc6v+4n/S601dTvhtCxC6XdPY3bwog3Qb2+yQkzr3PGfmRe5zwW+/FdTksDYOA9zvxU4RLBr/ymHu81zNe1dfe6sjES5tBENXGIyGDgKZw1x19R1XFBxwcCHwClwzzfV9UHKzpXRFoC7wAZOGuOX6aqof+HGBMPxOM8+RTk5L/Ppq/8zN9THnCqrfiY97zZYfsA0iSPzdqKZal/qPCtvutyKyf98hyChr3RDXBc53bg3jP/Tb+eDDv7OvjsAU4Y/A/Yfbsz/xPQtkkEE+N5kuDEa32JA6DDCXCPez+ldN6o4MdxfxPaiiHjdBjyT+g9AhLdPrXT73QeL26aBtf5zfGUnul0SQG0OQqum1F5rP4aNK9afRMial1VIuIBngOGAL2AK0Qk3CMAX6pqH/fvwQjOHQPMVtXuwGx335j4lBD42+yjHzdzzYTvAegWNKFduJvTABd39dI/YVm5b/FM+uPwp184qZ8zriIt+SBHuE+j7mrbPygeT9nmFWccS1KTNs6TRSmNoW3oY6shhob50i9Pp5Ph+BG+7qKKiMBJIwMHu511H1z8Smjdjn2hQYvI4zDVLpotjv7AKlVdAyAiE4FhQPhHMiI/dxgw0K33OvA5cHd1Bm5MpbLfgt05gd0hm7IhqQH/8+kBEj3CH88+ivYk4N9Dv/ydv/BFyUWAcq2n4l/K3gYtSTi4g9s33smapA7l1ht5/hlOt1EnJ0kkFe+jRWOnk6n5kHudCQjLLurX+qnql68nxel+atkV8nf5yoe/FDqvFUBiMlwUOnDO1H7RTBwdAf9ROznASWHqDRCRRcAmYLSqLqnk3HaquhlAVTeLSFuMqWlTb3Ze3cShqshLzjiGefnPk0tzvliRy5xiIcnvoZ47k97jmZKLeC3pEY5JWBd81QAJzTs53So71tBVQqfbLpXSzP1foEl7OOFq6HyK8xjwf//HeZR14Fj4/O9OHfHrZPB/zLTUrd87s9n6u/R1WDULTh/t7B95VuDx3pc7f6beiOZTVRKmLHho6kKgs6r2Bp4Bplbh3IrfXGSkiGSJSFZubgVrCRhTBQXFJbzn93RTzrrV/PGdbE4d55uxdX7qLaRQyL2Fj9NUDoRcY1CPNgyq4BHYAKPCTNYXfGPXPwEMexb6XAknXuOMMUhuBAP9enOH/MNpOaT1Bk+Y341tevjmrip1zIVOd1bpfQVT70WzxZEDdPLbT8dpVZRR1T1+29NF5HkRaV3JuVtFJM1tbaQBYRfUVdWXgJfAmavqcD+MqX+27snnzEc/50+Dj2bocWks37KH/520iNy9BVzi3jtOf60vU/PfoAX7wO9+8qCEbC70fBP2ui8PT4cnIwjgzHudcQWD/uLcA+jyK2cwW/5ueMFvagoJ9zurHE07wL3Vvwa1qV+imTjmA91FpAuwERgBXOlfQUTaA1tVVUWkP04LKA/YVcG504BrgHHu6wdR/Aymnios9vLYzBUcLCzigWk/cf+0JeXWvTPxXS7yBA4auzNtkfNfsr/Op8G6r0h8Mmg09sB74PP/C71wd2feJH51V2B5Y+udNbEVtcShqsUiMgqYgfNI7QRVXSIiN7nHxwOXADeLSDHO0+Uj1JmuN+y57qXHAZNE5DpgPXBptD6DqYe2LIbvXuDtVn9kUlYO36eMYo825OzCRwHlOs90ppYETq0xKjH0t0v3vDmh127VDdZ95du/6GXn8dXW3Z3BcKXjFo69uOIBap4kZ3K7hf92noaKxB0/QUKYgXTGHAKbVt3Ua8fdP4Pzeqfx0LBj+eOkRTyxagiJJQf5V/G5PFB8LWtTnYZutvRkbYsBXLhjArO8/TgnYX7lF2/by1nrWjxw1WTnyacX/aatuG9HwOOxbF8Fm7PhuEuq90Mac4jKm1bdRo6beqtg60pe1Xu5/vs7+XjxFnYdKOKZVGdY9bWJMykYdD+4PVB9dBl9djhjKc5KK4CtEbzBMcOdxKElzg1n/0dhW3UPTBoArY90/oyJczZXlalX5v6cy0XPf82p4z5j1rO30j9hBWcmZLPrQOiCPCOZEvYaCVvdtSLOui/w8dZgXd2nk0qn9U7wwO8/gT6/hSvLmdDPmFrAWhymzissLCJv8xpGTNrEujzf47GtkvYC8GTy85zQKY3LL78a/AZGy5eVjJLuMdRJAo/1CH+8Qx+4dT40au0r6zwg8sV6jIlT1uIwdVJRiTM/0u6DRbwy7jbSXuuPd8cvAXW6NPQtRnTNhntJPVBJ/9NJN8OVk3z7Lbs5g+5u+daZs6l04r30fnDyrc5N7DZHRWUFNmNiyVocpu747kUWF6XxzvauTM3eyBOX9eH6f2fxn6SfwAO/9cxmi7Zk73G/52+rL6JBQdDcmDvWhL8uON1SJ9/qTLF9/y5nvYzSRXna9nTmY5pyk7M2xHlPlL+cpzF1gD1VZWo9fW0oiz09OW6NMyFeRr4zPXgyRXybcistJXBhn5Krp+H5zwWhF2p3LGxdHFQocPM3kS3RWbAPVs+ueGU6Y2qR8p6qsq4qU/t4S+DLxyF/D8/P+RlZ93VZ0gBIwVnkp1/C8pCkAYRPGuAmDYF7t/vKel8R+brOKZUsZ2pMHWFdVaZ2WPUpNGzNhtSj2Dr5LjI3vsGq/cm89HlrbglaOqJr6n7evHMwqfOXw9wIr9/sCNi9Hhq1ce5NjFkPB3dBk7Tq/iTG1HqWOExc8nqVp2av5JIT00n0CGlvXAzA6LbTeGfbGwB8+dVcWso5IedOT7oLeezWwMKM06Hzqc5Kc5/eX/4bl07wl9rMVokzphyWOEx8UYWSQrr+5VMAnprtrL291m1V/LJ+Q9lkgj0T1vNbZodcQopCZ6Sl1ZEwaCysnBX+fb3uOI5Tbw9/3BhTxhKHiStTn76DC3f+i/MSbuNDb+h4h98m+hLFyQnLOLmClfECNHHngSrtemrcHq54y1mUaOc6KNwPXz0BrY863I9gTJ1nicPUiPlrd3Dp+Hl8fPvp9Exz1o/419e/0KpxCt3bNebp2StZsWUvz+yeAwnwbPIzXO/9iBXeI3ik2LdI0B/aroQdQRdvmg57cpw1JhBnvqdgxQXOa9tecO7DznxQpcmkdCW8jFOr9TMbU1dZ4jA1YvpPznradz//Fq/88XKKE1J5+L8/0l1yWKoZZfUWJ2bQy10Zr0/CGvokrOGSgSeCO6lsk71hxlpcNxNm/xXOuMuZaTZvtbNGxaz7oetAWPslnHSjUzchAU4ZFcVPakzdZ4nD1AhBaMNOpnnuZuLjH+PBy7vJG+mTsJrTC56g79FHcbHnC/qvDF38yPPVY76dov2hF2/aAS56ybffqpvzevl/nNd+11XjJzHGWOIw0bXqU+h8GopyhDgrzw30LKK9+EZtt2UXo/PupdOehc6iwa26Q6f+kP1m+dftdSG0OdqZ96kqK+AZYw6bJQ4TNXs3LKXJGxeTe+Ql7E66jbayCwAP3oB6t53Slk4LFvoKkhs5a1yn9XYWKwoZzQ1c9noUIzfGVMRGjpuoefxjZ/rxgpWf898f1nFb4lQA2sjugHoDFwSNudizyWlFnHQjpLuzHRxzEVz/WbRDNsZEwFocptpt2HGA0x+ZQ6ZshBRow26u9XxSdtO7Ugf8Futu1sl5TUyB9BOrP1hjTJVZi8NUu+9+cZ6XbSz5AKRIEX/omFP5iQPHOq/qt1JeWh/nNW+189q6Bxw1uJoiNcYciqgmDhEZLCIrRGSViIypoF4/ESkRkUvc/R4iku33t0dE7nCPPSAiG/2ODY3mZzBVMOPP6NIPWPX+Q9zi+YCG5JcdStsWwaRRA93/RDJO95WVdlX1HuG8jvreVs8zJsai1lUlIh7gOeAcIAeYLyLTVHVpmHr/AGaUlqnqCqCP3/GNELCO5xOqWsnybKYmeYuLSJj3LDIPxiQ5ZX8quqHyE29bCEUHwJPs7N+5AlKa+o43aA737fStfWGMiblo3uPoD6xS1TUAIjIRGAYsDap3GzAZ6FfOdc4CVqtqhB3kJmq2r3Sm6Ejw+MpKimHpVLLnzaZvUPW04CHerY6EvFVBZd0C90tHc/uzpGFMXInm/5EdgQ1++zluWRkR6QgMB8ZXcJ0RwNtBZaNE5EcRmSAiLaojWFOJ7avg2Uz4fJyvbMN8eKgVTL6OvpveCjnl98cEja9o6Zckrp4K92yKTqzGmKiKZuIINyoreLnBJ4G7Vf3vhvpdQCQZuAB416/4BaAbTlfWZuCx0DNBREaKSJaIZOXm5lYtchNqr/slv+5rX9nGildVbL59YWBBi86+7dRmzngNY0ytE82uqhygk99+OhD8EzMTmCjOyN/WwFARKVbVqe7xIcBCVd1aeoL/toi8DHwY7s1V9SXgJXCWjj2sT2JA3N8Y6oXNP/Lkj4kMLPY4N6LKE7yGd3O/xJHUoJoDNMbUlGi2OOYD3UWki9tyGAFM86+gql1UNUNVM4D3gFv8kgbAFQR1U4mI/5Jsw4Eww4pNtdm8yBm9rc5o720b18CLp9P2y3t47etfKj//yLN92+2P820npobWNcbUClFLHKpaDIzCeVpqGTBJVZeIyE0iclNl54tIQ5wnst4POvSIiPwkIj8Cg4A/VnPo9c+mbPh4jLOIUrAXz4Bpt1Fc4EwuKMUHARjkWUQDKaz82kcN9o276NDHV57U8PBiNsbETFRHjqvqdGB6UFnYG+Gqem3Q/gGgVZh6V1djiAbgtaHOrLOD7oHUpmGrLN+wlWOBNrIHgBbs5cHE1yq/doMWMHw85K0JXIo1yVocxtRW9pyj8RPY4igq8U1GOHneioBjqVJEsrjPNPT4TfmXbNDC+QueLsRaHMbUWpY46rM1n8P7N1KWMLyBD7c9+5nfmIuCveVf57iLA/e7neXbblDO09KepIjDNMbEF0sc9dm/h8GPE8tufFNSFHD4i599jzE35UD510kKeqw2qQFcMRE6newM+jPG1Ck2O67xJQyvL3F8uyaP7A27wL0V8cekyeWfH9waSUyBHkOcP2NMnWMtDuObjbakCFWluMTLmMk/0qZJSmTnt+kRuH/yLdUbnzEmrliLo14T/G+IFxQW0GOs7yG44Sd0dB6krkza8dCkgzO6fNQCaF1B99QJV8GG7w89ZGNMzFmLoz6TwH/9P/wSODXLnwYHtSQueCb0GqVll0yA9P7QvFNoHX/DnoNR86saqTEmjliLoz4TCXgC96FpP3KlZzVHnzyEi3s1olGu37xUbXtBl1+FXqPv75zXzgPg+lnRjdcYExcscdRrgfNQfpRyj7Ox4FVYEFQ1wePc9C7V93eBj90aY+oNSxz1mVShpzIhybfYEsBZD0CjkIH9xph6wO5x1GdVShyJgYP2EpPLr2uMqdMscdRnEm7JlHJ4ksDj11XlifBRXWNMnWOJoz4rqmA0eLAET2CLw6YMMabessRRT/386YTIKva60HlNSAxsoVSltWKMqVMscdRDqsqGL/4dWeXSSQoTrIVhjHFY4qiH1uUdoLnsi6zycZc4r627Ry8gY0ytYo/j1kM/bdxNT/ZHVjnjNLjiHeh2prPfoS90Pzd6wRlj4p4ljnqmuMTLbW//wPyUclocg/4CzTrC1JuhabpT1mOw7/jIOdEP0hgT1yxx1DPfr90BQKoUhx5s0gF+dZezndwI0vvVYGTGmNoiqvc4RGSwiKwQkVUiMqaCev1EpERELvErWysiP4lItohk+ZW3FJFZIrLSfS1niTkTbPfBIh6YtoT+DTbRJNzCTB6/3xG9hkHTDjUXnDGm1ogocYjIZBH5jUjkQ41FxAM8BwwBegFXiEivcur9A5gR5jKDVLWPqmb6lY0BZqtqd2C2u28icMubC/h56z4m6ejQgydcDSPeqvmgjDG1TqSJ4AXgSmCliIwTkaMjOKc/sEpV16hqITARGBam3m3AZGBbhLEMA153t18HLozwvHove1UOnWVL6IFW3WHYs9D+uJoPyhhT60SUOFT1U1X9LdAXWAvMEpFvROT3IlLeA/4dgQ1++zluWRkR6QgMB8aHe1tgpogsEJGRfuXtVHWzG9dmoG0kn6G+83qVJ1PG80XK/4YevKqCZWGNMSZIVbqeWgHXAtcDPwBP4SSS8hZhCDe0WIP2nwTuVi1duzTAqaraF6er61YROSPSWN14R4pIlohk5ebmVn5CXVNSDM+dDMudFf1ue/sHTmBF+LotOtdgYMaY2i7SexzvA18CDYHzVfUCVX1HVW8DGpdzWg7gvxxcOrApqE4mMFFE1gKXAM+LyIUAqrrJfd0GTMHp+gLYKiJpblxplNPFpaovqWqmqma2adMmko9ZtxzcCbnLYNooAD76aTN7tUGMgzLG1AWRtjieVdVeqvr30m6iUkE3rv3NB7qLSBcRSQZGANOCzu2iqhmqmgG8B9yiqlNFpJGINAEQkUbAucBi97RpwDXu9jXABxF+hvpFve6GcGDSDZwky0iScA07Y4ypmkjHcfQUkYWqugvAfQT2ClV9vrwTVLVYREbhPC3lASao6hIRuck9Hu6+Rql2wBRxJtJLBN5S1U/cY+OASSJyHbAeuDTCz1C/eIuc1wPbabh0Em8mJ+BNTAXLHcaYwySqwbcdwlQSyVbVPkFlP6jqCdEKrDplZmZqVlZW5RVroz2b4fGj4eJXffNKAeSthmf6RnaNB3ZHJzZjTK0mIgvC9SpF2lWVIOKbR9sde2FLwMWD3GXO6w//CSwvKar5WIwx9UKkiWMGTvfQWSJyJvA28Ekl55hYKikIXz7wHkhtVrOxGGPqlEjvcdwN3AjcjPOY7UzglWgFZaqgvK7G4sLw5SdeA7s3+Foo5z8VnbiMMXVWRIlDVb04o8dfiG445rBsXAiF+6HL6eW3OJIbOav5AZzzEJx4bY2FZ4ypGyJKHCLSHfg7zpxTqaXlqto1SnGZQ/HyIOf1gd1QUk6LI6khNGzlbBdGuCaHMcb4ifQex2s4rY1iYBDwb+A/FZ5haljQQP1wXVVJDSHBA03TnP29weMxjTGmcpEmjgaqOhvn8d11qvoAcGb0wjJVF3ivo7DwYGiVpIbOa4subkG4WWGMMaZikd4cz3enVF/pDurbiE0uGNdycncT0o+Y3Mh57XYmDH00cNyHMcZEKNIWxx0481T9D3AicBW+aT9MXAhsPeRs3xVaZdc6t6pA/xugga2BZYypukpbHO5gv8tU9S5gH/D7qEdlqiDM47heL5vybDS4MSY6Km1xuFOen+g/ctzEkXDDOIrz2bLDEocxJjoivcfxA/CBiLwLlD3DqarvRyUqEzl3KRPdvKiss2rmorWUHNgNpUts9bsB2h4Nqc1jEaExpo6JNHG0BPIIfJJKAUscseYtBkAO7igrevSjbK6Rnb46v3m0pqMyxtRhkY4ct/sa8cobOk96UcEBTkkrgB1h6htjzGGKdOT4a4TpTVfVP1R7RKZq3BaHvwYU0LK4Hi6Xa4ypEZF2VX3ot50KDCd0GVgTC2Ur/fmkUkiD/G3Q7Ag4+eYYBGWMqcsi7aqa7L8vIm8Dn0YlIlM1Ybqqmsl+kgt3wmm3woBbYhCUMaYui3QAYLDuwBHVGYg5RGG6qo6SHGejaccaDsYYUx9Eeo9jL4H3OLbgrNFhYszrLQ7J/mOT3nY2mqTVeDzGmLovohaHqjZR1aZ+f0cFd1+FIyKDRWSFiKwSkTEV1OsnIiUicom730lE5ojIMhFZIiK3+9V9QEQ2iki2+zc0ks9QV+3Zn1/+wRYZNRaHMab+iChxiMhwEWnmt99cRC6s5BwP8BwwBGcdjytEpFc59f6BszxtqWLgTlXtCZwM3Bp07hOq2sf9mx7JZ6irdlWUOJp1qrlAjDH1RqT3OO5X1bI5LFR1F3B/Jef0B1ap6hpVLQQmAsPC1LsNmAxs87v+ZlVd6G7vBZYB1mEfRoWJwxPpQ3PGGBO5SBNHuHqVfSt1BDb47ecQ9OUvIh1xHu0dX95FRCQDOAH4zq94lIj8KCITRCTsFK8iMlJEskQkKze37o5p2LM/zLobALctrNlAjDH1RqSJI0tEHheRbiLSVUSeABZUck64SRGDBxE+CdztTqQYegGRxjitkTtUdY9b/ALQDegDbAYeC3euqr6kqpmqmtmmTZtKQq299hwop8XRqlvNBmKMqTciTRy3AYXAO8Ak4CBwayXn5AD+nezphA4azAQmisha4BLg+dJ7JyKShJM03vSfTFFVt6pqiap6gZdxusTqn2+ehS2L2XugINaRGGPqmUgHAO4Hyn0qqhzzge4i0gVnxcARwJVB1y1dwxQR+RfwoapOdadwfxVYpqqP+58jImmqutndHQ4srmJcdcPMPwOQU3SZbxZcY4ypAZGO45gFXOreFMe9rzBRVX9d3jmqWuwuMzsD8AATVHWJiNzkHi/3vgZwKnA18JOIZLtl97hPUD0iIn1wur3WAjdG8hnqFPX1+CXi18t3wbOw9ktI7xeDoIwx9UWkj920Lk0aAKq6U0QqXXPc/aKfHlQWNmGo6rV+218R/h4Jqnp1ZCHXYX7TjJziWeor73u182eMMVEU6T0Or4iUTTHiPukUbu05UxP8niU4KWFZDAMxxtRHkbY4/gx8JSJfuPtnACOjE5KpVJj5qYwxpqZEenP8ExHJxEkW2cAHOE9WmViwxGGMiaFIb45fD9yO80htNs40IPMIXErW1JQwU6nTuH3Nx2GMqZcivcdxO9APWKeqg3BGctfd4djxLjhxpDaD0StiE4sxpt6JNHHkq2o+gIikqOpyoEf0wjIV8u+qatkNbvo6drEYY+qdSG+O54hIc2AqMEtEdmJLx8aOf+I4eig0t1lwjTE1J9Kb48PdzQdEZA7QDPgkalGZivlP7ZXUKHZxGGPqpSrPu62qX1Rey0STt9hv1b/khrEMxRhTDx3qmuMmhtbn7fHtJFniMMbULEsctdCynB2+nWTrqjLG1CxLHLXQury9vh1rcRhjapgljlooxz9xNGgesziMMfWTJY7aJm81f9t2m28/tVnsYjHG1EuWOGqZ/O9eCyywxGGMqWGWOGqZg5uWBhakNo9JHMaY+ssSRy1TtG97YEFK09gEYoyptyxx1CYHd9F216LAMk+Vx3AaY8xhscRRi+hnfwss+NXdsQnEGFOvRTVxiMhgEVkhIqtEZEwF9fqJSImIXFLZuSLSUkRmichK97VFND9DXPCWwIEd5BcWBJb3GBqbeIwx9VrUEoeIeIDngCFAL+AKEelVTr1/ADMiPHcMMFtVuwOz3f26bea98EgX9u/ZHVie4IlNPMaYei2aLY7+wCpVXaOqhcBEYFiYercBk4FtEZ47DHjd3X4duDAKsceXnyYBULRjPSu9HX3lCXZ/wxhT86KZODoCG/z2c9yyMiLSERgOjK/Cue1UdTOA+9o23JuLyEgRyRKRrNzcWr5YobviX9HuLRSl+vXMWeIwxsRANBOHhCnToP0ngbtVNXgR7UjOrZCqvqSqmaqa2aZNm6qcGn/cfzwtdSetW7fzlYs922CMqXnR/MmaA/gvTZdO6KqBmcBEEQFoDQwVkeJKzt0qImmqullE0gjs4qqbvF4AGks+CU2aQZMOsHcTqDfGgRlj6qNo/mSdD3QXkS4ikgyMAKb5V1DVLqqaoaoZwHvALao6tZJzpwHXuNvXAB9E8TPEB78GWWqDhnDlROeJquadYxiUMaa+ilqLQ1WLRWQUztNSHmCCqi4RkZvc48H3NSo91z08DpgkItcB64FLo/UZ4oZfyyIhKRXSesMVb8cwIGNMfRbVu6uqOh2YHlQWNmGo6rWVneuW5wFnVV+UtYDX7xZQYmrs4jDGGGzkeK0Q8OxAYkrsAjHGGCxx1ArifxPcWhzGmBizxFHbWIvDGBNjljji3PZ9QfNTWYvDGBNjljji3PbPngsssNHixpgYs2+heLV3C3x0J0cv/zCwvKQwNvEYY4zLWhzx6svHIDhpABQdrPlYjDHGjyWOeOVJDl9enF+zcRhjTBBLHPEq+Ompzqc5r62613wsxhjjx+5xxCtPUOLofg4MGQftjo1NPMYY47LEEa+CZ75tlg7tj4tNLMYY48e6quJV4b6yTU1sAMdeHMNgjDHGxxJHvCo6ULYp7XqBhFvbyhhjap4ljjhVeHAfO7SxszPg1tgGY4wxfuweR5xanbMV0Rb8fM2PnNy1VazDMcaYMtbiiDdbl6BP9aHh7pUUp7bkpC4tYx2RMcYEsMQRb758DNn5C53ZRMN2XRG7t2GMiTOWOOKNeMo2W6cfFcNAjDEmPEsc8SbBlziadjomhoEYY0x4UU0cIjJYRFaIyCoRGRPm+DAR+VFEskUkS0ROc8t7uGWlf3tE5A732AMistHv2NBofoaatq9QfTudTo5dIMYYU46oPVUlIh7gOeAcIAeYLyLTVHWpX7XZwDRVVRE5HpgEHK2qK4A+ftfZCEzxO+8JVX00WrHHiterfPjTFkaU/ltp0i6m8RhjTDjRbHH0B1ap6hpVLQQmAsP8K6jqPlUt/YndCFBCnQWsVtV1UYw1LizdvAcvdjPcGBPfopk4OgIb/PZz3LIAIjJcRJYDHwF/CHOdEcDbQWWj3C6uCSLSItybi8hIt/srKzc399A+QQ377pcdpEpRrMMwxpgKRTNxhPvpHNKiUNUpqno0cCHwUMAFRJKBC4B3/YpfALrhdGVtBh4L9+aq+pKqZqpqZps2bQ4l/hr186YdfDlrKuckZjsFV0+psL4xxsRKNEeO5wCd/PbTgU3lVVbVuSLSTURaq+p2t3gIsFBVt/rVK9sWkZeBMMvk1S479xcyd8JY/iUTndTa+ijodmaswzLGmLCi2eKYD3QXkS5uy2EEMM2/gogcKe4INxHpCyQDeX5VriCom0pE0vx2hwOLoxB7jVm+ZQ8PvjmDK4r8WhjnPRmzeIwxpjJRa3GoarGIjAJmAB5ggqouEZGb3OPjgYuB34lIEXAQuLz0ZrmINMR5IuvGoEs/IiJ9cH6brw1zPG6pKks372He6jz+PW8d7Zumsnj9Vj5LuoNGUuBUatkVOp8S20CNMaYC4nuoqe7KzMzUrKysmLz36tx9fLJ4C5+v2MbyLXvZm18MgODl4obZPOr1e6r4yknQ/VybQt2YOFBUVEROTg75+fmxDiXqUlNTSU9PJykpKaBcRBaoamZwfZsdN1pUef6td5m7ZB3pksv/JnxJcWoLUtqlk9ZISN8wDSk6AE3ToWNfGPpPaNI+1lEbY1w5OTk0adKEjIyMOj1nnKqSl5dHTk4OXbp0iegcSxxR8uk7z3DLynu5JdmvsAgovbXfspuzjvjAsdCgec0HaIypUH5+fp1PGgAiQqtWrajKsAVLHNVNlcXffMygZfeBwN5zn6RJl75wIM9ZRzy9HxQXQKM21iVlTJyr60mjVFU/pyWOalY8416O/fYZDkoKReeOo+kpv491SMYYU61sdtxqVJS/j5LvXmaxN4MfL/uOpqeEGwhvjDGR2bVrF88//3yVzxs6dCi7du2q/oBcljiq0YqX/0CK5vPzcaM5qVdkN5mMMaY85SWOkpKSCs+bPn06zZs3j1JU1lVVffL3cFTebHZ42nLR8MtjHY0xphr99b9LWLppT7Ves1eHptx/fsVr7owZM4bVq1fTp08fkpKSaNy4MWlpaWRnZ7N06VIuvPBCNmzYQH5+PrfffjsjR44EICMjg6ysLPbt28eQIUM47bTT+Oabb+jYsSMffPABDRo0OKzYrcVRTXav/YFkivnu2PsgMbnyE4wxphLjxo2jW7duZGdn889//pPvv/+ehx9+mKVLndUpJkyYwIIFC8jKyuLpp58mLy8v5BorV67k1ltvZcmSJTRv3pzJkycfdlzW4qgma9f9Qm+gwxHdYh2KMaaaVdYyqCn9+/cPGGvx9NNPM2WKM13Rhg0bWLlyJa1atQo4p0uXLvTp0weAE088kbVr1x52HJY4qsnGDWvpDRzd/chYh2KMqaMaNWpUtv3555/z6aefMm/ePBo2bMjAgQPDjnJPSUkp2/Z4PBw8ePCw47DEEYHdB4soLvGWe1yB7Vs2UEICKY1b11xgxpg6rUmTJuzduzfssd27d9OiRQsaNmzI8uXL+fbbb2ssLksclRj38XLGf7G6klrKf5OzONCoPU0S7LaRMaZ6tGrVilNPPZVjjz2WBg0a0K6dbznpwYMHM378eI4//nh69OjBySefXGNxWeKoQH5RCTO+yWJU+81kZoRdaBCABgV5HLdsLd6B/6zB6Iwx9cFbb70VtjwlJYWPP/447LHS+xitW7dm8WLfyhOjR4+ulpgscVTgl42beC9hDK127YXsSip7kknoNaySSsYYU/tZ4qhAwvYVtJK9rO49mm4DhldcuUELaNKu4jrGGFMHWOKoyH7nmeh9HU+D9sfGOBhjjIkPdie3Igecpc8TGrWqpKIxxtQfljgqIAecFkdC47YxjsQYY+KHJY4KePJ3cFCTSU5tVHllY4ypJ6KaOERksIisEJFVIjImzPFhIvKjiGSLSJaInOZ3bK2I/FR6zK+8pYjMEpGV7mv5z8kepn3JbZnrPZ7kRMuvxpiad6jTqgM8+eSTHDhwoJojckTtG1FEPMBzwBCgF3CFiPQKqjYb6K2qfYA/AK8EHR+kqn2CFksfA8xW1e7u+SEJqbos7XwVNxb9LymJnmi9hTHGlCteE0c0n6rqD6xS1TUAIjIRGAYsLa2gqvv86jfCmb2jMsOAge7268DnwN2HH26ogiJnzntrcRhTz308Brb8VL3XbH8cDBlXYRX/adXPOecc2rZty6RJkygoKGD48OH89a9/Zf/+/Vx22WXk5ORQUlLCvffey9atW9m0aRODBg2idevWzJkzp1pDj2bi6Ahs8NvPAU4KriQiw4G/A22B3/gdUmCmiCjwoqq+5Ja3U9XNAKq6WUTC3rkWkZHASIAjjjjikD5AQbEzP1WKJQ5jTAyMGzeOxYsXk52dzcyZM3nvvff4/vvvUVUuuOAC5s6dS25uLh06dOCjjz4CnDmsmjVrxuOPP86cOXNo3br658+LZuIIt/p5SItCVacAU0TkDOAh4Gz30KmquslNDLNEZLmqzo30zd1E8xJAZmZmJC2ZEIVu4rAWhzH1XCUtg5owc+ZMZs6cyQknnADAvn37WLlyJaeffjqjR4/m7rvv5rzzzuP000+PeizRTBw5QCe//XRgU3mVVXWuiHQTkdaqul1VN7nl20RkCk7X11xgq4ikua2NNGBbtD5AQbGXBIHEhHA50Bhjao6qMnbsWG688caQYwsWLGD69OmMHTuWc889l/vuuy+qsUTzp/R8oLuIdBGRZGAEMM2/gogcKSLibvcFkoE8EWkkIk3c8kbAuUDpTF3TgGvc7WuAD6L1AQpLvKQkenBDNMaYGuU/rfqvf/1rJkyYwL59zq3hjRs3sm3bNjZt2kTDhg256qqrGD16NAsXLgw5t7pFrcWhqsUiMgqYAXiACaq6RERuco+PBy4GficiRcBB4HJVVRFph9N9VRrjW6r6iXvpccAkEbkOWA9cGq3PUFBUYt1UxpiY8Z9WfciQIVx55ZUMGDAAgMaNG/PGG2+watUq7rrrLhISEkhKSuKFF14AYOTIkQwZMoS0tLRqvzkuqofU/V+rZGZmalZWVuUVg0z8fj0L1+/kkUt6RyEqY0w8W7ZsGT179ox1GDUm3OcVkQVBwyEAm+SwQiP6H8GI/of2RJYxxtRV1g9jjDGmSixxGGNMOepDVz5U/XNa4jDGmDBSU1PJy8ur88lDVcnLyyM1NTXic+wehzHGhJGenk5OTg65ubmxDiXqUlNTSU9Pj7i+JQ5jjAkjKSmJLl26xDqMuGRdVcYYY6rEEocxxpgqscRhjDGmSurFyHERyQXWHeLprYHt1RhONMR7jPEeH1iM1SHe4wOLsao6q2qb4MJ6kTgOh4hkhRtyH0/iPcZ4jw8sxuoQ7/GBxVhdrKvKGGNMlVjiMMYYUyWWOCr3UuVVYi7eY4z3+MBirA7xHh9YjNXC7nEYY4ypEmtxGGOMqRJLHMYYY6rEEkcFRGSwiKwQkVUiMiZGMUwQkW0istivrKWIzBKRle5rC79jY914V4jIr2soxk4iMkdElonIEhG5PZ7iFJFUEfleRBa58f01nuILitUjIj+IyIfxGKOIrBWRn0QkW0Sy4i1GEWkuIu+JyHL3v8cBcRZfD/efXenfHhG5I55ijIiq2l+YP5x10lcDXYFkYBHQKwZxnAH0BRb7lT0CjHG3xwD/cLd7uXGmAF3c+D01EGMa0NfdbgL87MYSF3ECAjR2t5OA74CT4yW+oFj/F3gL+DBO/12vBVoHlcVNjMDrwPXudjLQPJ7iC4rVA2wBOsdrjOXGHusA4vUPGADM8NsfC4yNUSwZBCaOFUCau50GrAgXIzADGBCDeD8AzonHOIGGwELgpHiLD0gHZgNn+iWOeIsxXOKIixiBpsAvuA/9xFt8YeI9F/g6nmMs78+6qsrXEdjgt5/jlsWDdqq6GcB9beuWxzxmEckATsD5VR83cbpdQNnANmCWqsZVfK4ngT8BXr+yeItRgZkiskBERsZZjF2BXOA1t7vvFRFpFEfxBRsBvO1ux2uMYVniKJ+EKYv3Z5djGrOINAYmA3eo6p6KqoYpi2qcqlqiqn1wftX3F5FjK6he4/GJyHnANlVdEOkpYcpq4t/1qaraFxgC3CoiZ1RQt6ZjTMTp1n1BVU8A9uN0+5QnZv+/iEgycAHwbmVVw5TF/HvIEkf5coBOfvvpwKYYxRJsq4ikAbiv29zymMUsIkk4SeNNVX0/XuNU1V3A58DgOIvvVOACEVkLTATOFJE34ixGVHWT+7oNmAL0j6MYc4ActzUJ8B5OIomX+PwNARaq6lZ3Px5jLJcljvLNB7qLSBf318EIYFqMYyo1DbjG3b4G555CafkIEUkRkS5Ad+D7aAcjIgK8CixT1cfjLU4RaSMizd3tBsDZwPJ4iQ9AVceqarqqZuD8t/aZql4VTzGKSCMRaVK6jdNHvzheYlTVLcAGEenhFp0FLI2X+IJcga+bqjSWeIuxfLG+yRLPf8BQnCeEVgN/jlEMbwObgSKcXx/XAa1wbqKudF9b+tX/sxvvCmBIDcV4Gk7z+Ucg2/0bGi9xAscDP7jxLQbuc8vjIr4w8Q7Ed3M8bmLEuYewyP1bUvr/RJzF2AfIcv9dTwVaxFN87ns2BPKAZn5lcRVjZX825Ygxxpgqsa4qY4wxVWKJwxhjTJVY4jDGGFMlljiMMcZUiSUOY4wxVWKJw5g4JCIDS2fINSbeWOIwxhhTJZY4jDkMInKVu9ZHtoi86E6muE9EHhORhSIyW0TauHX7iMi3IvKjiEwpXXNBRI4UkU/FWS9koYh0cy/f2G9tiTfdEfqIyDgRWepe59EYfXRTj1niMOYQiUhP4HKcif/6ACXAb4FGOPMQ9QW+AO53T/k3cLeqHg/85Ff+JvCcqvYGTsGZKQCcWYbvwFmToStwqoi0BIYDx7jX+Vs0P6Mx4VjiMObQnQWcCMx3p2w/C+cL3gu849Z5AzhNRJoBzVX1C7f8deAMd+6njqo6BUBV81X1gFvne1XNUVUvzjQuGcAeIB94RUQuAkrrGlNjLHEYc+gEeF1V+7h/PVT1gTD1KprXJ9y02aUK/LZLgERVLcaZkXYycCHwSdVCNubwWeIw5tDNBi4RkbZQtvZ2Z5z/ry5x61wJfKWqu4GdInK6W3418IU665bkiMiF7jVSRKRheW/ornnSTFWn43Rj9an2T2VMJRJjHYAxtZWqLhWRv+CsiJeAM4PxrTgLCB0jIguA3Tj3QcCZLnu8mxjWAL93y68GXhSRB91rXFrB2zYBPhCRVJzWyh+r+WMZUymbHdeYaiYi+1S1cazjMCZarKvKGGNMlViLwxhjTJVYi8MYY0yVWOIwxhhTJZY4jDHGVIklDmOMMVViicMYY0yV/D+6mmx3/mHyDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(hist2.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abef339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 2.0346 - accuracy: 0.2405 - val_loss: 1.9755 - val_accuracy: 0.3573\n",
      "Epoch 2/747\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.9447 - accuracy: 0.2156 - val_loss: 1.9211 - val_accuracy: 0.1912\n",
      "Epoch 3/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.9036 - accuracy: 0.2740 - val_loss: 1.8855 - val_accuracy: 0.3579\n",
      "Epoch 4/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.8709 - accuracy: 0.3595 - val_loss: 1.8547 - val_accuracy: 0.3579\n",
      "Epoch 5/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.8421 - accuracy: 0.3595 - val_loss: 1.8275 - val_accuracy: 0.3579\n",
      "Epoch 6/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.8168 - accuracy: 0.3595 - val_loss: 1.8036 - val_accuracy: 0.3579\n",
      "Epoch 7/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7946 - accuracy: 0.3595 - val_loss: 1.7828 - val_accuracy: 0.3579\n",
      "Epoch 8/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7753 - accuracy: 0.3595 - val_loss: 1.7649 - val_accuracy: 0.3579\n",
      "Epoch 9/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7588 - accuracy: 0.3595 - val_loss: 1.7497 - val_accuracy: 0.3579\n",
      "Epoch 10/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.7450 - accuracy: 0.3595 - val_loss: 1.7370 - val_accuracy: 0.3579\n",
      "Epoch 11/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.7334 - accuracy: 0.3595 - val_loss: 1.7265 - val_accuracy: 0.3579\n",
      "Epoch 12/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.7240 - accuracy: 0.3595 - val_loss: 1.7181 - val_accuracy: 0.3579\n",
      "Epoch 13/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.7163 - accuracy: 0.3595 - val_loss: 1.7110 - val_accuracy: 0.3579\n",
      "Epoch 14/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.7100 - accuracy: 0.3595 - val_loss: 1.7054 - val_accuracy: 0.3579\n",
      "Epoch 15/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.7050 - accuracy: 0.3595 - val_loss: 1.7009 - val_accuracy: 0.3579\n",
      "Epoch 16/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.7009 - accuracy: 0.3595 - val_loss: 1.6972 - val_accuracy: 0.3579\n",
      "Epoch 17/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6976 - accuracy: 0.3595 - val_loss: 1.6942 - val_accuracy: 0.3579\n",
      "Epoch 18/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6948 - accuracy: 0.3595 - val_loss: 1.6916 - val_accuracy: 0.3579\n",
      "Epoch 19/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6926 - accuracy: 0.3595 - val_loss: 1.6896 - val_accuracy: 0.3579\n",
      "Epoch 20/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6907 - accuracy: 0.3595 - val_loss: 1.6878 - val_accuracy: 0.3579\n",
      "Epoch 21/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6891 - accuracy: 0.3595 - val_loss: 1.6863 - val_accuracy: 0.3579\n",
      "Epoch 22/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6877 - accuracy: 0.3595 - val_loss: 1.6850 - val_accuracy: 0.3579\n",
      "Epoch 23/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6866 - accuracy: 0.3595 - val_loss: 1.6840 - val_accuracy: 0.3579\n",
      "Epoch 24/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6856 - accuracy: 0.3595 - val_loss: 1.6830 - val_accuracy: 0.3579\n",
      "Epoch 25/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6848 - accuracy: 0.3595 - val_loss: 1.6822 - val_accuracy: 0.3579\n",
      "Epoch 26/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6841 - accuracy: 0.3595 - val_loss: 1.6816 - val_accuracy: 0.3579\n",
      "Epoch 27/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6834 - accuracy: 0.3595 - val_loss: 1.6810 - val_accuracy: 0.3579\n",
      "Epoch 28/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6829 - accuracy: 0.3595 - val_loss: 1.6805 - val_accuracy: 0.3579\n",
      "Epoch 29/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6824 - accuracy: 0.3595 - val_loss: 1.6800 - val_accuracy: 0.3579\n",
      "Epoch 30/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6820 - accuracy: 0.3595 - val_loss: 1.6796 - val_accuracy: 0.3579\n",
      "Epoch 31/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6817 - accuracy: 0.3595 - val_loss: 1.6793 - val_accuracy: 0.3579\n",
      "Epoch 32/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6814 - accuracy: 0.3595 - val_loss: 1.6790 - val_accuracy: 0.3579\n",
      "Epoch 33/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6811 - accuracy: 0.3595 - val_loss: 1.6787 - val_accuracy: 0.3579\n",
      "Epoch 34/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6808 - accuracy: 0.3595 - val_loss: 1.6785 - val_accuracy: 0.3579\n",
      "Epoch 35/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6806 - accuracy: 0.3595 - val_loss: 1.6783 - val_accuracy: 0.3579\n",
      "Epoch 36/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6804 - accuracy: 0.3595 - val_loss: 1.6781 - val_accuracy: 0.3579\n",
      "Epoch 37/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6803 - accuracy: 0.3595 - val_loss: 1.6779 - val_accuracy: 0.3579\n",
      "Epoch 38/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6801 - accuracy: 0.3595 - val_loss: 1.6778 - val_accuracy: 0.3579\n",
      "Epoch 39/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6800 - accuracy: 0.3595 - val_loss: 1.6777 - val_accuracy: 0.3579\n",
      "Epoch 40/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6799 - accuracy: 0.3595 - val_loss: 1.6775 - val_accuracy: 0.3579\n",
      "Epoch 41/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6797 - accuracy: 0.3595 - val_loss: 1.6774 - val_accuracy: 0.3579\n",
      "Epoch 42/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6796 - accuracy: 0.3595 - val_loss: 1.6773 - val_accuracy: 0.3579\n",
      "Epoch 43/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6795 - accuracy: 0.3595 - val_loss: 1.6772 - val_accuracy: 0.3579\n",
      "Epoch 44/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6794 - accuracy: 0.3595 - val_loss: 1.6771 - val_accuracy: 0.3579\n",
      "Epoch 45/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6794 - accuracy: 0.3595 - val_loss: 1.6771 - val_accuracy: 0.3579\n",
      "Epoch 46/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6793 - accuracy: 0.3595 - val_loss: 1.6770 - val_accuracy: 0.3579\n",
      "Epoch 47/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6792 - accuracy: 0.3595 - val_loss: 1.6769 - val_accuracy: 0.3579\n",
      "Epoch 48/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6792 - accuracy: 0.3595 - val_loss: 1.6769 - val_accuracy: 0.3579\n",
      "Epoch 49/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6791 - accuracy: 0.3595 - val_loss: 1.6768 - val_accuracy: 0.3579\n",
      "Epoch 50/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6791 - accuracy: 0.3595 - val_loss: 1.6768 - val_accuracy: 0.3579\n",
      "Epoch 51/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6790 - accuracy: 0.3595 - val_loss: 1.6767 - val_accuracy: 0.3579\n",
      "Epoch 52/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6790 - accuracy: 0.3595 - val_loss: 1.6767 - val_accuracy: 0.3579\n",
      "Epoch 53/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6789 - accuracy: 0.3595 - val_loss: 1.6766 - val_accuracy: 0.3579\n",
      "Epoch 54/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6789 - accuracy: 0.3595 - val_loss: 1.6766 - val_accuracy: 0.3579\n",
      "Epoch 55/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6788 - accuracy: 0.3595 - val_loss: 1.6765 - val_accuracy: 0.3579\n",
      "Epoch 56/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6788 - accuracy: 0.3595 - val_loss: 1.6765 - val_accuracy: 0.3579\n",
      "Epoch 57/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6788 - accuracy: 0.3595 - val_loss: 1.6765 - val_accuracy: 0.3579\n",
      "Epoch 58/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6787 - accuracy: 0.3595 - val_loss: 1.6764 - val_accuracy: 0.3579\n",
      "Epoch 59/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6787 - accuracy: 0.3595 - val_loss: 1.6764 - val_accuracy: 0.3579\n",
      "Epoch 60/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6787 - accuracy: 0.3595 - val_loss: 1.6764 - val_accuracy: 0.3579\n",
      "Epoch 61/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6786 - accuracy: 0.3595 - val_loss: 1.6764 - val_accuracy: 0.3579\n",
      "Epoch 62/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6786 - accuracy: 0.3595 - val_loss: 1.6763 - val_accuracy: 0.3579\n",
      "Epoch 63/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6786 - accuracy: 0.3595 - val_loss: 1.6763 - val_accuracy: 0.3579\n",
      "Epoch 64/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6786 - accuracy: 0.3595 - val_loss: 1.6763 - val_accuracy: 0.3579\n",
      "Epoch 65/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6785 - accuracy: 0.3595 - val_loss: 1.6763 - val_accuracy: 0.3579\n",
      "Epoch 66/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6785 - accuracy: 0.3595 - val_loss: 1.6762 - val_accuracy: 0.3579\n",
      "Epoch 67/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6785 - accuracy: 0.3595 - val_loss: 1.6762 - val_accuracy: 0.3579\n",
      "Epoch 68/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6785 - accuracy: 0.3595 - val_loss: 1.6762 - val_accuracy: 0.3579\n",
      "Epoch 69/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6785 - accuracy: 0.3595 - val_loss: 1.6762 - val_accuracy: 0.3579\n",
      "Epoch 70/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6784 - accuracy: 0.3595 - val_loss: 1.6762 - val_accuracy: 0.3579\n",
      "Epoch 71/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6784 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 72/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6784 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 73/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6784 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 74/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6784 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 75/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 76/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 77/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6761 - val_accuracy: 0.3579\n",
      "Epoch 78/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 79/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 80/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 81/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6783 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 82/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 83/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 84/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 85/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6760 - val_accuracy: 0.3579\n",
      "Epoch 86/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 87/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 88/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 89/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 90/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6782 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 91/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 92/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 93/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 94/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 95/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6759 - val_accuracy: 0.3579\n",
      "Epoch 96/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 97/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 98/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 99/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 100/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6781 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 101/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 102/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 103/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 104/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 105/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 106/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 107/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 108/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 109/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 110/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 111/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 112/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6758 - val_accuracy: 0.3579\n",
      "Epoch 113/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6780 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 114/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 115/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 116/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 117/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 118/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 119/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 120/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 121/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 122/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 123/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 124/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 125/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 126/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 127/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 128/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6757 - val_accuracy: 0.3579\n",
      "Epoch 129/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6779 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 130/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 131/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 132/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 133/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 134/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 135/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 136/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 137/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 138/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 139/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 140/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 141/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 142/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 143/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 144/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 145/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 146/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 147/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 148/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 149/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 150/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 151/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 152/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 153/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 154/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6756 - val_accuracy: 0.3579\n",
      "Epoch 155/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 156/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 157/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 158/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 159/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 160/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 161/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 162/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 163/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6777 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 164/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 165/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 166/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 167/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 168/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 169/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 170/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 171/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 172/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 173/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 174/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 175/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 176/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 177/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 178/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 179/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 180/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 181/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6776 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 182/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 183/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 184/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 185/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6755 - val_accuracy: 0.3579\n",
      "Epoch 186/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 187/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 188/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 189/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 190/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 191/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 192/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 193/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 194/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 195/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 196/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6775 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 197/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 198/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 199/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 200/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 201/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 202/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 203/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 204/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 205/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 206/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 207/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 208/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 209/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 210/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 211/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 212/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 213/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6774 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 214/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 215/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 216/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 217/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 218/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 219/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 220/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 221/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 222/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 223/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 224/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 225/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 226/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 227/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 228/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 229/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6773 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 230/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6754 - val_accuracy: 0.3579\n",
      "Epoch 231/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 232/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 233/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 234/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 235/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 236/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 237/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 238/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 239/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 240/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 241/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 242/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 243/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6772 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 244/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 245/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 246/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 247/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 248/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 249/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 250/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 251/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 252/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 253/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 254/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 255/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 256/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 257/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 258/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 259/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6771 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 260/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 261/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 262/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 263/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 264/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 265/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 266/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 267/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 268/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 269/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 270/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 271/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 272/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 273/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 274/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6770 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 275/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 276/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 277/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 278/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 279/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 280/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 281/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 282/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 283/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 284/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 285/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 286/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6769 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 287/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6768 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 288/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6768 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 289/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6768 - accuracy: 0.3595 - val_loss: 1.6753 - val_accuracy: 0.3579\n",
      "Epoch 290/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6768 - accuracy: 0.3595 - val_loss: 1.6752 - val_accuracy: 0.3579\n",
      "Epoch 291/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6743 - accuracy: 0.3595 - val_loss: 1.6724 - val_accuracy: 0.3579\n",
      "Epoch 292/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6726 - accuracy: 0.3595 - val_loss: 1.6715 - val_accuracy: 0.3579\n",
      "Epoch 293/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6719 - accuracy: 0.3595 - val_loss: 1.6709 - val_accuracy: 0.3579\n",
      "Epoch 294/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6713 - accuracy: 0.3595 - val_loss: 1.6705 - val_accuracy: 0.3579\n",
      "Epoch 295/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6709 - accuracy: 0.3595 - val_loss: 1.6700 - val_accuracy: 0.3579\n",
      "Epoch 296/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6704 - accuracy: 0.3594 - val_loss: 1.6696 - val_accuracy: 0.3579\n",
      "Epoch 297/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6700 - accuracy: 0.3594 - val_loss: 1.6691 - val_accuracy: 0.3579\n",
      "Epoch 298/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6696 - accuracy: 0.3595 - val_loss: 1.6688 - val_accuracy: 0.3579\n",
      "Epoch 299/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6692 - accuracy: 0.3595 - val_loss: 1.6684 - val_accuracy: 0.3580\n",
      "Epoch 300/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6688 - accuracy: 0.3593 - val_loss: 1.6686 - val_accuracy: 0.3582\n",
      "Epoch 301/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6686 - accuracy: 0.3594 - val_loss: 1.6677 - val_accuracy: 0.3579\n",
      "Epoch 302/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6680 - accuracy: 0.3595 - val_loss: 1.6677 - val_accuracy: 0.3580\n",
      "Epoch 303/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6678 - accuracy: 0.3593 - val_loss: 1.6672 - val_accuracy: 0.3582\n",
      "Epoch 304/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6675 - accuracy: 0.3595 - val_loss: 1.6668 - val_accuracy: 0.3582\n",
      "Epoch 305/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6673 - accuracy: 0.3597 - val_loss: 1.6672 - val_accuracy: 0.3580\n",
      "Epoch 306/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6669 - accuracy: 0.3597 - val_loss: 1.6669 - val_accuracy: 0.3579\n",
      "Epoch 307/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6666 - accuracy: 0.3595 - val_loss: 1.6659 - val_accuracy: 0.3583\n",
      "Epoch 308/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6662 - accuracy: 0.3596 - val_loss: 1.6656 - val_accuracy: 0.3585\n",
      "Epoch 309/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6660 - accuracy: 0.3595 - val_loss: 1.6655 - val_accuracy: 0.3579\n",
      "Epoch 310/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6658 - accuracy: 0.3599 - val_loss: 1.6650 - val_accuracy: 0.3580\n",
      "Epoch 311/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6653 - accuracy: 0.3600 - val_loss: 1.6648 - val_accuracy: 0.3582\n",
      "Epoch 312/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6650 - accuracy: 0.3599 - val_loss: 1.6645 - val_accuracy: 0.3579\n",
      "Epoch 313/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6646 - accuracy: 0.3601 - val_loss: 1.6641 - val_accuracy: 0.3579\n",
      "Epoch 314/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6644 - accuracy: 0.3601 - val_loss: 1.6638 - val_accuracy: 0.3579\n",
      "Epoch 315/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6640 - accuracy: 0.3602 - val_loss: 1.6635 - val_accuracy: 0.3577\n",
      "Epoch 316/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6636 - accuracy: 0.3605 - val_loss: 1.6632 - val_accuracy: 0.3576\n",
      "Epoch 317/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6632 - accuracy: 0.3601 - val_loss: 1.6629 - val_accuracy: 0.3574\n",
      "Epoch 318/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6629 - accuracy: 0.3598 - val_loss: 1.6627 - val_accuracy: 0.3579\n",
      "Epoch 319/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6627 - accuracy: 0.3603 - val_loss: 1.6623 - val_accuracy: 0.3577\n",
      "Epoch 320/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6622 - accuracy: 0.3606 - val_loss: 1.6621 - val_accuracy: 0.3577\n",
      "Epoch 321/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6619 - accuracy: 0.3606 - val_loss: 1.6615 - val_accuracy: 0.3577\n",
      "Epoch 322/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6615 - accuracy: 0.3603 - val_loss: 1.6612 - val_accuracy: 0.3577\n",
      "Epoch 323/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6612 - accuracy: 0.3610 - val_loss: 1.6608 - val_accuracy: 0.3577\n",
      "Epoch 324/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6608 - accuracy: 0.3611 - val_loss: 1.6616 - val_accuracy: 0.3596\n",
      "Epoch 325/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6602 - accuracy: 0.3617 - val_loss: 1.6607 - val_accuracy: 0.3587\n",
      "Epoch 326/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6600 - accuracy: 0.3615 - val_loss: 1.6597 - val_accuracy: 0.3579\n",
      "Epoch 327/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6594 - accuracy: 0.3618 - val_loss: 1.6593 - val_accuracy: 0.3582\n",
      "Epoch 328/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6591 - accuracy: 0.3614 - val_loss: 1.6588 - val_accuracy: 0.3582\n",
      "Epoch 329/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6588 - accuracy: 0.3627 - val_loss: 1.6585 - val_accuracy: 0.3576\n",
      "Epoch 330/747\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.6583 - accuracy: 0.3624 - val_loss: 1.6583 - val_accuracy: 0.3596\n",
      "Epoch 331/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.6576 - accuracy: 0.3631 - val_loss: 1.6583 - val_accuracy: 0.3602\n",
      "Epoch 332/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.6572 - accuracy: 0.3635 - val_loss: 1.6573 - val_accuracy: 0.3582\n",
      "Epoch 333/747\n",
      "408/408 [==============================] - 3s 7ms/step - loss: 1.6567 - accuracy: 0.3630 - val_loss: 1.6571 - val_accuracy: 0.3605\n",
      "Epoch 334/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.6562 - accuracy: 0.3636 - val_loss: 1.6565 - val_accuracy: 0.3583\n",
      "Epoch 335/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.6559 - accuracy: 0.3642 - val_loss: 1.6557 - val_accuracy: 0.3604\n",
      "Epoch 336/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6554 - accuracy: 0.3638 - val_loss: 1.6566 - val_accuracy: 0.3621\n",
      "Epoch 337/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6548 - accuracy: 0.3651 - val_loss: 1.6547 - val_accuracy: 0.3605\n",
      "Epoch 338/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6542 - accuracy: 0.3648 - val_loss: 1.6542 - val_accuracy: 0.3613\n",
      "Epoch 339/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6538 - accuracy: 0.3654 - val_loss: 1.6538 - val_accuracy: 0.3604\n",
      "Epoch 340/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6532 - accuracy: 0.3657 - val_loss: 1.6534 - val_accuracy: 0.3602\n",
      "Epoch 341/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6524 - accuracy: 0.3659 - val_loss: 1.6544 - val_accuracy: 0.3641\n",
      "Epoch 342/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6520 - accuracy: 0.3661 - val_loss: 1.6523 - val_accuracy: 0.3633\n",
      "Epoch 343/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6515 - accuracy: 0.3666 - val_loss: 1.6515 - val_accuracy: 0.3627\n",
      "Epoch 344/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6509 - accuracy: 0.3666 - val_loss: 1.6510 - val_accuracy: 0.3636\n",
      "Epoch 345/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6502 - accuracy: 0.3678 - val_loss: 1.6503 - val_accuracy: 0.3630\n",
      "Epoch 346/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6494 - accuracy: 0.3674 - val_loss: 1.6511 - val_accuracy: 0.3660\n",
      "Epoch 347/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6488 - accuracy: 0.3675 - val_loss: 1.6492 - val_accuracy: 0.3630\n",
      "Epoch 348/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6483 - accuracy: 0.3679 - val_loss: 1.6489 - val_accuracy: 0.3622\n",
      "Epoch 349/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6477 - accuracy: 0.3681 - val_loss: 1.6481 - val_accuracy: 0.3646\n",
      "Epoch 350/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6471 - accuracy: 0.3697 - val_loss: 1.6472 - val_accuracy: 0.3636\n",
      "Epoch 351/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6461 - accuracy: 0.3693 - val_loss: 1.6465 - val_accuracy: 0.3633\n",
      "Epoch 352/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6455 - accuracy: 0.3696 - val_loss: 1.6463 - val_accuracy: 0.3683\n",
      "Epoch 353/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6450 - accuracy: 0.3702 - val_loss: 1.6452 - val_accuracy: 0.3669\n",
      "Epoch 354/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6439 - accuracy: 0.3710 - val_loss: 1.6444 - val_accuracy: 0.3647\n",
      "Epoch 355/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6434 - accuracy: 0.3706 - val_loss: 1.6437 - val_accuracy: 0.3672\n",
      "Epoch 356/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6428 - accuracy: 0.3710 - val_loss: 1.6432 - val_accuracy: 0.3703\n",
      "Epoch 357/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6416 - accuracy: 0.3726 - val_loss: 1.6425 - val_accuracy: 0.3653\n",
      "Epoch 358/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6409 - accuracy: 0.3733 - val_loss: 1.6419 - val_accuracy: 0.3716\n",
      "Epoch 359/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6405 - accuracy: 0.3728 - val_loss: 1.6407 - val_accuracy: 0.3702\n",
      "Epoch 360/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6396 - accuracy: 0.3743 - val_loss: 1.6400 - val_accuracy: 0.3702\n",
      "Epoch 361/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6389 - accuracy: 0.3744 - val_loss: 1.6393 - val_accuracy: 0.3700\n",
      "Epoch 362/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6380 - accuracy: 0.3741 - val_loss: 1.6388 - val_accuracy: 0.3742\n",
      "Epoch 363/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6373 - accuracy: 0.3751 - val_loss: 1.6378 - val_accuracy: 0.3708\n",
      "Epoch 364/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6364 - accuracy: 0.3769 - val_loss: 1.6369 - val_accuracy: 0.3734\n",
      "Epoch 365/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6357 - accuracy: 0.3775 - val_loss: 1.6361 - val_accuracy: 0.3747\n",
      "Epoch 366/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6351 - accuracy: 0.3782 - val_loss: 1.6355 - val_accuracy: 0.3761\n",
      "Epoch 367/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6337 - accuracy: 0.3796 - val_loss: 1.6345 - val_accuracy: 0.3742\n",
      "Epoch 368/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6333 - accuracy: 0.3789 - val_loss: 1.6338 - val_accuracy: 0.3741\n",
      "Epoch 369/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6322 - accuracy: 0.3815 - val_loss: 1.6351 - val_accuracy: 0.3685\n",
      "Epoch 370/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6318 - accuracy: 0.3808 - val_loss: 1.6324 - val_accuracy: 0.3744\n",
      "Epoch 371/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6309 - accuracy: 0.3818 - val_loss: 1.6317 - val_accuracy: 0.3795\n",
      "Epoch 372/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6303 - accuracy: 0.3828 - val_loss: 1.6305 - val_accuracy: 0.3767\n",
      "Epoch 373/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6291 - accuracy: 0.3830 - val_loss: 1.6307 - val_accuracy: 0.3826\n",
      "Epoch 374/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6285 - accuracy: 0.3839 - val_loss: 1.6291 - val_accuracy: 0.3811\n",
      "Epoch 375/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6276 - accuracy: 0.3860 - val_loss: 1.6287 - val_accuracy: 0.3758\n",
      "Epoch 376/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6271 - accuracy: 0.3865 - val_loss: 1.6279 - val_accuracy: 0.3847\n",
      "Epoch 377/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6258 - accuracy: 0.3880 - val_loss: 1.6269 - val_accuracy: 0.3850\n",
      "Epoch 378/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6248 - accuracy: 0.3869 - val_loss: 1.6257 - val_accuracy: 0.3848\n",
      "Epoch 379/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6242 - accuracy: 0.3887 - val_loss: 1.6244 - val_accuracy: 0.3814\n",
      "Epoch 380/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6232 - accuracy: 0.3893 - val_loss: 1.6240 - val_accuracy: 0.3814\n",
      "Epoch 381/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6221 - accuracy: 0.3907 - val_loss: 1.6239 - val_accuracy: 0.3884\n",
      "Epoch 382/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6212 - accuracy: 0.3914 - val_loss: 1.6227 - val_accuracy: 0.3871\n",
      "Epoch 383/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6206 - accuracy: 0.3916 - val_loss: 1.6221 - val_accuracy: 0.3892\n",
      "Epoch 384/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6195 - accuracy: 0.3930 - val_loss: 1.6202 - val_accuracy: 0.3873\n",
      "Epoch 385/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6185 - accuracy: 0.3925 - val_loss: 1.6192 - val_accuracy: 0.3871\n",
      "Epoch 386/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6176 - accuracy: 0.3935 - val_loss: 1.6184 - val_accuracy: 0.3848\n",
      "Epoch 387/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6167 - accuracy: 0.3937 - val_loss: 1.6176 - val_accuracy: 0.3848\n",
      "Epoch 388/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6156 - accuracy: 0.3953 - val_loss: 1.6164 - val_accuracy: 0.3868\n",
      "Epoch 389/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6151 - accuracy: 0.3956 - val_loss: 1.6157 - val_accuracy: 0.3889\n",
      "Epoch 390/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6144 - accuracy: 0.3953 - val_loss: 1.6147 - val_accuracy: 0.3873\n",
      "Epoch 391/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6129 - accuracy: 0.3969 - val_loss: 1.6138 - val_accuracy: 0.3895\n",
      "Epoch 392/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6121 - accuracy: 0.3953 - val_loss: 1.6127 - val_accuracy: 0.3885\n",
      "Epoch 393/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6110 - accuracy: 0.3976 - val_loss: 1.6127 - val_accuracy: 0.3935\n",
      "Epoch 394/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6101 - accuracy: 0.3980 - val_loss: 1.6109 - val_accuracy: 0.3890\n",
      "Epoch 395/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6092 - accuracy: 0.3976 - val_loss: 1.6101 - val_accuracy: 0.3889\n",
      "Epoch 396/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6081 - accuracy: 0.3987 - val_loss: 1.6124 - val_accuracy: 0.3957\n",
      "Epoch 397/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6070 - accuracy: 0.3992 - val_loss: 1.6085 - val_accuracy: 0.3881\n",
      "Epoch 398/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6063 - accuracy: 0.3984 - val_loss: 1.6072 - val_accuracy: 0.3915\n",
      "Epoch 399/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6051 - accuracy: 0.3990 - val_loss: 1.6089 - val_accuracy: 0.3957\n",
      "Epoch 400/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6044 - accuracy: 0.3989 - val_loss: 1.6052 - val_accuracy: 0.3910\n",
      "Epoch 401/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6033 - accuracy: 0.3997 - val_loss: 1.6042 - val_accuracy: 0.3918\n",
      "Epoch 402/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6023 - accuracy: 0.4012 - val_loss: 1.6031 - val_accuracy: 0.3915\n",
      "Epoch 403/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.6012 - accuracy: 0.4021 - val_loss: 1.6021 - val_accuracy: 0.3921\n",
      "Epoch 404/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.6001 - accuracy: 0.4011 - val_loss: 1.6010 - val_accuracy: 0.3913\n",
      "Epoch 405/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5990 - accuracy: 0.4022 - val_loss: 1.6009 - val_accuracy: 0.3954\n",
      "Epoch 406/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5984 - accuracy: 0.4020 - val_loss: 1.6001 - val_accuracy: 0.3901\n",
      "Epoch 407/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5969 - accuracy: 0.4021 - val_loss: 1.5978 - val_accuracy: 0.3912\n",
      "Epoch 408/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5958 - accuracy: 0.4013 - val_loss: 1.5974 - val_accuracy: 0.3973\n",
      "Epoch 409/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5946 - accuracy: 0.4027 - val_loss: 1.5951 - val_accuracy: 0.3927\n",
      "Epoch 410/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5933 - accuracy: 0.4032 - val_loss: 1.5939 - val_accuracy: 0.3946\n",
      "Epoch 411/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5917 - accuracy: 0.4039 - val_loss: 1.5968 - val_accuracy: 0.3892\n",
      "Epoch 412/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5907 - accuracy: 0.4034 - val_loss: 1.5923 - val_accuracy: 0.3912\n",
      "Epoch 413/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5894 - accuracy: 0.4048 - val_loss: 1.5906 - val_accuracy: 0.3912\n",
      "Epoch 414/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5883 - accuracy: 0.4044 - val_loss: 1.5886 - val_accuracy: 0.3946\n",
      "Epoch 415/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5868 - accuracy: 0.4054 - val_loss: 1.5878 - val_accuracy: 0.3988\n",
      "Epoch 416/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5856 - accuracy: 0.4047 - val_loss: 1.5865 - val_accuracy: 0.3994\n",
      "Epoch 417/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5841 - accuracy: 0.4065 - val_loss: 1.5846 - val_accuracy: 0.3980\n",
      "Epoch 418/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5830 - accuracy: 0.4064 - val_loss: 1.5832 - val_accuracy: 0.3969\n",
      "Epoch 419/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5817 - accuracy: 0.4072 - val_loss: 1.5820 - val_accuracy: 0.4002\n",
      "Epoch 420/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5806 - accuracy: 0.4071 - val_loss: 1.5805 - val_accuracy: 0.3991\n",
      "Epoch 421/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5791 - accuracy: 0.4091 - val_loss: 1.5794 - val_accuracy: 0.4005\n",
      "Epoch 422/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5780 - accuracy: 0.4090 - val_loss: 1.5778 - val_accuracy: 0.4013\n",
      "Epoch 423/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5766 - accuracy: 0.4108 - val_loss: 1.5767 - val_accuracy: 0.3994\n",
      "Epoch 424/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5755 - accuracy: 0.4100 - val_loss: 1.5751 - val_accuracy: 0.4022\n",
      "Epoch 425/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5738 - accuracy: 0.4123 - val_loss: 1.5757 - val_accuracy: 0.3966\n",
      "Epoch 426/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5729 - accuracy: 0.4112 - val_loss: 1.5732 - val_accuracy: 0.4038\n",
      "Epoch 427/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5710 - accuracy: 0.4121 - val_loss: 1.5715 - val_accuracy: 0.4050\n",
      "Epoch 428/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5699 - accuracy: 0.4125 - val_loss: 1.5709 - val_accuracy: 0.4064\n",
      "Epoch 429/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5689 - accuracy: 0.4124 - val_loss: 1.5687 - val_accuracy: 0.4038\n",
      "Epoch 430/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5674 - accuracy: 0.4147 - val_loss: 1.5687 - val_accuracy: 0.4092\n",
      "Epoch 431/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5664 - accuracy: 0.4142 - val_loss: 1.5663 - val_accuracy: 0.4040\n",
      "Epoch 432/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5652 - accuracy: 0.4147 - val_loss: 1.5657 - val_accuracy: 0.4083\n",
      "Epoch 433/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5643 - accuracy: 0.4142 - val_loss: 1.5643 - val_accuracy: 0.4040\n",
      "Epoch 434/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5624 - accuracy: 0.4145 - val_loss: 1.5636 - val_accuracy: 0.4110\n",
      "Epoch 435/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5617 - accuracy: 0.4153 - val_loss: 1.5618 - val_accuracy: 0.4047\n",
      "Epoch 436/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5604 - accuracy: 0.4155 - val_loss: 1.5606 - val_accuracy: 0.4058\n",
      "Epoch 437/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5588 - accuracy: 0.4152 - val_loss: 1.5641 - val_accuracy: 0.4150\n",
      "Epoch 438/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5586 - accuracy: 0.4160 - val_loss: 1.5581 - val_accuracy: 0.4069\n",
      "Epoch 439/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5572 - accuracy: 0.4174 - val_loss: 1.5608 - val_accuracy: 0.4153\n",
      "Epoch 440/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5559 - accuracy: 0.4173 - val_loss: 1.5560 - val_accuracy: 0.4063\n",
      "Epoch 441/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5549 - accuracy: 0.4174 - val_loss: 1.5555 - val_accuracy: 0.4130\n",
      "Epoch 442/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5540 - accuracy: 0.4163 - val_loss: 1.5545 - val_accuracy: 0.4138\n",
      "Epoch 443/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5523 - accuracy: 0.4180 - val_loss: 1.5522 - val_accuracy: 0.4102\n",
      "Epoch 444/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5516 - accuracy: 0.4183 - val_loss: 1.5515 - val_accuracy: 0.4113\n",
      "Epoch 445/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5508 - accuracy: 0.4181 - val_loss: 1.5501 - val_accuracy: 0.4088\n",
      "Epoch 446/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5494 - accuracy: 0.4182 - val_loss: 1.5490 - val_accuracy: 0.4097\n",
      "Epoch 447/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5485 - accuracy: 0.4190 - val_loss: 1.5493 - val_accuracy: 0.4127\n",
      "Epoch 448/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5472 - accuracy: 0.4183 - val_loss: 1.5472 - val_accuracy: 0.4125\n",
      "Epoch 449/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5462 - accuracy: 0.4186 - val_loss: 1.5461 - val_accuracy: 0.4097\n",
      "Epoch 450/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5459 - accuracy: 0.4194 - val_loss: 1.5455 - val_accuracy: 0.4080\n",
      "Epoch 451/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5448 - accuracy: 0.4180 - val_loss: 1.5439 - val_accuracy: 0.4116\n",
      "Epoch 452/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5435 - accuracy: 0.4188 - val_loss: 1.5435 - val_accuracy: 0.4124\n",
      "Epoch 453/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5422 - accuracy: 0.4198 - val_loss: 1.5429 - val_accuracy: 0.4139\n",
      "Epoch 454/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5415 - accuracy: 0.4194 - val_loss: 1.5457 - val_accuracy: 0.4069\n",
      "Epoch 455/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5410 - accuracy: 0.4186 - val_loss: 1.5407 - val_accuracy: 0.4091\n",
      "Epoch 456/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5393 - accuracy: 0.4204 - val_loss: 1.5396 - val_accuracy: 0.4120\n",
      "Epoch 457/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5387 - accuracy: 0.4203 - val_loss: 1.5383 - val_accuracy: 0.4128\n",
      "Epoch 458/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5379 - accuracy: 0.4204 - val_loss: 1.5402 - val_accuracy: 0.4172\n",
      "Epoch 459/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5372 - accuracy: 0.4200 - val_loss: 1.5368 - val_accuracy: 0.4150\n",
      "Epoch 460/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5360 - accuracy: 0.4208 - val_loss: 1.5370 - val_accuracy: 0.4155\n",
      "Epoch 461/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5353 - accuracy: 0.4200 - val_loss: 1.5351 - val_accuracy: 0.4111\n",
      "Epoch 462/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5347 - accuracy: 0.4213 - val_loss: 1.5350 - val_accuracy: 0.4088\n",
      "Epoch 463/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5337 - accuracy: 0.4205 - val_loss: 1.5332 - val_accuracy: 0.4125\n",
      "Epoch 464/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5327 - accuracy: 0.4214 - val_loss: 1.5331 - val_accuracy: 0.4158\n",
      "Epoch 465/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5317 - accuracy: 0.4216 - val_loss: 1.5322 - val_accuracy: 0.4105\n",
      "Epoch 466/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5309 - accuracy: 0.4204 - val_loss: 1.5310 - val_accuracy: 0.4159\n",
      "Epoch 467/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5302 - accuracy: 0.4221 - val_loss: 1.5305 - val_accuracy: 0.4150\n",
      "Epoch 468/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5290 - accuracy: 0.4221 - val_loss: 1.5354 - val_accuracy: 0.4077\n",
      "Epoch 469/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5293 - accuracy: 0.4209 - val_loss: 1.5317 - val_accuracy: 0.4077\n",
      "Epoch 470/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5278 - accuracy: 0.4220 - val_loss: 1.5295 - val_accuracy: 0.4183\n",
      "Epoch 471/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5275 - accuracy: 0.4218 - val_loss: 1.5265 - val_accuracy: 0.4147\n",
      "Epoch 472/747\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.5259 - accuracy: 0.4214 - val_loss: 1.5261 - val_accuracy: 0.4164\n",
      "Epoch 473/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5253 - accuracy: 0.4212 - val_loss: 1.5263 - val_accuracy: 0.4181\n",
      "Epoch 474/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5249 - accuracy: 0.4233 - val_loss: 1.5243 - val_accuracy: 0.4156\n",
      "Epoch 475/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5239 - accuracy: 0.4223 - val_loss: 1.5240 - val_accuracy: 0.4150\n",
      "Epoch 476/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5235 - accuracy: 0.4225 - val_loss: 1.5232 - val_accuracy: 0.4097\n",
      "Epoch 477/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5224 - accuracy: 0.4205 - val_loss: 1.5223 - val_accuracy: 0.4141\n",
      "Epoch 478/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5218 - accuracy: 0.4195 - val_loss: 1.5221 - val_accuracy: 0.4150\n",
      "Epoch 479/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5213 - accuracy: 0.4182 - val_loss: 1.5211 - val_accuracy: 0.4144\n",
      "Epoch 480/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5209 - accuracy: 0.4176 - val_loss: 1.5201 - val_accuracy: 0.4116\n",
      "Epoch 481/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5198 - accuracy: 0.4186 - val_loss: 1.5198 - val_accuracy: 0.4078\n",
      "Epoch 482/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5188 - accuracy: 0.4180 - val_loss: 1.5190 - val_accuracy: 0.4092\n",
      "Epoch 483/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5182 - accuracy: 0.4162 - val_loss: 1.5194 - val_accuracy: 0.4145\n",
      "Epoch 484/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5175 - accuracy: 0.4180 - val_loss: 1.5181 - val_accuracy: 0.4133\n",
      "Epoch 485/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5171 - accuracy: 0.4187 - val_loss: 1.5184 - val_accuracy: 0.4138\n",
      "Epoch 486/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5166 - accuracy: 0.4171 - val_loss: 1.5167 - val_accuracy: 0.4130\n",
      "Epoch 487/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5157 - accuracy: 0.4176 - val_loss: 1.5154 - val_accuracy: 0.4086\n",
      "Epoch 488/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5148 - accuracy: 0.4179 - val_loss: 1.5148 - val_accuracy: 0.4106\n",
      "Epoch 489/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5147 - accuracy: 0.4170 - val_loss: 1.5141 - val_accuracy: 0.4110\n",
      "Epoch 490/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5139 - accuracy: 0.4173 - val_loss: 1.5174 - val_accuracy: 0.4141\n",
      "Epoch 491/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5133 - accuracy: 0.4167 - val_loss: 1.5139 - val_accuracy: 0.4063\n",
      "Epoch 492/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5126 - accuracy: 0.4180 - val_loss: 1.5123 - val_accuracy: 0.4125\n",
      "Epoch 493/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5122 - accuracy: 0.4181 - val_loss: 1.5121 - val_accuracy: 0.4086\n",
      "Epoch 494/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5112 - accuracy: 0.4181 - val_loss: 1.5110 - val_accuracy: 0.4124\n",
      "Epoch 495/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5108 - accuracy: 0.4180 - val_loss: 1.5109 - val_accuracy: 0.4131\n",
      "Epoch 496/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5106 - accuracy: 0.4165 - val_loss: 1.5101 - val_accuracy: 0.4130\n",
      "Epoch 497/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5097 - accuracy: 0.4170 - val_loss: 1.5126 - val_accuracy: 0.4147\n",
      "Epoch 498/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5089 - accuracy: 0.4185 - val_loss: 1.5089 - val_accuracy: 0.4139\n",
      "Epoch 499/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5087 - accuracy: 0.4176 - val_loss: 1.5083 - val_accuracy: 0.4108\n",
      "Epoch 500/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5080 - accuracy: 0.4164 - val_loss: 1.5076 - val_accuracy: 0.4119\n",
      "Epoch 501/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5074 - accuracy: 0.4189 - val_loss: 1.5076 - val_accuracy: 0.4139\n",
      "Epoch 502/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5074 - accuracy: 0.4191 - val_loss: 1.5067 - val_accuracy: 0.4141\n",
      "Epoch 503/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5061 - accuracy: 0.4186 - val_loss: 1.5066 - val_accuracy: 0.4108\n",
      "Epoch 504/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5058 - accuracy: 0.4193 - val_loss: 1.5056 - val_accuracy: 0.4144\n",
      "Epoch 505/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5054 - accuracy: 0.4186 - val_loss: 1.5056 - val_accuracy: 0.4139\n",
      "Epoch 506/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5049 - accuracy: 0.4196 - val_loss: 1.5057 - val_accuracy: 0.4103\n",
      "Epoch 507/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5042 - accuracy: 0.4203 - val_loss: 1.5040 - val_accuracy: 0.4158\n",
      "Epoch 508/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5037 - accuracy: 0.4197 - val_loss: 1.5044 - val_accuracy: 0.4156\n",
      "Epoch 509/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.5037 - accuracy: 0.4194 - val_loss: 1.5038 - val_accuracy: 0.4125\n",
      "Epoch 510/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5031 - accuracy: 0.4200 - val_loss: 1.5024 - val_accuracy: 0.4166\n",
      "Epoch 511/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5022 - accuracy: 0.4206 - val_loss: 1.5020 - val_accuracy: 0.4170\n",
      "Epoch 512/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5013 - accuracy: 0.4216 - val_loss: 1.5033 - val_accuracy: 0.4184\n",
      "Epoch 513/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5015 - accuracy: 0.4202 - val_loss: 1.5011 - val_accuracy: 0.4166\n",
      "Epoch 514/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.5008 - accuracy: 0.4203 - val_loss: 1.5006 - val_accuracy: 0.4180\n",
      "Epoch 515/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.5004 - accuracy: 0.4202 - val_loss: 1.5020 - val_accuracy: 0.4184\n",
      "Epoch 516/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.5000 - accuracy: 0.4203 - val_loss: 1.5027 - val_accuracy: 0.4183\n",
      "Epoch 517/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4995 - accuracy: 0.4214 - val_loss: 1.4993 - val_accuracy: 0.4183\n",
      "Epoch 518/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4989 - accuracy: 0.4208 - val_loss: 1.5000 - val_accuracy: 0.4147\n",
      "Epoch 519/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4983 - accuracy: 0.4216 - val_loss: 1.5009 - val_accuracy: 0.4145\n",
      "Epoch 520/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4983 - accuracy: 0.4200 - val_loss: 1.4980 - val_accuracy: 0.4200\n",
      "Epoch 521/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4981 - accuracy: 0.4223 - val_loss: 1.4983 - val_accuracy: 0.4192\n",
      "Epoch 522/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4974 - accuracy: 0.4215 - val_loss: 1.4979 - val_accuracy: 0.4194\n",
      "Epoch 523/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4966 - accuracy: 0.4221 - val_loss: 1.5019 - val_accuracy: 0.4200\n",
      "Epoch 524/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4966 - accuracy: 0.4214 - val_loss: 1.4970 - val_accuracy: 0.4198\n",
      "Epoch 525/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4959 - accuracy: 0.4218 - val_loss: 1.4965 - val_accuracy: 0.4197\n",
      "Epoch 526/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4958 - accuracy: 0.4228 - val_loss: 1.4964 - val_accuracy: 0.4198\n",
      "Epoch 527/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4951 - accuracy: 0.4233 - val_loss: 1.4960 - val_accuracy: 0.4189\n",
      "Epoch 528/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4948 - accuracy: 0.4216 - val_loss: 1.4949 - val_accuracy: 0.4205\n",
      "Epoch 529/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4943 - accuracy: 0.4243 - val_loss: 1.4943 - val_accuracy: 0.4212\n",
      "Epoch 530/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4938 - accuracy: 0.4239 - val_loss: 1.4949 - val_accuracy: 0.4211\n",
      "Epoch 531/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4933 - accuracy: 0.4240 - val_loss: 1.4949 - val_accuracy: 0.4209\n",
      "Epoch 532/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4930 - accuracy: 0.4230 - val_loss: 1.4944 - val_accuracy: 0.4201\n",
      "Epoch 533/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4928 - accuracy: 0.4252 - val_loss: 1.4931 - val_accuracy: 0.4192\n",
      "Epoch 534/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4928 - accuracy: 0.4237 - val_loss: 1.4934 - val_accuracy: 0.4197\n",
      "Epoch 535/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4921 - accuracy: 0.4241 - val_loss: 1.4924 - val_accuracy: 0.4215\n",
      "Epoch 536/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4917 - accuracy: 0.4259 - val_loss: 1.4921 - val_accuracy: 0.4205\n",
      "Epoch 537/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4911 - accuracy: 0.4259 - val_loss: 1.4928 - val_accuracy: 0.4228\n",
      "Epoch 538/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4910 - accuracy: 0.4245 - val_loss: 1.4911 - val_accuracy: 0.4212\n",
      "Epoch 539/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4909 - accuracy: 0.4256 - val_loss: 1.4908 - val_accuracy: 0.4220\n",
      "Epoch 540/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4907 - accuracy: 0.4259 - val_loss: 1.4913 - val_accuracy: 0.4201\n",
      "Epoch 541/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4894 - accuracy: 0.4274 - val_loss: 1.4903 - val_accuracy: 0.4219\n",
      "Epoch 542/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4895 - accuracy: 0.4266 - val_loss: 1.4907 - val_accuracy: 0.4229\n",
      "Epoch 543/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4886 - accuracy: 0.4271 - val_loss: 1.4895 - val_accuracy: 0.4226\n",
      "Epoch 544/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4886 - accuracy: 0.4278 - val_loss: 1.4900 - val_accuracy: 0.4250\n",
      "Epoch 545/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4884 - accuracy: 0.4289 - val_loss: 1.4900 - val_accuracy: 0.4256\n",
      "Epoch 546/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4881 - accuracy: 0.4275 - val_loss: 1.4932 - val_accuracy: 0.4253\n",
      "Epoch 547/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4878 - accuracy: 0.4275 - val_loss: 1.4898 - val_accuracy: 0.4267\n",
      "Epoch 548/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4875 - accuracy: 0.4284 - val_loss: 1.4885 - val_accuracy: 0.4265\n",
      "Epoch 549/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4872 - accuracy: 0.4305 - val_loss: 1.4881 - val_accuracy: 0.4236\n",
      "Epoch 550/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4864 - accuracy: 0.4280 - val_loss: 1.4897 - val_accuracy: 0.4292\n",
      "Epoch 551/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4863 - accuracy: 0.4282 - val_loss: 1.4885 - val_accuracy: 0.4212\n",
      "Epoch 552/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4860 - accuracy: 0.4305 - val_loss: 1.4879 - val_accuracy: 0.4289\n",
      "Epoch 553/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4855 - accuracy: 0.4308 - val_loss: 1.4868 - val_accuracy: 0.4267\n",
      "Epoch 554/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4857 - accuracy: 0.4298 - val_loss: 1.4886 - val_accuracy: 0.4290\n",
      "Epoch 555/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4850 - accuracy: 0.4305 - val_loss: 1.4861 - val_accuracy: 0.4289\n",
      "Epoch 556/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4854 - accuracy: 0.4297 - val_loss: 1.4887 - val_accuracy: 0.4279\n",
      "Epoch 557/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4846 - accuracy: 0.4308 - val_loss: 1.4855 - val_accuracy: 0.4315\n",
      "Epoch 558/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4847 - accuracy: 0.4301 - val_loss: 1.4852 - val_accuracy: 0.4278\n",
      "Epoch 559/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4840 - accuracy: 0.4306 - val_loss: 1.4850 - val_accuracy: 0.4324\n",
      "Epoch 560/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4836 - accuracy: 0.4308 - val_loss: 1.4849 - val_accuracy: 0.4320\n",
      "Epoch 561/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4829 - accuracy: 0.4321 - val_loss: 1.4853 - val_accuracy: 0.4256\n",
      "Epoch 562/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4833 - accuracy: 0.4324 - val_loss: 1.4849 - val_accuracy: 0.4312\n",
      "Epoch 563/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4827 - accuracy: 0.4318 - val_loss: 1.4840 - val_accuracy: 0.4301\n",
      "Epoch 564/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4825 - accuracy: 0.4311 - val_loss: 1.4836 - val_accuracy: 0.4301\n",
      "Epoch 565/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4826 - accuracy: 0.4327 - val_loss: 1.4831 - val_accuracy: 0.4342\n",
      "Epoch 566/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4811 - accuracy: 0.4341 - val_loss: 1.4911 - val_accuracy: 0.4335\n",
      "Epoch 567/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4817 - accuracy: 0.4328 - val_loss: 1.4853 - val_accuracy: 0.4256\n",
      "Epoch 568/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4812 - accuracy: 0.4338 - val_loss: 1.4826 - val_accuracy: 0.4320\n",
      "Epoch 569/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4807 - accuracy: 0.4335 - val_loss: 1.4819 - val_accuracy: 0.4337\n",
      "Epoch 570/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4806 - accuracy: 0.4336 - val_loss: 1.4817 - val_accuracy: 0.4331\n",
      "Epoch 571/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4800 - accuracy: 0.4352 - val_loss: 1.4815 - val_accuracy: 0.4324\n",
      "Epoch 572/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4804 - accuracy: 0.4353 - val_loss: 1.4841 - val_accuracy: 0.4267\n",
      "Epoch 573/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4804 - accuracy: 0.4331 - val_loss: 1.4808 - val_accuracy: 0.4340\n",
      "Epoch 574/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4794 - accuracy: 0.4348 - val_loss: 1.4805 - val_accuracy: 0.4326\n",
      "Epoch 575/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4794 - accuracy: 0.4344 - val_loss: 1.4801 - val_accuracy: 0.4340\n",
      "Epoch 576/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4790 - accuracy: 0.4357 - val_loss: 1.4828 - val_accuracy: 0.4356\n",
      "Epoch 577/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4787 - accuracy: 0.4343 - val_loss: 1.4804 - val_accuracy: 0.4314\n",
      "Epoch 578/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4782 - accuracy: 0.4332 - val_loss: 1.4797 - val_accuracy: 0.4331\n",
      "Epoch 579/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4777 - accuracy: 0.4343 - val_loss: 1.4801 - val_accuracy: 0.4335\n",
      "Epoch 580/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4778 - accuracy: 0.4346 - val_loss: 1.4798 - val_accuracy: 0.4356\n",
      "Epoch 581/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4773 - accuracy: 0.4361 - val_loss: 1.4792 - val_accuracy: 0.4335\n",
      "Epoch 582/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4770 - accuracy: 0.4351 - val_loss: 1.4803 - val_accuracy: 0.4310\n",
      "Epoch 583/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4764 - accuracy: 0.4355 - val_loss: 1.4778 - val_accuracy: 0.4340\n",
      "Epoch 584/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4760 - accuracy: 0.4351 - val_loss: 1.4779 - val_accuracy: 0.4365\n",
      "Epoch 585/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4756 - accuracy: 0.4365 - val_loss: 1.4817 - val_accuracy: 0.4270\n",
      "Epoch 586/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4760 - accuracy: 0.4364 - val_loss: 1.4768 - val_accuracy: 0.4366\n",
      "Epoch 587/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4757 - accuracy: 0.4359 - val_loss: 1.4775 - val_accuracy: 0.4343\n",
      "Epoch 588/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4747 - accuracy: 0.4369 - val_loss: 1.4762 - val_accuracy: 0.4343\n",
      "Epoch 589/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4743 - accuracy: 0.4371 - val_loss: 1.4768 - val_accuracy: 0.4340\n",
      "Epoch 590/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4740 - accuracy: 0.4367 - val_loss: 1.4756 - val_accuracy: 0.4376\n",
      "Epoch 591/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4736 - accuracy: 0.4364 - val_loss: 1.4759 - val_accuracy: 0.4362\n",
      "Epoch 592/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4729 - accuracy: 0.4364 - val_loss: 1.4744 - val_accuracy: 0.4377\n",
      "Epoch 593/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4729 - accuracy: 0.4369 - val_loss: 1.4744 - val_accuracy: 0.4365\n",
      "Epoch 594/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4723 - accuracy: 0.4370 - val_loss: 1.4737 - val_accuracy: 0.4368\n",
      "Epoch 595/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4714 - accuracy: 0.4372 - val_loss: 1.4747 - val_accuracy: 0.4393\n",
      "Epoch 596/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4710 - accuracy: 0.4403 - val_loss: 1.4728 - val_accuracy: 0.4393\n",
      "Epoch 597/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4695 - accuracy: 0.4393 - val_loss: 1.4705 - val_accuracy: 0.4385\n",
      "Epoch 598/747\n",
      "408/408 [==============================] - 3s 6ms/step - loss: 1.4689 - accuracy: 0.4382 - val_loss: 1.4710 - val_accuracy: 0.4363\n",
      "Epoch 599/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4683 - accuracy: 0.4404 - val_loss: 1.4706 - val_accuracy: 0.4371\n",
      "Epoch 600/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4679 - accuracy: 0.4406 - val_loss: 1.4692 - val_accuracy: 0.4379\n",
      "Epoch 601/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4671 - accuracy: 0.4396 - val_loss: 1.4698 - val_accuracy: 0.4387\n",
      "Epoch 602/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4671 - accuracy: 0.4404 - val_loss: 1.4680 - val_accuracy: 0.4385\n",
      "Epoch 603/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4661 - accuracy: 0.4406 - val_loss: 1.4677 - val_accuracy: 0.4404\n",
      "Epoch 604/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4649 - accuracy: 0.4440 - val_loss: 1.4669 - val_accuracy: 0.4377\n",
      "Epoch 605/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4644 - accuracy: 0.4428 - val_loss: 1.4666 - val_accuracy: 0.4371\n",
      "Epoch 606/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4637 - accuracy: 0.4442 - val_loss: 1.4676 - val_accuracy: 0.4390\n",
      "Epoch 607/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4636 - accuracy: 0.4428 - val_loss: 1.4655 - val_accuracy: 0.4391\n",
      "Epoch 608/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4631 - accuracy: 0.4444 - val_loss: 1.4666 - val_accuracy: 0.4376\n",
      "Epoch 609/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4624 - accuracy: 0.4450 - val_loss: 1.4644 - val_accuracy: 0.4398\n",
      "Epoch 610/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4618 - accuracy: 0.4459 - val_loss: 1.4634 - val_accuracy: 0.4407\n",
      "Epoch 611/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4606 - accuracy: 0.4482 - val_loss: 1.4659 - val_accuracy: 0.4360\n",
      "Epoch 612/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4603 - accuracy: 0.4454 - val_loss: 1.4631 - val_accuracy: 0.4398\n",
      "Epoch 613/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4597 - accuracy: 0.4460 - val_loss: 1.4628 - val_accuracy: 0.4407\n",
      "Epoch 614/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4590 - accuracy: 0.4469 - val_loss: 1.4615 - val_accuracy: 0.4402\n",
      "Epoch 615/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4590 - accuracy: 0.4487 - val_loss: 1.4615 - val_accuracy: 0.4415\n",
      "Epoch 616/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4581 - accuracy: 0.4476 - val_loss: 1.4631 - val_accuracy: 0.4440\n",
      "Epoch 617/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4571 - accuracy: 0.4509 - val_loss: 1.4620 - val_accuracy: 0.4393\n",
      "Epoch 618/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4570 - accuracy: 0.4474 - val_loss: 1.4647 - val_accuracy: 0.4384\n",
      "Epoch 619/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4565 - accuracy: 0.4509 - val_loss: 1.4599 - val_accuracy: 0.4413\n",
      "Epoch 620/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4561 - accuracy: 0.4472 - val_loss: 1.4581 - val_accuracy: 0.4435\n",
      "Epoch 621/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4546 - accuracy: 0.4489 - val_loss: 1.4581 - val_accuracy: 0.4433\n",
      "Epoch 622/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4542 - accuracy: 0.4505 - val_loss: 1.4568 - val_accuracy: 0.4422\n",
      "Epoch 623/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4535 - accuracy: 0.4500 - val_loss: 1.4563 - val_accuracy: 0.4433\n",
      "Epoch 624/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4526 - accuracy: 0.4503 - val_loss: 1.4569 - val_accuracy: 0.4427\n",
      "Epoch 625/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4527 - accuracy: 0.4509 - val_loss: 1.4595 - val_accuracy: 0.4401\n",
      "Epoch 626/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4519 - accuracy: 0.4520 - val_loss: 1.4549 - val_accuracy: 0.4460\n",
      "Epoch 627/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4508 - accuracy: 0.4523 - val_loss: 1.4551 - val_accuracy: 0.4430\n",
      "Epoch 628/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4506 - accuracy: 0.4521 - val_loss: 1.4548 - val_accuracy: 0.4441\n",
      "Epoch 629/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4502 - accuracy: 0.4545 - val_loss: 1.4530 - val_accuracy: 0.4480\n",
      "Epoch 630/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4492 - accuracy: 0.4561 - val_loss: 1.4532 - val_accuracy: 0.4491\n",
      "Epoch 631/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4485 - accuracy: 0.4538 - val_loss: 1.4535 - val_accuracy: 0.4491\n",
      "Epoch 632/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4487 - accuracy: 0.4563 - val_loss: 1.4516 - val_accuracy: 0.4468\n",
      "Epoch 633/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4476 - accuracy: 0.4568 - val_loss: 1.4518 - val_accuracy: 0.4513\n",
      "Epoch 634/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4469 - accuracy: 0.4583 - val_loss: 1.4505 - val_accuracy: 0.4513\n",
      "Epoch 635/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4465 - accuracy: 0.4583 - val_loss: 1.4507 - val_accuracy: 0.4482\n",
      "Epoch 636/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4460 - accuracy: 0.4581 - val_loss: 1.4499 - val_accuracy: 0.4494\n",
      "Epoch 637/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4453 - accuracy: 0.4588 - val_loss: 1.4491 - val_accuracy: 0.4521\n",
      "Epoch 638/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4446 - accuracy: 0.4564 - val_loss: 1.4525 - val_accuracy: 0.4482\n",
      "Epoch 639/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4442 - accuracy: 0.4580 - val_loss: 1.4485 - val_accuracy: 0.4530\n",
      "Epoch 640/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4434 - accuracy: 0.4583 - val_loss: 1.4481 - val_accuracy: 0.4530\n",
      "Epoch 641/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4431 - accuracy: 0.4589 - val_loss: 1.4471 - val_accuracy: 0.4536\n",
      "Epoch 642/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4428 - accuracy: 0.4605 - val_loss: 1.4464 - val_accuracy: 0.4531\n",
      "Epoch 643/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4424 - accuracy: 0.4598 - val_loss: 1.4455 - val_accuracy: 0.4541\n",
      "Epoch 644/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4414 - accuracy: 0.4595 - val_loss: 1.4452 - val_accuracy: 0.4545\n",
      "Epoch 645/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4407 - accuracy: 0.4599 - val_loss: 1.4451 - val_accuracy: 0.4538\n",
      "Epoch 646/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4400 - accuracy: 0.4611 - val_loss: 1.4442 - val_accuracy: 0.4542\n",
      "Epoch 647/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4398 - accuracy: 0.4607 - val_loss: 1.4436 - val_accuracy: 0.4553\n",
      "Epoch 648/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4394 - accuracy: 0.4620 - val_loss: 1.4441 - val_accuracy: 0.4552\n",
      "Epoch 649/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4385 - accuracy: 0.4636 - val_loss: 1.4435 - val_accuracy: 0.4533\n",
      "Epoch 650/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4381 - accuracy: 0.4620 - val_loss: 1.4431 - val_accuracy: 0.4555\n",
      "Epoch 651/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4378 - accuracy: 0.4628 - val_loss: 1.4414 - val_accuracy: 0.4561\n",
      "Epoch 652/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4376 - accuracy: 0.4620 - val_loss: 1.4424 - val_accuracy: 0.4544\n",
      "Epoch 653/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4363 - accuracy: 0.4630 - val_loss: 1.4413 - val_accuracy: 0.4555\n",
      "Epoch 654/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4366 - accuracy: 0.4635 - val_loss: 1.4438 - val_accuracy: 0.4569\n",
      "Epoch 655/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4362 - accuracy: 0.4642 - val_loss: 1.4451 - val_accuracy: 0.4603\n",
      "Epoch 656/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4360 - accuracy: 0.4643 - val_loss: 1.4409 - val_accuracy: 0.4556\n",
      "Epoch 657/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4349 - accuracy: 0.4624 - val_loss: 1.4397 - val_accuracy: 0.4558\n",
      "Epoch 658/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4345 - accuracy: 0.4634 - val_loss: 1.4416 - val_accuracy: 0.4597\n",
      "Epoch 659/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4336 - accuracy: 0.4664 - val_loss: 1.4417 - val_accuracy: 0.4575\n",
      "Epoch 660/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4334 - accuracy: 0.4645 - val_loss: 1.4380 - val_accuracy: 0.4600\n",
      "Epoch 661/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4332 - accuracy: 0.4661 - val_loss: 1.4393 - val_accuracy: 0.4597\n",
      "Epoch 662/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4326 - accuracy: 0.4660 - val_loss: 1.4376 - val_accuracy: 0.4619\n",
      "Epoch 663/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4329 - accuracy: 0.4663 - val_loss: 1.4364 - val_accuracy: 0.4622\n",
      "Epoch 664/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4316 - accuracy: 0.4673 - val_loss: 1.4373 - val_accuracy: 0.4601\n",
      "Epoch 665/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4311 - accuracy: 0.4654 - val_loss: 1.4375 - val_accuracy: 0.4636\n",
      "Epoch 666/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4309 - accuracy: 0.4676 - val_loss: 1.4372 - val_accuracy: 0.4617\n",
      "Epoch 667/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4303 - accuracy: 0.4656 - val_loss: 1.4358 - val_accuracy: 0.4645\n",
      "Epoch 668/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4302 - accuracy: 0.4674 - val_loss: 1.4364 - val_accuracy: 0.4622\n",
      "Epoch 669/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4303 - accuracy: 0.4696 - val_loss: 1.4351 - val_accuracy: 0.4637\n",
      "Epoch 670/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4288 - accuracy: 0.4713 - val_loss: 1.4377 - val_accuracy: 0.4642\n",
      "Epoch 671/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4285 - accuracy: 0.4693 - val_loss: 1.4341 - val_accuracy: 0.4634\n",
      "Epoch 672/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4282 - accuracy: 0.4685 - val_loss: 1.4323 - val_accuracy: 0.4654\n",
      "Epoch 673/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4275 - accuracy: 0.4703 - val_loss: 1.4327 - val_accuracy: 0.4661\n",
      "Epoch 674/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4278 - accuracy: 0.4706 - val_loss: 1.4323 - val_accuracy: 0.4681\n",
      "Epoch 675/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4273 - accuracy: 0.4702 - val_loss: 1.4315 - val_accuracy: 0.4647\n",
      "Epoch 676/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4269 - accuracy: 0.4710 - val_loss: 1.4313 - val_accuracy: 0.4665\n",
      "Epoch 677/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4266 - accuracy: 0.4706 - val_loss: 1.4374 - val_accuracy: 0.4659\n",
      "Epoch 678/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4257 - accuracy: 0.4716 - val_loss: 1.4331 - val_accuracy: 0.4679\n",
      "Epoch 679/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4263 - accuracy: 0.4725 - val_loss: 1.4301 - val_accuracy: 0.4679\n",
      "Epoch 680/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4254 - accuracy: 0.4713 - val_loss: 1.4312 - val_accuracy: 0.4634\n",
      "Epoch 681/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4248 - accuracy: 0.4726 - val_loss: 1.4312 - val_accuracy: 0.4675\n",
      "Epoch 682/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4242 - accuracy: 0.4733 - val_loss: 1.4293 - val_accuracy: 0.4695\n",
      "Epoch 683/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4237 - accuracy: 0.4726 - val_loss: 1.4288 - val_accuracy: 0.4675\n",
      "Epoch 684/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4237 - accuracy: 0.4729 - val_loss: 1.4277 - val_accuracy: 0.4673\n",
      "Epoch 685/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4235 - accuracy: 0.4739 - val_loss: 1.4278 - val_accuracy: 0.4686\n",
      "Epoch 686/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4229 - accuracy: 0.4734 - val_loss: 1.4278 - val_accuracy: 0.4695\n",
      "Epoch 687/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4230 - accuracy: 0.4735 - val_loss: 1.4293 - val_accuracy: 0.4712\n",
      "Epoch 688/747\n",
      "408/408 [==============================] - 3s 8ms/step - loss: 1.4224 - accuracy: 0.4731 - val_loss: 1.4269 - val_accuracy: 0.4701\n",
      "Epoch 689/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4216 - accuracy: 0.4767 - val_loss: 1.4272 - val_accuracy: 0.4676\n",
      "Epoch 690/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4215 - accuracy: 0.4768 - val_loss: 1.4260 - val_accuracy: 0.4715\n",
      "Epoch 691/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4214 - accuracy: 0.4739 - val_loss: 1.4254 - val_accuracy: 0.4731\n",
      "Epoch 692/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4208 - accuracy: 0.4753 - val_loss: 1.4255 - val_accuracy: 0.4715\n",
      "Epoch 693/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4203 - accuracy: 0.4744 - val_loss: 1.4264 - val_accuracy: 0.4735\n",
      "Epoch 694/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4199 - accuracy: 0.4746 - val_loss: 1.4250 - val_accuracy: 0.4723\n",
      "Epoch 695/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4198 - accuracy: 0.4769 - val_loss: 1.4257 - val_accuracy: 0.4714\n",
      "Epoch 696/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4198 - accuracy: 0.4775 - val_loss: 1.4245 - val_accuracy: 0.4737\n",
      "Epoch 697/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4192 - accuracy: 0.4772 - val_loss: 1.4250 - val_accuracy: 0.4726\n",
      "Epoch 698/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4188 - accuracy: 0.4764 - val_loss: 1.4235 - val_accuracy: 0.4731\n",
      "Epoch 699/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4181 - accuracy: 0.4788 - val_loss: 1.4227 - val_accuracy: 0.4735\n",
      "Epoch 700/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4175 - accuracy: 0.4775 - val_loss: 1.4234 - val_accuracy: 0.4732\n",
      "Epoch 701/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4175 - accuracy: 0.4786 - val_loss: 1.4241 - val_accuracy: 0.4703\n",
      "Epoch 702/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4174 - accuracy: 0.4777 - val_loss: 1.4223 - val_accuracy: 0.4759\n",
      "Epoch 703/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4171 - accuracy: 0.4774 - val_loss: 1.4218 - val_accuracy: 0.4748\n",
      "Epoch 704/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4168 - accuracy: 0.4766 - val_loss: 1.4211 - val_accuracy: 0.4767\n",
      "Epoch 705/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4163 - accuracy: 0.4788 - val_loss: 1.4218 - val_accuracy: 0.4763\n",
      "Epoch 706/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4157 - accuracy: 0.4799 - val_loss: 1.4204 - val_accuracy: 0.4738\n",
      "Epoch 707/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4153 - accuracy: 0.4794 - val_loss: 1.4214 - val_accuracy: 0.4715\n",
      "Epoch 708/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4152 - accuracy: 0.4789 - val_loss: 1.4197 - val_accuracy: 0.4763\n",
      "Epoch 709/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4146 - accuracy: 0.4799 - val_loss: 1.4201 - val_accuracy: 0.4768\n",
      "Epoch 710/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4143 - accuracy: 0.4801 - val_loss: 1.4204 - val_accuracy: 0.4751\n",
      "Epoch 711/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4138 - accuracy: 0.4806 - val_loss: 1.4219 - val_accuracy: 0.4737\n",
      "Epoch 712/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4137 - accuracy: 0.4798 - val_loss: 1.4198 - val_accuracy: 0.4767\n",
      "Epoch 713/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4135 - accuracy: 0.4821 - val_loss: 1.4213 - val_accuracy: 0.4796\n",
      "Epoch 714/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4133 - accuracy: 0.4812 - val_loss: 1.4180 - val_accuracy: 0.4760\n",
      "Epoch 715/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4126 - accuracy: 0.4801 - val_loss: 1.4172 - val_accuracy: 0.4757\n",
      "Epoch 716/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4121 - accuracy: 0.4811 - val_loss: 1.4181 - val_accuracy: 0.4785\n",
      "Epoch 717/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4128 - accuracy: 0.4813 - val_loss: 1.4170 - val_accuracy: 0.4787\n",
      "Epoch 718/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4121 - accuracy: 0.4801 - val_loss: 1.4225 - val_accuracy: 0.4779\n",
      "Epoch 719/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4114 - accuracy: 0.4833 - val_loss: 1.4160 - val_accuracy: 0.4782\n",
      "Epoch 720/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4115 - accuracy: 0.4813 - val_loss: 1.4158 - val_accuracy: 0.4790\n",
      "Epoch 721/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4112 - accuracy: 0.4806 - val_loss: 1.4183 - val_accuracy: 0.4812\n",
      "Epoch 722/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4108 - accuracy: 0.4824 - val_loss: 1.4178 - val_accuracy: 0.4751\n",
      "Epoch 723/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4100 - accuracy: 0.4830 - val_loss: 1.4166 - val_accuracy: 0.4809\n",
      "Epoch 724/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4101 - accuracy: 0.4844 - val_loss: 1.4147 - val_accuracy: 0.4793\n",
      "Epoch 725/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4094 - accuracy: 0.4827 - val_loss: 1.4186 - val_accuracy: 0.4763\n",
      "Epoch 726/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4096 - accuracy: 0.4842 - val_loss: 1.4144 - val_accuracy: 0.4807\n",
      "Epoch 727/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4090 - accuracy: 0.4845 - val_loss: 1.4137 - val_accuracy: 0.4809\n",
      "Epoch 728/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4087 - accuracy: 0.4855 - val_loss: 1.4147 - val_accuracy: 0.4804\n",
      "Epoch 729/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4081 - accuracy: 0.4857 - val_loss: 1.4155 - val_accuracy: 0.4810\n",
      "Epoch 730/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4080 - accuracy: 0.4853 - val_loss: 1.4185 - val_accuracy: 0.4843\n",
      "Epoch 731/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4076 - accuracy: 0.4863 - val_loss: 1.4135 - val_accuracy: 0.4829\n",
      "Epoch 732/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4075 - accuracy: 0.4833 - val_loss: 1.4156 - val_accuracy: 0.4752\n",
      "Epoch 733/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4071 - accuracy: 0.4825 - val_loss: 1.4122 - val_accuracy: 0.4812\n",
      "Epoch 734/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4069 - accuracy: 0.4855 - val_loss: 1.4151 - val_accuracy: 0.4805\n",
      "Epoch 735/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4067 - accuracy: 0.4861 - val_loss: 1.4121 - val_accuracy: 0.4807\n",
      "Epoch 736/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4066 - accuracy: 0.4864 - val_loss: 1.4129 - val_accuracy: 0.4833\n",
      "Epoch 737/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4061 - accuracy: 0.4831 - val_loss: 1.4111 - val_accuracy: 0.4827\n",
      "Epoch 738/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4055 - accuracy: 0.4872 - val_loss: 1.4112 - val_accuracy: 0.4841\n",
      "Epoch 739/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4051 - accuracy: 0.4863 - val_loss: 1.4123 - val_accuracy: 0.4872\n",
      "Epoch 740/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4052 - accuracy: 0.4867 - val_loss: 1.4129 - val_accuracy: 0.4851\n",
      "Epoch 741/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4056 - accuracy: 0.4871 - val_loss: 1.4113 - val_accuracy: 0.4838\n",
      "Epoch 742/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4045 - accuracy: 0.4870 - val_loss: 1.4141 - val_accuracy: 0.4872\n",
      "Epoch 743/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4040 - accuracy: 0.4872 - val_loss: 1.4097 - val_accuracy: 0.4835\n",
      "Epoch 744/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4041 - accuracy: 0.4869 - val_loss: 1.4102 - val_accuracy: 0.4840\n",
      "Epoch 745/747\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.4038 - accuracy: 0.4868 - val_loss: 1.4092 - val_accuracy: 0.4838\n",
      "Epoch 746/747\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.4028 - accuracy: 0.4904 - val_loss: 1.4108 - val_accuracy: 0.4824\n",
      "Epoch 747/747\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4033 - accuracy: 0.4863 - val_loss: 1.4114 - val_accuracy: 0.4791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7192932b0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_epoch = hist2.history[\"val_accuracy\"]\n",
    "best_epoch_c = val_acc_epoch.index(max(val_acc_epoch)) + 1\n",
    "\n",
    "model_c = build_model_c()\n",
    "model_c.fit(X_train, y_train, epochs=best_epoch_c, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38d061a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4026 - accuracy: 0.4873 - val_loss: 1.4083 - val_accuracy: 0.4833\n",
      "Epoch 2/200\n",
      "408/408 [==============================] - 1s 4ms/step - loss: 1.4026 - accuracy: 0.4884 - val_loss: 1.4089 - val_accuracy: 0.4877\n",
      "Epoch 3/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4026 - accuracy: 0.4877 - val_loss: 1.4096 - val_accuracy: 0.4889\n",
      "Epoch 4/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4024 - accuracy: 0.4883 - val_loss: 1.4103 - val_accuracy: 0.4860\n",
      "Epoch 5/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4013 - accuracy: 0.4891 - val_loss: 1.4091 - val_accuracy: 0.4852\n",
      "Epoch 6/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4015 - accuracy: 0.4887 - val_loss: 1.4077 - val_accuracy: 0.4871\n",
      "Epoch 7/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4013 - accuracy: 0.4893 - val_loss: 1.4079 - val_accuracy: 0.4837\n",
      "Epoch 8/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4008 - accuracy: 0.4898 - val_loss: 1.4068 - val_accuracy: 0.4841\n",
      "Epoch 9/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4009 - accuracy: 0.4893 - val_loss: 1.4077 - val_accuracy: 0.4875\n",
      "Epoch 10/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4006 - accuracy: 0.4895 - val_loss: 1.4071 - val_accuracy: 0.4852\n",
      "Epoch 11/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.4001 - accuracy: 0.4877 - val_loss: 1.4076 - val_accuracy: 0.4868\n",
      "Epoch 12/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3993 - accuracy: 0.4883 - val_loss: 1.4058 - val_accuracy: 0.4872\n",
      "Epoch 13/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3993 - accuracy: 0.4903 - val_loss: 1.4047 - val_accuracy: 0.4861\n",
      "Epoch 14/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3993 - accuracy: 0.4892 - val_loss: 1.4059 - val_accuracy: 0.4847\n",
      "Epoch 15/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3988 - accuracy: 0.4904 - val_loss: 1.4045 - val_accuracy: 0.4874\n",
      "Epoch 16/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3982 - accuracy: 0.4910 - val_loss: 1.4044 - val_accuracy: 0.4902\n",
      "Epoch 17/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3982 - accuracy: 0.4896 - val_loss: 1.4043 - val_accuracy: 0.4872\n",
      "Epoch 18/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3980 - accuracy: 0.4890 - val_loss: 1.4060 - val_accuracy: 0.4886\n",
      "Epoch 19/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3979 - accuracy: 0.4902 - val_loss: 1.4048 - val_accuracy: 0.4874\n",
      "Epoch 20/200\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3976 - accuracy: 0.4909 - val_loss: 1.4036 - val_accuracy: 0.4893\n",
      "Epoch 21/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3970 - accuracy: 0.4905 - val_loss: 1.4048 - val_accuracy: 0.4861\n",
      "Epoch 22/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3976 - accuracy: 0.4905 - val_loss: 1.4034 - val_accuracy: 0.4879\n",
      "Epoch 23/200\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3970 - accuracy: 0.4903 - val_loss: 1.4042 - val_accuracy: 0.4922\n",
      "Epoch 24/200\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3959 - accuracy: 0.4911 - val_loss: 1.4035 - val_accuracy: 0.4913\n",
      "Epoch 25/200\n",
      "408/408 [==============================] - 2s 6ms/step - loss: 1.3969 - accuracy: 0.4916 - val_loss: 1.4037 - val_accuracy: 0.4893\n",
      "Epoch 26/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3963 - accuracy: 0.4908 - val_loss: 1.4031 - val_accuracy: 0.4922\n",
      "Epoch 27/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3957 - accuracy: 0.4923 - val_loss: 1.4022 - val_accuracy: 0.4925\n",
      "Epoch 28/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3960 - accuracy: 0.4913 - val_loss: 1.4013 - val_accuracy: 0.4885\n",
      "Epoch 29/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3956 - accuracy: 0.4910 - val_loss: 1.4009 - val_accuracy: 0.4922\n",
      "Epoch 30/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3952 - accuracy: 0.4928 - val_loss: 1.4011 - val_accuracy: 0.4913\n",
      "Epoch 31/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3948 - accuracy: 0.4919 - val_loss: 1.4011 - val_accuracy: 0.4921\n",
      "Epoch 32/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3947 - accuracy: 0.4910 - val_loss: 1.4038 - val_accuracy: 0.4888\n",
      "Epoch 33/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3946 - accuracy: 0.4923 - val_loss: 1.4008 - val_accuracy: 0.4913\n",
      "Epoch 34/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3942 - accuracy: 0.4923 - val_loss: 1.4002 - val_accuracy: 0.4938\n",
      "Epoch 35/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3940 - accuracy: 0.4921 - val_loss: 1.4002 - val_accuracy: 0.4916\n",
      "Epoch 36/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3937 - accuracy: 0.4943 - val_loss: 1.4015 - val_accuracy: 0.4947\n",
      "Epoch 37/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3935 - accuracy: 0.4919 - val_loss: 1.3993 - val_accuracy: 0.4932\n",
      "Epoch 38/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3932 - accuracy: 0.4943 - val_loss: 1.3990 - val_accuracy: 0.4933\n",
      "Epoch 39/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3933 - accuracy: 0.4932 - val_loss: 1.3993 - val_accuracy: 0.4932\n",
      "Epoch 40/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3926 - accuracy: 0.4923 - val_loss: 1.3992 - val_accuracy: 0.4914\n",
      "Epoch 41/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3927 - accuracy: 0.4926 - val_loss: 1.3992 - val_accuracy: 0.4958\n",
      "Epoch 42/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3924 - accuracy: 0.4923 - val_loss: 1.3984 - val_accuracy: 0.4935\n",
      "Epoch 43/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3921 - accuracy: 0.4926 - val_loss: 1.3992 - val_accuracy: 0.4914\n",
      "Epoch 44/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3916 - accuracy: 0.4932 - val_loss: 1.4028 - val_accuracy: 0.4963\n",
      "Epoch 45/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3920 - accuracy: 0.4950 - val_loss: 1.4012 - val_accuracy: 0.4939\n",
      "Epoch 46/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3914 - accuracy: 0.4962 - val_loss: 1.3989 - val_accuracy: 0.4907\n",
      "Epoch 47/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3916 - accuracy: 0.4923 - val_loss: 1.3983 - val_accuracy: 0.4960\n",
      "Epoch 48/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3910 - accuracy: 0.4938 - val_loss: 1.3984 - val_accuracy: 0.4917\n",
      "Epoch 49/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3904 - accuracy: 0.4957 - val_loss: 1.3976 - val_accuracy: 0.4958\n",
      "Epoch 50/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3903 - accuracy: 0.4946 - val_loss: 1.3962 - val_accuracy: 0.4970\n",
      "Epoch 51/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3900 - accuracy: 0.4951 - val_loss: 1.3974 - val_accuracy: 0.4983\n",
      "Epoch 52/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3902 - accuracy: 0.4945 - val_loss: 1.3963 - val_accuracy: 0.4963\n",
      "Epoch 53/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3893 - accuracy: 0.4949 - val_loss: 1.3976 - val_accuracy: 0.4928\n",
      "Epoch 54/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3897 - accuracy: 0.4943 - val_loss: 1.3991 - val_accuracy: 0.4907\n",
      "Epoch 55/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3892 - accuracy: 0.4934 - val_loss: 1.3965 - val_accuracy: 0.4991\n",
      "Epoch 56/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3889 - accuracy: 0.4970 - val_loss: 1.3961 - val_accuracy: 0.4947\n",
      "Epoch 57/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3886 - accuracy: 0.4952 - val_loss: 1.3951 - val_accuracy: 0.4978\n",
      "Epoch 58/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3884 - accuracy: 0.4928 - val_loss: 1.3944 - val_accuracy: 0.4967\n",
      "Epoch 59/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3888 - accuracy: 0.4957 - val_loss: 1.3947 - val_accuracy: 0.4986\n",
      "Epoch 60/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3879 - accuracy: 0.4949 - val_loss: 1.3954 - val_accuracy: 0.4998\n",
      "Epoch 61/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3878 - accuracy: 0.4962 - val_loss: 1.3967 - val_accuracy: 0.4995\n",
      "Epoch 62/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3881 - accuracy: 0.4962 - val_loss: 1.3950 - val_accuracy: 0.4952\n",
      "Epoch 63/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3870 - accuracy: 0.4968 - val_loss: 1.3934 - val_accuracy: 0.4980\n",
      "Epoch 64/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3873 - accuracy: 0.4969 - val_loss: 1.3959 - val_accuracy: 0.4919\n",
      "Epoch 65/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3872 - accuracy: 0.4967 - val_loss: 1.3934 - val_accuracy: 0.4970\n",
      "Epoch 66/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3867 - accuracy: 0.4952 - val_loss: 1.3933 - val_accuracy: 0.4983\n",
      "Epoch 67/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3866 - accuracy: 0.4978 - val_loss: 1.3933 - val_accuracy: 0.4972\n",
      "Epoch 68/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3863 - accuracy: 0.4968 - val_loss: 1.3925 - val_accuracy: 0.4958\n",
      "Epoch 69/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3861 - accuracy: 0.4960 - val_loss: 1.3945 - val_accuracy: 0.4967\n",
      "Epoch 70/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3857 - accuracy: 0.4975 - val_loss: 1.3930 - val_accuracy: 0.5012\n",
      "Epoch 71/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3854 - accuracy: 0.4964 - val_loss: 1.3935 - val_accuracy: 0.4994\n",
      "Epoch 72/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3855 - accuracy: 0.4985 - val_loss: 1.3922 - val_accuracy: 0.4983\n",
      "Epoch 73/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3853 - accuracy: 0.4985 - val_loss: 1.3935 - val_accuracy: 0.4955\n",
      "Epoch 74/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3852 - accuracy: 0.4961 - val_loss: 1.3973 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3848 - accuracy: 0.4972 - val_loss: 1.3940 - val_accuracy: 0.5030\n",
      "Epoch 76/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3847 - accuracy: 0.4969 - val_loss: 1.3910 - val_accuracy: 0.5005\n",
      "Epoch 77/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3847 - accuracy: 0.4982 - val_loss: 1.3907 - val_accuracy: 0.4998\n",
      "Epoch 78/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3844 - accuracy: 0.4979 - val_loss: 1.3904 - val_accuracy: 0.5002\n",
      "Epoch 79/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3839 - accuracy: 0.4956 - val_loss: 1.3912 - val_accuracy: 0.5016\n",
      "Epoch 80/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3838 - accuracy: 0.4972 - val_loss: 1.3903 - val_accuracy: 0.5002\n",
      "Epoch 81/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3842 - accuracy: 0.4979 - val_loss: 1.3902 - val_accuracy: 0.4988\n",
      "Epoch 82/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3838 - accuracy: 0.4985 - val_loss: 1.3905 - val_accuracy: 0.5012\n",
      "Epoch 83/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3837 - accuracy: 0.4992 - val_loss: 1.3922 - val_accuracy: 0.4981\n",
      "Epoch 84/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3832 - accuracy: 0.4979 - val_loss: 1.3901 - val_accuracy: 0.5022\n",
      "Epoch 85/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3828 - accuracy: 0.4983 - val_loss: 1.3922 - val_accuracy: 0.4964\n",
      "Epoch 86/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3825 - accuracy: 0.4995 - val_loss: 1.3892 - val_accuracy: 0.5017\n",
      "Epoch 87/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3821 - accuracy: 0.5000 - val_loss: 1.3894 - val_accuracy: 0.5014\n",
      "Epoch 88/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3821 - accuracy: 0.4986 - val_loss: 1.3930 - val_accuracy: 0.4977\n",
      "Epoch 89/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3822 - accuracy: 0.5012 - val_loss: 1.3908 - val_accuracy: 0.5005\n",
      "Epoch 90/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3820 - accuracy: 0.5008 - val_loss: 1.3885 - val_accuracy: 0.5019\n",
      "Epoch 91/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3819 - accuracy: 0.5017 - val_loss: 1.3880 - val_accuracy: 0.5025\n",
      "Epoch 92/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3811 - accuracy: 0.5006 - val_loss: 1.3891 - val_accuracy: 0.5040\n",
      "Epoch 93/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3816 - accuracy: 0.5011 - val_loss: 1.3900 - val_accuracy: 0.5022\n",
      "Epoch 94/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3806 - accuracy: 0.5006 - val_loss: 1.3881 - val_accuracy: 0.5022\n",
      "Epoch 95/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3808 - accuracy: 0.5019 - val_loss: 1.3882 - val_accuracy: 0.5056\n",
      "Epoch 96/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3812 - accuracy: 0.5021 - val_loss: 1.3879 - val_accuracy: 0.5005\n",
      "Epoch 97/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3811 - accuracy: 0.5020 - val_loss: 1.3871 - val_accuracy: 0.5034\n",
      "Epoch 98/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3800 - accuracy: 0.5023 - val_loss: 1.3869 - val_accuracy: 0.5020\n",
      "Epoch 99/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3809 - accuracy: 0.5007 - val_loss: 1.3891 - val_accuracy: 0.5016\n",
      "Epoch 100/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3807 - accuracy: 0.5022 - val_loss: 1.3863 - val_accuracy: 0.5031\n",
      "Epoch 101/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3800 - accuracy: 0.5025 - val_loss: 1.3876 - val_accuracy: 0.5026\n",
      "Epoch 102/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3804 - accuracy: 0.5020 - val_loss: 1.3873 - val_accuracy: 0.5039\n",
      "Epoch 103/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3794 - accuracy: 0.5037 - val_loss: 1.3880 - val_accuracy: 0.5030\n",
      "Epoch 104/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3798 - accuracy: 0.5044 - val_loss: 1.3861 - val_accuracy: 0.5048\n",
      "Epoch 105/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3795 - accuracy: 0.5038 - val_loss: 1.3915 - val_accuracy: 0.5002\n",
      "Epoch 106/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3793 - accuracy: 0.5033 - val_loss: 1.3852 - val_accuracy: 0.5044\n",
      "Epoch 107/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3785 - accuracy: 0.5039 - val_loss: 1.3886 - val_accuracy: 0.4966\n",
      "Epoch 108/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3790 - accuracy: 0.5017 - val_loss: 1.3855 - val_accuracy: 0.5039\n",
      "Epoch 109/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3782 - accuracy: 0.5041 - val_loss: 1.3848 - val_accuracy: 0.5053\n",
      "Epoch 110/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3789 - accuracy: 0.5039 - val_loss: 1.3871 - val_accuracy: 0.5039\n",
      "Epoch 111/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3776 - accuracy: 0.5057 - val_loss: 1.3893 - val_accuracy: 0.4970\n",
      "Epoch 112/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3785 - accuracy: 0.5027 - val_loss: 1.3846 - val_accuracy: 0.5040\n",
      "Epoch 113/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3778 - accuracy: 0.5056 - val_loss: 1.3849 - val_accuracy: 0.5070\n",
      "Epoch 114/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3775 - accuracy: 0.5066 - val_loss: 1.3857 - val_accuracy: 0.5050\n",
      "Epoch 115/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3783 - accuracy: 0.5044 - val_loss: 1.3856 - val_accuracy: 0.5064\n",
      "Epoch 116/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3769 - accuracy: 0.5069 - val_loss: 1.3865 - val_accuracy: 0.5006\n",
      "Epoch 117/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3772 - accuracy: 0.5048 - val_loss: 1.3847 - val_accuracy: 0.5050\n",
      "Epoch 118/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3766 - accuracy: 0.5044 - val_loss: 1.3877 - val_accuracy: 0.5045\n",
      "Epoch 119/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3777 - accuracy: 0.5059 - val_loss: 1.3854 - val_accuracy: 0.5079\n",
      "Epoch 120/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3768 - accuracy: 0.5055 - val_loss: 1.3854 - val_accuracy: 0.5042\n",
      "Epoch 121/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3765 - accuracy: 0.5054 - val_loss: 1.3844 - val_accuracy: 0.5083\n",
      "Epoch 122/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3768 - accuracy: 0.5054 - val_loss: 1.3850 - val_accuracy: 0.5075\n",
      "Epoch 123/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3761 - accuracy: 0.5066 - val_loss: 1.3828 - val_accuracy: 0.5051\n",
      "Epoch 124/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3763 - accuracy: 0.5060 - val_loss: 1.3833 - val_accuracy: 0.5092\n",
      "Epoch 125/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3766 - accuracy: 0.5031 - val_loss: 1.3829 - val_accuracy: 0.5076\n",
      "Epoch 126/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3759 - accuracy: 0.5061 - val_loss: 1.3822 - val_accuracy: 0.5067\n",
      "Epoch 127/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3751 - accuracy: 0.5061 - val_loss: 1.3825 - val_accuracy: 0.5040\n",
      "Epoch 128/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3756 - accuracy: 0.5048 - val_loss: 1.3826 - val_accuracy: 0.5090\n",
      "Epoch 129/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3752 - accuracy: 0.5063 - val_loss: 1.3863 - val_accuracy: 0.4992\n",
      "Epoch 130/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3749 - accuracy: 0.5053 - val_loss: 1.3819 - val_accuracy: 0.5084\n",
      "Epoch 131/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3753 - accuracy: 0.5036 - val_loss: 1.3813 - val_accuracy: 0.5068\n",
      "Epoch 132/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3748 - accuracy: 0.5059 - val_loss: 1.3827 - val_accuracy: 0.5034\n",
      "Epoch 133/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3743 - accuracy: 0.5074 - val_loss: 1.3817 - val_accuracy: 0.5056\n",
      "Epoch 134/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3744 - accuracy: 0.5058 - val_loss: 1.3877 - val_accuracy: 0.5075\n",
      "Epoch 135/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3747 - accuracy: 0.5077 - val_loss: 1.3813 - val_accuracy: 0.5059\n",
      "Epoch 136/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3741 - accuracy: 0.5062 - val_loss: 1.3809 - val_accuracy: 0.5086\n",
      "Epoch 137/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3744 - accuracy: 0.5062 - val_loss: 1.3808 - val_accuracy: 0.5073\n",
      "Epoch 138/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3734 - accuracy: 0.5077 - val_loss: 1.3833 - val_accuracy: 0.5054\n",
      "Epoch 139/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3742 - accuracy: 0.5079 - val_loss: 1.3832 - val_accuracy: 0.5044\n",
      "Epoch 140/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3732 - accuracy: 0.5071 - val_loss: 1.3867 - val_accuracy: 0.5006\n",
      "Epoch 141/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3735 - accuracy: 0.5051 - val_loss: 1.3831 - val_accuracy: 0.5117\n",
      "Epoch 142/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3734 - accuracy: 0.5062 - val_loss: 1.3827 - val_accuracy: 0.5103\n",
      "Epoch 143/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3734 - accuracy: 0.5091 - val_loss: 1.3829 - val_accuracy: 0.5123\n",
      "Epoch 144/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3734 - accuracy: 0.5065 - val_loss: 1.3816 - val_accuracy: 0.5064\n",
      "Epoch 145/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3731 - accuracy: 0.5054 - val_loss: 1.3800 - val_accuracy: 0.5078\n",
      "Epoch 146/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3730 - accuracy: 0.5058 - val_loss: 1.3799 - val_accuracy: 0.5040\n",
      "Epoch 147/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3724 - accuracy: 0.5077 - val_loss: 1.3824 - val_accuracy: 0.5044\n",
      "Epoch 148/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3727 - accuracy: 0.5057 - val_loss: 1.3806 - val_accuracy: 0.5045\n",
      "Epoch 149/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3724 - accuracy: 0.5067 - val_loss: 1.3797 - val_accuracy: 0.5109\n",
      "Epoch 150/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3720 - accuracy: 0.5083 - val_loss: 1.3793 - val_accuracy: 0.5078\n",
      "Epoch 151/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3723 - accuracy: 0.5069 - val_loss: 1.3817 - val_accuracy: 0.5062\n",
      "Epoch 152/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3718 - accuracy: 0.5070 - val_loss: 1.3801 - val_accuracy: 0.5039\n",
      "Epoch 153/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3718 - accuracy: 0.5059 - val_loss: 1.3789 - val_accuracy: 0.5093\n",
      "Epoch 154/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3712 - accuracy: 0.5068 - val_loss: 1.3805 - val_accuracy: 0.5101\n",
      "Epoch 155/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3716 - accuracy: 0.5080 - val_loss: 1.3785 - val_accuracy: 0.5104\n",
      "Epoch 156/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3716 - accuracy: 0.5067 - val_loss: 1.3776 - val_accuracy: 0.5092\n",
      "Epoch 157/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3712 - accuracy: 0.5082 - val_loss: 1.3780 - val_accuracy: 0.5065\n",
      "Epoch 158/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3715 - accuracy: 0.5048 - val_loss: 1.3779 - val_accuracy: 0.5098\n",
      "Epoch 159/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3711 - accuracy: 0.5070 - val_loss: 1.3776 - val_accuracy: 0.5078\n",
      "Epoch 160/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3717 - accuracy: 0.5064 - val_loss: 1.3780 - val_accuracy: 0.5111\n",
      "Epoch 161/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3708 - accuracy: 0.5060 - val_loss: 1.3793 - val_accuracy: 0.5056\n",
      "Epoch 162/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3704 - accuracy: 0.5081 - val_loss: 1.3780 - val_accuracy: 0.5095\n",
      "Epoch 163/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3705 - accuracy: 0.5089 - val_loss: 1.3778 - val_accuracy: 0.5131\n",
      "Epoch 164/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3711 - accuracy: 0.5080 - val_loss: 1.3775 - val_accuracy: 0.5078\n",
      "Epoch 165/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3701 - accuracy: 0.5078 - val_loss: 1.3772 - val_accuracy: 0.5081\n",
      "Epoch 166/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3698 - accuracy: 0.5059 - val_loss: 1.3794 - val_accuracy: 0.5050\n",
      "Epoch 167/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3703 - accuracy: 0.5076 - val_loss: 1.3764 - val_accuracy: 0.5089\n",
      "Epoch 168/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3693 - accuracy: 0.5064 - val_loss: 1.3774 - val_accuracy: 0.5065\n",
      "Epoch 169/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3700 - accuracy: 0.5066 - val_loss: 1.3759 - val_accuracy: 0.5100\n",
      "Epoch 170/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3696 - accuracy: 0.5078 - val_loss: 1.3771 - val_accuracy: 0.5131\n",
      "Epoch 171/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3699 - accuracy: 0.5070 - val_loss: 1.3771 - val_accuracy: 0.5044\n",
      "Epoch 172/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3696 - accuracy: 0.5067 - val_loss: 1.3772 - val_accuracy: 0.5142\n",
      "Epoch 173/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3694 - accuracy: 0.5072 - val_loss: 1.3759 - val_accuracy: 0.5109\n",
      "Epoch 174/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3681 - accuracy: 0.5082 - val_loss: 1.3777 - val_accuracy: 0.5040\n",
      "Epoch 175/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3686 - accuracy: 0.5080 - val_loss: 1.3753 - val_accuracy: 0.5121\n",
      "Epoch 176/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3693 - accuracy: 0.5074 - val_loss: 1.3760 - val_accuracy: 0.5090\n",
      "Epoch 177/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3683 - accuracy: 0.5097 - val_loss: 1.3783 - val_accuracy: 0.5078\n",
      "Epoch 178/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3681 - accuracy: 0.5093 - val_loss: 1.3750 - val_accuracy: 0.5092\n",
      "Epoch 179/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3678 - accuracy: 0.5081 - val_loss: 1.3757 - val_accuracy: 0.5092\n",
      "Epoch 180/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3679 - accuracy: 0.5080 - val_loss: 1.3750 - val_accuracy: 0.5072\n",
      "Epoch 181/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3688 - accuracy: 0.5070 - val_loss: 1.3759 - val_accuracy: 0.5125\n",
      "Epoch 182/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3677 - accuracy: 0.5104 - val_loss: 1.3770 - val_accuracy: 0.5126\n",
      "Epoch 183/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3678 - accuracy: 0.5073 - val_loss: 1.3755 - val_accuracy: 0.5118\n",
      "Epoch 184/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3682 - accuracy: 0.5067 - val_loss: 1.3743 - val_accuracy: 0.5106\n",
      "Epoch 185/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3678 - accuracy: 0.5086 - val_loss: 1.3741 - val_accuracy: 0.5095\n",
      "Epoch 186/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3675 - accuracy: 0.5084 - val_loss: 1.3760 - val_accuracy: 0.5079\n",
      "Epoch 187/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3673 - accuracy: 0.5074 - val_loss: 1.3759 - val_accuracy: 0.5073\n",
      "Epoch 188/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3669 - accuracy: 0.5077 - val_loss: 1.3752 - val_accuracy: 0.5086\n",
      "Epoch 189/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3672 - accuracy: 0.5077 - val_loss: 1.3759 - val_accuracy: 0.5120\n",
      "Epoch 190/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3670 - accuracy: 0.5077 - val_loss: 1.3772 - val_accuracy: 0.5067\n",
      "Epoch 191/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3673 - accuracy: 0.5069 - val_loss: 1.3732 - val_accuracy: 0.5095\n",
      "Epoch 192/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3668 - accuracy: 0.5096 - val_loss: 1.3848 - val_accuracy: 0.5061\n",
      "Epoch 193/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3672 - accuracy: 0.5075 - val_loss: 1.3737 - val_accuracy: 0.5103\n",
      "Epoch 194/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3664 - accuracy: 0.5083 - val_loss: 1.3739 - val_accuracy: 0.5134\n",
      "Epoch 195/200\n",
      "408/408 [==============================] - 2s 5ms/step - loss: 1.3674 - accuracy: 0.5075 - val_loss: 1.3731 - val_accuracy: 0.5123\n",
      "Epoch 196/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3667 - accuracy: 0.5091 - val_loss: 1.3733 - val_accuracy: 0.5125\n",
      "Epoch 197/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3669 - accuracy: 0.5058 - val_loss: 1.3732 - val_accuracy: 0.5090\n",
      "Epoch 198/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3660 - accuracy: 0.5071 - val_loss: 1.3780 - val_accuracy: 0.5011\n",
      "Epoch 199/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3658 - accuracy: 0.5081 - val_loss: 1.3814 - val_accuracy: 0.4970\n",
      "Epoch 200/200\n",
      "408/408 [==============================] - 2s 4ms/step - loss: 1.3660 - accuracy: 0.5079 - val_loss: 1.3736 - val_accuracy: 0.5135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e71c744d30>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c.fit(X_train, y_train, epochs=200, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca61ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 7], dtype=int64),\n",
       " array([5069, 2171,  207, 2142], dtype=int64))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(model_c.predict(X_test), axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "219ea844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 3ms/step - loss: 1.3264 - accuracy: 0.5162\n",
      "[1.3264199495315552, 0.516216516494751]\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.3454 - accuracy: 0.5177\n",
      "[1.345361590385437, 0.5176765322685242]\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.4003 - accuracy: 0.5029\n",
      "[1.4002587795257568, 0.5028678774833679]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, y_test))\n",
    "print(model_b.evaluate(X_test, y_test))\n",
    "print(model_c.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "518081fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44175617895505265"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=10000, learning_rate=\"adaptive\")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ccb7f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_examples, train_score, valid_score = learning_curve(mlp, X_train, y_train, cv=StratifiedKFold(3))\n",
    "plt.plot(training_examples, np.mean(train_score, axis=1), label=\"train_score\")\n",
    "plt.plot(training_examples, np.mean(valid_score, axis=1), label=\"valid_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aed4108c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 5, 6, 7], dtype=int64),\n",
       " array([1841, 4107, 1088,    1,    1,   21, 2530], dtype=int64))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mlp.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c12eaa",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148fc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d74c2453f9b4>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  a = KerasClassifier(build_model_a, epochs=400, batch_size=10)\n",
      "<ipython-input-8-d74c2453f9b4>:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  b = KerasClassifier(build_model_b, epochs=400, batch_size=10)\n",
      "<ipython-input-8-d74c2453f9b4>:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  c = KerasClassifier(build_model_c, epochs=600, batch_size=10)\n"
     ]
    }
   ],
   "source": [
    "a = KerasClassifier(build_model_a, epochs=400, batch_size=10)\n",
    "a._estimator_type = \"classifier\"\n",
    "b = KerasClassifier(build_model_b, epochs=400, batch_size=10)\n",
    "b._estimator_type = \"classifier\"\n",
    "c = KerasClassifier(build_model_c, epochs=600, batch_size=10)\n",
    "c._estimator_type = \"classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0e348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = VotingClassifier([(\"a\", a), (\"b\", b), (\"c\", c)], voting=\"hard\", weights=[0.37, 0.33, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864149bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1947/1947 [==============================] - 8s 3ms/step - loss: 1.7451 - accuracy: 0.3442\n",
      "Epoch 2/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.6940 - accuracy: 0.3519\n",
      "Epoch 3/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6929 - accuracy: 0.3519\n",
      "Epoch 4/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6924 - accuracy: 0.3519\n",
      "Epoch 5/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6922 - accuracy: 0.3519\n",
      "Epoch 6/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6883 - accuracy: 0.3525\n",
      "Epoch 7/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.6803 - accuracy: 0.3609\n",
      "Epoch 8/400\n",
      "1947/1947 [==============================] - 6s 3ms/step - loss: 1.6723 - accuracy: 0.3637\n",
      "Epoch 9/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.6512 - accuracy: 0.3737\n",
      "Epoch 10/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6173 - accuracy: 0.3918\n",
      "Epoch 11/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5748 - accuracy: 0.4087\n",
      "Epoch 12/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5405 - accuracy: 0.4250\n",
      "Epoch 13/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5146 - accuracy: 0.4431\n",
      "Epoch 14/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4920 - accuracy: 0.4500\n",
      "Epoch 15/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4734 - accuracy: 0.4597\n",
      "Epoch 16/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4605 - accuracy: 0.4613\n",
      "Epoch 17/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4406 - accuracy: 0.4711\n",
      "Epoch 18/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4349 - accuracy: 0.4724\n",
      "Epoch 19/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4277 - accuracy: 0.4738\n",
      "Epoch 20/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4186 - accuracy: 0.4792\n",
      "Epoch 21/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4149 - accuracy: 0.4780\n",
      "Epoch 22/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4124 - accuracy: 0.4800\n",
      "Epoch 23/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4069 - accuracy: 0.4828\n",
      "Epoch 24/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4002 - accuracy: 0.4862\n",
      "Epoch 25/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4026 - accuracy: 0.4856\n",
      "Epoch 26/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3941 - accuracy: 0.4907\n",
      "Epoch 27/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3926 - accuracy: 0.4873\n",
      "Epoch 28/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3909 - accuracy: 0.4871\n",
      "Epoch 29/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3844 - accuracy: 0.4896\n",
      "Epoch 30/400\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3850 - accuracy: 0.4901\n",
      "Epoch 31/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3872 - accuracy: 0.4889\n",
      "Epoch 32/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3899 - accuracy: 0.4894\n",
      "Epoch 33/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3839 - accuracy: 0.4912\n",
      "Epoch 34/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3815 - accuracy: 0.4881\n",
      "Epoch 35/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3789 - accuracy: 0.4951\n",
      "Epoch 36/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3748 - accuracy: 0.4953\n",
      "Epoch 37/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3739 - accuracy: 0.4959\n",
      "Epoch 38/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3738 - accuracy: 0.4928\n",
      "Epoch 39/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3735 - accuracy: 0.4958\n",
      "Epoch 40/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3686 - accuracy: 0.4986\n",
      "Epoch 41/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3691 - accuracy: 0.4969\n",
      "Epoch 42/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3664 - accuracy: 0.5008\n",
      "Epoch 43/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3698 - accuracy: 0.4978\n",
      "Epoch 44/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3679 - accuracy: 0.4998\n",
      "Epoch 45/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3712 - accuracy: 0.4958\n",
      "Epoch 46/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3690 - accuracy: 0.4989\n",
      "Epoch 47/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3695 - accuracy: 0.4978\n",
      "Epoch 48/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3666 - accuracy: 0.4969\n",
      "Epoch 49/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3609 - accuracy: 0.4995\n",
      "Epoch 50/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3643 - accuracy: 0.5004\n",
      "Epoch 51/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3627 - accuracy: 0.4979\n",
      "Epoch 52/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3652 - accuracy: 0.4974\n",
      "Epoch 53/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3623 - accuracy: 0.4986\n",
      "Epoch 54/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3580 - accuracy: 0.5008\n",
      "Epoch 55/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3638 - accuracy: 0.4974\n",
      "Epoch 56/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3605 - accuracy: 0.5020\n",
      "Epoch 57/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3634 - accuracy: 0.4992\n",
      "Epoch 58/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3560 - accuracy: 0.4997\n",
      "Epoch 59/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3612 - accuracy: 0.5027\n",
      "Epoch 60/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3617 - accuracy: 0.4997\n",
      "Epoch 61/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3587 - accuracy: 0.5023\n",
      "Epoch 62/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3587 - accuracy: 0.5015\n",
      "Epoch 63/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3550 - accuracy: 0.5020\n",
      "Epoch 64/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3557 - accuracy: 0.5035\n",
      "Epoch 65/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3599 - accuracy: 0.4999\n",
      "Epoch 66/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3567 - accuracy: 0.5008\n",
      "Epoch 67/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3540 - accuracy: 0.5032\n",
      "Epoch 68/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3533 - accuracy: 0.5030\n",
      "Epoch 69/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3557 - accuracy: 0.5023\n",
      "Epoch 70/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3506 - accuracy: 0.5062\n",
      "Epoch 71/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3535 - accuracy: 0.5010\n",
      "Epoch 72/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3524 - accuracy: 0.5067\n",
      "Epoch 73/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3563 - accuracy: 0.5023\n",
      "Epoch 74/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3531 - accuracy: 0.5016\n",
      "Epoch 75/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3492 - accuracy: 0.5076\n",
      "Epoch 76/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3528 - accuracy: 0.5026\n",
      "Epoch 77/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3538 - accuracy: 0.5055\n",
      "Epoch 78/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3531 - accuracy: 0.5034\n",
      "Epoch 79/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3549 - accuracy: 0.5035\n",
      "Epoch 80/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3525 - accuracy: 0.5055\n",
      "Epoch 81/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3497 - accuracy: 0.5071\n",
      "Epoch 82/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3520 - accuracy: 0.5036\n",
      "Epoch 83/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3506 - accuracy: 0.5046\n",
      "Epoch 84/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3508 - accuracy: 0.5037\n",
      "Epoch 85/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3519 - accuracy: 0.5059\n",
      "Epoch 86/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3492 - accuracy: 0.5061\n",
      "Epoch 87/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3501 - accuracy: 0.5049\n",
      "Epoch 88/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3472 - accuracy: 0.5043\n",
      "Epoch 89/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3507 - accuracy: 0.5029\n",
      "Epoch 90/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3495 - accuracy: 0.5034\n",
      "Epoch 91/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3524 - accuracy: 0.5051\n",
      "Epoch 92/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3499 - accuracy: 0.5031\n",
      "Epoch 93/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3496 - accuracy: 0.5032\n",
      "Epoch 94/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3466 - accuracy: 0.5068\n",
      "Epoch 95/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3461 - accuracy: 0.5058\n",
      "Epoch 96/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3471 - accuracy: 0.5071\n",
      "Epoch 97/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3500 - accuracy: 0.5049\n",
      "Epoch 98/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3458 - accuracy: 0.5058\n",
      "Epoch 99/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3460 - accuracy: 0.5070\n",
      "Epoch 100/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3462 - accuracy: 0.5026\n",
      "Epoch 101/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3459 - accuracy: 0.5062\n",
      "Epoch 102/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3468 - accuracy: 0.5065\n",
      "Epoch 103/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3444 - accuracy: 0.5071\n",
      "Epoch 104/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3469 - accuracy: 0.5036\n",
      "Epoch 105/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3419 - accuracy: 0.5073\n",
      "Epoch 106/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3474 - accuracy: 0.5055\n",
      "Epoch 107/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3443 - accuracy: 0.5074\n",
      "Epoch 108/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3434 - accuracy: 0.5061\n",
      "Epoch 109/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3443 - accuracy: 0.5048\n",
      "Epoch 110/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3455 - accuracy: 0.5079\n",
      "Epoch 111/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3431 - accuracy: 0.5077\n",
      "Epoch 112/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3381 - accuracy: 0.5090\n",
      "Epoch 113/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3430 - accuracy: 0.5057\n",
      "Epoch 114/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3456 - accuracy: 0.5041\n",
      "Epoch 115/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3450 - accuracy: 0.5063\n",
      "Epoch 116/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3436 - accuracy: 0.5090\n",
      "Epoch 117/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3431 - accuracy: 0.5083\n",
      "Epoch 118/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3412 - accuracy: 0.5086\n",
      "Epoch 119/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3457 - accuracy: 0.5058\n",
      "Epoch 120/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3395 - accuracy: 0.5063\n",
      "Epoch 121/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3396 - accuracy: 0.5063\n",
      "Epoch 122/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3389 - accuracy: 0.5095\n",
      "Epoch 123/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3413 - accuracy: 0.5060\n",
      "Epoch 124/400\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.3411 - accuracy: 0.5081\n",
      "Epoch 125/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3433 - accuracy: 0.5057\n",
      "Epoch 126/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3432 - accuracy: 0.5068\n",
      "Epoch 127/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3396 - accuracy: 0.5084\n",
      "Epoch 128/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3388 - accuracy: 0.5065\n",
      "Epoch 129/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3456 - accuracy: 0.5059\n",
      "Epoch 130/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3410 - accuracy: 0.5084\n",
      "Epoch 131/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3432 - accuracy: 0.5053\n",
      "Epoch 132/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3380 - accuracy: 0.5071\n",
      "Epoch 133/400\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3405 - accuracy: 0.5092\n",
      "Epoch 134/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3397 - accuracy: 0.5081\n",
      "Epoch 135/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3383 - accuracy: 0.5060\n",
      "Epoch 136/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3369 - accuracy: 0.5095\n",
      "Epoch 137/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3403 - accuracy: 0.5104\n",
      "Epoch 138/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3397 - accuracy: 0.5073\n",
      "Epoch 139/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3427 - accuracy: 0.5081\n",
      "Epoch 140/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3401 - accuracy: 0.5078\n",
      "Epoch 141/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3396 - accuracy: 0.5079\n",
      "Epoch 142/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3371 - accuracy: 0.5100\n",
      "Epoch 143/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3421 - accuracy: 0.5068\n",
      "Epoch 144/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3377 - accuracy: 0.5106\n",
      "Epoch 145/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3404 - accuracy: 0.5095\n",
      "Epoch 146/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3375 - accuracy: 0.5076\n",
      "Epoch 147/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3375 - accuracy: 0.5077\n",
      "Epoch 148/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3398 - accuracy: 0.5072\n",
      "Epoch 149/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3370 - accuracy: 0.5074\n",
      "Epoch 150/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3364 - accuracy: 0.5121\n",
      "Epoch 151/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3340 - accuracy: 0.5120\n",
      "Epoch 152/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3383 - accuracy: 0.5123\n",
      "Epoch 153/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3398 - accuracy: 0.5083\n",
      "Epoch 154/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3352 - accuracy: 0.5080\n",
      "Epoch 155/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3383 - accuracy: 0.5102\n",
      "Epoch 156/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3368 - accuracy: 0.5087\n",
      "Epoch 157/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3383 - accuracy: 0.5053\n",
      "Epoch 158/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3368 - accuracy: 0.5098\n",
      "Epoch 159/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3364 - accuracy: 0.5090\n",
      "Epoch 160/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3356 - accuracy: 0.5100\n",
      "Epoch 161/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3358 - accuracy: 0.5073\n",
      "Epoch 162/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3368 - accuracy: 0.5105\n",
      "Epoch 163/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3360 - accuracy: 0.5085\n",
      "Epoch 164/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3345 - accuracy: 0.5105\n",
      "Epoch 165/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3320 - accuracy: 0.5121\n",
      "Epoch 166/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3355 - accuracy: 0.5092\n",
      "Epoch 167/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3345 - accuracy: 0.5098\n",
      "Epoch 168/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3364 - accuracy: 0.5110\n",
      "Epoch 169/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3365 - accuracy: 0.5104\n",
      "Epoch 170/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3283 - accuracy: 0.5126\n",
      "Epoch 171/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3337 - accuracy: 0.5059\n",
      "Epoch 172/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3306 - accuracy: 0.5127\n",
      "Epoch 173/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3325 - accuracy: 0.5095\n",
      "Epoch 174/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3314 - accuracy: 0.5124\n",
      "Epoch 175/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3339 - accuracy: 0.5098\n",
      "Epoch 176/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3327 - accuracy: 0.5121\n",
      "Epoch 177/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3306 - accuracy: 0.5114\n",
      "Epoch 178/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3318 - accuracy: 0.5115\n",
      "Epoch 179/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3331 - accuracy: 0.5110\n",
      "Epoch 180/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3285 - accuracy: 0.5091\n",
      "Epoch 181/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3294 - accuracy: 0.5133\n",
      "Epoch 182/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3286 - accuracy: 0.5104\n",
      "Epoch 183/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3290 - accuracy: 0.5123\n",
      "Epoch 184/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3331 - accuracy: 0.5103\n",
      "Epoch 185/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3323 - accuracy: 0.5111\n",
      "Epoch 186/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3280 - accuracy: 0.5149\n",
      "Epoch 187/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3310 - accuracy: 0.5101\n",
      "Epoch 188/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3297 - accuracy: 0.5092\n",
      "Epoch 189/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3287 - accuracy: 0.5129\n",
      "Epoch 190/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3284 - accuracy: 0.5127\n",
      "Epoch 191/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3292 - accuracy: 0.5123\n",
      "Epoch 192/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3272 - accuracy: 0.5120\n",
      "Epoch 193/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3243 - accuracy: 0.5129\n",
      "Epoch 194/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3265 - accuracy: 0.5141\n",
      "Epoch 195/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3270 - accuracy: 0.5121\n",
      "Epoch 196/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3277 - accuracy: 0.5101\n",
      "Epoch 197/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3326 - accuracy: 0.5120\n",
      "Epoch 198/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3276 - accuracy: 0.5098\n",
      "Epoch 199/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3284 - accuracy: 0.5119\n",
      "Epoch 200/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3252 - accuracy: 0.5145\n",
      "Epoch 201/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3255 - accuracy: 0.5135\n",
      "Epoch 202/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3249 - accuracy: 0.5136\n",
      "Epoch 203/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3238 - accuracy: 0.5127\n",
      "Epoch 204/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3255 - accuracy: 0.5153\n",
      "Epoch 205/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3280 - accuracy: 0.5128\n",
      "Epoch 206/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3252 - accuracy: 0.5134\n",
      "Epoch 207/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3285 - accuracy: 0.5121\n",
      "Epoch 208/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3224 - accuracy: 0.5131\n",
      "Epoch 209/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3248 - accuracy: 0.5125\n",
      "Epoch 210/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3217 - accuracy: 0.5161\n",
      "Epoch 211/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3229 - accuracy: 0.5148\n",
      "Epoch 212/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3242 - accuracy: 0.5158\n",
      "Epoch 213/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3257 - accuracy: 0.5130\n",
      "Epoch 214/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3255 - accuracy: 0.5153\n",
      "Epoch 215/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3237 - accuracy: 0.5164\n",
      "Epoch 216/400\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3247 - accuracy: 0.5128\n",
      "Epoch 217/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3261 - accuracy: 0.5103\n",
      "Epoch 218/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3228 - accuracy: 0.5141\n",
      "Epoch 219/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3243 - accuracy: 0.5147\n",
      "Epoch 220/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3254 - accuracy: 0.5149\n",
      "Epoch 221/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3260 - accuracy: 0.5115\n",
      "Epoch 222/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3309 - accuracy: 0.5119\n",
      "Epoch 223/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3230 - accuracy: 0.5151\n",
      "Epoch 224/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3214 - accuracy: 0.5136\n",
      "Epoch 225/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3227 - accuracy: 0.5139\n",
      "Epoch 226/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3263 - accuracy: 0.5117\n",
      "Epoch 227/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3219 - accuracy: 0.5172\n",
      "Epoch 228/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3204 - accuracy: 0.5172\n",
      "Epoch 229/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3203 - accuracy: 0.5158\n",
      "Epoch 230/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3201 - accuracy: 0.5152\n",
      "Epoch 231/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3230 - accuracy: 0.5163\n",
      "Epoch 232/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3173 - accuracy: 0.5172\n",
      "Epoch 233/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3260 - accuracy: 0.5151\n",
      "Epoch 234/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3191 - accuracy: 0.5175\n",
      "Epoch 235/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3206 - accuracy: 0.5150\n",
      "Epoch 236/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3228 - accuracy: 0.5137\n",
      "Epoch 237/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3210 - accuracy: 0.5143\n",
      "Epoch 238/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3220 - accuracy: 0.5136\n",
      "Epoch 239/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3231 - accuracy: 0.5133\n",
      "Epoch 240/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3201 - accuracy: 0.5159\n",
      "Epoch 241/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3192 - accuracy: 0.5166\n",
      "Epoch 242/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3222 - accuracy: 0.5139\n",
      "Epoch 243/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3227 - accuracy: 0.5149\n",
      "Epoch 244/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3184 - accuracy: 0.5161\n",
      "Epoch 245/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3211 - accuracy: 0.5149\n",
      "Epoch 246/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3229 - accuracy: 0.5140\n",
      "Epoch 247/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3188 - accuracy: 0.5182\n",
      "Epoch 248/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3172 - accuracy: 0.5176\n",
      "Epoch 249/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3202 - accuracy: 0.5186\n",
      "Epoch 250/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3215 - accuracy: 0.5165\n",
      "Epoch 251/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3192 - accuracy: 0.5147\n",
      "Epoch 252/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3181 - accuracy: 0.5171\n",
      "Epoch 253/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3161 - accuracy: 0.5218\n",
      "Epoch 254/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3159 - accuracy: 0.5152\n",
      "Epoch 255/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3210 - accuracy: 0.5174\n",
      "Epoch 256/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3148 - accuracy: 0.5162\n",
      "Epoch 257/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3199 - accuracy: 0.5154\n",
      "Epoch 258/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3219 - accuracy: 0.5140\n",
      "Epoch 259/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3128 - accuracy: 0.5188\n",
      "Epoch 260/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3158 - accuracy: 0.5170\n",
      "Epoch 261/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3136 - accuracy: 0.5208\n",
      "Epoch 262/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3153 - accuracy: 0.5195\n",
      "Epoch 263/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3156 - accuracy: 0.5143\n",
      "Epoch 264/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3149 - accuracy: 0.5180\n",
      "Epoch 265/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3176 - accuracy: 0.5160\n",
      "Epoch 266/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3172 - accuracy: 0.5165\n",
      "Epoch 267/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3151 - accuracy: 0.5191\n",
      "Epoch 268/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3160 - accuracy: 0.5175\n",
      "Epoch 269/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3209 - accuracy: 0.5155\n",
      "Epoch 270/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3120 - accuracy: 0.5170\n",
      "Epoch 271/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3132 - accuracy: 0.5187\n",
      "Epoch 272/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3162 - accuracy: 0.5186\n",
      "Epoch 273/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3126 - accuracy: 0.5183\n",
      "Epoch 274/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3126 - accuracy: 0.5201\n",
      "Epoch 275/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3140 - accuracy: 0.5169\n",
      "Epoch 276/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3126 - accuracy: 0.5202\n",
      "Epoch 277/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3187 - accuracy: 0.5173\n",
      "Epoch 278/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3159 - accuracy: 0.5157\n",
      "Epoch 279/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3115 - accuracy: 0.5177\n",
      "Epoch 280/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3097 - accuracy: 0.5203\n",
      "Epoch 281/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3135 - accuracy: 0.5182\n",
      "Epoch 282/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3135 - accuracy: 0.5189\n",
      "Epoch 283/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3127 - accuracy: 0.5204\n",
      "Epoch 284/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3105 - accuracy: 0.5193\n",
      "Epoch 285/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3126 - accuracy: 0.5184\n",
      "Epoch 286/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3142 - accuracy: 0.5176\n",
      "Epoch 287/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3103 - accuracy: 0.5188\n",
      "Epoch 288/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3131 - accuracy: 0.5185\n",
      "Epoch 289/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3167 - accuracy: 0.5136\n",
      "Epoch 290/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3097 - accuracy: 0.5205\n",
      "Epoch 291/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3138 - accuracy: 0.5188\n",
      "Epoch 292/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3136 - accuracy: 0.5183\n",
      "Epoch 293/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3124 - accuracy: 0.5179\n",
      "Epoch 294/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3116 - accuracy: 0.5195\n",
      "Epoch 295/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3106 - accuracy: 0.5208\n",
      "Epoch 296/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3112 - accuracy: 0.5193\n",
      "Epoch 297/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3108 - accuracy: 0.5197\n",
      "Epoch 298/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3126 - accuracy: 0.5194\n",
      "Epoch 299/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3130 - accuracy: 0.5190\n",
      "Epoch 300/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3093 - accuracy: 0.5201\n",
      "Epoch 301/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3108 - accuracy: 0.5174\n",
      "Epoch 302/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3118 - accuracy: 0.5191\n",
      "Epoch 303/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3090 - accuracy: 0.5195\n",
      "Epoch 304/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3075 - accuracy: 0.5213\n",
      "Epoch 305/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3091 - accuracy: 0.5196\n",
      "Epoch 306/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3098 - accuracy: 0.5213\n",
      "Epoch 307/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3093 - accuracy: 0.5220\n",
      "Epoch 308/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3104 - accuracy: 0.5216\n",
      "Epoch 309/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3103 - accuracy: 0.5184\n",
      "Epoch 310/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3074 - accuracy: 0.5216\n",
      "Epoch 311/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3131 - accuracy: 0.5179\n",
      "Epoch 312/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3073 - accuracy: 0.5202\n",
      "Epoch 313/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3091 - accuracy: 0.5218\n",
      "Epoch 314/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3076 - accuracy: 0.5208\n",
      "Epoch 315/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3076 - accuracy: 0.5218\n",
      "Epoch 316/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3076 - accuracy: 0.5202\n",
      "Epoch 317/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3074 - accuracy: 0.5204\n",
      "Epoch 318/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3091 - accuracy: 0.5213\n",
      "Epoch 319/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3079 - accuracy: 0.5239\n",
      "Epoch 320/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3065 - accuracy: 0.5194\n",
      "Epoch 321/400\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3066 - accuracy: 0.5202\n",
      "Epoch 322/400\n",
      "1947/1947 [==============================] - 13s 7ms/step - loss: 1.3101 - accuracy: 0.5189\n",
      "Epoch 323/400\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3078 - accuracy: 0.5224\n",
      "Epoch 324/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3060 - accuracy: 0.5218\n",
      "Epoch 325/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3089 - accuracy: 0.5202\n",
      "Epoch 326/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3042 - accuracy: 0.5219\n",
      "Epoch 327/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3073 - accuracy: 0.5222\n",
      "Epoch 328/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3032 - accuracy: 0.5233\n",
      "Epoch 329/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3042 - accuracy: 0.5223\n",
      "Epoch 330/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3080 - accuracy: 0.5194\n",
      "Epoch 331/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3087 - accuracy: 0.5184\n",
      "Epoch 332/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3037 - accuracy: 0.5221\n",
      "Epoch 333/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3071 - accuracy: 0.5219\n",
      "Epoch 334/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3066 - accuracy: 0.5206\n",
      "Epoch 335/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3040 - accuracy: 0.5246\n",
      "Epoch 336/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3048 - accuracy: 0.5223\n",
      "Epoch 337/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3061 - accuracy: 0.5226\n",
      "Epoch 338/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3090 - accuracy: 0.5191\n",
      "Epoch 339/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3060 - accuracy: 0.5216\n",
      "Epoch 340/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3017 - accuracy: 0.5213\n",
      "Epoch 341/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3072 - accuracy: 0.5212\n",
      "Epoch 342/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3062 - accuracy: 0.5213\n",
      "Epoch 343/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3063 - accuracy: 0.5193\n",
      "Epoch 344/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3030 - accuracy: 0.5224\n",
      "Epoch 345/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3007 - accuracy: 0.5249\n",
      "Epoch 346/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3036 - accuracy: 0.5232\n",
      "Epoch 347/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3020 - accuracy: 0.5223\n",
      "Epoch 348/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3032 - accuracy: 0.5211\n",
      "Epoch 349/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3069 - accuracy: 0.5211\n",
      "Epoch 350/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3098 - accuracy: 0.5201\n",
      "Epoch 351/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3045 - accuracy: 0.5200\n",
      "Epoch 352/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3046 - accuracy: 0.5227\n",
      "Epoch 353/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3033 - accuracy: 0.5213\n",
      "Epoch 354/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3028 - accuracy: 0.5232\n",
      "Epoch 355/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3089 - accuracy: 0.5212\n",
      "Epoch 356/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3039 - accuracy: 0.5226\n",
      "Epoch 357/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3045 - accuracy: 0.5221\n",
      "Epoch 358/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3038 - accuracy: 0.5228\n",
      "Epoch 359/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3033 - accuracy: 0.5209\n",
      "Epoch 360/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3030 - accuracy: 0.5235\n",
      "Epoch 361/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3001 - accuracy: 0.5229\n",
      "Epoch 362/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3041 - accuracy: 0.5217\n",
      "Epoch 363/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3005 - accuracy: 0.5228\n",
      "Epoch 364/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3036 - accuracy: 0.5211\n",
      "Epoch 365/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3041 - accuracy: 0.5212\n",
      "Epoch 366/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3043 - accuracy: 0.5233\n",
      "Epoch 367/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3062 - accuracy: 0.5211\n",
      "Epoch 368/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3010 - accuracy: 0.5212\n",
      "Epoch 369/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3037 - accuracy: 0.5206\n",
      "Epoch 370/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3013 - accuracy: 0.5221\n",
      "Epoch 371/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3007 - accuracy: 0.5217\n",
      "Epoch 372/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3001 - accuracy: 0.5247\n",
      "Epoch 373/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3014 - accuracy: 0.5241\n",
      "Epoch 374/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.2994 - accuracy: 0.5229\n",
      "Epoch 375/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3010 - accuracy: 0.5190\n",
      "Epoch 376/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2990 - accuracy: 0.5234\n",
      "Epoch 377/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3026 - accuracy: 0.5199\n",
      "Epoch 378/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3009 - accuracy: 0.5214\n",
      "Epoch 379/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3028 - accuracy: 0.5217\n",
      "Epoch 380/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3001 - accuracy: 0.5219\n",
      "Epoch 381/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3003 - accuracy: 0.5258\n",
      "Epoch 382/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3011 - accuracy: 0.5203\n",
      "Epoch 383/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3004 - accuracy: 0.5233\n",
      "Epoch 384/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3001 - accuracy: 0.5239\n",
      "Epoch 385/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.2978 - accuracy: 0.5246\n",
      "Epoch 386/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3044 - accuracy: 0.5212\n",
      "Epoch 387/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2999 - accuracy: 0.5220\n",
      "Epoch 388/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2967 - accuracy: 0.5238\n",
      "Epoch 389/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2987 - accuracy: 0.5233\n",
      "Epoch 390/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3016 - accuracy: 0.5240\n",
      "Epoch 391/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3001 - accuracy: 0.5219\n",
      "Epoch 392/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3029 - accuracy: 0.5207\n",
      "Epoch 393/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3005 - accuracy: 0.5213\n",
      "Epoch 394/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3010 - accuracy: 0.5264\n",
      "Epoch 395/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2986 - accuracy: 0.5223\n",
      "Epoch 396/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2995 - accuracy: 0.5216\n",
      "Epoch 397/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3009 - accuracy: 0.5221\n",
      "Epoch 398/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2999 - accuracy: 0.5207\n",
      "Epoch 399/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2997 - accuracy: 0.5215\n",
      "Epoch 400/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.2968 - accuracy: 0.5210\n",
      "Epoch 1/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.7457 - accuracy: 0.3512\n",
      "Epoch 2/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6945 - accuracy: 0.3519\n",
      "Epoch 3/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6925 - accuracy: 0.3519\n",
      "Epoch 4/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6922 - accuracy: 0.3519\n",
      "Epoch 5/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6919 - accuracy: 0.3519\n",
      "Epoch 6/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6918 - accuracy: 0.3519\n",
      "Epoch 7/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6918 - accuracy: 0.3520\n",
      "Epoch 8/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6917 - accuracy: 0.3519\n",
      "Epoch 9/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6913 - accuracy: 0.3520\n",
      "Epoch 10/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6912 - accuracy: 0.3520\n",
      "Epoch 11/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6911 - accuracy: 0.3520\n",
      "Epoch 12/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6909 - accuracy: 0.3518\n",
      "Epoch 13/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6905 - accuracy: 0.3522\n",
      "Epoch 14/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6904 - accuracy: 0.3518\n",
      "Epoch 15/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6892 - accuracy: 0.3530\n",
      "Epoch 16/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6821 - accuracy: 0.3557\n",
      "Epoch 17/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6636 - accuracy: 0.3643\n",
      "Epoch 18/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5816 - accuracy: 0.3979\n",
      "Epoch 19/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5465 - accuracy: 0.4029\n",
      "Epoch 20/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5277 - accuracy: 0.4105\n",
      "Epoch 21/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5104 - accuracy: 0.4190\n",
      "Epoch 22/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5032 - accuracy: 0.4275\n",
      "Epoch 23/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.4956 - accuracy: 0.4275\n",
      "Epoch 24/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.4843 - accuracy: 0.4358\n",
      "Epoch 25/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4788 - accuracy: 0.4380\n",
      "Epoch 26/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4691 - accuracy: 0.4400\n",
      "Epoch 27/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4629 - accuracy: 0.4466\n",
      "Epoch 28/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4564 - accuracy: 0.4532\n",
      "Epoch 29/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4537 - accuracy: 0.4546\n",
      "Epoch 30/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4514 - accuracy: 0.4526\n",
      "Epoch 31/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4493 - accuracy: 0.4560\n",
      "Epoch 32/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4359 - accuracy: 0.4634\n",
      "Epoch 33/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4339 - accuracy: 0.4635\n",
      "Epoch 34/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4299 - accuracy: 0.4675\n",
      "Epoch 35/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4303 - accuracy: 0.4675\n",
      "Epoch 36/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4261 - accuracy: 0.4659\n",
      "Epoch 37/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4288 - accuracy: 0.4648\n",
      "Epoch 38/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4261 - accuracy: 0.4664\n",
      "Epoch 39/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4254 - accuracy: 0.4662\n",
      "Epoch 40/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4208 - accuracy: 0.4679\n",
      "Epoch 41/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4183 - accuracy: 0.4691\n",
      "Epoch 42/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4211 - accuracy: 0.4682\n",
      "Epoch 43/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4147 - accuracy: 0.4674\n",
      "Epoch 44/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4164 - accuracy: 0.4687\n",
      "Epoch 45/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4138 - accuracy: 0.4740\n",
      "Epoch 46/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4160 - accuracy: 0.4726\n",
      "Epoch 47/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4145 - accuracy: 0.4702\n",
      "Epoch 48/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4133 - accuracy: 0.4710\n",
      "Epoch 49/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4138 - accuracy: 0.4721\n",
      "Epoch 50/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4141 - accuracy: 0.4706\n",
      "Epoch 51/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4089 - accuracy: 0.4731\n",
      "Epoch 52/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4113 - accuracy: 0.4727\n",
      "Epoch 53/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4113 - accuracy: 0.4733\n",
      "Epoch 54/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4069 - accuracy: 0.4756\n",
      "Epoch 55/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4065 - accuracy: 0.4771\n",
      "Epoch 56/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4067 - accuracy: 0.4752\n",
      "Epoch 57/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4045 - accuracy: 0.4752\n",
      "Epoch 58/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4061 - accuracy: 0.4743\n",
      "Epoch 59/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4050 - accuracy: 0.4752\n",
      "Epoch 60/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4059 - accuracy: 0.4743\n",
      "Epoch 61/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4043 - accuracy: 0.4753\n",
      "Epoch 62/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4047 - accuracy: 0.4747\n",
      "Epoch 63/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4036 - accuracy: 0.4750\n",
      "Epoch 64/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3994 - accuracy: 0.4803\n",
      "Epoch 65/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3990 - accuracy: 0.4791\n",
      "Epoch 66/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3990 - accuracy: 0.4786\n",
      "Epoch 67/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4009 - accuracy: 0.4760\n",
      "Epoch 68/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3970 - accuracy: 0.4776\n",
      "Epoch 69/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3925 - accuracy: 0.4814\n",
      "Epoch 70/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4001 - accuracy: 0.4762\n",
      "Epoch 71/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3958 - accuracy: 0.4785\n",
      "Epoch 72/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3933 - accuracy: 0.4805\n",
      "Epoch 73/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3957 - accuracy: 0.4781\n",
      "Epoch 74/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3932 - accuracy: 0.4808\n",
      "Epoch 75/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3935 - accuracy: 0.4805\n",
      "Epoch 76/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3956 - accuracy: 0.4790\n",
      "Epoch 77/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3941 - accuracy: 0.4787\n",
      "Epoch 78/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3971 - accuracy: 0.4789\n",
      "Epoch 79/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3949 - accuracy: 0.4804\n",
      "Epoch 80/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3917 - accuracy: 0.4802\n",
      "Epoch 81/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3928 - accuracy: 0.4823\n",
      "Epoch 82/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3938 - accuracy: 0.4826\n",
      "Epoch 83/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3877 - accuracy: 0.4866\n",
      "Epoch 84/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3932 - accuracy: 0.4804\n",
      "Epoch 85/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3931 - accuracy: 0.4810\n",
      "Epoch 86/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3906 - accuracy: 0.4825\n",
      "Epoch 87/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3885 - accuracy: 0.4848\n",
      "Epoch 88/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3887 - accuracy: 0.4811\n",
      "Epoch 89/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3875 - accuracy: 0.4819\n",
      "Epoch 90/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3892 - accuracy: 0.4837\n",
      "Epoch 91/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3882 - accuracy: 0.4817\n",
      "Epoch 92/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3907 - accuracy: 0.4812\n",
      "Epoch 93/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3909 - accuracy: 0.4815\n",
      "Epoch 94/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3902 - accuracy: 0.4832\n",
      "Epoch 95/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3901 - accuracy: 0.4817\n",
      "Epoch 96/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3871 - accuracy: 0.4839\n",
      "Epoch 97/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3877 - accuracy: 0.4836\n",
      "Epoch 98/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3914 - accuracy: 0.4812\n",
      "Epoch 99/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3898 - accuracy: 0.4821\n",
      "Epoch 100/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3865 - accuracy: 0.4821\n",
      "Epoch 101/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3878 - accuracy: 0.4843\n",
      "Epoch 102/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3874 - accuracy: 0.4847\n",
      "Epoch 103/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3873 - accuracy: 0.4822\n",
      "Epoch 104/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3867 - accuracy: 0.4834\n",
      "Epoch 105/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3910 - accuracy: 0.4782\n",
      "Epoch 106/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3856 - accuracy: 0.4837\n",
      "Epoch 107/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3849 - accuracy: 0.4825\n",
      "Epoch 108/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3854 - accuracy: 0.4850\n",
      "Epoch 109/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3847 - accuracy: 0.4882\n",
      "Epoch 110/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3874 - accuracy: 0.4836\n",
      "Epoch 111/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3833 - accuracy: 0.4860\n",
      "Epoch 112/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3827 - accuracy: 0.4853\n",
      "Epoch 113/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3869 - accuracy: 0.4819\n",
      "Epoch 114/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3820 - accuracy: 0.4856\n",
      "Epoch 115/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3828 - accuracy: 0.4865\n",
      "Epoch 116/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3819 - accuracy: 0.4864\n",
      "Epoch 117/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3839 - accuracy: 0.4839\n",
      "Epoch 118/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3826 - accuracy: 0.4858\n",
      "Epoch 119/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3867 - accuracy: 0.4846\n",
      "Epoch 120/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3814 - accuracy: 0.4891\n",
      "Epoch 121/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3864 - accuracy: 0.4812\n",
      "Epoch 122/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3856 - accuracy: 0.4856\n",
      "Epoch 123/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3840 - accuracy: 0.4849\n",
      "Epoch 124/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3826 - accuracy: 0.4867\n",
      "Epoch 125/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3845 - accuracy: 0.4846\n",
      "Epoch 126/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3794 - accuracy: 0.4877\n",
      "Epoch 127/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3839 - accuracy: 0.4861\n",
      "Epoch 128/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3806 - accuracy: 0.4862\n",
      "Epoch 129/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3816 - accuracy: 0.4858\n",
      "Epoch 130/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3827 - accuracy: 0.4865\n",
      "Epoch 131/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3820 - accuracy: 0.4891\n",
      "Epoch 132/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3779 - accuracy: 0.4899\n",
      "Epoch 133/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3822 - accuracy: 0.4861\n",
      "Epoch 134/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3860 - accuracy: 0.4835\n",
      "Epoch 135/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3761 - accuracy: 0.4894\n",
      "Epoch 136/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3780 - accuracy: 0.4904\n",
      "Epoch 137/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3816 - accuracy: 0.4872\n",
      "Epoch 138/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3808 - accuracy: 0.4883\n",
      "Epoch 139/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3797 - accuracy: 0.4900\n",
      "Epoch 140/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3796 - accuracy: 0.4857\n",
      "Epoch 141/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3805 - accuracy: 0.4861\n",
      "Epoch 142/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3819 - accuracy: 0.4860\n",
      "Epoch 143/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3844 - accuracy: 0.4867\n",
      "Epoch 144/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3798 - accuracy: 0.4873\n",
      "Epoch 145/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3790 - accuracy: 0.4894\n",
      "Epoch 146/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3765 - accuracy: 0.4892\n",
      "Epoch 147/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3772 - accuracy: 0.4881\n",
      "Epoch 148/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3784 - accuracy: 0.4881\n",
      "Epoch 149/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3800 - accuracy: 0.4883\n",
      "Epoch 150/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3792 - accuracy: 0.4890\n",
      "Epoch 151/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3771 - accuracy: 0.4904\n",
      "Epoch 152/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3778 - accuracy: 0.4875\n",
      "Epoch 153/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3756 - accuracy: 0.4898\n",
      "Epoch 154/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3773 - accuracy: 0.4881\n",
      "Epoch 155/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3743 - accuracy: 0.4889\n",
      "Epoch 156/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3765 - accuracy: 0.4878\n",
      "Epoch 157/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3754 - accuracy: 0.4914\n",
      "Epoch 158/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3745 - accuracy: 0.4905\n",
      "Epoch 159/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3733 - accuracy: 0.4901\n",
      "Epoch 160/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3769 - accuracy: 0.4905\n",
      "Epoch 161/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3738 - accuracy: 0.4924\n",
      "Epoch 162/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3738 - accuracy: 0.4908\n",
      "Epoch 163/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3757 - accuracy: 0.4911\n",
      "Epoch 164/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3745 - accuracy: 0.4913\n",
      "Epoch 165/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3739 - accuracy: 0.4895\n",
      "Epoch 166/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3713 - accuracy: 0.4934\n",
      "Epoch 167/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3702 - accuracy: 0.4925\n",
      "Epoch 168/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3727 - accuracy: 0.4903\n",
      "Epoch 169/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3697 - accuracy: 0.4961\n",
      "Epoch 170/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3694 - accuracy: 0.4943\n",
      "Epoch 171/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3689 - accuracy: 0.4932\n",
      "Epoch 172/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3666 - accuracy: 0.4936\n",
      "Epoch 173/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3686 - accuracy: 0.4937\n",
      "Epoch 174/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3705 - accuracy: 0.4915\n",
      "Epoch 175/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3689 - accuracy: 0.4920\n",
      "Epoch 176/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3706 - accuracy: 0.4911\n",
      "Epoch 177/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3629 - accuracy: 0.4958\n",
      "Epoch 178/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3680 - accuracy: 0.4948\n",
      "Epoch 179/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3692 - accuracy: 0.4932\n",
      "Epoch 180/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3618 - accuracy: 0.4957\n",
      "Epoch 181/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3647 - accuracy: 0.4946\n",
      "Epoch 182/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3604 - accuracy: 0.4975\n",
      "Epoch 183/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3640 - accuracy: 0.4943\n",
      "Epoch 184/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3677 - accuracy: 0.4950\n",
      "Epoch 185/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3628 - accuracy: 0.4963\n",
      "Epoch 186/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3640 - accuracy: 0.4957\n",
      "Epoch 187/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3625 - accuracy: 0.4930\n",
      "Epoch 188/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3649 - accuracy: 0.4965\n",
      "Epoch 189/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3680 - accuracy: 0.4922\n",
      "Epoch 190/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3639 - accuracy: 0.4950\n",
      "Epoch 191/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3647 - accuracy: 0.4955\n",
      "Epoch 192/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3674 - accuracy: 0.4940\n",
      "Epoch 193/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3612 - accuracy: 0.4970\n",
      "Epoch 194/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3665 - accuracy: 0.4947\n",
      "Epoch 195/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3626 - accuracy: 0.4957\n",
      "Epoch 196/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3644 - accuracy: 0.4945\n",
      "Epoch 197/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3658 - accuracy: 0.4938\n",
      "Epoch 198/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3660 - accuracy: 0.4939\n",
      "Epoch 199/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3630 - accuracy: 0.4978\n",
      "Epoch 200/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3677 - accuracy: 0.4919\n",
      "Epoch 201/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3625 - accuracy: 0.4974\n",
      "Epoch 202/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3620 - accuracy: 0.4964\n",
      "Epoch 203/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3623 - accuracy: 0.4937\n",
      "Epoch 204/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3606 - accuracy: 0.4983\n",
      "Epoch 205/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3647 - accuracy: 0.4935\n",
      "Epoch 206/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3635 - accuracy: 0.4968\n",
      "Epoch 207/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3609 - accuracy: 0.4968\n",
      "Epoch 208/400\n",
      "1947/1947 [==============================] - 12s 6ms/step - loss: 1.3643 - accuracy: 0.4959\n",
      "Epoch 209/400\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3621 - accuracy: 0.4957\n",
      "Epoch 210/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3651 - accuracy: 0.4937\n",
      "Epoch 211/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3629 - accuracy: 0.4960\n",
      "Epoch 212/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3631 - accuracy: 0.4962\n",
      "Epoch 213/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3603 - accuracy: 0.4976\n",
      "Epoch 214/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3624 - accuracy: 0.4960\n",
      "Epoch 215/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3616 - accuracy: 0.4976\n",
      "Epoch 216/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3632 - accuracy: 0.4973\n",
      "Epoch 217/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3612 - accuracy: 0.4986\n",
      "Epoch 218/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3633 - accuracy: 0.4969\n",
      "Epoch 219/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3614 - accuracy: 0.4974\n",
      "Epoch 220/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3588 - accuracy: 0.4972\n",
      "Epoch 221/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3586 - accuracy: 0.4970\n",
      "Epoch 222/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3609 - accuracy: 0.4952\n",
      "Epoch 223/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3622 - accuracy: 0.4960\n",
      "Epoch 224/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3618 - accuracy: 0.4975\n",
      "Epoch 225/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3600 - accuracy: 0.4973\n",
      "Epoch 226/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3573 - accuracy: 0.5003\n",
      "Epoch 227/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3591 - accuracy: 0.4960\n",
      "Epoch 228/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3597 - accuracy: 0.4958\n",
      "Epoch 229/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3586 - accuracy: 0.4991\n",
      "Epoch 230/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3566 - accuracy: 0.5011\n",
      "Epoch 231/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3570 - accuracy: 0.4993\n",
      "Epoch 232/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3607 - accuracy: 0.4989\n",
      "Epoch 233/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3612 - accuracy: 0.4967\n",
      "Epoch 234/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3583 - accuracy: 0.4994\n",
      "Epoch 235/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3620 - accuracy: 0.4986\n",
      "Epoch 236/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3611 - accuracy: 0.4973\n",
      "Epoch 237/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3575 - accuracy: 0.4976\n",
      "Epoch 238/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3580 - accuracy: 0.4986\n",
      "Epoch 239/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3624 - accuracy: 0.4956\n",
      "Epoch 240/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3577 - accuracy: 0.4968\n",
      "Epoch 241/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3571 - accuracy: 0.5002\n",
      "Epoch 242/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3565 - accuracy: 0.4979\n",
      "Epoch 243/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3590 - accuracy: 0.4992\n",
      "Epoch 244/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3554 - accuracy: 0.5028\n",
      "Epoch 245/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3637 - accuracy: 0.4965\n",
      "Epoch 246/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3557 - accuracy: 0.5006\n",
      "Epoch 247/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3608 - accuracy: 0.4972\n",
      "Epoch 248/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3598 - accuracy: 0.4956\n",
      "Epoch 249/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3559 - accuracy: 0.5003\n",
      "Epoch 250/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3593 - accuracy: 0.4964\n",
      "Epoch 251/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3591 - accuracy: 0.5004\n",
      "Epoch 252/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3559 - accuracy: 0.5021\n",
      "Epoch 253/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3596 - accuracy: 0.4983\n",
      "Epoch 254/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3568 - accuracy: 0.4989\n",
      "Epoch 255/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3575 - accuracy: 0.5038\n",
      "Epoch 256/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3561 - accuracy: 0.4987\n",
      "Epoch 257/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3574 - accuracy: 0.5006\n",
      "Epoch 258/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3540 - accuracy: 0.5002\n",
      "Epoch 259/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3531 - accuracy: 0.4993\n",
      "Epoch 260/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3535 - accuracy: 0.4998\n",
      "Epoch 261/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3507 - accuracy: 0.5023\n",
      "Epoch 262/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3525 - accuracy: 0.4991\n",
      "Epoch 263/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3542 - accuracy: 0.5018\n",
      "Epoch 264/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3535 - accuracy: 0.5039\n",
      "Epoch 265/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3531 - accuracy: 0.5015\n",
      "Epoch 266/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3510 - accuracy: 0.5033\n",
      "Epoch 267/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3497 - accuracy: 0.5035\n",
      "Epoch 268/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3483 - accuracy: 0.5037\n",
      "Epoch 269/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3514 - accuracy: 0.5020\n",
      "Epoch 270/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3522 - accuracy: 0.5021\n",
      "Epoch 271/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3492 - accuracy: 0.5049\n",
      "Epoch 272/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3515 - accuracy: 0.5023\n",
      "Epoch 273/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3531 - accuracy: 0.5017\n",
      "Epoch 274/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3477 - accuracy: 0.5052\n",
      "Epoch 275/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3508 - accuracy: 0.5025\n",
      "Epoch 276/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3507 - accuracy: 0.5016\n",
      "Epoch 277/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3484 - accuracy: 0.5020\n",
      "Epoch 278/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3481 - accuracy: 0.5044\n",
      "Epoch 279/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3490 - accuracy: 0.5027\n",
      "Epoch 280/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3467 - accuracy: 0.5036\n",
      "Epoch 281/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3461 - accuracy: 0.5042\n",
      "Epoch 282/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3478 - accuracy: 0.5062\n",
      "Epoch 283/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3489 - accuracy: 0.5043\n",
      "Epoch 284/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3486 - accuracy: 0.5062\n",
      "Epoch 285/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3446 - accuracy: 0.5057\n",
      "Epoch 286/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3466 - accuracy: 0.5077\n",
      "Epoch 287/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3436 - accuracy: 0.5061\n",
      "Epoch 288/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3459 - accuracy: 0.5072\n",
      "Epoch 289/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3455 - accuracy: 0.5074\n",
      "Epoch 290/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3482 - accuracy: 0.5038\n",
      "Epoch 291/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3459 - accuracy: 0.5057\n",
      "Epoch 292/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3466 - accuracy: 0.5045\n",
      "Epoch 293/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3422 - accuracy: 0.5072\n",
      "Epoch 294/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3426 - accuracy: 0.5082\n",
      "Epoch 295/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3430 - accuracy: 0.5066\n",
      "Epoch 296/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3435 - accuracy: 0.5083\n",
      "Epoch 297/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3430 - accuracy: 0.5099\n",
      "Epoch 298/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3429 - accuracy: 0.5089\n",
      "Epoch 299/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3446 - accuracy: 0.5049\n",
      "Epoch 300/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3435 - accuracy: 0.5077\n",
      "Epoch 301/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3411 - accuracy: 0.5074\n",
      "Epoch 302/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3436 - accuracy: 0.5075\n",
      "Epoch 303/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3437 - accuracy: 0.5052\n",
      "Epoch 304/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3421 - accuracy: 0.5077\n",
      "Epoch 305/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3468 - accuracy: 0.5083\n",
      "Epoch 306/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3421 - accuracy: 0.5082\n",
      "Epoch 307/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3411 - accuracy: 0.5076\n",
      "Epoch 308/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3414 - accuracy: 0.5056\n",
      "Epoch 309/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3417 - accuracy: 0.5089\n",
      "Epoch 310/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3404 - accuracy: 0.5072\n",
      "Epoch 311/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3433 - accuracy: 0.5090\n",
      "Epoch 312/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3462 - accuracy: 0.5034\n",
      "Epoch 313/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3410 - accuracy: 0.5106\n",
      "Epoch 314/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3389 - accuracy: 0.5108\n",
      "Epoch 315/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3416 - accuracy: 0.5076\n",
      "Epoch 316/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3396 - accuracy: 0.5097\n",
      "Epoch 317/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3401 - accuracy: 0.5075\n",
      "Epoch 318/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3363 - accuracy: 0.5095\n",
      "Epoch 319/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3392 - accuracy: 0.5084\n",
      "Epoch 320/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3397 - accuracy: 0.5065\n",
      "Epoch 321/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3420 - accuracy: 0.5058\n",
      "Epoch 322/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3370 - accuracy: 0.5088\n",
      "Epoch 323/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3390 - accuracy: 0.5077\n",
      "Epoch 324/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3401 - accuracy: 0.5073\n",
      "Epoch 325/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3387 - accuracy: 0.5082\n",
      "Epoch 326/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3397 - accuracy: 0.5070\n",
      "Epoch 327/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3405 - accuracy: 0.5090\n",
      "Epoch 328/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3361 - accuracy: 0.5102\n",
      "Epoch 329/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3436 - accuracy: 0.5050\n",
      "Epoch 330/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3386 - accuracy: 0.5083\n",
      "Epoch 331/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3391 - accuracy: 0.5086\n",
      "Epoch 332/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3394 - accuracy: 0.5079\n",
      "Epoch 333/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3386 - accuracy: 0.5088\n",
      "Epoch 334/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3373 - accuracy: 0.5096\n",
      "Epoch 335/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3381 - accuracy: 0.5059\n",
      "Epoch 336/400\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3384 - accuracy: 0.5081\n",
      "Epoch 337/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3380 - accuracy: 0.5064\n",
      "Epoch 338/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3363 - accuracy: 0.5102\n",
      "Epoch 339/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3408 - accuracy: 0.5087\n",
      "Epoch 340/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3383 - accuracy: 0.5102\n",
      "Epoch 341/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3379 - accuracy: 0.5087\n",
      "Epoch 342/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3383 - accuracy: 0.5082\n",
      "Epoch 343/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3416 - accuracy: 0.5077\n",
      "Epoch 344/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3386 - accuracy: 0.5075\n",
      "Epoch 345/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3388 - accuracy: 0.5100\n",
      "Epoch 346/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3382 - accuracy: 0.5066\n",
      "Epoch 347/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3373 - accuracy: 0.5094\n",
      "Epoch 348/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3383 - accuracy: 0.5081\n",
      "Epoch 349/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3341 - accuracy: 0.5109\n",
      "Epoch 350/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3382 - accuracy: 0.5082\n",
      "Epoch 351/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3360 - accuracy: 0.5087\n",
      "Epoch 352/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3386 - accuracy: 0.5085\n",
      "Epoch 353/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3347 - accuracy: 0.5111\n",
      "Epoch 354/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3375 - accuracy: 0.5078\n",
      "Epoch 355/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3368 - accuracy: 0.5088\n",
      "Epoch 356/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3349 - accuracy: 0.5106\n",
      "Epoch 357/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3347 - accuracy: 0.5086\n",
      "Epoch 358/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3368 - accuracy: 0.5091\n",
      "Epoch 359/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3380 - accuracy: 0.5100\n",
      "Epoch 360/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3355 - accuracy: 0.5106\n",
      "Epoch 361/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3366 - accuracy: 0.5078\n",
      "Epoch 362/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3361 - accuracy: 0.5090\n",
      "Epoch 363/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3360 - accuracy: 0.5096\n",
      "Epoch 364/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3346 - accuracy: 0.5074\n",
      "Epoch 365/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3353 - accuracy: 0.5094\n",
      "Epoch 366/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3340 - accuracy: 0.5108\n",
      "Epoch 367/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3386 - accuracy: 0.5089\n",
      "Epoch 368/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3399 - accuracy: 0.5071\n",
      "Epoch 369/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3353 - accuracy: 0.5093\n",
      "Epoch 370/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3344 - accuracy: 0.5103\n",
      "Epoch 371/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3357 - accuracy: 0.5106\n",
      "Epoch 372/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3330 - accuracy: 0.5089\n",
      "Epoch 373/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3355 - accuracy: 0.5091\n",
      "Epoch 374/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3362 - accuracy: 0.5102\n",
      "Epoch 375/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3353 - accuracy: 0.5104\n",
      "Epoch 376/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3355 - accuracy: 0.5100\n",
      "Epoch 377/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3354 - accuracy: 0.5082\n",
      "Epoch 378/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3356 - accuracy: 0.5103\n",
      "Epoch 379/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3370 - accuracy: 0.5081\n",
      "Epoch 380/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3351 - accuracy: 0.5112\n",
      "Epoch 381/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3335 - accuracy: 0.5113\n",
      "Epoch 382/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3319 - accuracy: 0.5106\n",
      "Epoch 383/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3330 - accuracy: 0.5114\n",
      "Epoch 384/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3351 - accuracy: 0.5098\n",
      "Epoch 385/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3333 - accuracy: 0.5106\n",
      "Epoch 386/400\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3352 - accuracy: 0.5082\n",
      "Epoch 387/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3348 - accuracy: 0.5082\n",
      "Epoch 388/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3349 - accuracy: 0.5125\n",
      "Epoch 389/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3327 - accuracy: 0.5093\n",
      "Epoch 390/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3341 - accuracy: 0.5093\n",
      "Epoch 391/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3356 - accuracy: 0.5092\n",
      "Epoch 392/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3310 - accuracy: 0.5112\n",
      "Epoch 393/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3350 - accuracy: 0.5092\n",
      "Epoch 394/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3329 - accuracy: 0.5117\n",
      "Epoch 395/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3326 - accuracy: 0.5119\n",
      "Epoch 396/400\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3343 - accuracy: 0.5095\n",
      "Epoch 397/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3343 - accuracy: 0.5101\n",
      "Epoch 398/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3350 - accuracy: 0.5080\n",
      "Epoch 399/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3316 - accuracy: 0.5106\n",
      "Epoch 400/400\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3355 - accuracy: 0.5097\n",
      "Epoch 1/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.9591 - accuracy: 0.2578\n",
      "Epoch 2/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.8312 - accuracy: 0.3519\n",
      "Epoch 3/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.7622 - accuracy: 0.3519\n",
      "Epoch 4/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.7283 - accuracy: 0.3519\n",
      "Epoch 5/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.7123 - accuracy: 0.3519\n",
      "Epoch 6/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.7043 - accuracy: 0.3519\n",
      "Epoch 7/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.7001 - accuracy: 0.3519\n",
      "Epoch 8/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6976 - accuracy: 0.3519\n",
      "Epoch 9/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6961 - accuracy: 0.3519\n",
      "Epoch 10/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6952 - accuracy: 0.3519\n",
      "Epoch 11/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6945 - accuracy: 0.3519\n",
      "Epoch 12/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6941 - accuracy: 0.3519\n",
      "Epoch 13/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6937 - accuracy: 0.3519\n",
      "Epoch 14/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6935 - accuracy: 0.3519\n",
      "Epoch 15/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6933 - accuracy: 0.3519\n",
      "Epoch 16/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6931 - accuracy: 0.3519\n",
      "Epoch 17/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6930 - accuracy: 0.3519\n",
      "Epoch 18/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6929 - accuracy: 0.3519\n",
      "Epoch 19/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6928 - accuracy: 0.3519\n",
      "Epoch 20/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6927 - accuracy: 0.3519\n",
      "Epoch 21/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6926 - accuracy: 0.3519\n",
      "Epoch 22/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6925 - accuracy: 0.3519\n",
      "Epoch 23/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6925 - accuracy: 0.3519\n",
      "Epoch 24/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6924 - accuracy: 0.3519\n",
      "Epoch 25/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6924 - accuracy: 0.3519\n",
      "Epoch 26/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6923 - accuracy: 0.3519\n",
      "Epoch 27/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6923 - accuracy: 0.3519\n",
      "Epoch 28/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6922 - accuracy: 0.3519\n",
      "Epoch 29/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6922 - accuracy: 0.3519\n",
      "Epoch 30/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6921 - accuracy: 0.3519\n",
      "Epoch 31/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6921 - accuracy: 0.3519\n",
      "Epoch 32/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6921 - accuracy: 0.3519\n",
      "Epoch 33/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6921 - accuracy: 0.3519\n",
      "Epoch 34/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6920 - accuracy: 0.3519\n",
      "Epoch 35/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6920 - accuracy: 0.3519\n",
      "Epoch 36/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6920 - accuracy: 0.3519\n",
      "Epoch 37/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6920 - accuracy: 0.3519\n",
      "Epoch 38/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6919 - accuracy: 0.3519\n",
      "Epoch 39/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6919 - accuracy: 0.3519\n",
      "Epoch 40/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6919 - accuracy: 0.3519\n",
      "Epoch 41/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6919 - accuracy: 0.3519\n",
      "Epoch 42/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6919 - accuracy: 0.3519\n",
      "Epoch 43/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6918 - accuracy: 0.3519\n",
      "Epoch 44/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6918 - accuracy: 0.3519\n",
      "Epoch 45/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6918 - accuracy: 0.3519\n",
      "Epoch 46/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6915 - accuracy: 0.3519\n",
      "Epoch 47/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6877 - accuracy: 0.3519\n",
      "Epoch 48/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6865 - accuracy: 0.3519\n",
      "Epoch 49/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6857 - accuracy: 0.3519\n",
      "Epoch 50/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6850 - accuracy: 0.3519\n",
      "Epoch 51/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6842 - accuracy: 0.3519\n",
      "Epoch 52/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6835 - accuracy: 0.3545\n",
      "Epoch 53/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6828 - accuracy: 0.3591\n",
      "Epoch 54/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6822 - accuracy: 0.3607\n",
      "Epoch 55/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6816 - accuracy: 0.3611\n",
      "Epoch 56/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6811 - accuracy: 0.3615\n",
      "Epoch 57/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6805 - accuracy: 0.3618\n",
      "Epoch 58/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6800 - accuracy: 0.3622\n",
      "Epoch 59/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6794 - accuracy: 0.3622\n",
      "Epoch 60/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6787 - accuracy: 0.3626\n",
      "Epoch 61/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6784 - accuracy: 0.3623\n",
      "Epoch 62/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6778 - accuracy: 0.3626\n",
      "Epoch 63/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6773 - accuracy: 0.3628\n",
      "Epoch 64/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6769 - accuracy: 0.3628\n",
      "Epoch 65/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6763 - accuracy: 0.3628\n",
      "Epoch 66/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6758 - accuracy: 0.3630\n",
      "Epoch 67/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6753 - accuracy: 0.3632\n",
      "Epoch 68/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6747 - accuracy: 0.3635\n",
      "Epoch 69/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6742 - accuracy: 0.3634\n",
      "Epoch 70/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6737 - accuracy: 0.3637\n",
      "Epoch 71/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6731 - accuracy: 0.3639\n",
      "Epoch 72/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6725 - accuracy: 0.3642\n",
      "Epoch 73/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6718 - accuracy: 0.3641\n",
      "Epoch 74/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6712 - accuracy: 0.3642\n",
      "Epoch 75/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6706 - accuracy: 0.3642\n",
      "Epoch 76/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6699 - accuracy: 0.3646\n",
      "Epoch 77/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6692 - accuracy: 0.3642\n",
      "Epoch 78/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6684 - accuracy: 0.3648\n",
      "Epoch 79/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6675 - accuracy: 0.3654\n",
      "Epoch 80/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6667 - accuracy: 0.3654\n",
      "Epoch 81/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6657 - accuracy: 0.3653\n",
      "Epoch 82/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6646 - accuracy: 0.3656\n",
      "Epoch 83/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6633 - accuracy: 0.3660\n",
      "Epoch 84/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6621 - accuracy: 0.3661\n",
      "Epoch 85/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6610 - accuracy: 0.3665\n",
      "Epoch 86/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6599 - accuracy: 0.3667\n",
      "Epoch 87/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6581 - accuracy: 0.3666\n",
      "Epoch 88/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6568 - accuracy: 0.3666\n",
      "Epoch 89/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6553 - accuracy: 0.3667\n",
      "Epoch 90/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6535 - accuracy: 0.3675\n",
      "Epoch 91/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6522 - accuracy: 0.3670\n",
      "Epoch 92/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6506 - accuracy: 0.3673\n",
      "Epoch 93/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6486 - accuracy: 0.3681\n",
      "Epoch 94/600\n",
      "1947/1947 [==============================] - 12s 6ms/step - loss: 1.6469 - accuracy: 0.3678\n",
      "Epoch 95/600\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.6452 - accuracy: 0.3675\n",
      "Epoch 96/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6434 - accuracy: 0.3686\n",
      "Epoch 97/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6414 - accuracy: 0.3690\n",
      "Epoch 98/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6398 - accuracy: 0.3710\n",
      "Epoch 99/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6378 - accuracy: 0.3751\n",
      "Epoch 100/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6357 - accuracy: 0.3754\n",
      "Epoch 101/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.6342 - accuracy: 0.3797\n",
      "Epoch 102/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.6319 - accuracy: 0.3827\n",
      "Epoch 103/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6300 - accuracy: 0.3858\n",
      "Epoch 104/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.6284 - accuracy: 0.3870\n",
      "Epoch 105/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6264 - accuracy: 0.3917\n",
      "Epoch 106/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6244 - accuracy: 0.3941\n",
      "Epoch 107/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6228 - accuracy: 0.3942\n",
      "Epoch 108/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6205 - accuracy: 0.4005\n",
      "Epoch 109/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6183 - accuracy: 0.3993\n",
      "Epoch 110/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6166 - accuracy: 0.4021\n",
      "Epoch 111/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6145 - accuracy: 0.4052\n",
      "Epoch 112/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6132 - accuracy: 0.4066\n",
      "Epoch 113/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6113 - accuracy: 0.4087\n",
      "Epoch 114/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6090 - accuracy: 0.4107\n",
      "Epoch 115/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6067 - accuracy: 0.4126\n",
      "Epoch 116/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6049 - accuracy: 0.4156\n",
      "Epoch 117/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6031 - accuracy: 0.4153\n",
      "Epoch 118/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.6014 - accuracy: 0.4174\n",
      "Epoch 119/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5997 - accuracy: 0.4192\n",
      "Epoch 120/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5985 - accuracy: 0.4210\n",
      "Epoch 121/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5961 - accuracy: 0.4220\n",
      "Epoch 122/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5942 - accuracy: 0.4223\n",
      "Epoch 123/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5924 - accuracy: 0.4238\n",
      "Epoch 124/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5901 - accuracy: 0.4250\n",
      "Epoch 125/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5882 - accuracy: 0.4254\n",
      "Epoch 126/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5862 - accuracy: 0.4246\n",
      "Epoch 127/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.5832 - accuracy: 0.4157\n",
      "Epoch 128/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5808 - accuracy: 0.4157\n",
      "Epoch 129/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5781 - accuracy: 0.4153\n",
      "Epoch 130/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.5748 - accuracy: 0.4152\n",
      "Epoch 131/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5720 - accuracy: 0.4170\n",
      "Epoch 132/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5688 - accuracy: 0.4173\n",
      "Epoch 133/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5661 - accuracy: 0.4173\n",
      "Epoch 134/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5632 - accuracy: 0.4180\n",
      "Epoch 135/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5594 - accuracy: 0.4178\n",
      "Epoch 136/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5562 - accuracy: 0.4185\n",
      "Epoch 137/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5530 - accuracy: 0.4187\n",
      "Epoch 138/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5487 - accuracy: 0.4200\n",
      "Epoch 139/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5451 - accuracy: 0.4217\n",
      "Epoch 140/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5419 - accuracy: 0.4216\n",
      "Epoch 141/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5385 - accuracy: 0.4244\n",
      "Epoch 142/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5347 - accuracy: 0.4255\n",
      "Epoch 143/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5313 - accuracy: 0.4282\n",
      "Epoch 144/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.5273 - accuracy: 0.4303\n",
      "Epoch 145/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5246 - accuracy: 0.4326\n",
      "Epoch 146/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5215 - accuracy: 0.4350\n",
      "Epoch 147/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5182 - accuracy: 0.4361\n",
      "Epoch 148/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5149 - accuracy: 0.4396\n",
      "Epoch 149/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5117 - accuracy: 0.4407\n",
      "Epoch 150/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5093 - accuracy: 0.4412\n",
      "Epoch 151/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5062 - accuracy: 0.4441\n",
      "Epoch 152/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.5036 - accuracy: 0.4453\n",
      "Epoch 153/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.5014 - accuracy: 0.4454\n",
      "Epoch 154/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4990 - accuracy: 0.4477\n",
      "Epoch 155/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4963 - accuracy: 0.4478\n",
      "Epoch 156/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4937 - accuracy: 0.4512\n",
      "Epoch 157/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4916 - accuracy: 0.4512\n",
      "Epoch 158/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4897 - accuracy: 0.4518\n",
      "Epoch 159/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4873 - accuracy: 0.4534\n",
      "Epoch 160/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4852 - accuracy: 0.4532\n",
      "Epoch 161/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4833 - accuracy: 0.4545\n",
      "Epoch 162/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4815 - accuracy: 0.4556\n",
      "Epoch 163/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4797 - accuracy: 0.4562\n",
      "Epoch 164/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4775 - accuracy: 0.4567\n",
      "Epoch 165/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4751 - accuracy: 0.4604\n",
      "Epoch 166/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4715 - accuracy: 0.4597\n",
      "Epoch 167/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4694 - accuracy: 0.4632\n",
      "Epoch 168/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4667 - accuracy: 0.4655\n",
      "Epoch 169/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4639 - accuracy: 0.4658\n",
      "Epoch 170/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4619 - accuracy: 0.4685\n",
      "Epoch 171/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4591 - accuracy: 0.4679\n",
      "Epoch 172/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4573 - accuracy: 0.4681\n",
      "Epoch 173/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4550 - accuracy: 0.4698\n",
      "Epoch 174/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4524 - accuracy: 0.4687\n",
      "Epoch 175/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4508 - accuracy: 0.4690\n",
      "Epoch 176/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4485 - accuracy: 0.4699\n",
      "Epoch 177/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4467 - accuracy: 0.4716\n",
      "Epoch 178/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4444 - accuracy: 0.4713\n",
      "Epoch 179/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4428 - accuracy: 0.4721\n",
      "Epoch 180/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4411 - accuracy: 0.4708\n",
      "Epoch 181/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4396 - accuracy: 0.4722\n",
      "Epoch 182/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4379 - accuracy: 0.4730\n",
      "Epoch 183/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4362 - accuracy: 0.4724\n",
      "Epoch 184/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4349 - accuracy: 0.4727\n",
      "Epoch 185/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4328 - accuracy: 0.4756\n",
      "Epoch 186/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4317 - accuracy: 0.4746\n",
      "Epoch 187/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4302 - accuracy: 0.4745\n",
      "Epoch 188/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4288 - accuracy: 0.4747\n",
      "Epoch 189/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4283 - accuracy: 0.4748\n",
      "Epoch 190/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.4265 - accuracy: 0.4773\n",
      "Epoch 191/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4257 - accuracy: 0.4755\n",
      "Epoch 192/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4247 - accuracy: 0.4762\n",
      "Epoch 193/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4233 - accuracy: 0.4780\n",
      "Epoch 194/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.4225 - accuracy: 0.4769\n",
      "Epoch 195/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4214 - accuracy: 0.4798\n",
      "Epoch 196/600\n",
      "1947/1947 [==============================] - 6s 3ms/step - loss: 1.4205 - accuracy: 0.4808\n",
      "Epoch 197/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4188 - accuracy: 0.4796\n",
      "Epoch 198/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4181 - accuracy: 0.4810\n",
      "Epoch 199/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4174 - accuracy: 0.4787\n",
      "Epoch 200/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4161 - accuracy: 0.4811\n",
      "Epoch 201/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4156 - accuracy: 0.4803\n",
      "Epoch 202/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4154 - accuracy: 0.4809\n",
      "Epoch 203/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4140 - accuracy: 0.4792\n",
      "Epoch 204/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4128 - accuracy: 0.4816\n",
      "Epoch 205/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.4127 - accuracy: 0.4815\n",
      "Epoch 206/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4115 - accuracy: 0.4822\n",
      "Epoch 207/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4111 - accuracy: 0.4825\n",
      "Epoch 208/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4100 - accuracy: 0.4825\n",
      "Epoch 209/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4095 - accuracy: 0.4845\n",
      "Epoch 210/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4086 - accuracy: 0.4824\n",
      "Epoch 211/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4083 - accuracy: 0.4833\n",
      "Epoch 212/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4078 - accuracy: 0.4839\n",
      "Epoch 213/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.4072 - accuracy: 0.4822\n",
      "Epoch 214/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4060 - accuracy: 0.4836\n",
      "Epoch 215/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4057 - accuracy: 0.4840\n",
      "Epoch 216/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4046 - accuracy: 0.4837\n",
      "Epoch 217/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4038 - accuracy: 0.4840\n",
      "Epoch 218/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4038 - accuracy: 0.4848\n",
      "Epoch 219/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.4030 - accuracy: 0.4831\n",
      "Epoch 220/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4020 - accuracy: 0.4843\n",
      "Epoch 221/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.4018 - accuracy: 0.4849\n",
      "Epoch 222/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4008 - accuracy: 0.4854\n",
      "Epoch 223/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.4012 - accuracy: 0.4851\n",
      "Epoch 224/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.4001 - accuracy: 0.4862\n",
      "Epoch 225/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3995 - accuracy: 0.4851\n",
      "Epoch 226/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3990 - accuracy: 0.4843\n",
      "Epoch 227/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.3986 - accuracy: 0.4884\n",
      "Epoch 228/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3978 - accuracy: 0.4863\n",
      "Epoch 229/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3973 - accuracy: 0.4856\n",
      "Epoch 230/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3969 - accuracy: 0.4862\n",
      "Epoch 231/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3963 - accuracy: 0.4871\n",
      "Epoch 232/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3965 - accuracy: 0.4854\n",
      "Epoch 233/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3956 - accuracy: 0.4874\n",
      "Epoch 234/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.3945 - accuracy: 0.4893\n",
      "Epoch 235/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3947 - accuracy: 0.4876\n",
      "Epoch 236/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3936 - accuracy: 0.4877\n",
      "Epoch 237/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3936 - accuracy: 0.4869\n",
      "Epoch 238/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3927 - accuracy: 0.4881\n",
      "Epoch 239/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3923 - accuracy: 0.4891\n",
      "Epoch 240/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3927 - accuracy: 0.4878\n",
      "Epoch 241/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3921 - accuracy: 0.4870\n",
      "Epoch 242/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3909 - accuracy: 0.4881\n",
      "Epoch 243/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3911 - accuracy: 0.4899\n",
      "Epoch 244/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3902 - accuracy: 0.4882\n",
      "Epoch 245/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3898 - accuracy: 0.4902\n",
      "Epoch 246/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3904 - accuracy: 0.4894\n",
      "Epoch 247/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3897 - accuracy: 0.4884\n",
      "Epoch 248/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3888 - accuracy: 0.4919\n",
      "Epoch 249/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3883 - accuracy: 0.4891\n",
      "Epoch 250/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3884 - accuracy: 0.4918\n",
      "Epoch 251/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3875 - accuracy: 0.4913\n",
      "Epoch 252/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3868 - accuracy: 0.4905\n",
      "Epoch 253/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3872 - accuracy: 0.4898\n",
      "Epoch 254/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3870 - accuracy: 0.4904\n",
      "Epoch 255/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3866 - accuracy: 0.4890\n",
      "Epoch 256/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3853 - accuracy: 0.4929\n",
      "Epoch 257/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3857 - accuracy: 0.4908\n",
      "Epoch 258/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3856 - accuracy: 0.4910\n",
      "Epoch 259/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3850 - accuracy: 0.4900\n",
      "Epoch 260/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3850 - accuracy: 0.4927\n",
      "Epoch 261/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3853 - accuracy: 0.4927\n",
      "Epoch 262/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3842 - accuracy: 0.4897\n",
      "Epoch 263/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3840 - accuracy: 0.4914\n",
      "Epoch 264/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3835 - accuracy: 0.4923\n",
      "Epoch 265/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3836 - accuracy: 0.4929\n",
      "Epoch 266/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3827 - accuracy: 0.4927\n",
      "Epoch 267/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3826 - accuracy: 0.4922\n",
      "Epoch 268/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3831 - accuracy: 0.4917\n",
      "Epoch 269/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3826 - accuracy: 0.4911\n",
      "Epoch 270/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3820 - accuracy: 0.4941\n",
      "Epoch 271/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.3813 - accuracy: 0.4912\n",
      "Epoch 272/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3800 - accuracy: 0.4930\n",
      "Epoch 273/600\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3789 - accuracy: 0.4922\n",
      "Epoch 274/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3786 - accuracy: 0.4923\n",
      "Epoch 275/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3779 - accuracy: 0.4911\n",
      "Epoch 276/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3768 - accuracy: 0.4928\n",
      "Epoch 277/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3771 - accuracy: 0.4922\n",
      "Epoch 278/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3768 - accuracy: 0.4943\n",
      "Epoch 279/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3766 - accuracy: 0.4938\n",
      "Epoch 280/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3759 - accuracy: 0.4921\n",
      "Epoch 281/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3757 - accuracy: 0.4929\n",
      "Epoch 282/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3751 - accuracy: 0.4945\n",
      "Epoch 283/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3751 - accuracy: 0.4920\n",
      "Epoch 284/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3745 - accuracy: 0.4935\n",
      "Epoch 285/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3748 - accuracy: 0.4949\n",
      "Epoch 286/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3743 - accuracy: 0.4945\n",
      "Epoch 287/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3740 - accuracy: 0.4950\n",
      "Epoch 288/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3732 - accuracy: 0.4932\n",
      "Epoch 289/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3731 - accuracy: 0.4941\n",
      "Epoch 290/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3721 - accuracy: 0.4928\n",
      "Epoch 291/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3713 - accuracy: 0.4941\n",
      "Epoch 292/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3722 - accuracy: 0.4941\n",
      "Epoch 293/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3721 - accuracy: 0.4956\n",
      "Epoch 294/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3716 - accuracy: 0.4953\n",
      "Epoch 295/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3710 - accuracy: 0.4947\n",
      "Epoch 296/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3706 - accuracy: 0.4970\n",
      "Epoch 297/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3702 - accuracy: 0.4957\n",
      "Epoch 298/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3700 - accuracy: 0.4974\n",
      "Epoch 299/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3697 - accuracy: 0.4962\n",
      "Epoch 300/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3692 - accuracy: 0.4972\n",
      "Epoch 301/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3693 - accuracy: 0.4974\n",
      "Epoch 302/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3684 - accuracy: 0.4972\n",
      "Epoch 303/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3680 - accuracy: 0.4991\n",
      "Epoch 304/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3683 - accuracy: 0.4994\n",
      "Epoch 305/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3680 - accuracy: 0.4983\n",
      "Epoch 306/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3671 - accuracy: 0.4993\n",
      "Epoch 307/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3675 - accuracy: 0.4984\n",
      "Epoch 308/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3673 - accuracy: 0.4991\n",
      "Epoch 309/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3661 - accuracy: 0.4976\n",
      "Epoch 310/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3661 - accuracy: 0.4972\n",
      "Epoch 311/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3658 - accuracy: 0.5000\n",
      "Epoch 312/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3656 - accuracy: 0.4993\n",
      "Epoch 313/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3647 - accuracy: 0.4995\n",
      "Epoch 314/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3651 - accuracy: 0.5004\n",
      "Epoch 315/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3644 - accuracy: 0.4985\n",
      "Epoch 316/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3646 - accuracy: 0.5002\n",
      "Epoch 317/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3637 - accuracy: 0.5002\n",
      "Epoch 318/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3641 - accuracy: 0.5010\n",
      "Epoch 319/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3637 - accuracy: 0.4998\n",
      "Epoch 320/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3634 - accuracy: 0.4989\n",
      "Epoch 321/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3628 - accuracy: 0.5018\n",
      "Epoch 322/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3623 - accuracy: 0.4990\n",
      "Epoch 323/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3625 - accuracy: 0.5013\n",
      "Epoch 324/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3623 - accuracy: 0.5005\n",
      "Epoch 325/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3620 - accuracy: 0.5006\n",
      "Epoch 326/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3621 - accuracy: 0.5025\n",
      "Epoch 327/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3622 - accuracy: 0.5016\n",
      "Epoch 328/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3609 - accuracy: 0.5014\n",
      "Epoch 329/600\n",
      "1947/1947 [==============================] - 6s 3ms/step - loss: 1.3611 - accuracy: 0.5004\n",
      "Epoch 330/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3615 - accuracy: 0.4997\n",
      "Epoch 331/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3609 - accuracy: 0.5030\n",
      "Epoch 332/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3607 - accuracy: 0.5007\n",
      "Epoch 333/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3602 - accuracy: 0.5028\n",
      "Epoch 334/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3601 - accuracy: 0.5036\n",
      "Epoch 335/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3599 - accuracy: 0.5007\n",
      "Epoch 336/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3598 - accuracy: 0.5019\n",
      "Epoch 337/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3594 - accuracy: 0.5024\n",
      "Epoch 338/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3594 - accuracy: 0.5030\n",
      "Epoch 339/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3588 - accuracy: 0.5027\n",
      "Epoch 340/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3585 - accuracy: 0.5025\n",
      "Epoch 341/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3583 - accuracy: 0.5012\n",
      "Epoch 342/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3580 - accuracy: 0.5038\n",
      "Epoch 343/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3580 - accuracy: 0.5033\n",
      "Epoch 344/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3577 - accuracy: 0.5047\n",
      "Epoch 345/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3579 - accuracy: 0.5031\n",
      "Epoch 346/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3581 - accuracy: 0.5030\n",
      "Epoch 347/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3577 - accuracy: 0.5047\n",
      "Epoch 348/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3576 - accuracy: 0.5042\n",
      "Epoch 349/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3569 - accuracy: 0.5035\n",
      "Epoch 350/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3568 - accuracy: 0.5033\n",
      "Epoch 351/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3567 - accuracy: 0.5027\n",
      "Epoch 352/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3566 - accuracy: 0.5017\n",
      "Epoch 353/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3568 - accuracy: 0.5039\n",
      "Epoch 354/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3562 - accuracy: 0.5055\n",
      "Epoch 355/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3563 - accuracy: 0.5058\n",
      "Epoch 356/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3561 - accuracy: 0.5039\n",
      "Epoch 357/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3561 - accuracy: 0.5028\n",
      "Epoch 358/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3554 - accuracy: 0.5036\n",
      "Epoch 359/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3551 - accuracy: 0.5054\n",
      "Epoch 360/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3547 - accuracy: 0.5062\n",
      "Epoch 361/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3554 - accuracy: 0.5060\n",
      "Epoch 362/600\n",
      "1947/1947 [==============================] - 11s 5ms/step - loss: 1.3549 - accuracy: 0.5065\n",
      "Epoch 363/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3549 - accuracy: 0.5045\n",
      "Epoch 364/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3542 - accuracy: 0.5051\n",
      "Epoch 365/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3544 - accuracy: 0.5048\n",
      "Epoch 366/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3548 - accuracy: 0.5057\n",
      "Epoch 367/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3550 - accuracy: 0.5037\n",
      "Epoch 368/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3540 - accuracy: 0.5060\n",
      "Epoch 369/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3534 - accuracy: 0.5040\n",
      "Epoch 370/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3544 - accuracy: 0.5047\n",
      "Epoch 371/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3540 - accuracy: 0.5047\n",
      "Epoch 372/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3535 - accuracy: 0.5052\n",
      "Epoch 373/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3535 - accuracy: 0.5047\n",
      "Epoch 374/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3532 - accuracy: 0.5064\n",
      "Epoch 375/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3530 - accuracy: 0.5068\n",
      "Epoch 376/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3526 - accuracy: 0.5055\n",
      "Epoch 377/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3525 - accuracy: 0.5058\n",
      "Epoch 378/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3527 - accuracy: 0.5043\n",
      "Epoch 379/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3532 - accuracy: 0.5049\n",
      "Epoch 380/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3523 - accuracy: 0.5067\n",
      "Epoch 381/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3522 - accuracy: 0.5055\n",
      "Epoch 382/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3521 - accuracy: 0.5054\n",
      "Epoch 383/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3522 - accuracy: 0.5063\n",
      "Epoch 384/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3520 - accuracy: 0.5078\n",
      "Epoch 385/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3510 - accuracy: 0.5065\n",
      "Epoch 386/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3517 - accuracy: 0.5060\n",
      "Epoch 387/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3515 - accuracy: 0.5071\n",
      "Epoch 388/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3507 - accuracy: 0.5077\n",
      "Epoch 389/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3506 - accuracy: 0.5082\n",
      "Epoch 390/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3505 - accuracy: 0.5061\n",
      "Epoch 391/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3508 - accuracy: 0.5052\n",
      "Epoch 392/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3504 - accuracy: 0.5072\n",
      "Epoch 393/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3508 - accuracy: 0.5062\n",
      "Epoch 394/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3504 - accuracy: 0.5063\n",
      "Epoch 395/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3501 - accuracy: 0.5051\n",
      "Epoch 396/600\n",
      "1947/1947 [==============================] - 7s 3ms/step - loss: 1.3495 - accuracy: 0.5046\n",
      "Epoch 397/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3499 - accuracy: 0.5082\n",
      "Epoch 398/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3497 - accuracy: 0.5063\n",
      "Epoch 399/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3495 - accuracy: 0.5073\n",
      "Epoch 400/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3494 - accuracy: 0.5067\n",
      "Epoch 401/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3491 - accuracy: 0.5080\n",
      "Epoch 402/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3490 - accuracy: 0.5067\n",
      "Epoch 403/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3481 - accuracy: 0.5057\n",
      "Epoch 404/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3484 - accuracy: 0.5052\n",
      "Epoch 405/600\n",
      "1947/1947 [==============================] - 14s 7ms/step - loss: 1.3475 - accuracy: 0.5088\n",
      "Epoch 406/600\n",
      "1947/1947 [==============================] - 14s 7ms/step - loss: 1.3475 - accuracy: 0.5074\n",
      "Epoch 407/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3467 - accuracy: 0.5085\n",
      "Epoch 408/600\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3469 - accuracy: 0.5078\n",
      "Epoch 409/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3475 - accuracy: 0.5066\n",
      "Epoch 410/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3477 - accuracy: 0.5093\n",
      "Epoch 411/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3468 - accuracy: 0.5059\n",
      "Epoch 412/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3460 - accuracy: 0.5078\n",
      "Epoch 413/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3465 - accuracy: 0.5095\n",
      "Epoch 414/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3464 - accuracy: 0.5065\n",
      "Epoch 415/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3466 - accuracy: 0.5065\n",
      "Epoch 416/600\n",
      "1947/1947 [==============================] - 11s 5ms/step - loss: 1.3462 - accuracy: 0.5069\n",
      "Epoch 417/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3457 - accuracy: 0.5090\n",
      "Epoch 418/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3446 - accuracy: 0.5067\n",
      "Epoch 419/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3455 - accuracy: 0.5051\n",
      "Epoch 420/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3448 - accuracy: 0.5086\n",
      "Epoch 421/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3451 - accuracy: 0.5085\n",
      "Epoch 422/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3444 - accuracy: 0.5095\n",
      "Epoch 423/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3445 - accuracy: 0.5087\n",
      "Epoch 424/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3446 - accuracy: 0.5051\n",
      "Epoch 425/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3439 - accuracy: 0.5084\n",
      "Epoch 426/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3441 - accuracy: 0.5077\n",
      "Epoch 427/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3434 - accuracy: 0.5082\n",
      "Epoch 428/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3435 - accuracy: 0.5084\n",
      "Epoch 429/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3438 - accuracy: 0.5084\n",
      "Epoch 430/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3439 - accuracy: 0.5087\n",
      "Epoch 431/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3436 - accuracy: 0.5071\n",
      "Epoch 432/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3422 - accuracy: 0.5091\n",
      "Epoch 433/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3430 - accuracy: 0.5087\n",
      "Epoch 434/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3437 - accuracy: 0.5080\n",
      "Epoch 435/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3423 - accuracy: 0.5104\n",
      "Epoch 436/600\n",
      "1947/1947 [==============================] - 13s 7ms/step - loss: 1.3419 - accuracy: 0.5076\n",
      "Epoch 437/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3417 - accuracy: 0.5094\n",
      "Epoch 438/600\n",
      "1947/1947 [==============================] - 11s 5ms/step - loss: 1.3425 - accuracy: 0.5089\n",
      "Epoch 439/600\n",
      "1947/1947 [==============================] - 12s 6ms/step - loss: 1.3417 - accuracy: 0.5089\n",
      "Epoch 440/600\n",
      "1947/1947 [==============================] - 11s 6ms/step - loss: 1.3419 - accuracy: 0.5098\n",
      "Epoch 441/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3407 - accuracy: 0.5084\n",
      "Epoch 442/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3418 - accuracy: 0.5099\n",
      "Epoch 443/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3410 - accuracy: 0.5103\n",
      "Epoch 444/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3407 - accuracy: 0.5088\n",
      "Epoch 445/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3406 - accuracy: 0.5080\n",
      "Epoch 446/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3414 - accuracy: 0.5085\n",
      "Epoch 447/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3404 - accuracy: 0.5091\n",
      "Epoch 448/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3406 - accuracy: 0.5105\n",
      "Epoch 449/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3405 - accuracy: 0.5084\n",
      "Epoch 450/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3399 - accuracy: 0.5095\n",
      "Epoch 451/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3401 - accuracy: 0.5093\n",
      "Epoch 452/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3396 - accuracy: 0.5100\n",
      "Epoch 453/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3392 - accuracy: 0.5092\n",
      "Epoch 454/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3389 - accuracy: 0.5111\n",
      "Epoch 455/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3389 - accuracy: 0.5103\n",
      "Epoch 456/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3394 - accuracy: 0.5102\n",
      "Epoch 457/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3392 - accuracy: 0.5110\n",
      "Epoch 458/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3384 - accuracy: 0.5110\n",
      "Epoch 459/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3393 - accuracy: 0.5104\n",
      "Epoch 460/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3382 - accuracy: 0.5101\n",
      "Epoch 461/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3382 - accuracy: 0.5102\n",
      "Epoch 462/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3383 - accuracy: 0.5102\n",
      "Epoch 463/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3380 - accuracy: 0.5106\n",
      "Epoch 464/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3375 - accuracy: 0.5099\n",
      "Epoch 465/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3370 - accuracy: 0.5100\n",
      "Epoch 466/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3373 - accuracy: 0.5095\n",
      "Epoch 467/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3369 - accuracy: 0.5120\n",
      "Epoch 468/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3373 - accuracy: 0.5109\n",
      "Epoch 469/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3370 - accuracy: 0.5095\n",
      "Epoch 470/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3367 - accuracy: 0.5090\n",
      "Epoch 471/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3365 - accuracy: 0.5115\n",
      "Epoch 472/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3358 - accuracy: 0.5092\n",
      "Epoch 473/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3363 - accuracy: 0.5115\n",
      "Epoch 474/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3363 - accuracy: 0.5142\n",
      "Epoch 475/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3358 - accuracy: 0.5115\n",
      "Epoch 476/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3362 - accuracy: 0.5127\n",
      "Epoch 477/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3354 - accuracy: 0.5124\n",
      "Epoch 478/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3350 - accuracy: 0.5125\n",
      "Epoch 479/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3352 - accuracy: 0.5102\n",
      "Epoch 480/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3353 - accuracy: 0.5089\n",
      "Epoch 481/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3351 - accuracy: 0.5116\n",
      "Epoch 482/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3355 - accuracy: 0.5123\n",
      "Epoch 483/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3349 - accuracy: 0.5111\n",
      "Epoch 484/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3348 - accuracy: 0.5107\n",
      "Epoch 485/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3337 - accuracy: 0.5131\n",
      "Epoch 486/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3339 - accuracy: 0.5124\n",
      "Epoch 487/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3344 - accuracy: 0.5118\n",
      "Epoch 488/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3346 - accuracy: 0.5115\n",
      "Epoch 489/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3343 - accuracy: 0.5107\n",
      "Epoch 490/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3335 - accuracy: 0.5120\n",
      "Epoch 491/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3334 - accuracy: 0.5125\n",
      "Epoch 492/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3335 - accuracy: 0.5132\n",
      "Epoch 493/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3337 - accuracy: 0.5120\n",
      "Epoch 494/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3333 - accuracy: 0.5097\n",
      "Epoch 495/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3328 - accuracy: 0.5128\n",
      "Epoch 496/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3337 - accuracy: 0.5121\n",
      "Epoch 497/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3327 - accuracy: 0.5123\n",
      "Epoch 498/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3333 - accuracy: 0.5122\n",
      "Epoch 499/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3326 - accuracy: 0.5117\n",
      "Epoch 500/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3324 - accuracy: 0.5136\n",
      "Epoch 501/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3322 - accuracy: 0.5120\n",
      "Epoch 502/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3325 - accuracy: 0.5130\n",
      "Epoch 503/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3322 - accuracy: 0.5105\n",
      "Epoch 504/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3325 - accuracy: 0.5113\n",
      "Epoch 505/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3319 - accuracy: 0.5122\n",
      "Epoch 506/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3320 - accuracy: 0.5125\n",
      "Epoch 507/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3319 - accuracy: 0.5131\n",
      "Epoch 508/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3320 - accuracy: 0.5130\n",
      "Epoch 509/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3315 - accuracy: 0.5122\n",
      "Epoch 510/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3313 - accuracy: 0.5142\n",
      "Epoch 511/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3312 - accuracy: 0.5137\n",
      "Epoch 512/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3310 - accuracy: 0.5107\n",
      "Epoch 513/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3315 - accuracy: 0.5134\n",
      "Epoch 514/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3312 - accuracy: 0.5115\n",
      "Epoch 515/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3315 - accuracy: 0.5126\n",
      "Epoch 516/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3306 - accuracy: 0.5131\n",
      "Epoch 517/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3308 - accuracy: 0.5119\n",
      "Epoch 518/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3311 - accuracy: 0.5128\n",
      "Epoch 519/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3306 - accuracy: 0.5118\n",
      "Epoch 520/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3303 - accuracy: 0.5127\n",
      "Epoch 521/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3309 - accuracy: 0.5130\n",
      "Epoch 522/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3303 - accuracy: 0.5127\n",
      "Epoch 523/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3301 - accuracy: 0.5137\n",
      "Epoch 524/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3296 - accuracy: 0.5133\n",
      "Epoch 525/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3297 - accuracy: 0.5139\n",
      "Epoch 526/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3298 - accuracy: 0.5122\n",
      "Epoch 527/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3294 - accuracy: 0.5132\n",
      "Epoch 528/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3300 - accuracy: 0.5126\n",
      "Epoch 529/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3297 - accuracy: 0.5134\n",
      "Epoch 530/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3299 - accuracy: 0.5137\n",
      "Epoch 531/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3290 - accuracy: 0.5148\n",
      "Epoch 532/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3294 - accuracy: 0.5133\n",
      "Epoch 533/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3294 - accuracy: 0.5125\n",
      "Epoch 534/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3294 - accuracy: 0.5142\n",
      "Epoch 535/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3283 - accuracy: 0.5134\n",
      "Epoch 536/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3291 - accuracy: 0.5134\n",
      "Epoch 537/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3289 - accuracy: 0.5153\n",
      "Epoch 538/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3281 - accuracy: 0.5130\n",
      "Epoch 539/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3285 - accuracy: 0.5138\n",
      "Epoch 540/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3284 - accuracy: 0.5140\n",
      "Epoch 541/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3283 - accuracy: 0.5135\n",
      "Epoch 542/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3283 - accuracy: 0.5139\n",
      "Epoch 543/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3278 - accuracy: 0.5145\n",
      "Epoch 544/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3285 - accuracy: 0.5147\n",
      "Epoch 545/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3282 - accuracy: 0.5146\n",
      "Epoch 546/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3273 - accuracy: 0.5139\n",
      "Epoch 547/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3275 - accuracy: 0.5136\n",
      "Epoch 548/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3276 - accuracy: 0.5132\n",
      "Epoch 549/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3274 - accuracy: 0.5122\n",
      "Epoch 550/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3277 - accuracy: 0.5148\n",
      "Epoch 551/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3269 - accuracy: 0.5155\n",
      "Epoch 552/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3267 - accuracy: 0.5146\n",
      "Epoch 553/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3268 - accuracy: 0.5163\n",
      "Epoch 554/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3265 - accuracy: 0.5146\n",
      "Epoch 555/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3269 - accuracy: 0.5145\n",
      "Epoch 556/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3259 - accuracy: 0.5146\n",
      "Epoch 557/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3266 - accuracy: 0.5157\n",
      "Epoch 558/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3259 - accuracy: 0.5142\n",
      "Epoch 559/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3267 - accuracy: 0.5145\n",
      "Epoch 560/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3258 - accuracy: 0.5146\n",
      "Epoch 561/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3264 - accuracy: 0.5156\n",
      "Epoch 562/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3257 - accuracy: 0.5139\n",
      "Epoch 563/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3250 - accuracy: 0.5139\n",
      "Epoch 564/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3260 - accuracy: 0.5154\n",
      "Epoch 565/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3253 - accuracy: 0.5160\n",
      "Epoch 566/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3251 - accuracy: 0.5138\n",
      "Epoch 567/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3247 - accuracy: 0.5149\n",
      "Epoch 568/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3244 - accuracy: 0.5140\n",
      "Epoch 569/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3250 - accuracy: 0.5151\n",
      "Epoch 570/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3252 - accuracy: 0.5155\n",
      "Epoch 571/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3243 - accuracy: 0.5150\n",
      "Epoch 572/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3245 - accuracy: 0.5147\n",
      "Epoch 573/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3245 - accuracy: 0.5169\n",
      "Epoch 574/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3245 - accuracy: 0.5152\n",
      "Epoch 575/600\n",
      "1947/1947 [==============================] - 10s 5ms/step - loss: 1.3238 - accuracy: 0.5156\n",
      "Epoch 576/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3233 - accuracy: 0.5165\n",
      "Epoch 577/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3241 - accuracy: 0.5150\n",
      "Epoch 578/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3238 - accuracy: 0.5157\n",
      "Epoch 579/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3236 - accuracy: 0.5155\n",
      "Epoch 580/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3241 - accuracy: 0.5157\n",
      "Epoch 581/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3238 - accuracy: 0.5157\n",
      "Epoch 582/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3224 - accuracy: 0.5174\n",
      "Epoch 583/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3227 - accuracy: 0.5152\n",
      "Epoch 584/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3234 - accuracy: 0.5149\n",
      "Epoch 585/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3236 - accuracy: 0.5168\n",
      "Epoch 586/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3228 - accuracy: 0.5167\n",
      "Epoch 587/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3231 - accuracy: 0.5159\n",
      "Epoch 588/600\n",
      "1947/1947 [==============================] - 9s 5ms/step - loss: 1.3226 - accuracy: 0.5170\n",
      "Epoch 589/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3228 - accuracy: 0.5161\n",
      "Epoch 590/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3218 - accuracy: 0.5157\n",
      "Epoch 591/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3218 - accuracy: 0.5151\n",
      "Epoch 592/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3214 - accuracy: 0.5180\n",
      "Epoch 593/600\n",
      "1947/1947 [==============================] - 7s 4ms/step - loss: 1.3219 - accuracy: 0.5166\n",
      "Epoch 594/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3221 - accuracy: 0.5170\n",
      "Epoch 595/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3213 - accuracy: 0.5172\n",
      "Epoch 596/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3217 - accuracy: 0.5168\n",
      "Epoch 597/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3216 - accuracy: 0.5165\n",
      "Epoch 598/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3216 - accuracy: 0.5164\n",
      "Epoch 599/600\n",
      "1947/1947 [==============================] - 8s 4ms/step - loss: 1.3206 - accuracy: 0.5172\n",
      "Epoch 600/600\n",
      "1947/1947 [==============================] - 9s 4ms/step - loss: 1.3214 - accuracy: 0.5160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;a&#x27;,\n",
       "                              &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FE20&gt;),\n",
       "                             (&#x27;b&#x27;,\n",
       "                              &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFD0&gt;),\n",
       "                             (&#x27;c&#x27;,\n",
       "                              &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFA0&gt;)],\n",
       "                 weights=[0.37, 0.33, 0.3])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;a&#x27;,\n",
       "                              &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FE20&gt;),\n",
       "                             (&#x27;b&#x27;,\n",
       "                              &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFD0&gt;),\n",
       "                             (&#x27;c&#x27;,\n",
       "                              &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFA0&gt;)],\n",
       "                 weights=[0.37, 0.33, 0.3])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>a</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FE20&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>b</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFD0&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>c</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFA0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('a',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FE20>),\n",
       "                             ('b',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFD0>),\n",
       "                             ('c',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000028F73A5FFA0>)],\n",
       "                 weights=[0.37, 0.33, 0.3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf0e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "300/300 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5303994159974972"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e656c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "300/300 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 6, 7], dtype=int64),\n",
       " array([4502, 2619,  134,    1,   81, 2252], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ens.predict(X_test), return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
